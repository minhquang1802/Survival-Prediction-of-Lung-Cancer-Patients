
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-04-06 13:56:31.242800: Using torch.compile... 
2025-04-06 13:56:31.246964: do_dummy_2d_data_aug: False 
2025-04-06 13:56:31.247737: Using splits from existing split file: /mrhung_nguyen_minh_quang_108/workspace/train/nnUNet_preprocessed/Dataset015_lungTumor/splits_final.json 
2025-04-06 13:56:31.248481: The split file contains 5 splits. 
2025-04-06 13:56:31.248657: Desired fold for training: 4 
2025-04-06 13:56:31.248694: This split has 92 training and 23 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [251.0, 512.0, 512.0], 'spacing': [1.25, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset015_lungTumor', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [1.25, 0.78125, 0.78125], 'original_median_shape_after_transp': [251, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2750.0, 'mean': -292.26348876953125, 'median': -205.0, 'min': -1270.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 308.0, 'std': 352.5594787597656}}} 
 
2025-04-06 13:56:34.530021: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-04-06 13:56:34.581971:  
2025-04-06 13:56:34.582199: Epoch 0 
2025-04-06 13:56:34.582416: Current learning rate: 0.01 
2025-04-06 14:01:26.672118: train_loss 0.0695 
2025-04-06 14:01:26.672518: val_loss -0.0734 
2025-04-06 14:01:26.672601: Pseudo dice [0.0] 
2025-04-06 14:01:26.672679: Epoch time: 292.09 s 
2025-04-06 14:01:26.672735: Yayy! New best EMA pseudo Dice: 0.0 
2025-04-06 14:01:33.536355:  
2025-04-06 14:01:33.536583: Epoch 1 
2025-04-06 14:01:33.536707: Current learning rate: 0.00999 
2025-04-06 14:06:09.817389: train_loss -0.1081 
2025-04-06 14:06:09.817863: val_loss -0.3028 
2025-04-06 14:06:09.817939: Pseudo dice [0.353] 
2025-04-06 14:06:09.818079: Epoch time: 276.28 s 
2025-04-06 14:06:09.818176: Yayy! New best EMA pseudo Dice: 0.0353 
2025-04-06 14:06:16.445632:  
2025-04-06 14:06:16.445898: Epoch 2 
2025-04-06 14:06:16.446034: Current learning rate: 0.00998 
2025-04-06 14:10:52.762202: train_loss -0.2511 
2025-04-06 14:10:52.763002: val_loss -0.3418 
2025-04-06 14:10:52.763085: Pseudo dice [0.4144] 
2025-04-06 14:10:52.763167: Epoch time: 276.32 s 
2025-04-06 14:10:52.763225: Yayy! New best EMA pseudo Dice: 0.0732 
2025-04-06 14:10:58.841625:  
2025-04-06 14:10:58.841807: Epoch 3 
2025-04-06 14:10:58.841934: Current learning rate: 0.00997 
2025-04-06 14:15:34.196437: train_loss -0.3726 
2025-04-06 14:15:34.196953: val_loss -0.5736 
2025-04-06 14:15:34.197068: Pseudo dice [0.6387] 
2025-04-06 14:15:34.197152: Epoch time: 275.36 s 
2025-04-06 14:15:34.197214: Yayy! New best EMA pseudo Dice: 0.1298 
2025-04-06 14:15:40.862832:  
2025-04-06 14:15:40.863039: Epoch 4 
2025-04-06 14:15:40.863155: Current learning rate: 0.00996 
2025-04-06 14:20:16.099308: train_loss -0.4257 
2025-04-06 14:20:16.100205: val_loss -0.5712 
2025-04-06 14:20:16.100310: Pseudo dice [0.6321] 
2025-04-06 14:20:16.100417: Epoch time: 275.24 s 
2025-04-06 14:20:16.100478: Yayy! New best EMA pseudo Dice: 0.18 
2025-04-06 14:20:22.499678:  
2025-04-06 14:20:22.499959: Epoch 5 
2025-04-06 14:20:22.500073: Current learning rate: 0.00995 
2025-04-06 14:24:57.438441: train_loss -0.4326 
2025-04-06 14:24:57.438753: val_loss -0.5125 
2025-04-06 14:24:57.438846: Pseudo dice [0.5634] 
2025-04-06 14:24:57.439066: Epoch time: 274.94 s 
2025-04-06 14:24:57.439127: Yayy! New best EMA pseudo Dice: 0.2183 
2025-04-06 14:25:02.045691:  
2025-04-06 14:25:02.045966: Epoch 6 
2025-04-06 14:25:02.046132: Current learning rate: 0.00995 
2025-04-06 14:29:36.771230: train_loss -0.4997 
2025-04-06 14:29:36.771783: val_loss -0.635 
2025-04-06 14:29:36.771915: Pseudo dice [0.6881] 
2025-04-06 14:29:36.772007: Epoch time: 274.73 s 
2025-04-06 14:29:36.772094: Yayy! New best EMA pseudo Dice: 0.2653 
2025-04-06 14:29:40.734280:  
2025-04-06 14:29:40.734495: Epoch 7 
2025-04-06 14:29:40.734608: Current learning rate: 0.00994 
2025-04-06 14:34:15.414981: train_loss -0.5378 
2025-04-06 14:34:15.415318: val_loss -0.6125 
2025-04-06 14:34:15.415405: Pseudo dice [0.6751] 
2025-04-06 14:34:15.415503: Epoch time: 274.68 s 
2025-04-06 14:34:15.415565: Yayy! New best EMA pseudo Dice: 0.3063 
2025-04-06 14:34:18.653883:  
2025-04-06 14:34:18.654142: Epoch 8 
2025-04-06 14:34:18.654280: Current learning rate: 0.00993 
2025-04-06 14:38:53.816146: train_loss -0.5091 
2025-04-06 14:38:53.816712: val_loss -0.6323 
2025-04-06 14:38:53.816838: Pseudo dice [0.7346] 
2025-04-06 14:38:53.816922: Epoch time: 275.17 s 
2025-04-06 14:38:53.816980: Yayy! New best EMA pseudo Dice: 0.3491 
2025-04-06 14:38:57.013628:  
2025-04-06 14:38:57.013837: Epoch 9 
2025-04-06 14:38:57.013950: Current learning rate: 0.00992 
2025-04-06 14:43:32.008206: train_loss -0.5468 
2025-04-06 14:43:32.008569: val_loss -0.6512 
2025-04-06 14:43:32.008660: Pseudo dice [0.7181] 
2025-04-06 14:43:32.008752: Epoch time: 275.0 s 
2025-04-06 14:43:32.008810: Yayy! New best EMA pseudo Dice: 0.386 
2025-04-06 14:43:35.124459:  
2025-04-06 14:43:35.124663: Epoch 10 
2025-04-06 14:43:35.124781: Current learning rate: 0.00991 
2025-04-06 14:48:10.267476: train_loss -0.5522 
2025-04-06 14:48:10.268014: val_loss -0.644 
2025-04-06 14:48:10.268131: Pseudo dice [0.723] 
2025-04-06 14:48:10.268217: Epoch time: 275.15 s 
2025-04-06 14:48:10.268273: Yayy! New best EMA pseudo Dice: 0.4197 
2025-04-06 14:48:13.384797:  
2025-04-06 14:48:13.385068: Epoch 11 
2025-04-06 14:48:13.385207: Current learning rate: 0.0099 
2025-04-06 14:52:48.390596: train_loss -0.562 
2025-04-06 14:52:48.390943: val_loss -0.6608 
2025-04-06 14:52:48.391025: Pseudo dice [0.6993] 
2025-04-06 14:52:48.391124: Epoch time: 275.01 s 
2025-04-06 14:52:48.391208: Yayy! New best EMA pseudo Dice: 0.4477 
2025-04-06 14:52:51.477412:  
2025-04-06 14:52:51.477664: Epoch 12 
2025-04-06 14:52:51.477798: Current learning rate: 0.00989 
2025-04-06 14:57:26.105281: train_loss -0.574 
2025-04-06 14:57:26.105595: val_loss -0.5537 
2025-04-06 14:57:26.105691: Pseudo dice [0.6892] 
2025-04-06 14:57:26.105783: Epoch time: 274.63 s 
2025-04-06 14:57:26.105860: Yayy! New best EMA pseudo Dice: 0.4718 
2025-04-06 14:57:29.273546:  
2025-04-06 14:57:29.273735: Epoch 13 
2025-04-06 14:57:29.273893: Current learning rate: 0.00988 
2025-04-06 15:02:04.261236: train_loss -0.5675 
2025-04-06 15:02:04.261535: val_loss -0.6233 
2025-04-06 15:02:04.261634: Pseudo dice [0.7208] 
2025-04-06 15:02:04.261802: Epoch time: 274.99 s 
2025-04-06 15:02:04.261861: Yayy! New best EMA pseudo Dice: 0.4967 
2025-04-06 15:02:07.431652:  
2025-04-06 15:02:07.431916: Epoch 14 
2025-04-06 15:02:07.432040: Current learning rate: 0.00987 
2025-04-06 15:06:42.255084: train_loss -0.5972 
2025-04-06 15:06:42.255387: val_loss -0.6432 
2025-04-06 15:06:42.255471: Pseudo dice [0.7148] 
2025-04-06 15:06:42.255553: Epoch time: 274.83 s 
2025-04-06 15:06:42.255629: Yayy! New best EMA pseudo Dice: 0.5185 
2025-04-06 15:06:45.447667:  
2025-04-06 15:06:45.447896: Epoch 15 
2025-04-06 15:06:45.448012: Current learning rate: 0.00986 
2025-04-06 15:11:20.228009: train_loss -0.5773 
2025-04-06 15:11:20.228367: val_loss -0.6977 
2025-04-06 15:11:20.228502: Pseudo dice [0.7482] 
2025-04-06 15:11:20.228601: Epoch time: 274.78 s 
2025-04-06 15:11:20.228663: Yayy! New best EMA pseudo Dice: 0.5415 
2025-04-06 15:11:23.424374:  
2025-04-06 15:11:23.424613: Epoch 16 
2025-04-06 15:11:23.424785: Current learning rate: 0.00986 
2025-04-06 15:15:58.911674: train_loss -0.5838 
2025-04-06 15:15:58.911991: val_loss -0.7198 
2025-04-06 15:15:58.912076: Pseudo dice [0.7576] 
2025-04-06 15:15:58.912162: Epoch time: 275.49 s 
2025-04-06 15:15:58.912229: Yayy! New best EMA pseudo Dice: 0.5631 
2025-04-06 15:16:02.137313:  
2025-04-06 15:16:02.137470: Epoch 17 
2025-04-06 15:16:02.137617: Current learning rate: 0.00985 
2025-04-06 15:20:36.863899: train_loss -0.5981 
2025-04-06 15:20:36.864251: val_loss -0.6585 
2025-04-06 15:20:36.864344: Pseudo dice [0.7034] 
2025-04-06 15:20:36.864446: Epoch time: 274.73 s 
2025-04-06 15:20:36.864501: Yayy! New best EMA pseudo Dice: 0.5771 
2025-04-06 15:20:40.059821:  
2025-04-06 15:20:40.060072: Epoch 18 
2025-04-06 15:20:40.060211: Current learning rate: 0.00984 
2025-04-06 15:25:15.120175: train_loss -0.587 
2025-04-06 15:25:15.120726: val_loss -0.6793 
2025-04-06 15:25:15.120828: Pseudo dice [0.7306] 
2025-04-06 15:25:15.120914: Epoch time: 275.06 s 
2025-04-06 15:25:15.120970: Yayy! New best EMA pseudo Dice: 0.5925 
2025-04-06 15:25:18.348660:  
2025-04-06 15:25:18.348914: Epoch 19 
2025-04-06 15:25:18.349036: Current learning rate: 0.00983 
2025-04-06 15:29:53.169040: train_loss -0.5684 
2025-04-06 15:29:53.169381: val_loss -0.6698 
2025-04-06 15:29:53.169467: Pseudo dice [0.7121] 
2025-04-06 15:29:53.169566: Epoch time: 274.82 s 
2025-04-06 15:29:53.169622: Yayy! New best EMA pseudo Dice: 0.6044 
2025-04-06 15:29:56.360269:  
2025-04-06 15:29:56.360477: Epoch 20 
2025-04-06 15:29:56.360590: Current learning rate: 0.00982 
2025-04-06 15:34:31.131074: train_loss -0.577 
2025-04-06 15:34:31.131420: val_loss -0.6403 
2025-04-06 15:34:31.131499: Pseudo dice [0.7393] 
2025-04-06 15:34:31.131593: Epoch time: 274.77 s 
2025-04-06 15:34:31.131649: Yayy! New best EMA pseudo Dice: 0.6179 
2025-04-06 15:34:34.637269:  
2025-04-06 15:34:34.637431: Epoch 21 
2025-04-06 15:34:34.637568: Current learning rate: 0.00981 
2025-04-06 15:39:09.417239: train_loss -0.6019 
2025-04-06 15:39:09.417577: val_loss -0.6548 
2025-04-06 15:39:09.417663: Pseudo dice [0.7397] 
2025-04-06 15:39:09.417760: Epoch time: 274.78 s 
2025-04-06 15:39:09.417816: Yayy! New best EMA pseudo Dice: 0.6301 
2025-04-06 15:39:12.563864:  
2025-04-06 15:39:12.564152: Epoch 22 
2025-04-06 15:39:12.564296: Current learning rate: 0.0098 
2025-04-06 15:43:47.248237: train_loss -0.6144 
2025-04-06 15:43:47.248550: val_loss -0.681 
2025-04-06 15:43:47.248629: Pseudo dice [0.7506] 
2025-04-06 15:43:47.248717: Epoch time: 274.69 s 
2025-04-06 15:43:47.248834: Yayy! New best EMA pseudo Dice: 0.6421 
2025-04-06 15:43:50.395225:  
2025-04-06 15:43:50.395444: Epoch 23 
2025-04-06 15:43:50.395576: Current learning rate: 0.00979 
2025-04-06 15:48:25.360458: train_loss -0.6201 
2025-04-06 15:48:25.360764: val_loss -0.6725 
2025-04-06 15:48:25.360852: Pseudo dice [0.7501] 
2025-04-06 15:48:25.360940: Epoch time: 274.97 s 
2025-04-06 15:48:25.361008: Yayy! New best EMA pseudo Dice: 0.6529 
2025-04-06 15:48:28.501619:  
2025-04-06 15:48:28.501838: Epoch 24 
2025-04-06 15:48:28.502024: Current learning rate: 0.00978 
2025-04-06 15:53:02.699878: train_loss -0.5959 
2025-04-06 15:53:02.700188: val_loss -0.6448 
2025-04-06 15:53:02.700275: Pseudo dice [0.7447] 
2025-04-06 15:53:02.700373: Epoch time: 274.2 s 
2025-04-06 15:53:02.700429: Yayy! New best EMA pseudo Dice: 0.6621 
2025-04-06 15:53:05.839743:  
2025-04-06 15:53:05.840114: Epoch 25 
2025-04-06 15:53:05.840251: Current learning rate: 0.00977 
2025-04-06 15:57:40.058655: train_loss -0.5819 
2025-04-06 15:57:40.058946: val_loss -0.6764 
2025-04-06 15:57:40.059030: Pseudo dice [0.645] 
2025-04-06 15:57:40.059112: Epoch time: 274.22 s 
2025-04-06 15:57:41.877378:  
2025-04-06 15:57:41.877618: Epoch 26 
2025-04-06 15:57:41.877782: Current learning rate: 0.00977 
2025-04-06 16:02:16.461744: train_loss -0.6325 
2025-04-06 16:02:16.462077: val_loss -0.7095 
2025-04-06 16:02:16.462207: Pseudo dice [0.772] 
2025-04-06 16:02:16.462303: Epoch time: 274.59 s 
2025-04-06 16:02:16.462363: Yayy! New best EMA pseudo Dice: 0.6716 
2025-04-06 16:02:19.606936:  
2025-04-06 16:02:19.607143: Epoch 27 
2025-04-06 16:02:19.607317: Current learning rate: 0.00976 
2025-04-06 16:06:54.158310: train_loss -0.6155 
2025-04-06 16:06:54.158626: val_loss -0.652 
2025-04-06 16:06:54.158726: Pseudo dice [0.6921] 
2025-04-06 16:06:54.158814: Epoch time: 274.56 s 
2025-04-06 16:06:54.158882: Yayy! New best EMA pseudo Dice: 0.6736 
2025-04-06 16:06:57.340810:  
2025-04-06 16:06:57.341050: Epoch 28 
2025-04-06 16:06:57.341180: Current learning rate: 0.00975 
2025-04-06 16:11:31.574768: train_loss -0.6592 
2025-04-06 16:11:31.575089: val_loss -0.7508 
2025-04-06 16:11:31.575185: Pseudo dice [0.7839] 
2025-04-06 16:11:31.575266: Epoch time: 274.24 s 
2025-04-06 16:11:31.575335: Yayy! New best EMA pseudo Dice: 0.6846 
2025-04-06 16:11:34.973949:  
2025-04-06 16:11:34.974160: Epoch 29 
2025-04-06 16:11:34.974276: Current learning rate: 0.00974 
2025-04-06 16:16:09.368081: train_loss -0.6448 
2025-04-06 16:16:09.368429: val_loss -0.7185 
2025-04-06 16:16:09.368536: Pseudo dice [0.7719] 
2025-04-06 16:16:09.368634: Epoch time: 274.4 s 
2025-04-06 16:16:09.368689: Yayy! New best EMA pseudo Dice: 0.6934 
2025-04-06 16:16:12.524825:  
2025-04-06 16:16:12.525067: Epoch 30 
2025-04-06 16:16:12.525238: Current learning rate: 0.00973 
2025-04-06 16:20:46.627775: train_loss -0.6338 
2025-04-06 16:20:46.628079: val_loss -0.6582 
2025-04-06 16:20:46.628177: Pseudo dice [0.586] 
2025-04-06 16:20:46.628283: Epoch time: 274.11 s 
2025-04-06 16:20:48.453279:  
2025-04-06 16:20:48.453497: Epoch 31 
2025-04-06 16:20:48.453615: Current learning rate: 0.00972 
2025-04-06 16:25:22.504510: train_loss -0.6769 
2025-04-06 16:25:22.504812: val_loss -0.7471 
2025-04-06 16:25:22.504893: Pseudo dice [0.7921] 
2025-04-06 16:25:22.504981: Epoch time: 274.06 s 
2025-04-06 16:25:22.505054: Yayy! New best EMA pseudo Dice: 0.6936 
2025-04-06 16:25:25.679645:  
2025-04-06 16:25:25.679851: Epoch 32 
2025-04-06 16:25:25.679966: Current learning rate: 0.00971 
2025-04-06 16:29:59.831651: train_loss -0.6425 
2025-04-06 16:29:59.832120: val_loss -0.7218 
2025-04-06 16:29:59.832248: Pseudo dice [0.7434] 
2025-04-06 16:29:59.832373: Epoch time: 274.16 s 
2025-04-06 16:29:59.832462: Yayy! New best EMA pseudo Dice: 0.6986 
2025-04-06 16:30:03.074594:  
2025-04-06 16:30:03.074847: Epoch 33 
2025-04-06 16:30:03.074958: Current learning rate: 0.0097 
2025-04-06 16:34:37.552971: train_loss -0.616 
2025-04-06 16:34:37.553285: val_loss -0.6874 
2025-04-06 16:34:37.553394: Pseudo dice [0.7117] 
2025-04-06 16:34:37.553491: Epoch time: 274.48 s 
2025-04-06 16:34:37.553555: Yayy! New best EMA pseudo Dice: 0.6999 
2025-04-06 16:34:40.733197:  
2025-04-06 16:34:40.733418: Epoch 34 
2025-04-06 16:34:40.733529: Current learning rate: 0.00969 
2025-04-06 16:39:15.127629: train_loss -0.6488 
2025-04-06 16:39:15.128013: val_loss -0.6703 
2025-04-06 16:39:15.128100: Pseudo dice [0.7327] 
2025-04-06 16:39:15.128193: Epoch time: 274.4 s 
2025-04-06 16:39:15.128268: Yayy! New best EMA pseudo Dice: 0.7031 
2025-04-06 16:39:18.347924:  
2025-04-06 16:39:18.348130: Epoch 35 
2025-04-06 16:39:18.348274: Current learning rate: 0.00968 
2025-04-06 16:43:52.982175: train_loss -0.62 
2025-04-06 16:43:52.982491: val_loss -0.6932 
2025-04-06 16:43:52.982597: Pseudo dice [0.7543] 
2025-04-06 16:43:52.982695: Epoch time: 274.64 s 
2025-04-06 16:43:52.982757: Yayy! New best EMA pseudo Dice: 0.7083 
2025-04-06 16:43:56.421449:  
2025-04-06 16:43:56.421651: Epoch 36 
2025-04-06 16:43:56.421813: Current learning rate: 0.00968 
2025-04-06 16:48:30.873884: train_loss -0.664 
2025-04-06 16:48:30.874253: val_loss -0.7325 
2025-04-06 16:48:30.874341: Pseudo dice [0.7857] 
2025-04-06 16:48:30.874434: Epoch time: 274.46 s 
2025-04-06 16:48:30.874488: Yayy! New best EMA pseudo Dice: 0.716 
2025-04-06 16:48:34.037553:  
2025-04-06 16:48:34.037792: Epoch 37 
2025-04-06 16:48:34.037917: Current learning rate: 0.00967 
2025-04-06 16:53:08.315432: train_loss -0.671 
2025-04-06 16:53:08.315831: val_loss -0.7252 
2025-04-06 16:53:08.315967: Pseudo dice [0.795] 
2025-04-06 16:53:08.316056: Epoch time: 274.28 s 
2025-04-06 16:53:08.316115: Yayy! New best EMA pseudo Dice: 0.7239 
2025-04-06 16:53:11.538582:  
2025-04-06 16:53:11.538762: Epoch 38 
2025-04-06 16:53:11.538906: Current learning rate: 0.00966 
2025-04-06 16:57:45.543511: train_loss -0.7084 
2025-04-06 16:57:45.543843: val_loss -0.7251 
2025-04-06 16:57:45.543936: Pseudo dice [0.7399] 
2025-04-06 16:57:45.544025: Epoch time: 274.01 s 
2025-04-06 16:57:45.544093: Yayy! New best EMA pseudo Dice: 0.7255 
2025-04-06 16:57:48.732744:  
2025-04-06 16:57:48.732966: Epoch 39 
2025-04-06 16:57:48.733119: Current learning rate: 0.00965 
2025-04-06 17:02:23.421193: train_loss -0.6515 
2025-04-06 17:02:23.421522: val_loss -0.6893 
2025-04-06 17:02:23.423592: Pseudo dice [0.7907] 
2025-04-06 17:02:23.423677: Epoch time: 274.69 s 
2025-04-06 17:02:23.423733: Yayy! New best EMA pseudo Dice: 0.732 
2025-04-06 17:02:26.646734:  
2025-04-06 17:02:26.646922: Epoch 40 
2025-04-06 17:02:26.647041: Current learning rate: 0.00964 
2025-04-06 17:07:01.018182: train_loss -0.6726 
2025-04-06 17:07:01.018545: val_loss -0.6823 
2025-04-06 17:07:01.018667: Pseudo dice [0.7507] 
2025-04-06 17:07:01.018770: Epoch time: 274.38 s 
2025-04-06 17:07:01.018830: Yayy! New best EMA pseudo Dice: 0.7339 
2025-04-06 17:07:04.203271:  
2025-04-06 17:07:04.203492: Epoch 41 
2025-04-06 17:07:04.203683: Current learning rate: 0.00963 
2025-04-06 17:11:38.393236: train_loss -0.6915 
2025-04-06 17:11:38.393563: val_loss -0.7471 
2025-04-06 17:11:38.393714: Pseudo dice [0.7965] 
2025-04-06 17:11:38.393881: Epoch time: 274.19 s 
2025-04-06 17:11:38.393946: Yayy! New best EMA pseudo Dice: 0.7401 
2025-04-06 17:11:41.538370:  
2025-04-06 17:11:41.538646: Epoch 42 
2025-04-06 17:11:41.538770: Current learning rate: 0.00962 
2025-04-06 17:16:15.866545: train_loss -0.6893 
2025-04-06 17:16:15.866845: val_loss -0.7371 
2025-04-06 17:16:15.866925: Pseudo dice [0.7845] 
2025-04-06 17:16:15.867011: Epoch time: 274.33 s 
2025-04-06 17:16:15.867135: Yayy! New best EMA pseudo Dice: 0.7446 
2025-04-06 17:16:19.259641:  
2025-04-06 17:16:19.259860: Epoch 43 
2025-04-06 17:16:19.259987: Current learning rate: 0.00961 
2025-04-06 17:20:53.958952: train_loss -0.6596 
2025-04-06 17:20:53.959269: val_loss -0.7592 
2025-04-06 17:20:53.959358: Pseudo dice [0.7981] 
2025-04-06 17:20:53.959447: Epoch time: 274.7 s 
2025-04-06 17:20:53.959520: Yayy! New best EMA pseudo Dice: 0.7499 
2025-04-06 17:20:57.134083:  
2025-04-06 17:20:57.134302: Epoch 44 
2025-04-06 17:20:57.134415: Current learning rate: 0.0096 
2025-04-06 17:25:31.945862: train_loss -0.6557 
2025-04-06 17:25:31.946238: val_loss -0.697 
2025-04-06 17:25:31.946331: Pseudo dice [0.7547] 
2025-04-06 17:25:31.946442: Epoch time: 274.82 s 
2025-04-06 17:25:31.946498: Yayy! New best EMA pseudo Dice: 0.7504 
2025-04-06 17:25:35.086666:  
2025-04-06 17:25:35.086907: Epoch 45 
2025-04-06 17:25:35.087067: Current learning rate: 0.00959 
2025-04-06 17:30:09.833478: train_loss -0.6944 
2025-04-06 17:30:09.833807: val_loss -0.7186 
2025-04-06 17:30:09.833904: Pseudo dice [0.774] 
2025-04-06 17:30:09.834001: Epoch time: 274.75 s 
2025-04-06 17:30:09.834056: Yayy! New best EMA pseudo Dice: 0.7528 
2025-04-06 17:30:12.982998:  
2025-04-06 17:30:12.983242: Epoch 46 
2025-04-06 17:30:12.983387: Current learning rate: 0.00959 
2025-04-06 17:34:47.805790: train_loss -0.6692 
2025-04-06 17:34:47.806100: val_loss -0.7083 
2025-04-06 17:34:47.806180: Pseudo dice [0.7214] 
2025-04-06 17:34:47.806262: Epoch time: 274.83 s 
2025-04-06 17:34:49.592363:  
2025-04-06 17:34:49.592558: Epoch 47 
2025-04-06 17:34:49.592684: Current learning rate: 0.00958 
2025-04-06 17:39:24.304888: train_loss -0.645 
2025-04-06 17:39:24.305199: val_loss -0.7249 
2025-04-06 17:39:24.305286: Pseudo dice [0.7756] 
2025-04-06 17:39:24.305374: Epoch time: 274.72 s 
2025-04-06 17:39:26.075839:  
2025-04-06 17:39:26.076152: Epoch 48 
2025-04-06 17:39:26.076265: Current learning rate: 0.00957 
2025-04-06 17:44:00.785479: train_loss -0.6806 
2025-04-06 17:44:00.785779: val_loss -0.7272 
2025-04-06 17:44:00.785871: Pseudo dice [0.7554] 
2025-04-06 17:44:00.785952: Epoch time: 274.71 s 
2025-04-06 17:44:02.595984:  
2025-04-06 17:44:02.596209: Epoch 49 
2025-04-06 17:44:02.596324: Current learning rate: 0.00956 
2025-04-06 17:48:37.114173: train_loss -0.7135 
2025-04-06 17:48:37.114503: val_loss -0.7391 
2025-04-06 17:48:37.114591: Pseudo dice [0.7957] 
2025-04-06 17:48:37.114700: Epoch time: 274.52 s 
2025-04-06 17:48:39.250091: Yayy! New best EMA pseudo Dice: 0.7569 
2025-04-06 17:48:42.941663:  
2025-04-06 17:48:42.941898: Epoch 50 
2025-04-06 17:48:42.942026: Current learning rate: 0.00955 
2025-04-06 17:53:17.640390: train_loss -0.6509 
2025-04-06 17:53:17.640749: val_loss -0.6958 
2025-04-06 17:53:17.640841: Pseudo dice [0.7534] 
2025-04-06 17:53:17.640936: Epoch time: 274.7 s 
2025-04-06 17:53:19.448599:  
2025-04-06 17:53:19.448789: Epoch 51 
2025-04-06 17:53:19.448905: Current learning rate: 0.00954 
2025-04-06 17:57:54.077102: train_loss -0.6909 
2025-04-06 17:57:54.077461: val_loss -0.675 
2025-04-06 17:57:54.077559: Pseudo dice [0.735] 
2025-04-06 17:57:54.077700: Epoch time: 274.63 s 
2025-04-06 17:57:55.895658:  
2025-04-06 17:57:55.895897: Epoch 52 
2025-04-06 17:57:55.896059: Current learning rate: 0.00953 
2025-04-06 18:02:30.032437: train_loss -0.7054 
2025-04-06 18:02:30.033221: val_loss -0.6985 
2025-04-06 18:02:30.033330: Pseudo dice [0.7427] 
2025-04-06 18:02:30.033414: Epoch time: 274.14 s 
2025-04-06 18:02:31.856035:  
2025-04-06 18:02:31.856325: Epoch 53 
2025-04-06 18:02:31.856442: Current learning rate: 0.00952 
2025-04-06 18:07:06.258936: train_loss -0.6714 
2025-04-06 18:07:06.259261: val_loss -0.7478 
2025-04-06 18:07:06.259345: Pseudo dice [0.7868] 
2025-04-06 18:07:06.259447: Epoch time: 274.41 s 
2025-04-06 18:07:08.083143:  
2025-04-06 18:07:08.083370: Epoch 54 
2025-04-06 18:07:08.083553: Current learning rate: 0.00951 
2025-04-06 18:11:42.622072: train_loss -0.6962 
2025-04-06 18:11:42.622435: val_loss -0.7347 
2025-04-06 18:11:42.622534: Pseudo dice [0.7979] 
2025-04-06 18:11:42.622634: Epoch time: 274.54 s 
2025-04-06 18:11:42.622693: Yayy! New best EMA pseudo Dice: 0.7607 
2025-04-06 18:11:45.771807:  
2025-04-06 18:11:45.772112: Epoch 55 
2025-04-06 18:11:45.772276: Current learning rate: 0.0095 
2025-04-06 18:16:20.378385: train_loss -0.6883 
2025-04-06 18:16:20.378690: val_loss -0.7221 
2025-04-06 18:16:20.378770: Pseudo dice [0.7639] 
2025-04-06 18:16:20.378857: Epoch time: 274.61 s 
2025-04-06 18:16:20.378923: Yayy! New best EMA pseudo Dice: 0.761 
2025-04-06 18:16:23.625191:  
2025-04-06 18:16:23.625444: Epoch 56 
2025-04-06 18:16:23.625636: Current learning rate: 0.00949 
2025-04-06 18:20:56.937762: train_loss -0.6811 
2025-04-06 18:20:56.938076: val_loss -0.7461 
2025-04-06 18:20:56.938160: Pseudo dice [0.7812] 
2025-04-06 18:20:56.938244: Epoch time: 273.32 s 
2025-04-06 18:20:56.938310: Yayy! New best EMA pseudo Dice: 0.763 
2025-04-06 18:21:00.099779:  
2025-04-06 18:21:00.099977: Epoch 57 
2025-04-06 18:21:00.100104: Current learning rate: 0.00949 
2025-04-06 18:25:33.822408: train_loss -0.6697 
2025-04-06 18:25:33.822811: val_loss -0.7343 
2025-04-06 18:25:33.823276: Pseudo dice [0.7521] 
2025-04-06 18:25:33.823435: Epoch time: 273.73 s 
2025-04-06 18:25:35.942205:  
2025-04-06 18:25:35.942411: Epoch 58 
2025-04-06 18:25:35.942558: Current learning rate: 0.00948 
2025-04-06 18:30:09.791380: train_loss -0.7022 
2025-04-06 18:30:09.791791: val_loss -0.7278 
2025-04-06 18:30:09.791892: Pseudo dice [0.7911] 
2025-04-06 18:30:09.792005: Epoch time: 273.85 s 
2025-04-06 18:30:09.792075: Yayy! New best EMA pseudo Dice: 0.7649 
2025-04-06 18:30:12.976047:  
2025-04-06 18:30:12.976257: Epoch 59 
2025-04-06 18:30:12.976375: Current learning rate: 0.00947 
2025-04-06 18:34:46.601969: train_loss -0.6916 
2025-04-06 18:34:46.602289: val_loss -0.7069 
2025-04-06 18:34:46.602378: Pseudo dice [0.7475] 
2025-04-06 18:34:46.602475: Epoch time: 273.63 s 
2025-04-06 18:34:48.447408:  
2025-04-06 18:34:48.447598: Epoch 60 
2025-04-06 18:34:48.447738: Current learning rate: 0.00946 
2025-04-06 18:39:21.830384: train_loss -0.6892 
2025-04-06 18:39:21.830689: val_loss -0.6902 
2025-04-06 18:39:21.830771: Pseudo dice [0.7458] 
2025-04-06 18:39:21.830858: Epoch time: 273.39 s 
2025-04-06 18:39:23.670744:  
2025-04-06 18:39:23.671043: Epoch 61 
2025-04-06 18:39:23.671180: Current learning rate: 0.00945 
2025-04-06 18:43:57.667068: train_loss -0.6319 
2025-04-06 18:43:57.667364: val_loss -0.7449 
2025-04-06 18:43:57.667445: Pseudo dice [0.787] 
2025-04-06 18:43:57.667523: Epoch time: 274.0 s 
2025-04-06 18:43:59.511273:  
2025-04-06 18:43:59.511467: Epoch 62 
2025-04-06 18:43:59.511605: Current learning rate: 0.00944 
2025-04-06 18:48:33.269983: train_loss -0.7043 
2025-04-06 18:48:33.270322: val_loss -0.7208 
2025-04-06 18:48:33.270420: Pseudo dice [0.763] 
2025-04-06 18:48:33.270521: Epoch time: 273.76 s 
2025-04-06 18:48:35.138777:  
2025-04-06 18:48:35.138998: Epoch 63 
2025-04-06 18:48:35.139111: Current learning rate: 0.00943 
2025-04-06 18:53:09.295487: train_loss -0.6862 
2025-04-06 18:53:09.295800: val_loss -0.7247 
2025-04-06 18:53:09.295887: Pseudo dice [0.7529] 
2025-04-06 18:53:09.295988: Epoch time: 274.16 s 
2025-04-06 18:53:11.166068:  
2025-04-06 18:53:11.166231: Epoch 64 
2025-04-06 18:53:11.166365: Current learning rate: 0.00942 
2025-04-06 18:57:45.626157: train_loss -0.6691 
2025-04-06 18:57:45.626497: val_loss -0.7185 
2025-04-06 18:57:45.626586: Pseudo dice [0.7711] 
2025-04-06 18:57:45.626684: Epoch time: 274.46 s 
2025-04-06 18:57:47.495396:  
2025-04-06 18:57:47.495601: Epoch 65 
2025-04-06 18:57:47.495711: Current learning rate: 0.00941 
2025-04-06 19:02:21.789318: train_loss -0.7089 
2025-04-06 19:02:21.789646: val_loss -0.7141 
2025-04-06 19:02:21.789737: Pseudo dice [0.7793] 
2025-04-06 19:02:21.789837: Epoch time: 274.3 s 
2025-04-06 19:02:21.789948: Yayy! New best EMA pseudo Dice: 0.7652 
2025-04-06 19:02:25.338690:  
2025-04-06 19:02:25.338920: Epoch 66 
2025-04-06 19:02:25.339055: Current learning rate: 0.0094 
2025-04-06 19:06:59.106656: train_loss -0.6982 
2025-04-06 19:06:59.106956: val_loss -0.6954 
2025-04-06 19:06:59.107048: Pseudo dice [0.7305] 
2025-04-06 19:06:59.107135: Epoch time: 273.77 s 
2025-04-06 19:07:00.952668:  
2025-04-06 19:07:00.952883: Epoch 67 
2025-04-06 19:07:00.953003: Current learning rate: 0.00939 
2025-04-06 19:11:34.260759: train_loss -0.7391 
2025-04-06 19:11:34.261117: val_loss -0.7288 
2025-04-06 19:11:34.261196: Pseudo dice [0.7795] 
2025-04-06 19:11:34.261277: Epoch time: 273.31 s 
2025-04-06 19:11:36.130402:  
2025-04-06 19:11:36.130610: Epoch 68 
2025-04-06 19:11:36.130728: Current learning rate: 0.00939 
2025-04-06 19:16:09.868925: train_loss -0.6963 
2025-04-06 19:16:09.869230: val_loss -0.7266 
2025-04-06 19:16:09.869311: Pseudo dice [0.7537] 
2025-04-06 19:16:09.869447: Epoch time: 273.74 s 
2025-04-06 19:16:11.739095:  
2025-04-06 19:16:11.739344: Epoch 69 
2025-04-06 19:16:11.739479: Current learning rate: 0.00938 
2025-04-06 19:20:45.202762: train_loss -0.7131 
2025-04-06 19:20:45.203093: val_loss -0.7507 
2025-04-06 19:20:45.203177: Pseudo dice [0.7821] 
2025-04-06 19:20:45.203261: Epoch time: 273.47 s 
2025-04-06 19:20:47.084666:  
2025-04-06 19:20:47.084857: Epoch 70 
2025-04-06 19:20:47.085006: Current learning rate: 0.00937 
2025-04-06 19:25:20.946588: train_loss -0.6991 
2025-04-06 19:25:20.946913: val_loss -0.7427 
2025-04-06 19:25:20.946999: Pseudo dice [0.7601] 
2025-04-06 19:25:20.947101: Epoch time: 273.87 s 
2025-04-06 19:25:22.814886:  
2025-04-06 19:25:22.815219: Epoch 71 
2025-04-06 19:25:22.815390: Current learning rate: 0.00936 
2025-04-06 19:29:56.248821: train_loss -0.6726 
2025-04-06 19:29:56.249202: val_loss -0.7412 
2025-04-06 19:29:56.249289: Pseudo dice [0.7546] 
2025-04-06 19:29:56.249381: Epoch time: 273.44 s 
2025-04-06 19:29:58.111624:  
2025-04-06 19:29:58.111823: Epoch 72 
2025-04-06 19:29:58.111944: Current learning rate: 0.00935 
2025-04-06 19:34:31.870068: train_loss -0.6955 
2025-04-06 19:34:31.870396: val_loss -0.7186 
2025-04-06 19:34:31.870481: Pseudo dice [0.7349] 
2025-04-06 19:34:31.870580: Epoch time: 273.76 s 
2025-04-06 19:34:34.029425:  
2025-04-06 19:34:34.029642: Epoch 73 
2025-04-06 19:34:34.029756: Current learning rate: 0.00934 
2025-04-06 19:39:07.541451: train_loss -0.7158 
2025-04-06 19:39:07.541751: val_loss -0.7221 
2025-04-06 19:39:07.541837: Pseudo dice [0.7505] 
2025-04-06 19:39:07.541926: Epoch time: 273.52 s 
2025-04-06 19:39:09.407032:  
2025-04-06 19:39:09.407230: Epoch 74 
2025-04-06 19:39:09.407347: Current learning rate: 0.00933 
2025-04-06 19:43:43.164755: train_loss -0.6973 
2025-04-06 19:43:43.165117: val_loss -0.722 
2025-04-06 19:43:43.165205: Pseudo dice [0.7545] 
2025-04-06 19:43:43.165301: Epoch time: 273.76 s 
2025-04-06 19:43:45.049577:  
2025-04-06 19:43:45.049824: Epoch 75 
2025-04-06 19:43:45.049973: Current learning rate: 0.00932 
2025-04-06 19:48:19.329648: train_loss -0.681 
2025-04-06 19:48:19.329987: val_loss -0.7108 
2025-04-06 19:48:19.330070: Pseudo dice [0.7337] 
2025-04-06 19:48:19.330165: Epoch time: 274.28 s 
2025-04-06 19:48:21.204724:  
2025-04-06 19:48:21.204992: Epoch 76 
2025-04-06 19:48:21.205136: Current learning rate: 0.00931 
2025-04-06 19:52:54.665911: train_loss -0.7441 
2025-04-06 19:52:54.666212: val_loss -0.7154 
2025-04-06 19:52:54.666288: Pseudo dice [0.7277] 
2025-04-06 19:52:54.666371: Epoch time: 273.47 s 
2025-04-06 19:52:56.547130:  
2025-04-06 19:52:56.547397: Epoch 77 
2025-04-06 19:52:56.547513: Current learning rate: 0.0093 
2025-04-06 19:57:29.831869: train_loss -0.7269 
2025-04-06 19:57:29.832203: val_loss -0.7354 
2025-04-06 19:57:29.832294: Pseudo dice [0.7674] 
2025-04-06 19:57:29.832388: Epoch time: 273.29 s 
2025-04-06 19:57:31.732496:  
2025-04-06 19:57:31.732685: Epoch 78 
2025-04-06 19:57:31.732828: Current learning rate: 0.0093 
2025-04-06 20:02:05.317982: train_loss -0.6921 
2025-04-06 20:02:05.318378: val_loss -0.7388 
2025-04-06 20:02:05.318473: Pseudo dice [0.7638] 
2025-04-06 20:02:05.318566: Epoch time: 273.59 s 
2025-04-06 20:02:07.216488:  
2025-04-06 20:02:07.216828: Epoch 79 
2025-04-06 20:02:07.216969: Current learning rate: 0.00929 
2025-04-06 20:06:40.511049: train_loss -0.72 
2025-04-06 20:06:40.511380: val_loss -0.7699 
2025-04-06 20:06:40.511474: Pseudo dice [0.7934] 
2025-04-06 20:06:40.511588: Epoch time: 273.3 s 
2025-04-06 20:06:42.409410:  
2025-04-06 20:06:42.409559: Epoch 80 
2025-04-06 20:06:42.409673: Current learning rate: 0.00928 
2025-04-06 20:11:15.620845: train_loss -0.7279 
2025-04-06 20:11:15.621194: val_loss -0.7244 
2025-04-06 20:11:15.621340: Pseudo dice [0.7089] 
2025-04-06 20:11:15.621426: Epoch time: 273.22 s 
2025-04-06 20:11:17.833159:  
2025-04-06 20:11:17.833355: Epoch 81 
2025-04-06 20:11:17.833483: Current learning rate: 0.00927 
2025-04-06 20:15:51.064888: train_loss -0.7211 
2025-04-06 20:15:51.065196: val_loss -0.7464 
2025-04-06 20:15:51.065331: Pseudo dice [0.7728] 
2025-04-06 20:15:51.065446: Epoch time: 273.24 s 
2025-04-06 20:15:52.959031:  
2025-04-06 20:15:52.959345: Epoch 82 
2025-04-06 20:15:52.959497: Current learning rate: 0.00926 
2025-04-06 20:20:26.626348: train_loss -0.6954 
2025-04-06 20:20:26.626642: val_loss -0.7618 
2025-04-06 20:20:26.626727: Pseudo dice [0.7918] 
2025-04-06 20:20:26.626815: Epoch time: 273.67 s 
2025-04-06 20:20:28.435365:  
2025-04-06 20:20:28.435625: Epoch 83 
2025-04-06 20:20:28.435741: Current learning rate: 0.00925 
2025-04-06 20:25:02.308346: train_loss -0.6822 
2025-04-06 20:25:02.308661: val_loss -0.718 
2025-04-06 20:25:02.308740: Pseudo dice [0.7675] 
2025-04-06 20:25:02.308820: Epoch time: 273.88 s 
2025-04-06 20:25:04.101501:  
2025-04-06 20:25:04.101782: Epoch 84 
2025-04-06 20:25:04.101929: Current learning rate: 0.00924 
2025-04-06 20:29:37.576065: train_loss -0.7052 
2025-04-06 20:29:37.576392: val_loss -0.7269 
2025-04-06 20:29:37.576514: Pseudo dice [0.7937] 
2025-04-06 20:29:37.576611: Epoch time: 273.48 s 
2025-04-06 20:29:39.385078:  
2025-04-06 20:29:39.385316: Epoch 85 
2025-04-06 20:29:39.385493: Current learning rate: 0.00923 
2025-04-06 20:34:13.598540: train_loss -0.6749 
2025-04-06 20:34:13.598875: val_loss -0.7437 
2025-04-06 20:34:13.598987: Pseudo dice [0.7737] 
2025-04-06 20:34:13.599086: Epoch time: 274.22 s 
2025-04-06 20:34:15.439692:  
2025-04-06 20:34:15.439951: Epoch 86 
2025-04-06 20:34:15.440079: Current learning rate: 0.00922 
2025-04-06 20:38:49.417122: train_loss -0.7358 
2025-04-06 20:38:49.417436: val_loss -0.7507 
2025-04-06 20:38:49.417539: Pseudo dice [0.801] 
2025-04-06 20:38:49.417650: Epoch time: 273.98 s 
2025-04-06 20:38:49.417802: Yayy! New best EMA pseudo Dice: 0.7685 
2025-04-06 20:38:52.589391:  
2025-04-06 20:38:52.589594: Epoch 87 
2025-04-06 20:38:52.589714: Current learning rate: 0.00921 
2025-04-06 20:43:26.420438: train_loss -0.7466 
2025-04-06 20:43:26.420831: val_loss -0.7433 
2025-04-06 20:43:26.420927: Pseudo dice [0.789] 
2025-04-06 20:43:26.421009: Epoch time: 273.84 s 
2025-04-06 20:43:26.421073: Yayy! New best EMA pseudo Dice: 0.7705 
2025-04-06 20:43:29.581120:  
2025-04-06 20:43:29.581366: Epoch 88 
2025-04-06 20:43:29.581482: Current learning rate: 0.0092 
2025-04-06 20:48:03.956832: train_loss -0.7027 
2025-04-06 20:48:03.957154: val_loss -0.7519 
2025-04-06 20:48:03.957233: Pseudo dice [0.7911] 
2025-04-06 20:48:03.957325: Epoch time: 274.38 s 
2025-04-06 20:48:03.957382: Yayy! New best EMA pseudo Dice: 0.7726 
2025-04-06 20:48:07.409897:  
2025-04-06 20:48:07.410126: Epoch 89 
2025-04-06 20:48:07.410254: Current learning rate: 0.0092 
2025-04-06 20:52:41.328564: train_loss -0.6958 
2025-04-06 20:52:41.328902: val_loss -0.7447 
2025-04-06 20:52:41.328987: Pseudo dice [0.7674] 
2025-04-06 20:52:41.329183: Epoch time: 273.92 s 
2025-04-06 20:52:43.133306:  
2025-04-06 20:52:43.133534: Epoch 90 
2025-04-06 20:52:43.133650: Current learning rate: 0.00919 
2025-04-06 20:57:17.119368: train_loss -0.7235 
2025-04-06 20:57:17.119723: val_loss -0.7531 
2025-04-06 20:57:17.119850: Pseudo dice [0.8033] 
2025-04-06 20:57:17.119976: Epoch time: 273.99 s 
2025-04-06 20:57:17.120052: Yayy! New best EMA pseudo Dice: 0.7752 
2025-04-06 20:57:20.287772:  
2025-04-06 20:57:20.288060: Epoch 91 
2025-04-06 20:57:20.288226: Current learning rate: 0.00918 
2025-04-06 21:01:54.286269: train_loss -0.6992 
2025-04-06 21:01:54.286618: val_loss -0.7602 
2025-04-06 21:01:54.286701: Pseudo dice [0.7985] 
2025-04-06 21:01:54.286796: Epoch time: 274.0 s 
2025-04-06 21:01:54.286852: Yayy! New best EMA pseudo Dice: 0.7775 
2025-04-06 21:01:57.448983:  
2025-04-06 21:01:57.449220: Epoch 92 
2025-04-06 21:01:57.449335: Current learning rate: 0.00917 
2025-04-06 21:06:31.730176: train_loss -0.732 
2025-04-06 21:06:31.730581: val_loss -0.7532 
2025-04-06 21:06:31.730708: Pseudo dice [0.7854] 
2025-04-06 21:06:31.730800: Epoch time: 274.29 s 
2025-04-06 21:06:31.730859: Yayy! New best EMA pseudo Dice: 0.7783 
2025-04-06 21:06:34.900085:  
2025-04-06 21:06:34.900296: Epoch 93 
2025-04-06 21:06:34.900454: Current learning rate: 0.00916 
2025-04-06 21:11:09.529519: train_loss -0.7204 
2025-04-06 21:11:09.529851: val_loss -0.7606 
2025-04-06 21:11:09.529950: Pseudo dice [0.796] 
2025-04-06 21:11:09.530046: Epoch time: 274.63 s 
2025-04-06 21:11:09.530100: Yayy! New best EMA pseudo Dice: 0.7801 
2025-04-06 21:11:12.638927:  
2025-04-06 21:11:12.639174: Epoch 94 
2025-04-06 21:11:12.639308: Current learning rate: 0.00915 
2025-04-06 21:15:47.364484: train_loss -0.7272 
2025-04-06 21:15:47.364780: val_loss -0.7277 
2025-04-06 21:15:47.364866: Pseudo dice [0.7518] 
2025-04-06 21:15:47.364964: Epoch time: 274.73 s 
2025-04-06 21:15:49.188171:  
2025-04-06 21:15:49.188471: Epoch 95 
2025-04-06 21:15:49.188589: Current learning rate: 0.00914 
2025-04-06 21:20:23.359226: train_loss -0.751 
2025-04-06 21:20:23.359532: val_loss -0.7235 
2025-04-06 21:20:23.359613: Pseudo dice [0.7475] 
2025-04-06 21:20:23.359698: Epoch time: 274.18 s 
2025-04-06 21:20:25.153012:  
2025-04-06 21:20:25.153225: Epoch 96 
2025-04-06 21:20:25.153336: Current learning rate: 0.00913 
2025-04-06 21:24:59.307240: train_loss -0.75 
2025-04-06 21:24:59.307586: val_loss -0.7516 
2025-04-06 21:24:59.307669: Pseudo dice [0.7945] 
2025-04-06 21:24:59.307772: Epoch time: 274.16 s 
2025-04-06 21:25:01.156263:  
2025-04-06 21:25:01.156534: Epoch 97 
2025-04-06 21:25:01.156656: Current learning rate: 0.00912 
2025-04-06 21:29:35.332941: train_loss -0.7329 
2025-04-06 21:29:35.333292: val_loss -0.7609 
2025-04-06 21:29:35.333704: Pseudo dice [0.7993] 
2025-04-06 21:29:35.333791: Epoch time: 274.18 s 
2025-04-06 21:29:37.477416:  
2025-04-06 21:29:37.477594: Epoch 98 
2025-04-06 21:29:37.477726: Current learning rate: 0.00911 
2025-04-06 21:34:11.610387: train_loss -0.7354 
2025-04-06 21:34:11.610823: val_loss -0.7463 
2025-04-06 21:34:11.610919: Pseudo dice [0.7624] 
2025-04-06 21:34:11.610999: Epoch time: 274.14 s 
2025-04-06 21:34:13.430934:  
2025-04-06 21:34:13.431190: Epoch 99 
2025-04-06 21:34:13.431468: Current learning rate: 0.0091 
2025-04-06 21:38:47.427316: train_loss -0.7411 
2025-04-06 21:38:47.427651: val_loss -0.7584 
2025-04-06 21:38:47.427742: Pseudo dice [0.7643] 
2025-04-06 21:38:47.427859: Epoch time: 274.0 s 
2025-04-06 21:38:50.493536:  
2025-04-06 21:38:50.493760: Epoch 100 
2025-04-06 21:38:50.493875: Current learning rate: 0.0091 
2025-04-06 21:43:24.351945: train_loss -0.7155 
2025-04-06 21:43:24.352505: val_loss -0.7672 
2025-04-06 21:43:24.352611: Pseudo dice [0.793] 
2025-04-06 21:43:24.352695: Epoch time: 273.86 s 
2025-04-06 21:43:26.159270:  
2025-04-06 21:43:26.159445: Epoch 101 
2025-04-06 21:43:26.159586: Current learning rate: 0.00909 
2025-04-06 21:48:00.540249: train_loss -0.7524 
2025-04-06 21:48:00.540575: val_loss -0.7475 
2025-04-06 21:48:00.540694: Pseudo dice [0.7769] 
2025-04-06 21:48:00.540796: Epoch time: 274.38 s 
2025-04-06 21:48:02.349335:  
2025-04-06 21:48:02.349559: Epoch 102 
2025-04-06 21:48:02.349677: Current learning rate: 0.00908 
2025-04-06 21:52:36.456875: train_loss -0.7246 
2025-04-06 21:52:36.457216: val_loss -0.752 
2025-04-06 21:52:36.457299: Pseudo dice [0.7852] 
2025-04-06 21:52:36.457398: Epoch time: 274.11 s 
2025-04-06 21:52:38.313640:  
2025-04-06 21:52:38.313848: Epoch 103 
2025-04-06 21:52:38.314043: Current learning rate: 0.00907 
2025-04-06 21:57:12.091665: train_loss -0.7544 
2025-04-06 21:57:12.092021: val_loss -0.6752 
2025-04-06 21:57:12.092104: Pseudo dice [0.7414] 
2025-04-06 21:57:12.092202: Epoch time: 273.78 s 
2025-04-06 21:57:13.909999:  
2025-04-06 21:57:13.910219: Epoch 104 
2025-04-06 21:57:13.910416: Current learning rate: 0.00906 
2025-04-06 22:01:48.228852: train_loss -0.7163 
2025-04-06 22:01:48.229189: val_loss -0.674 
2025-04-06 22:01:48.229286: Pseudo dice [0.7418] 
2025-04-06 22:01:48.229385: Epoch time: 274.32 s 
2025-04-06 22:01:50.317204:  
2025-04-06 22:01:50.317432: Epoch 105 
2025-04-06 22:01:50.317557: Current learning rate: 0.00905 
2025-04-06 22:06:24.426491: train_loss -0.7017 
2025-04-06 22:06:24.426833: val_loss -0.7549 
2025-04-06 22:06:24.426934: Pseudo dice [0.7781] 
2025-04-06 22:06:24.427036: Epoch time: 274.11 s 
2025-04-06 22:06:26.280660:  
2025-04-06 22:06:26.280873: Epoch 106 
2025-04-06 22:06:26.280989: Current learning rate: 0.00904 
2025-04-06 22:11:00.556742: train_loss -0.6929 
2025-04-06 22:11:00.557119: val_loss -0.6817 
2025-04-06 22:11:00.557292: Pseudo dice [0.7514] 
2025-04-06 22:11:00.557379: Epoch time: 274.28 s 
2025-04-06 22:11:02.384567:  
2025-04-06 22:11:02.384829: Epoch 107 
2025-04-06 22:11:02.384990: Current learning rate: 0.00903 
2025-04-06 22:15:36.615663: train_loss -0.7295 
2025-04-06 22:15:36.615989: val_loss -0.7691 
2025-04-06 22:15:36.616072: Pseudo dice [0.7934] 
2025-04-06 22:15:36.616181: Epoch time: 274.23 s 
2025-04-06 22:15:38.438377:  
2025-04-06 22:15:38.438601: Epoch 108 
2025-04-06 22:15:38.438776: Current learning rate: 0.00902 
2025-04-06 22:20:12.379594: train_loss -0.7315 
2025-04-06 22:20:12.379832: val_loss -0.671 
2025-04-06 22:20:12.379943: Pseudo dice [0.6862] 
2025-04-06 22:20:12.380090: Epoch time: 273.95 s 
2025-04-06 22:20:14.207862:  
2025-04-06 22:20:14.208069: Epoch 109 
2025-04-06 22:20:14.208196: Current learning rate: 0.00901 
2025-04-06 22:24:48.508111: train_loss -0.7203 
2025-04-06 22:24:48.508488: val_loss -0.7384 
2025-04-06 22:24:48.508579: Pseudo dice [0.7767] 
2025-04-06 22:24:48.508675: Epoch time: 274.3 s 
2025-04-06 22:24:50.332893:  
2025-04-06 22:24:50.333161: Epoch 110 
2025-04-06 22:24:50.333315: Current learning rate: 0.009 
2025-04-06 22:29:24.566888: train_loss -0.7321 
2025-04-06 22:29:24.567253: val_loss -0.767 
2025-04-06 22:29:24.567347: Pseudo dice [0.7949] 
2025-04-06 22:29:24.567445: Epoch time: 274.24 s 
2025-04-06 22:29:26.389906:  
2025-04-06 22:29:26.390144: Epoch 111 
2025-04-06 22:29:26.390316: Current learning rate: 0.009 
2025-04-06 22:34:00.792771: train_loss -0.7459 
2025-04-06 22:34:00.793123: val_loss -0.7177 
2025-04-06 22:34:00.793231: Pseudo dice [0.7545] 
2025-04-06 22:34:00.793335: Epoch time: 274.41 s 
2025-04-06 22:34:02.606043:  
2025-04-06 22:34:02.606252: Epoch 112 
2025-04-06 22:34:02.606384: Current learning rate: 0.00899 
2025-04-06 22:38:36.989898: train_loss -0.7554 
2025-04-06 22:38:36.990228: val_loss -0.7372 
2025-04-06 22:38:36.990322: Pseudo dice [0.7995] 
2025-04-06 22:38:36.990490: Epoch time: 274.39 s 
2025-04-06 22:38:39.166812:  
2025-04-06 22:38:39.167083: Epoch 113 
2025-04-06 22:38:39.167245: Current learning rate: 0.00898 
2025-04-06 22:43:13.473096: train_loss -0.7353 
2025-04-06 22:43:13.473457: val_loss -0.7619 
2025-04-06 22:43:13.473599: Pseudo dice [0.7945] 
2025-04-06 22:43:13.473692: Epoch time: 274.31 s 
2025-04-06 22:43:15.283229:  
2025-04-06 22:43:15.283496: Epoch 114 
2025-04-06 22:43:15.283623: Current learning rate: 0.00897 
2025-04-06 22:47:49.370768: train_loss -0.7535 
2025-04-06 22:47:49.371119: val_loss -0.7599 
2025-04-06 22:47:49.371216: Pseudo dice [0.7931] 
2025-04-06 22:47:49.371301: Epoch time: 274.09 s 
2025-04-06 22:47:51.195311:  
2025-04-06 22:47:51.195572: Epoch 115 
2025-04-06 22:47:51.195710: Current learning rate: 0.00896 
2025-04-06 22:52:25.143288: train_loss -0.7471 
2025-04-06 22:52:25.143614: val_loss -0.719 
2025-04-06 22:52:25.143694: Pseudo dice [0.7482] 
2025-04-06 22:52:25.143821: Epoch time: 273.95 s 
2025-04-06 22:52:26.997432:  
2025-04-06 22:52:26.997647: Epoch 116 
2025-04-06 22:52:26.997762: Current learning rate: 0.00895 
2025-04-06 22:57:01.130354: train_loss -0.7633 
2025-04-06 22:57:01.130702: val_loss -0.7356 
2025-04-06 22:57:01.130795: Pseudo dice [0.7628] 
2025-04-06 22:57:01.130909: Epoch time: 274.14 s 
2025-04-06 22:57:02.997918:  
2025-04-06 22:57:02.998180: Epoch 117 
2025-04-06 22:57:02.998298: Current learning rate: 0.00894 
2025-04-06 23:01:37.425143: train_loss -0.7586 
2025-04-06 23:01:37.425458: val_loss -0.741 
2025-04-06 23:01:37.425548: Pseudo dice [0.7868] 
2025-04-06 23:01:37.425665: Epoch time: 274.43 s 
2025-04-06 23:01:39.262376:  
2025-04-06 23:01:39.262634: Epoch 118 
2025-04-06 23:01:39.262774: Current learning rate: 0.00893 
2025-04-06 23:06:13.583554: train_loss -0.7373 
2025-04-06 23:06:13.583951: val_loss -0.7601 
2025-04-06 23:06:13.584039: Pseudo dice [0.8002] 
2025-04-06 23:06:13.584164: Epoch time: 274.33 s 
2025-04-06 23:06:15.436402:  
2025-04-06 23:06:15.436607: Epoch 119 
2025-04-06 23:06:15.436735: Current learning rate: 0.00892 
2025-04-06 23:10:49.469059: train_loss -0.7514 
2025-04-06 23:10:49.469425: val_loss -0.6849 
2025-04-06 23:10:49.469524: Pseudo dice [0.6695] 
2025-04-06 23:10:49.469620: Epoch time: 274.04 s 
2025-04-06 23:10:51.340445:  
2025-04-06 23:10:51.340652: Epoch 120 
2025-04-06 23:10:51.340766: Current learning rate: 0.00891 
2025-04-06 23:15:25.278329: train_loss -0.6732 
2025-04-06 23:15:25.278639: val_loss -0.7644 
2025-04-06 23:15:25.278725: Pseudo dice [0.7884] 
2025-04-06 23:15:25.278813: Epoch time: 273.94 s 
2025-04-06 23:15:27.111890:  
2025-04-06 23:15:27.112119: Epoch 121 
2025-04-06 23:15:27.112322: Current learning rate: 0.0089 
2025-04-06 23:20:00.905537: train_loss -0.6946 
2025-04-06 23:20:00.905842: val_loss -0.7116 
2025-04-06 23:20:00.905930: Pseudo dice [0.7661] 
2025-04-06 23:20:00.906014: Epoch time: 273.8 s 
2025-04-06 23:20:02.762124:  
2025-04-06 23:20:02.762341: Epoch 122 
2025-04-06 23:20:02.762459: Current learning rate: 0.00889 
2025-04-06 23:24:36.311277: train_loss -0.7513 
2025-04-06 23:24:36.311615: val_loss -0.7688 
2025-04-06 23:24:36.311706: Pseudo dice [0.7979] 
2025-04-06 23:24:36.311818: Epoch time: 273.55 s 
2025-04-06 23:24:38.158072:  
2025-04-06 23:24:38.158313: Epoch 123 
2025-04-06 23:24:38.158439: Current learning rate: 0.00889 
2025-04-06 23:29:11.819396: train_loss -0.7086 
2025-04-06 23:29:11.819736: val_loss -0.6891 
2025-04-06 23:29:11.819853: Pseudo dice [0.7054] 
2025-04-06 23:29:11.819948: Epoch time: 273.67 s 
2025-04-06 23:29:13.677160:  
2025-04-06 23:29:13.677380: Epoch 124 
2025-04-06 23:29:13.677495: Current learning rate: 0.00888 
2025-04-06 23:33:47.868087: train_loss -0.7189 
2025-04-06 23:33:47.868396: val_loss -0.732 
2025-04-06 23:33:47.868483: Pseudo dice [0.7561] 
2025-04-06 23:33:47.868580: Epoch time: 274.19 s 
2025-04-06 23:33:49.706605:  
2025-04-06 23:33:49.706841: Epoch 125 
2025-04-06 23:33:49.706957: Current learning rate: 0.00887 
2025-04-06 23:38:23.645668: train_loss -0.7303 
2025-04-06 23:38:23.645976: val_loss -0.6928 
2025-04-06 23:38:23.646055: Pseudo dice [0.7372] 
2025-04-06 23:38:23.646146: Epoch time: 273.94 s 
2025-04-06 23:38:25.509173:  
2025-04-06 23:38:25.509376: Epoch 126 
2025-04-06 23:38:25.509491: Current learning rate: 0.00886 
2025-04-06 23:42:59.125848: train_loss -0.7364 
2025-04-06 23:42:59.126180: val_loss -0.7728 
2025-04-06 23:42:59.126271: Pseudo dice [0.7948] 
2025-04-06 23:42:59.126371: Epoch time: 273.62 s 
2025-04-06 23:43:00.981030:  
2025-04-06 23:43:00.981280: Epoch 127 
2025-04-06 23:43:00.981431: Current learning rate: 0.00885 
2025-04-06 23:47:34.419392: train_loss -0.7294 
2025-04-06 23:47:34.419700: val_loss -0.7551 
2025-04-06 23:47:34.419817: Pseudo dice [0.7817] 
2025-04-06 23:47:34.419924: Epoch time: 273.44 s 
2025-04-06 23:47:36.263303:  
2025-04-06 23:47:36.263526: Epoch 128 
2025-04-06 23:47:36.263652: Current learning rate: 0.00884 
2025-04-06 23:52:10.517171: train_loss -0.7004 
2025-04-06 23:52:10.517433: val_loss -0.7321 
2025-04-06 23:52:10.517515: Pseudo dice [0.7782] 
2025-04-06 23:52:10.517607: Epoch time: 274.26 s 
2025-04-06 23:52:12.375255:  
2025-04-06 23:52:12.375535: Epoch 129 
2025-04-06 23:52:12.375715: Current learning rate: 0.00883 
2025-04-06 23:56:46.717829: train_loss -0.6937 
2025-04-06 23:56:46.718178: val_loss -0.7631 
2025-04-06 23:56:46.718265: Pseudo dice [0.7862] 
2025-04-06 23:56:46.718364: Epoch time: 274.35 s 
2025-04-06 23:56:48.870050:  
2025-04-06 23:56:48.870301: Epoch 130 
2025-04-06 23:56:48.870414: Current learning rate: 0.00882 
2025-04-07 00:01:23.413483: train_loss -0.6788 
2025-04-07 00:01:23.413841: val_loss -0.7393 
2025-04-07 00:01:23.413930: Pseudo dice [0.7855] 
2025-04-07 00:01:23.414025: Epoch time: 274.55 s 
2025-04-07 00:01:25.274278:  
2025-04-07 00:01:25.274501: Epoch 131 
2025-04-07 00:01:25.274693: Current learning rate: 0.00881 
2025-04-07 00:05:59.720588: train_loss -0.7015 
2025-04-07 00:05:59.720949: val_loss -0.7542 
2025-04-07 00:05:59.721064: Pseudo dice [0.7973] 
2025-04-07 00:05:59.721156: Epoch time: 274.45 s 
2025-04-07 00:06:01.566432:  
2025-04-07 00:06:01.566664: Epoch 132 
2025-04-07 00:06:01.566834: Current learning rate: 0.0088 
2025-04-07 00:10:35.617856: train_loss -0.6895 
2025-04-07 00:10:35.618164: val_loss -0.6823 
2025-04-07 00:10:35.618286: Pseudo dice [0.6796] 
2025-04-07 00:10:35.618386: Epoch time: 274.06 s 
2025-04-07 00:10:37.457565:  
2025-04-07 00:10:37.457816: Epoch 133 
2025-04-07 00:10:37.457949: Current learning rate: 0.00879 
2025-04-07 00:15:11.399241: train_loss -0.6825 
2025-04-07 00:15:11.399542: val_loss -0.7292 
2025-04-07 00:15:11.399626: Pseudo dice [0.7723] 
2025-04-07 00:15:11.399708: Epoch time: 273.95 s 
2025-04-07 00:15:13.246709:  
2025-04-07 00:15:13.246949: Epoch 134 
2025-04-07 00:15:13.247106: Current learning rate: 0.00879 
2025-04-07 00:19:47.179228: train_loss -0.696 
2025-04-07 00:19:47.179575: val_loss -0.7332 
2025-04-07 00:19:47.179665: Pseudo dice [0.7803] 
2025-04-07 00:19:47.179772: Epoch time: 273.94 s 
2025-04-07 00:19:49.060622:  
2025-04-07 00:19:49.060831: Epoch 135 
2025-04-07 00:19:49.060946: Current learning rate: 0.00878 
2025-04-07 00:24:23.037794: train_loss -0.7147 
2025-04-07 00:24:23.038166: val_loss -0.6984 
2025-04-07 00:24:23.038352: Pseudo dice [0.7435] 
2025-04-07 00:24:23.038436: Epoch time: 273.98 s 
2025-04-07 00:24:24.929412:  
2025-04-07 00:24:24.929646: Epoch 136 
2025-04-07 00:24:24.929813: Current learning rate: 0.00877 
2025-04-07 00:28:59.000437: train_loss -0.6891 
2025-04-07 00:28:59.000743: val_loss -0.7343 
2025-04-07 00:28:59.000826: Pseudo dice [0.7621] 
2025-04-07 00:28:59.000919: Epoch time: 274.08 s 
2025-04-07 00:29:00.903230:  
2025-04-07 00:29:00.903507: Epoch 137 
2025-04-07 00:29:00.903651: Current learning rate: 0.00876 
2025-04-07 00:33:34.436606: train_loss -0.7337 
2025-04-07 00:33:34.436957: val_loss -0.7517 
2025-04-07 00:33:34.437128: Pseudo dice [0.7797] 
2025-04-07 00:33:34.437212: Epoch time: 273.54 s 
2025-04-07 00:33:36.302950:  
2025-04-07 00:33:36.303174: Epoch 138 
2025-04-07 00:33:36.303284: Current learning rate: 0.00875 
2025-04-07 00:38:10.014007: train_loss -0.7016 
2025-04-07 00:38:10.014405: val_loss -0.7436 
2025-04-07 00:38:10.015381: Pseudo dice [0.7571] 
2025-04-07 00:38:10.015467: Epoch time: 273.71 s 
2025-04-07 00:38:11.900523:  
2025-04-07 00:38:11.900783: Epoch 139 
2025-04-07 00:38:11.900898: Current learning rate: 0.00874 
2025-04-07 00:42:45.592408: train_loss -0.714 
2025-04-07 00:42:45.592726: val_loss -0.6349 
2025-04-07 00:42:45.592811: Pseudo dice [0.6968] 
2025-04-07 00:42:45.592903: Epoch time: 273.7 s 
2025-04-07 00:42:47.498723:  
2025-04-07 00:42:47.498940: Epoch 140 
2025-04-07 00:42:47.499051: Current learning rate: 0.00873 
2025-04-07 00:47:21.796627: train_loss -0.7137 
2025-04-07 00:47:21.797007: val_loss -0.7563 
2025-04-07 00:47:21.797122: Pseudo dice [0.7787] 
2025-04-07 00:47:21.797226: Epoch time: 274.3 s 
2025-04-07 00:47:23.687572:  
2025-04-07 00:47:23.687878: Epoch 141 
2025-04-07 00:47:23.688055: Current learning rate: 0.00872 
2025-04-07 00:51:58.190419: train_loss -0.7139 
2025-04-07 00:51:58.190798: val_loss -0.752 
2025-04-07 00:51:58.190907: Pseudo dice [0.7677] 
2025-04-07 00:51:58.191004: Epoch time: 274.51 s 
2025-04-07 00:52:00.065476:  
2025-04-07 00:52:00.065720: Epoch 142 
2025-04-07 00:52:00.065832: Current learning rate: 0.00871 
2025-04-07 00:56:34.316713: train_loss -0.7588 
2025-04-07 00:56:34.317036: val_loss -0.712 
2025-04-07 00:56:34.317129: Pseudo dice [0.7302] 
2025-04-07 00:56:34.317229: Epoch time: 274.26 s 
2025-04-07 00:56:36.234581:  
2025-04-07 00:56:36.234791: Epoch 143 
2025-04-07 00:56:36.234909: Current learning rate: 0.0087 
2025-04-07 01:01:10.250716: train_loss -0.7572 
2025-04-07 01:01:10.251112: val_loss -0.7081 
2025-04-07 01:01:10.251220: Pseudo dice [0.7134] 
2025-04-07 01:01:10.251304: Epoch time: 274.02 s 
2025-04-07 01:01:12.138587:  
2025-04-07 01:01:12.138787: Epoch 144 
2025-04-07 01:01:12.138916: Current learning rate: 0.00869 
2025-04-07 01:05:46.557237: train_loss -0.7786 
2025-04-07 01:05:46.557552: val_loss -0.7613 
2025-04-07 01:05:46.557652: Pseudo dice [0.7804] 
2025-04-07 01:05:46.557829: Epoch time: 274.42 s 
2025-04-07 01:05:48.733753:  
2025-04-07 01:05:48.733983: Epoch 145 
2025-04-07 01:05:48.734096: Current learning rate: 0.00868 
2025-04-07 01:10:23.097323: train_loss -0.7606 
2025-04-07 01:10:23.097684: val_loss -0.7803 
2025-04-07 01:10:23.097788: Pseudo dice [0.8039] 
2025-04-07 01:10:23.097888: Epoch time: 274.37 s 
2025-04-07 01:10:25.016886:  
2025-04-07 01:10:25.017200: Epoch 146 
2025-04-07 01:10:25.017370: Current learning rate: 0.00868 
2025-04-07 01:14:58.764158: train_loss -0.7563 
2025-04-07 01:14:58.764504: val_loss -0.7776 
2025-04-07 01:14:58.764595: Pseudo dice [0.817] 
2025-04-07 01:14:58.764693: Epoch time: 273.75 s 
2025-04-07 01:15:00.642860:  
2025-04-07 01:15:00.643059: Epoch 147 
2025-04-07 01:15:00.643201: Current learning rate: 0.00867 
2025-04-07 01:19:34.416221: train_loss -0.7258 
2025-04-07 01:19:34.416588: val_loss -0.7562 
2025-04-07 01:19:34.416692: Pseudo dice [0.7493] 
2025-04-07 01:19:34.416789: Epoch time: 273.78 s 
2025-04-07 01:19:36.298598:  
2025-04-07 01:19:36.298828: Epoch 148 
2025-04-07 01:19:36.298968: Current learning rate: 0.00866 
2025-04-07 01:24:10.233300: train_loss -0.7276 
2025-04-07 01:24:10.233536: val_loss -0.7569 
2025-04-07 01:24:10.233620: Pseudo dice [0.7838] 
2025-04-07 01:24:10.233784: Epoch time: 273.94 s 
2025-04-07 01:24:12.131891:  
2025-04-07 01:24:12.132177: Epoch 149 
2025-04-07 01:24:12.132338: Current learning rate: 0.00865 
2025-04-07 01:28:46.005746: train_loss -0.7351 
2025-04-07 01:28:46.006086: val_loss -0.7531 
2025-04-07 01:28:46.006454: Pseudo dice [0.7847] 
2025-04-07 01:28:46.006550: Epoch time: 273.88 s 
2025-04-07 01:28:49.247454:  
2025-04-07 01:28:49.247709: Epoch 150 
2025-04-07 01:28:49.247859: Current learning rate: 0.00864 
2025-04-07 01:33:23.134164: train_loss -0.7599 
2025-04-07 01:33:23.134476: val_loss -0.7614 
2025-04-07 01:33:23.134618: Pseudo dice [0.7837] 
2025-04-07 01:33:23.134726: Epoch time: 273.89 s 
2025-04-07 01:33:25.031868:  
2025-04-07 01:33:25.032077: Epoch 151 
2025-04-07 01:33:25.032197: Current learning rate: 0.00863 
2025-04-07 01:37:58.646538: train_loss -0.7777 
2025-04-07 01:37:58.646855: val_loss -0.7777 
2025-04-07 01:37:58.646942: Pseudo dice [0.7991] 
2025-04-07 01:37:58.647035: Epoch time: 273.62 s 
2025-04-07 01:38:00.532026:  
2025-04-07 01:38:00.532285: Epoch 152 
2025-04-07 01:38:00.532411: Current learning rate: 0.00862 
2025-04-07 01:42:34.232344: train_loss -0.7508 
2025-04-07 01:42:34.232643: val_loss -0.7353 
2025-04-07 01:42:34.232718: Pseudo dice [0.7772] 
2025-04-07 01:42:34.232800: Epoch time: 273.7 s 
2025-04-07 01:42:36.428802:  
2025-04-07 01:42:36.429029: Epoch 153 
2025-04-07 01:42:36.429147: Current learning rate: 0.00861 
2025-04-07 01:47:10.183966: train_loss -0.7336 
2025-04-07 01:47:10.184374: val_loss -0.7352 
2025-04-07 01:47:10.184466: Pseudo dice [0.782] 
2025-04-07 01:47:10.184575: Epoch time: 273.76 s 
2025-04-07 01:47:12.097739:  
2025-04-07 01:47:12.098017: Epoch 154 
2025-04-07 01:47:12.098131: Current learning rate: 0.0086 
2025-04-07 01:51:46.042123: train_loss -0.7507 
2025-04-07 01:51:46.042462: val_loss -0.7127 
2025-04-07 01:51:46.042904: Pseudo dice [0.6443] 
2025-04-07 01:51:46.043044: Epoch time: 273.95 s 
2025-04-07 01:51:47.944853:  
2025-04-07 01:51:47.945052: Epoch 155 
2025-04-07 01:51:47.945196: Current learning rate: 0.00859 
2025-04-07 01:56:21.749149: train_loss -0.7472 
2025-04-07 01:56:21.749465: val_loss -0.7341 
2025-04-07 01:56:21.749548: Pseudo dice [0.7571] 
2025-04-07 01:56:21.749638: Epoch time: 273.81 s 
2025-04-07 01:56:23.657369:  
2025-04-07 01:56:23.657580: Epoch 156 
2025-04-07 01:56:23.657693: Current learning rate: 0.00858 
2025-04-07 02:00:56.925734: train_loss -0.7105 
2025-04-07 02:00:56.926106: val_loss -0.7594 
2025-04-07 02:00:56.926197: Pseudo dice [0.7655] 
2025-04-07 02:00:56.926292: Epoch time: 273.27 s 
2025-04-07 02:00:58.864813:  
2025-04-07 02:00:58.865013: Epoch 157 
2025-04-07 02:00:58.865158: Current learning rate: 0.00858 
2025-04-07 02:05:32.530012: train_loss -0.697 
2025-04-07 02:05:32.530393: val_loss -0.7381 
2025-04-07 02:05:32.530666: Pseudo dice [0.7153] 
2025-04-07 02:05:32.530756: Epoch time: 273.67 s 
2025-04-07 02:05:34.442719:  
2025-04-07 02:05:34.442986: Epoch 158 
2025-04-07 02:05:34.443123: Current learning rate: 0.00857 
2025-04-07 02:10:07.841083: train_loss -0.7194 
2025-04-07 02:10:07.841504: val_loss -0.7596 
2025-04-07 02:10:07.841619: Pseudo dice [0.7571] 
2025-04-07 02:10:07.841700: Epoch time: 273.4 s 
2025-04-07 02:10:09.773467:  
2025-04-07 02:10:09.773711: Epoch 159 
2025-04-07 02:10:09.773840: Current learning rate: 0.00856 
2025-04-07 02:14:42.621945: train_loss -0.7523 
2025-04-07 02:14:42.622251: val_loss -0.734 
2025-04-07 02:14:42.622354: Pseudo dice [0.7703] 
2025-04-07 02:14:42.622446: Epoch time: 272.85 s 
2025-04-07 02:14:44.532331:  
2025-04-07 02:14:44.532588: Epoch 160 
2025-04-07 02:14:44.532720: Current learning rate: 0.00855 
2025-04-07 02:19:17.956636: train_loss -0.7693 
2025-04-07 02:19:17.957257: val_loss -0.7746 
2025-04-07 02:19:17.957368: Pseudo dice [0.7789] 
2025-04-07 02:19:17.957453: Epoch time: 273.43 s 
2025-04-07 02:19:20.145582:  
2025-04-07 02:19:20.145804: Epoch 161 
2025-04-07 02:19:20.145938: Current learning rate: 0.00854 
2025-04-07 02:23:53.209543: train_loss -0.7655 
2025-04-07 02:23:53.209860: val_loss -0.7601 
2025-04-07 02:23:53.209949: Pseudo dice [0.766] 
2025-04-07 02:23:53.210047: Epoch time: 273.07 s 
2025-04-07 02:23:55.106867:  
2025-04-07 02:23:55.107160: Epoch 162 
2025-04-07 02:23:55.107272: Current learning rate: 0.00853 
2025-04-07 02:28:27.973974: train_loss -0.7812 
2025-04-07 02:28:27.974287: val_loss -0.7324 
2025-04-07 02:28:27.974376: Pseudo dice [0.6836] 
2025-04-07 02:28:27.974478: Epoch time: 272.87 s 
2025-04-07 02:28:29.875905:  
2025-04-07 02:28:29.876142: Epoch 163 
2025-04-07 02:28:29.876259: Current learning rate: 0.00852 
2025-04-07 02:33:03.736479: train_loss -0.7539 
2025-04-07 02:33:03.737119: val_loss -0.7772 
2025-04-07 02:33:03.737218: Pseudo dice [0.7963] 
2025-04-07 02:33:03.737303: Epoch time: 273.86 s 
2025-04-07 02:33:05.661073:  
2025-04-07 02:33:05.661341: Epoch 164 
2025-04-07 02:33:05.661512: Current learning rate: 0.00851 
2025-04-07 02:37:39.911288: train_loss -0.7146 
2025-04-07 02:37:39.911618: val_loss -0.7288 
2025-04-07 02:37:39.911705: Pseudo dice [0.7306] 
2025-04-07 02:37:39.911830: Epoch time: 274.25 s 
2025-04-07 02:37:41.765047:  
2025-04-07 02:37:41.765279: Epoch 165 
2025-04-07 02:37:41.765406: Current learning rate: 0.0085 
2025-04-07 02:42:16.110621: train_loss -0.7214 
2025-04-07 02:42:16.110935: val_loss -0.7334 
2025-04-07 02:42:16.111022: Pseudo dice [0.7669] 
2025-04-07 02:42:16.111125: Epoch time: 274.35 s 
2025-04-07 02:42:17.961355:  
2025-04-07 02:42:17.961581: Epoch 166 
2025-04-07 02:42:17.961704: Current learning rate: 0.00849 
2025-04-07 02:46:52.227196: train_loss -0.7476 
2025-04-07 02:46:52.227520: val_loss -0.753 
2025-04-07 02:46:52.227597: Pseudo dice [0.794] 
2025-04-07 02:46:52.227682: Epoch time: 274.27 s 
2025-04-07 02:46:54.098011:  
2025-04-07 02:46:54.098196: Epoch 167 
2025-04-07 02:46:54.098351: Current learning rate: 0.00848 
2025-04-07 02:51:28.507177: train_loss -0.7394 
2025-04-07 02:51:28.507504: val_loss -0.7772 
2025-04-07 02:51:28.507587: Pseudo dice [0.7792] 
2025-04-07 02:51:28.507675: Epoch time: 274.41 s 
2025-04-07 02:51:30.681222:  
2025-04-07 02:51:30.681493: Epoch 168 
2025-04-07 02:51:30.681646: Current learning rate: 0.00847 
2025-04-07 02:56:05.007111: train_loss -0.7404 
2025-04-07 02:56:05.007435: val_loss -0.7661 
2025-04-07 02:56:05.007541: Pseudo dice [0.791] 
2025-04-07 02:56:05.007639: Epoch time: 274.33 s 
2025-04-07 02:56:06.901558:  
2025-04-07 02:56:06.901744: Epoch 169 
2025-04-07 02:56:06.901921: Current learning rate: 0.00847 
2025-04-07 03:00:40.945413: train_loss -0.7504 
2025-04-07 03:00:40.945750: val_loss -0.7763 
2025-04-07 03:00:40.945910: Pseudo dice [0.789] 
2025-04-07 03:00:40.946005: Epoch time: 274.05 s 
2025-04-07 03:00:42.925506:  
2025-04-07 03:00:42.925721: Epoch 170 
2025-04-07 03:00:42.925834: Current learning rate: 0.00846 
2025-04-07 03:05:16.778580: train_loss -0.7672 
2025-04-07 03:05:16.778901: val_loss -0.7608 
2025-04-07 03:05:16.778984: Pseudo dice [0.7688] 
2025-04-07 03:05:16.779070: Epoch time: 273.86 s 
2025-04-07 03:05:18.676734:  
2025-04-07 03:05:18.677136: Epoch 171 
2025-04-07 03:05:18.677320: Current learning rate: 0.00845 
2025-04-07 03:09:52.700506: train_loss -0.7771 
2025-04-07 03:09:52.700803: val_loss -0.7814 
2025-04-07 03:09:52.700881: Pseudo dice [0.78] 
2025-04-07 03:09:52.700963: Epoch time: 274.03 s 
2025-04-07 03:09:54.602574:  
2025-04-07 03:09:54.602766: Epoch 172 
2025-04-07 03:09:54.602895: Current learning rate: 0.00844 
2025-04-07 03:14:29.362300: train_loss -0.763 
2025-04-07 03:14:29.362561: val_loss -0.7256 
2025-04-07 03:14:29.362644: Pseudo dice [0.6759] 
2025-04-07 03:14:29.362743: Epoch time: 274.76 s 
2025-04-07 03:14:31.257097:  
2025-04-07 03:14:31.257324: Epoch 173 
2025-04-07 03:14:31.257439: Current learning rate: 0.00843 
2025-04-07 03:19:05.922948: train_loss -0.7768 
2025-04-07 03:19:05.923269: val_loss -0.8151 
2025-04-07 03:19:05.923356: Pseudo dice [0.8145] 
2025-04-07 03:19:05.923458: Epoch time: 274.67 s 
2025-04-07 03:19:07.811255:  
2025-04-07 03:19:07.811472: Epoch 174 
2025-04-07 03:19:07.811606: Current learning rate: 0.00842 
2025-04-07 03:23:42.614381: train_loss -0.7781 
2025-04-07 03:23:42.614694: val_loss -0.7865 
2025-04-07 03:23:42.614782: Pseudo dice [0.8045] 
2025-04-07 03:23:42.614884: Epoch time: 274.81 s 
2025-04-07 03:23:44.515781:  
2025-04-07 03:23:44.516060: Epoch 175 
2025-04-07 03:23:44.516187: Current learning rate: 0.00841 
2025-04-07 03:28:19.163567: train_loss -0.7708 
2025-04-07 03:28:19.163891: val_loss -0.7184 
2025-04-07 03:28:19.163981: Pseudo dice [0.7794] 
2025-04-07 03:28:19.164079: Epoch time: 274.65 s 
2025-04-07 03:28:21.357223:  
2025-04-07 03:28:21.357482: Epoch 176 
2025-04-07 03:28:21.357609: Current learning rate: 0.0084 
2025-04-07 03:32:55.906004: train_loss -0.7444 
2025-04-07 03:32:55.906574: val_loss -0.7572 
2025-04-07 03:32:55.906690: Pseudo dice [0.7764] 
2025-04-07 03:32:55.906776: Epoch time: 274.55 s 
2025-04-07 03:32:57.808683:  
2025-04-07 03:32:57.808908: Epoch 177 
2025-04-07 03:32:57.809023: Current learning rate: 0.00839 
2025-04-07 03:37:31.756881: train_loss -0.7176 
2025-04-07 03:37:31.757187: val_loss -0.7141 
2025-04-07 03:37:31.757301: Pseudo dice [0.7671] 
2025-04-07 03:37:31.757386: Epoch time: 273.95 s 
2025-04-07 03:37:33.637956:  
2025-04-07 03:37:33.638175: Epoch 178 
2025-04-07 03:37:33.638290: Current learning rate: 0.00838 
2025-04-07 03:42:06.274650: train_loss -0.7484 
2025-04-07 03:42:06.274949: val_loss -0.7395 
2025-04-07 03:42:06.275031: Pseudo dice [0.7544] 
2025-04-07 03:42:06.275115: Epoch time: 272.64 s 
2025-04-07 03:42:08.149131:  
2025-04-07 03:42:08.149395: Epoch 179 
2025-04-07 03:42:08.149532: Current learning rate: 0.00837 
2025-04-07 03:46:41.681363: train_loss -0.7334 
2025-04-07 03:46:41.681763: val_loss -0.7193 
2025-04-07 03:46:41.681866: Pseudo dice [0.7568] 
2025-04-07 03:46:41.681959: Epoch time: 273.54 s 
2025-04-07 03:46:43.569754:  
2025-04-07 03:46:43.569935: Epoch 180 
2025-04-07 03:46:43.570114: Current learning rate: 0.00836 
2025-04-07 03:51:16.015017: train_loss -0.7328 
2025-04-07 03:51:16.015344: val_loss -0.7725 
2025-04-07 03:51:16.015528: Pseudo dice [0.801] 
2025-04-07 03:51:16.015628: Epoch time: 272.45 s 
2025-04-07 03:51:17.894811:  
2025-04-07 03:51:17.895023: Epoch 181 
2025-04-07 03:51:17.895137: Current learning rate: 0.00836 
2025-04-07 03:55:49.705091: train_loss -0.7389 
2025-04-07 03:55:49.705448: val_loss -0.7397 
2025-04-07 03:55:49.705571: Pseudo dice [0.7853] 
2025-04-07 03:55:49.705669: Epoch time: 271.81 s 
2025-04-07 03:55:51.606861:  
2025-04-07 03:55:51.607055: Epoch 182 
2025-04-07 03:55:51.607201: Current learning rate: 0.00835 
2025-04-07 04:00:23.745392: train_loss -0.7401 
2025-04-07 04:00:23.745732: val_loss -0.7509 
2025-04-07 04:00:23.745826: Pseudo dice [0.7905] 
2025-04-07 04:00:23.745928: Epoch time: 272.14 s 
2025-04-07 04:00:25.625253:  
2025-04-07 04:00:25.625427: Epoch 183 
2025-04-07 04:00:25.625584: Current learning rate: 0.00834 
2025-04-07 04:04:58.303199: train_loss -0.7338 
2025-04-07 04:04:58.303555: val_loss -0.7825 
2025-04-07 04:04:58.303640: Pseudo dice [0.8134] 
2025-04-07 04:04:58.303739: Epoch time: 272.68 s 
2025-04-07 04:05:00.545750:  
2025-04-07 04:05:00.546014: Epoch 184 
2025-04-07 04:05:00.546131: Current learning rate: 0.00833 
2025-04-07 04:09:32.982326: train_loss -0.7371 
2025-04-07 04:09:32.982713: val_loss -0.7537 
2025-04-07 04:09:32.982866: Pseudo dice [0.7866] 
2025-04-07 04:09:32.982964: Epoch time: 272.44 s 
2025-04-07 04:09:34.876225:  
2025-04-07 04:09:34.876530: Epoch 185 
2025-04-07 04:09:34.876684: Current learning rate: 0.00832 
2025-04-07 04:14:07.636915: train_loss -0.7632 
2025-04-07 04:14:07.637242: val_loss -0.7689 
2025-04-07 04:14:07.637374: Pseudo dice [0.7915] 
2025-04-07 04:14:07.637478: Epoch time: 272.76 s 
2025-04-07 04:14:07.637536: Yayy! New best EMA pseudo Dice: 0.7801 
2025-04-07 04:14:10.760867:  
2025-04-07 04:14:10.761071: Epoch 186 
2025-04-07 04:14:10.761184: Current learning rate: 0.00831 
2025-04-07 04:18:44.737329: train_loss -0.7162 
2025-04-07 04:18:44.737637: val_loss -0.7436 
2025-04-07 04:18:44.737721: Pseudo dice [0.7547] 
2025-04-07 04:18:44.737807: Epoch time: 273.98 s 
2025-04-07 04:18:46.620131:  
2025-04-07 04:18:46.620358: Epoch 187 
2025-04-07 04:18:46.620473: Current learning rate: 0.0083 
2025-04-07 04:23:20.384004: train_loss -0.7134 
2025-04-07 04:23:20.384387: val_loss -0.6662 
2025-04-07 04:23:20.384483: Pseudo dice [0.6559] 
2025-04-07 04:23:20.384586: Epoch time: 273.77 s 
2025-04-07 04:23:22.267121:  
2025-04-07 04:23:22.267436: Epoch 188 
2025-04-07 04:23:22.267601: Current learning rate: 0.00829 
2025-04-07 04:27:56.431472: train_loss -0.6543 
2025-04-07 04:27:56.431822: val_loss -0.7516 
2025-04-07 04:27:56.431921: Pseudo dice [0.7698] 
2025-04-07 04:27:56.432020: Epoch time: 274.17 s 
2025-04-07 04:27:58.312583:  
2025-04-07 04:27:58.312814: Epoch 189 
2025-04-07 04:27:58.312951: Current learning rate: 0.00828 
2025-04-07 04:32:32.454673: train_loss -0.709 
2025-04-07 04:32:32.454980: val_loss -0.7265 
2025-04-07 04:32:32.455063: Pseudo dice [0.7511] 
2025-04-07 04:32:32.455145: Epoch time: 274.15 s 
2025-04-07 04:32:34.367545:  
2025-04-07 04:32:34.367829: Epoch 190 
2025-04-07 04:32:34.367965: Current learning rate: 0.00827 
2025-04-07 04:37:08.661938: train_loss -0.6841 
2025-04-07 04:37:08.662707: val_loss -0.7087 
2025-04-07 04:37:08.662813: Pseudo dice [0.7191] 
2025-04-07 04:37:08.662903: Epoch time: 274.3 s 
2025-04-07 04:37:10.899422:  
2025-04-07 04:37:10.899630: Epoch 191 
2025-04-07 04:37:10.899743: Current learning rate: 0.00826 
2025-04-07 04:41:44.663242: train_loss -0.7073 
2025-04-07 04:41:44.663588: val_loss -0.7431 
2025-04-07 04:41:44.663728: Pseudo dice [0.7704] 
2025-04-07 04:41:44.663824: Epoch time: 273.77 s 
2025-04-07 04:41:46.589030:  
2025-04-07 04:41:46.589217: Epoch 192 
2025-04-07 04:41:46.589355: Current learning rate: 0.00825 
2025-04-07 04:46:21.758813: train_loss -0.7392 
2025-04-07 04:46:21.761157: val_loss -0.7452 
2025-04-07 04:46:21.761292: Pseudo dice [0.7573] 
2025-04-07 04:46:21.761386: Epoch time: 275.17 s 
2025-04-07 04:46:23.755388:  
2025-04-07 04:46:23.755627: Epoch 193 
2025-04-07 04:46:23.755830: Current learning rate: 0.00824 
2025-04-07 04:50:57.254258: train_loss -0.7677 
2025-04-07 04:50:57.254571: val_loss -0.6731 
2025-04-07 04:50:57.254657: Pseudo dice [0.7234] 
2025-04-07 04:50:57.254790: Epoch time: 273.5 s 
2025-04-07 04:50:59.165916:  
2025-04-07 04:50:59.166143: Epoch 194 
2025-04-07 04:50:59.166257: Current learning rate: 0.00824 
2025-04-07 04:55:33.799232: train_loss -0.7191 
2025-04-07 04:55:33.799599: val_loss -0.7536 
2025-04-07 04:55:33.799742: Pseudo dice [0.7929] 
2025-04-07 04:55:33.799860: Epoch time: 274.64 s 
2025-04-07 04:55:35.708284:  
2025-04-07 04:55:35.708487: Epoch 195 
2025-04-07 04:55:35.708595: Current learning rate: 0.00823 
2025-04-07 05:00:11.116835: train_loss -0.745 
2025-04-07 05:00:11.117165: val_loss -0.7544 
2025-04-07 05:00:11.117246: Pseudo dice [0.7744] 
2025-04-07 05:00:11.117386: Epoch time: 275.41 s 
2025-04-07 05:00:13.021042:  
2025-04-07 05:00:13.021253: Epoch 196 
2025-04-07 05:00:13.021358: Current learning rate: 0.00822 
2025-04-07 05:04:47.908348: train_loss -0.7071 
2025-04-07 05:04:47.913449: val_loss -0.7639 
2025-04-07 05:04:47.913556: Pseudo dice [0.7819] 
2025-04-07 05:04:47.913650: Epoch time: 274.89 s 
2025-04-07 05:04:49.830503:  
2025-04-07 05:04:49.830729: Epoch 197 
2025-04-07 05:04:49.830854: Current learning rate: 0.00821 
2025-04-07 05:09:24.476679: train_loss -0.7342 
2025-04-07 05:09:24.477013: val_loss -0.7777 
2025-04-07 05:09:24.477135: Pseudo dice [0.8047] 
2025-04-07 05:09:24.477237: Epoch time: 274.65 s 
2025-04-07 05:09:26.406568:  
2025-04-07 05:09:26.406768: Epoch 198 
2025-04-07 05:09:26.406882: Current learning rate: 0.0082 
2025-04-07 05:14:00.885772: train_loss -0.7637 
2025-04-07 05:14:00.886097: val_loss -0.7954 
2025-04-07 05:14:00.886185: Pseudo dice [0.8178] 
2025-04-07 05:14:00.886287: Epoch time: 274.48 s 
2025-04-07 05:14:03.117146:  
2025-04-07 05:14:03.117441: Epoch 199 
2025-04-07 05:14:03.117596: Current learning rate: 0.00819 
2025-04-07 05:18:37.608997: train_loss -0.7724 
2025-04-07 05:18:37.622733: val_loss -0.7396 
2025-04-07 05:18:37.622843: Pseudo dice [0.7899] 
2025-04-07 05:18:37.623044: Epoch time: 274.5 s 
2025-04-07 05:18:40.831452:  
2025-04-07 05:18:40.831676: Epoch 200 
2025-04-07 05:18:40.831909: Current learning rate: 0.00818 
2025-04-07 05:23:15.067976: train_loss -0.7692 
2025-04-07 05:23:15.068261: val_loss -0.7663 
2025-04-07 05:23:15.068388: Pseudo dice [0.8021] 
2025-04-07 05:23:15.068476: Epoch time: 274.24 s 
2025-04-07 05:23:16.981312:  
2025-04-07 05:23:16.981537: Epoch 201 
2025-04-07 05:23:16.981656: Current learning rate: 0.00817 
2025-04-07 05:27:51.754399: train_loss -0.764 
2025-04-07 05:27:51.759010: val_loss -0.7362 
2025-04-07 05:27:51.759138: Pseudo dice [0.795] 
2025-04-07 05:27:51.759225: Epoch time: 274.78 s 
2025-04-07 05:27:53.677940:  
2025-04-07 05:27:53.678227: Epoch 202 
2025-04-07 05:27:53.678374: Current learning rate: 0.00816 
2025-04-07 05:32:28.970770: train_loss -0.7289 
2025-04-07 05:32:28.971100: val_loss -0.717 
2025-04-07 05:32:28.971216: Pseudo dice [0.5985] 
2025-04-07 05:32:28.971324: Epoch time: 275.3 s 
2025-04-07 05:32:30.903827:  
2025-04-07 05:32:30.904127: Epoch 203 
2025-04-07 05:32:30.904306: Current learning rate: 0.00815 
2025-04-07 05:37:05.787675: train_loss -0.7383 
2025-04-07 05:37:05.793560: val_loss -0.7715 
2025-04-07 05:37:05.793646: Pseudo dice [0.8019] 
2025-04-07 05:37:05.793725: Epoch time: 274.89 s 
2025-04-07 05:37:07.713145:  
2025-04-07 05:37:07.713348: Epoch 204 
2025-04-07 05:37:07.713476: Current learning rate: 0.00814 
2025-04-07 05:41:41.412200: train_loss -0.7745 
2025-04-07 05:41:41.412556: val_loss -0.7998 
2025-04-07 05:41:41.412664: Pseudo dice [0.8147] 
2025-04-07 05:41:41.412764: Epoch time: 273.7 s 
2025-04-07 05:41:43.327886:  
2025-04-07 05:41:43.328123: Epoch 205 
2025-04-07 05:41:43.328249: Current learning rate: 0.00813 
2025-04-07 05:46:17.356073: train_loss -0.7547 
2025-04-07 05:46:17.356845: val_loss -0.7154 
2025-04-07 05:46:17.357007: Pseudo dice [0.6674] 
2025-04-07 05:46:17.357096: Epoch time: 274.03 s 
2025-04-07 05:46:19.185513:  
2025-04-07 05:46:19.185736: Epoch 206 
2025-04-07 05:46:19.185869: Current learning rate: 0.00813 
2025-04-07 05:50:53.677343: train_loss -0.7113 
2025-04-07 05:50:53.677933: val_loss -0.761 
2025-04-07 05:50:53.678073: Pseudo dice [0.7923] 
2025-04-07 05:50:53.678224: Epoch time: 274.5 s 
2025-04-07 05:50:55.806510:  
2025-04-07 05:50:55.806761: Epoch 207 
2025-04-07 05:50:55.806910: Current learning rate: 0.00812 
2025-04-07 05:55:30.165718: train_loss -0.7077 
2025-04-07 05:55:30.166045: val_loss -0.7423 
2025-04-07 05:55:30.166130: Pseudo dice [0.7775] 
2025-04-07 05:55:30.166233: Epoch time: 274.36 s 
2025-04-07 05:55:31.990353:  
2025-04-07 05:55:31.990560: Epoch 208 
2025-04-07 05:55:31.990681: Current learning rate: 0.00811 
2025-04-07 06:00:06.806414: train_loss -0.7184 
2025-04-07 06:00:06.806729: val_loss -0.7728 
2025-04-07 06:00:06.806813: Pseudo dice [0.7957] 
2025-04-07 06:00:06.806931: Epoch time: 274.82 s 
2025-04-07 06:00:08.635815:  
2025-04-07 06:00:08.636136: Epoch 209 
2025-04-07 06:00:08.636289: Current learning rate: 0.0081 
2025-04-07 06:04:43.027043: train_loss -0.7428 
2025-04-07 06:04:43.027369: val_loss -0.7876 
2025-04-07 06:04:43.027454: Pseudo dice [0.806] 
2025-04-07 06:04:43.027543: Epoch time: 274.4 s 
2025-04-07 06:04:44.875608:  
2025-04-07 06:04:44.875970: Epoch 210 
2025-04-07 06:04:44.876139: Current learning rate: 0.00809 
2025-04-07 06:09:19.233951: train_loss -0.7488 
2025-04-07 06:09:19.234304: val_loss -0.6971 
2025-04-07 06:09:19.234453: Pseudo dice [0.7365] 
2025-04-07 06:09:19.234599: Epoch time: 274.36 s 
2025-04-07 06:09:21.045140:  
2025-04-07 06:09:21.045350: Epoch 211 
2025-04-07 06:09:21.045479: Current learning rate: 0.00808 
2025-04-07 06:13:55.645422: train_loss -0.706 
2025-04-07 06:13:55.645754: val_loss -0.752 
2025-04-07 06:13:55.645852: Pseudo dice [0.7608] 
2025-04-07 06:13:55.645976: Epoch time: 274.6 s 
2025-04-07 06:13:57.514838:  
2025-04-07 06:13:57.515110: Epoch 212 
2025-04-07 06:13:57.515257: Current learning rate: 0.00807 
2025-04-07 06:18:31.958110: train_loss -0.722 
2025-04-07 06:18:31.958506: val_loss -0.7463 
2025-04-07 06:18:31.958592: Pseudo dice [0.76] 
2025-04-07 06:18:31.958683: Epoch time: 274.45 s 
2025-04-07 06:18:33.816119:  
2025-04-07 06:18:33.816335: Epoch 213 
2025-04-07 06:18:33.816456: Current learning rate: 0.00806 
2025-04-07 06:23:07.532578: train_loss -0.7554 
2025-04-07 06:23:07.532951: val_loss -0.7453 
2025-04-07 06:23:07.533064: Pseudo dice [0.7957] 
2025-04-07 06:23:07.533154: Epoch time: 273.72 s 
2025-04-07 06:23:09.526456:  
2025-04-07 06:23:09.526624: Epoch 214 
2025-04-07 06:23:09.526774: Current learning rate: 0.00805 
2025-04-07 06:27:42.921045: train_loss -0.7453 
2025-04-07 06:27:42.921811: val_loss -0.7637 
2025-04-07 06:27:42.921920: Pseudo dice [0.7021] 
2025-04-07 06:27:42.922004: Epoch time: 273.4 s 
2025-04-07 06:27:45.043236:  
2025-04-07 06:27:45.043447: Epoch 215 
2025-04-07 06:27:45.043562: Current learning rate: 0.00804 
2025-04-07 06:32:19.210992: train_loss -0.6781 
2025-04-07 06:32:19.211339: val_loss -0.7595 
2025-04-07 06:32:19.211432: Pseudo dice [0.7904] 
2025-04-07 06:32:19.211534: Epoch time: 274.17 s 
2025-04-07 06:32:21.045397:  
2025-04-07 06:32:21.045659: Epoch 216 
2025-04-07 06:32:21.045772: Current learning rate: 0.00803 
2025-04-07 06:36:55.386244: train_loss -0.7266 
2025-04-07 06:36:55.386577: val_loss -0.7931 
2025-04-07 06:36:55.386686: Pseudo dice [0.7993] 
2025-04-07 06:36:55.386783: Epoch time: 274.34 s 
2025-04-07 06:36:57.214594:  
2025-04-07 06:36:57.214821: Epoch 217 
2025-04-07 06:36:57.214940: Current learning rate: 0.00802 
2025-04-07 06:41:31.682281: train_loss -0.7499 
2025-04-07 06:41:31.682639: val_loss -0.7751 
2025-04-07 06:41:31.682788: Pseudo dice [0.7822] 
2025-04-07 06:41:31.682884: Epoch time: 274.47 s 
2025-04-07 06:41:33.505475:  
2025-04-07 06:41:33.505682: Epoch 218 
2025-04-07 06:41:33.505795: Current learning rate: 0.00801 
2025-04-07 06:46:07.635820: train_loss -0.7244 
2025-04-07 06:46:07.636393: val_loss -0.7541 
2025-04-07 06:46:07.636509: Pseudo dice [0.7849] 
2025-04-07 06:46:07.636596: Epoch time: 274.13 s 
2025-04-07 06:46:09.496872:  
2025-04-07 06:46:09.497125: Epoch 219 
2025-04-07 06:46:09.497266: Current learning rate: 0.00801 
2025-04-07 06:50:43.293810: train_loss -0.723 
2025-04-07 06:50:43.294150: val_loss -0.7693 
2025-04-07 06:50:43.294280: Pseudo dice [0.7778] 
2025-04-07 06:50:43.294382: Epoch time: 273.8 s 
2025-04-07 06:50:45.122831:  
2025-04-07 06:50:45.123122: Epoch 220 
2025-04-07 06:50:45.123331: Current learning rate: 0.008 
2025-04-07 06:55:18.387702: train_loss -0.7593 
2025-04-07 06:55:18.388008: val_loss -0.7486 
2025-04-07 06:55:18.388140: Pseudo dice [0.8005] 
2025-04-07 06:55:18.388257: Epoch time: 273.27 s 
2025-04-07 06:55:20.236136:  
2025-04-07 06:55:20.236403: Epoch 221 
2025-04-07 06:55:20.236551: Current learning rate: 0.00799 
2025-04-07 06:59:54.409995: train_loss -0.7624 
2025-04-07 06:59:54.410606: val_loss -0.7761 
2025-04-07 06:59:54.410899: Pseudo dice [0.8] 
2025-04-07 06:59:54.410985: Epoch time: 274.18 s 
2025-04-07 06:59:56.253561:  
2025-04-07 06:59:56.253775: Epoch 222 
2025-04-07 06:59:56.253910: Current learning rate: 0.00798 
2025-04-07 07:04:30.194328: train_loss -0.7756 
2025-04-07 07:04:30.194720: val_loss -0.7722 
2025-04-07 07:04:30.194829: Pseudo dice [0.8045] 
2025-04-07 07:04:30.194923: Epoch time: 273.94 s 
2025-04-07 07:04:30.194982: Yayy! New best EMA pseudo Dice: 0.7803 
2025-04-07 07:04:33.608496:  
2025-04-07 07:04:33.608794: Epoch 223 
2025-04-07 07:04:33.608943: Current learning rate: 0.00797 
2025-04-07 07:09:09.023557: train_loss -0.7783 
2025-04-07 07:09:09.024366: val_loss -0.7852 
2025-04-07 07:09:09.024527: Pseudo dice [0.7966] 
2025-04-07 07:09:09.024632: Epoch time: 275.42 s 
2025-04-07 07:09:09.024738: Yayy! New best EMA pseudo Dice: 0.7819 
2025-04-07 07:09:12.347620:  
2025-04-07 07:09:12.347900: Epoch 224 
2025-04-07 07:09:12.348063: Current learning rate: 0.00796 
2025-04-07 07:13:46.473229: train_loss -0.7698 
2025-04-07 07:13:46.473551: val_loss -0.7843 
2025-04-07 07:13:46.473636: Pseudo dice [0.7849] 
2025-04-07 07:13:46.473721: Epoch time: 274.13 s 
2025-04-07 07:13:46.473794: Yayy! New best EMA pseudo Dice: 0.7822 
2025-04-07 07:13:49.639041:  
2025-04-07 07:13:49.639241: Epoch 225 
2025-04-07 07:13:49.639366: Current learning rate: 0.00795 
2025-04-07 07:18:24.491515: train_loss -0.764 
2025-04-07 07:18:24.492162: val_loss -0.7728 
2025-04-07 07:18:24.492254: Pseudo dice [0.8021] 
2025-04-07 07:18:24.492339: Epoch time: 274.86 s 
2025-04-07 07:18:24.492406: Yayy! New best EMA pseudo Dice: 0.7842 
2025-04-07 07:18:27.572639:  
2025-04-07 07:18:27.572887: Epoch 226 
2025-04-07 07:18:27.573008: Current learning rate: 0.00794 
2025-04-07 07:23:02.029378: train_loss -0.7677 
2025-04-07 07:23:02.030005: val_loss -0.7523 
2025-04-07 07:23:02.030209: Pseudo dice [0.7747] 
2025-04-07 07:23:02.030298: Epoch time: 274.46 s 
2025-04-07 07:23:03.837006:  
2025-04-07 07:23:03.837206: Epoch 227 
2025-04-07 07:23:03.837322: Current learning rate: 0.00793 
2025-04-07 07:27:37.636247: train_loss -0.7609 
2025-04-07 07:27:37.636571: val_loss -0.7458 
2025-04-07 07:27:37.636656: Pseudo dice [0.7744] 
2025-04-07 07:27:37.636758: Epoch time: 273.8 s 
2025-04-07 07:27:39.455890:  
2025-04-07 07:27:39.456110: Epoch 228 
2025-04-07 07:27:39.456269: Current learning rate: 0.00792 
2025-04-07 07:32:13.076797: train_loss -0.763 
2025-04-07 07:32:13.077680: val_loss -0.7705 
2025-04-07 07:32:13.077783: Pseudo dice [0.778] 
2025-04-07 07:32:13.077865: Epoch time: 273.62 s 
2025-04-07 07:32:14.882188:  
2025-04-07 07:32:14.882490: Epoch 229 
2025-04-07 07:32:14.882664: Current learning rate: 0.00791 
2025-04-07 07:36:48.591468: train_loss -0.7661 
2025-04-07 07:36:48.591848: val_loss -0.7962 
2025-04-07 07:36:48.591993: Pseudo dice [0.8029] 
2025-04-07 07:36:48.592073: Epoch time: 273.71 s 
2025-04-07 07:36:50.395564:  
2025-04-07 07:36:50.395791: Epoch 230 
2025-04-07 07:36:50.395917: Current learning rate: 0.0079 
2025-04-07 07:41:24.527494: train_loss -0.7536 
2025-04-07 07:41:24.528081: val_loss -0.7671 
2025-04-07 07:41:24.528182: Pseudo dice [0.7775] 
2025-04-07 07:41:24.528269: Epoch time: 274.14 s 
2025-04-07 07:41:26.347532:  
2025-04-07 07:41:26.347820: Epoch 231 
2025-04-07 07:41:26.347979: Current learning rate: 0.00789 
2025-04-07 07:46:00.321165: train_loss -0.7732 
2025-04-07 07:46:00.321517: val_loss -0.7754 
2025-04-07 07:46:00.321607: Pseudo dice [0.7906] 
2025-04-07 07:46:00.321703: Epoch time: 273.98 s 
2025-04-07 07:46:02.120393:  
2025-04-07 07:46:02.120661: Epoch 232 
2025-04-07 07:46:02.120793: Current learning rate: 0.00789 
2025-04-07 07:50:36.346265: train_loss -0.7783 
2025-04-07 07:50:36.346806: val_loss -0.7728 
2025-04-07 07:50:36.346925: Pseudo dice [0.7897] 
2025-04-07 07:50:36.347038: Epoch time: 274.23 s 
2025-04-07 07:50:36.347150: Yayy! New best EMA pseudo Dice: 0.7847 
2025-04-07 07:50:39.382529:  
2025-04-07 07:50:39.382766: Epoch 233 
2025-04-07 07:50:39.382889: Current learning rate: 0.00788 
2025-04-07 07:55:12.384877: train_loss -0.7682 
2025-04-07 07:55:12.385221: val_loss -0.7581 
2025-04-07 07:55:12.385315: Pseudo dice [0.7851] 
2025-04-07 07:55:12.385418: Epoch time: 273.01 s 
2025-04-07 07:55:12.385483: Yayy! New best EMA pseudo Dice: 0.7847 
2025-04-07 07:55:15.504628:  
2025-04-07 07:55:15.504830: Epoch 234 
2025-04-07 07:55:15.504942: Current learning rate: 0.00787 
2025-04-07 08:01:22.853313: train_loss -0.7545 
2025-04-07 08:01:22.854053: val_loss -0.7803 
2025-04-07 08:01:22.854204: Pseudo dice [0.8111] 
2025-04-07 08:01:22.854288: Epoch time: 367.35 s 
2025-04-07 08:01:22.854343: Yayy! New best EMA pseudo Dice: 0.7873 
2025-04-07 08:01:26.036000:  
2025-04-07 08:01:26.036271: Epoch 235 
2025-04-07 08:01:26.036387: Current learning rate: 0.00786 
2025-04-07 08:05:58.609178: train_loss -0.7707 
2025-04-07 08:05:58.609494: val_loss -0.7642 
2025-04-07 08:05:58.609578: Pseudo dice [0.7766] 
2025-04-07 08:05:58.609710: Epoch time: 272.58 s 
2025-04-07 08:06:00.446583:  
2025-04-07 08:06:00.446792: Epoch 236 
2025-04-07 08:06:00.446916: Current learning rate: 0.00785 
2025-04-07 08:11:28.679828: train_loss -0.7581 
2025-04-07 08:11:28.680423: val_loss -0.7747 
2025-04-07 08:11:28.680553: Pseudo dice [0.8144] 
2025-04-07 08:11:28.680649: Epoch time: 328.24 s 
2025-04-07 08:11:28.680713: Yayy! New best EMA pseudo Dice: 0.7891 
2025-04-07 08:11:31.833464:  
2025-04-07 08:11:31.833643: Epoch 237 
2025-04-07 08:11:31.833809: Current learning rate: 0.00784 
2025-04-07 08:16:05.217542: train_loss -0.7533 
2025-04-07 08:16:05.217852: val_loss -0.7669 
2025-04-07 08:16:05.218012: Pseudo dice [0.7899] 
2025-04-07 08:16:05.218163: Epoch time: 273.39 s 
2025-04-07 08:16:05.218277: Yayy! New best EMA pseudo Dice: 0.7892 
2025-04-07 08:16:08.636331:  
2025-04-07 08:16:08.636530: Epoch 238 
2025-04-07 08:16:08.636662: Current learning rate: 0.00783 
2025-04-07 08:21:11.974871: train_loss -0.7806 
2025-04-07 08:21:11.975352: val_loss -0.8093 
2025-04-07 08:21:11.975497: Pseudo dice [0.8195] 
2025-04-07 08:21:11.975697: Epoch time: 303.34 s 
2025-04-07 08:21:11.975921: Yayy! New best EMA pseudo Dice: 0.7922 
2025-04-07 08:21:15.726697:  
2025-04-07 08:21:15.726920: Epoch 239 
2025-04-07 08:21:15.727051: Current learning rate: 0.00782 
2025-04-07 08:25:49.130433: train_loss -0.7672 
2025-04-07 08:25:49.130746: val_loss -0.795 
2025-04-07 08:25:49.130832: Pseudo dice [0.8145] 
2025-04-07 08:25:49.130928: Epoch time: 273.41 s 
2025-04-07 08:25:49.130983: Yayy! New best EMA pseudo Dice: 0.7944 
2025-04-07 08:25:52.316221:  
2025-04-07 08:25:52.316483: Epoch 240 
2025-04-07 08:25:52.316664: Current learning rate: 0.00781 
2025-04-07 08:30:32.563600: train_loss -0.715 
2025-04-07 08:30:32.564202: val_loss -0.7583 
2025-04-07 08:30:32.564357: Pseudo dice [0.7886] 
2025-04-07 08:30:32.564459: Epoch time: 280.25 s 
2025-04-07 08:30:34.893181:  
2025-04-07 08:30:34.893412: Epoch 241 
2025-04-07 08:30:34.893532: Current learning rate: 0.0078 
2025-04-07 08:35:10.426486: train_loss -0.7265 
2025-04-07 08:35:10.426798: val_loss -0.7355 
2025-04-07 08:35:10.426880: Pseudo dice [0.761] 
2025-04-07 08:35:10.426975: Epoch time: 275.54 s 
2025-04-07 08:35:12.283048:  
2025-04-07 08:35:12.283314: Epoch 242 
2025-04-07 08:35:12.283460: Current learning rate: 0.00779 
2025-04-07 08:39:47.295093: train_loss -0.745 
2025-04-07 08:39:47.295398: val_loss -0.7621 
2025-04-07 08:39:47.295511: Pseudo dice [0.7855] 
2025-04-07 08:39:47.295598: Epoch time: 275.02 s 
2025-04-07 08:39:49.175746:  
2025-04-07 08:39:49.175982: Epoch 243 
2025-04-07 08:39:49.176095: Current learning rate: 0.00778 
2025-04-07 08:44:52.417191: train_loss -0.7713 
2025-04-07 08:44:52.417738: val_loss -0.7621 
2025-04-07 08:44:52.417843: Pseudo dice [0.7907] 
2025-04-07 08:44:52.417925: Epoch time: 303.25 s 
2025-04-07 08:44:54.268676:  
2025-04-07 08:44:54.268943: Epoch 244 
2025-04-07 08:44:54.269068: Current learning rate: 0.00777 
2025-04-07 08:49:27.962320: train_loss -0.7646 
2025-04-07 08:49:27.962656: val_loss -0.7907 
2025-04-07 08:49:27.962742: Pseudo dice [0.8136] 
2025-04-07 08:49:27.962838: Epoch time: 273.7 s 
2025-04-07 08:49:29.808125:  
2025-04-07 08:49:29.808295: Epoch 245 
2025-04-07 08:49:29.808410: Current learning rate: 0.00777 
2025-04-07 08:54:29.889005: train_loss -0.7465 
2025-04-07 08:54:29.889775: val_loss -0.7437 
2025-04-07 08:54:29.889880: Pseudo dice [0.783] 
2025-04-07 08:54:29.889966: Epoch time: 300.08 s 
2025-04-07 08:54:31.743440:  
2025-04-07 08:54:31.743661: Epoch 246 
2025-04-07 08:54:31.743799: Current learning rate: 0.00776 
2025-04-07 08:59:05.277727: train_loss -0.758 
2025-04-07 08:59:05.278051: val_loss -0.6873 
2025-04-07 08:59:05.278141: Pseudo dice [0.7537] 
2025-04-07 08:59:05.278241: Epoch time: 273.54 s 
2025-04-07 08:59:07.453137:  
2025-04-07 08:59:07.453381: Epoch 247 
2025-04-07 08:59:07.453523: Current learning rate: 0.00775 
2025-04-07 09:04:17.075018: train_loss -0.7683 
2025-04-07 09:04:17.075604: val_loss -0.7489 
2025-04-07 09:04:17.075710: Pseudo dice [0.7738] 
2025-04-07 09:04:17.075820: Epoch time: 309.63 s 
2025-04-07 09:04:18.938990:  
2025-04-07 09:04:18.939323: Epoch 248 
2025-04-07 09:04:18.939502: Current learning rate: 0.00774 
2025-04-07 09:08:52.751098: train_loss -0.7445 
2025-04-07 09:08:52.751499: val_loss -0.7615 
2025-04-07 09:08:52.751606: Pseudo dice [0.8095] 
2025-04-07 09:08:52.751702: Epoch time: 273.82 s 
2025-04-07 09:08:54.611528:  
2025-04-07 09:08:54.611725: Epoch 249 
2025-04-07 09:08:54.611907: Current learning rate: 0.00773 
2025-04-07 09:14:19.851372: train_loss -0.7879 
2025-04-07 09:14:19.852168: val_loss -0.7766 
2025-04-07 09:14:19.852268: Pseudo dice [0.8027] 
2025-04-07 09:14:19.852359: Epoch time: 325.24 s 
2025-04-07 09:14:22.915880:  
2025-04-07 09:14:22.916110: Epoch 250 
2025-04-07 09:14:22.916230: Current learning rate: 0.00772 
2025-04-07 09:18:55.562933: train_loss -0.7644 
2025-04-07 09:18:55.563281: val_loss -0.6902 
2025-04-07 09:18:55.563369: Pseudo dice [0.7841] 
2025-04-07 09:18:55.563538: Epoch time: 272.65 s 
2025-04-07 09:18:57.432080:  
2025-04-07 09:18:57.432277: Epoch 251 
2025-04-07 09:18:57.432403: Current learning rate: 0.00771 
2025-04-07 09:23:30.836655: train_loss -0.7508 
2025-04-07 09:23:30.838122: val_loss -0.7349 
2025-04-07 09:23:30.838249: Pseudo dice [0.7713] 
2025-04-07 09:23:30.838372: Epoch time: 273.41 s 
2025-04-07 09:23:32.772391:  
2025-04-07 09:23:32.772662: Epoch 252 
2025-04-07 09:23:32.772779: Current learning rate: 0.0077 
2025-04-07 09:28:06.482924: train_loss -0.7268 
2025-04-07 09:28:06.483244: val_loss -0.7281 
2025-04-07 09:28:06.483335: Pseudo dice [0.775] 
2025-04-07 09:28:06.483435: Epoch time: 273.71 s 
2025-04-07 09:28:08.313132:  
2025-04-07 09:28:08.313341: Epoch 253 
2025-04-07 09:28:08.313473: Current learning rate: 0.00769 
2025-04-07 09:32:42.555144: train_loss -0.7431 
2025-04-07 09:32:42.555462: val_loss -0.7357 
2025-04-07 09:32:42.555557: Pseudo dice [0.7516] 
2025-04-07 09:32:42.555672: Epoch time: 274.25 s 
2025-04-07 09:32:44.397713:  
2025-04-07 09:32:44.397919: Epoch 254 
2025-04-07 09:32:44.398034: Current learning rate: 0.00768 
2025-04-07 09:37:18.678534: train_loss -0.7377 
2025-04-07 09:37:18.679144: val_loss -0.7948 
2025-04-07 09:37:18.679246: Pseudo dice [0.8097] 
2025-04-07 09:37:18.679337: Epoch time: 274.28 s 
2025-04-07 09:37:20.819208:  
2025-04-07 09:37:20.819463: Epoch 255 
2025-04-07 09:37:20.819587: Current learning rate: 0.00767 
2025-04-07 09:41:54.700410: train_loss -0.79 
2025-04-07 09:41:54.700944: val_loss -0.7743 
2025-04-07 09:41:54.701054: Pseudo dice [0.8117] 
2025-04-07 09:41:54.701138: Epoch time: 273.89 s 
2025-04-07 09:41:56.556771:  
2025-04-07 09:41:56.557018: Epoch 256 
2025-04-07 09:41:56.557146: Current learning rate: 0.00766 
2025-04-07 09:46:30.550234: train_loss -0.7686 
2025-04-07 09:46:30.550534: val_loss -0.7394 
2025-04-07 09:46:30.550611: Pseudo dice [0.779] 
2025-04-07 09:46:30.550696: Epoch time: 274.0 s 
2025-04-07 09:46:32.404965:  
2025-04-07 09:46:32.405186: Epoch 257 
2025-04-07 09:46:32.405299: Current learning rate: 0.00765 
2025-04-07 09:51:06.126604: train_loss -0.7893 
2025-04-07 09:51:06.126948: val_loss -0.7644 
2025-04-07 09:51:06.127480: Pseudo dice [0.7811] 
2025-04-07 09:51:06.127587: Epoch time: 273.73 s 
2025-04-07 09:51:08.074372:  
2025-04-07 09:51:08.074630: Epoch 258 
2025-04-07 09:51:08.074786: Current learning rate: 0.00764 
2025-04-07 09:56:52.027060: train_loss -0.6878 
2025-04-07 09:56:52.027633: val_loss -0.6945 
2025-04-07 09:56:52.027741: Pseudo dice [0.7075] 
2025-04-07 09:56:52.027844: Epoch time: 343.96 s 
2025-04-07 09:56:53.867166:  
2025-04-07 09:56:53.867467: Epoch 259 
2025-04-07 09:56:53.867605: Current learning rate: 0.00764 
2025-04-07 10:01:27.403134: train_loss -0.7413 
2025-04-07 10:01:27.403587: val_loss -0.7797 
2025-04-07 10:01:27.403685: Pseudo dice [0.8076] 
2025-04-07 10:01:27.403781: Epoch time: 273.54 s 
2025-04-07 10:01:29.296732:  
2025-04-07 10:01:29.296947: Epoch 260 
2025-04-07 10:01:29.297060: Current learning rate: 0.00763 
2025-04-07 10:06:51.430886: train_loss -0.7099 
2025-04-07 10:06:51.431570: val_loss -0.7069 
2025-04-07 10:06:51.431712: Pseudo dice [0.7482] 
2025-04-07 10:06:51.431816: Epoch time: 322.14 s 
2025-04-07 10:06:53.273922:  
2025-04-07 10:06:53.274118: Epoch 261 
2025-04-07 10:06:53.274255: Current learning rate: 0.00762 
2025-04-07 10:11:27.277350: train_loss -0.7033 
2025-04-07 10:11:27.277679: val_loss -0.7084 
2025-04-07 10:11:27.277765: Pseudo dice [0.7729] 
2025-04-07 10:11:27.277873: Epoch time: 274.01 s 
2025-04-07 10:11:29.141239:  
2025-04-07 10:11:29.141471: Epoch 262 
2025-04-07 10:11:29.141615: Current learning rate: 0.00761 
2025-04-07 10:17:06.342599: train_loss -0.7461 
2025-04-07 10:17:06.343390: val_loss -0.7488 
2025-04-07 10:17:06.343480: Pseudo dice [0.7928] 
2025-04-07 10:17:06.343563: Epoch time: 337.21 s 
2025-04-07 10:17:08.485981:  
2025-04-07 10:17:08.486214: Epoch 263 
2025-04-07 10:17:08.486362: Current learning rate: 0.0076 
2025-04-07 10:21:57.230920: train_loss -0.744 
2025-04-07 10:21:57.231505: val_loss -0.7636 
2025-04-07 10:21:57.231612: Pseudo dice [0.7663] 
2025-04-07 10:21:57.231697: Epoch time: 288.75 s 
2025-04-07 10:21:59.079115:  
2025-04-07 10:21:59.079345: Epoch 264 
2025-04-07 10:21:59.079507: Current learning rate: 0.00759 
2025-04-07 10:27:12.022540: train_loss -0.7569 
2025-04-07 10:27:12.023078: val_loss -0.7594 
2025-04-07 10:27:12.023226: Pseudo dice [0.7778] 
2025-04-07 10:27:12.023315: Epoch time: 312.95 s 
2025-04-07 10:27:13.926765:  
2025-04-07 10:27:13.926975: Epoch 265 
2025-04-07 10:27:13.927128: Current learning rate: 0.00758 
2025-04-07 10:31:48.045332: train_loss -0.768 
2025-04-07 10:31:48.045640: val_loss -0.7937 
2025-04-07 10:31:48.045727: Pseudo dice [0.8079] 
2025-04-07 10:31:48.045850: Epoch time: 274.12 s 
2025-04-07 10:31:49.943427:  
2025-04-07 10:31:49.943614: Epoch 266 
2025-04-07 10:31:49.943737: Current learning rate: 0.00757 
2025-04-07 10:36:36.574676: train_loss -0.7755 
2025-04-07 10:36:36.575020: val_loss -0.7977 
2025-04-07 10:36:36.575102: Pseudo dice [0.8065] 
2025-04-07 10:36:36.575199: Epoch time: 286.64 s 
2025-04-07 10:36:38.431918:  
2025-04-07 10:36:38.432214: Epoch 267 
2025-04-07 10:36:38.432332: Current learning rate: 0.00756 
2025-04-07 10:41:11.470778: train_loss -0.7637 
2025-04-07 10:41:11.471100: val_loss -0.7944 
2025-04-07 10:41:11.471186: Pseudo dice [0.8] 
2025-04-07 10:41:11.471303: Epoch time: 273.04 s 
2025-04-07 10:41:13.323549:  
2025-04-07 10:41:13.323800: Epoch 268 
2025-04-07 10:41:13.323940: Current learning rate: 0.00755 
2025-04-07 10:46:20.531650: train_loss -0.7288 
2025-04-07 10:46:20.531897: val_loss -0.7461 
2025-04-07 10:46:20.531977: Pseudo dice [0.7496] 
2025-04-07 10:46:20.532081: Epoch time: 307.21 s 
2025-04-07 10:46:22.404585:  
2025-04-07 10:46:22.404872: Epoch 269 
2025-04-07 10:46:22.405020: Current learning rate: 0.00754 
2025-04-07 10:50:55.025180: train_loss -0.7697 
2025-04-07 10:50:55.025533: val_loss -0.7758 
2025-04-07 10:50:55.025621: Pseudo dice [0.7885] 
2025-04-07 10:50:55.025717: Epoch time: 272.62 s 
2025-04-07 10:50:56.949295:  
2025-04-07 10:50:56.949514: Epoch 270 
2025-04-07 10:50:56.949645: Current learning rate: 0.00753 
2025-04-07 10:55:44.747700: train_loss -0.7918 
2025-04-07 10:55:44.748241: val_loss -0.771 
2025-04-07 10:55:44.748350: Pseudo dice [0.793] 
2025-04-07 10:55:44.748433: Epoch time: 287.8 s 
2025-04-07 10:55:46.600280:  
2025-04-07 10:55:46.600521: Epoch 271 
2025-04-07 10:55:46.600669: Current learning rate: 0.00752 
2025-04-07 11:00:19.189718: train_loss -0.7926 
2025-04-07 11:00:19.190052: val_loss -0.762 
2025-04-07 11:00:19.190139: Pseudo dice [0.7945] 
2025-04-07 11:00:19.190234: Epoch time: 272.59 s 
2025-04-07 11:00:21.042072:  
2025-04-07 11:00:21.042346: Epoch 272 
2025-04-07 11:00:21.042483: Current learning rate: 0.00751 
2025-04-07 11:06:24.213937: train_loss -0.7807 
2025-04-07 11:06:24.214465: val_loss -0.7491 
2025-04-07 11:06:24.214627: Pseudo dice [0.7903] 
2025-04-07 11:06:24.214737: Epoch time: 363.18 s 
2025-04-07 11:06:26.098134:  
2025-04-07 11:06:26.098360: Epoch 273 
2025-04-07 11:06:26.098477: Current learning rate: 0.00751 
2025-04-07 11:10:58.164058: train_loss -0.777 
2025-04-07 11:10:58.164370: val_loss -0.7317 
2025-04-07 11:10:58.164458: Pseudo dice [0.7619] 
2025-04-07 11:10:58.164611: Epoch time: 272.07 s 
2025-04-07 11:11:00.021698:  
2025-04-07 11:11:00.021896: Epoch 274 
2025-04-07 11:11:00.022007: Current learning rate: 0.0075 
2025-04-07 11:17:19.254134: train_loss -0.7762 
2025-04-07 11:17:19.254734: val_loss -0.7587 
2025-04-07 11:17:19.254847: Pseudo dice [0.7889] 
2025-04-07 11:17:19.254932: Epoch time: 379.24 s 
2025-04-07 11:17:21.119424:  
2025-04-07 11:17:21.119655: Epoch 275 
2025-04-07 11:17:21.119782: Current learning rate: 0.00749 
2025-04-07 11:21:53.783226: train_loss -0.7597 
2025-04-07 11:21:53.783571: val_loss -0.7371 
2025-04-07 11:21:53.783660: Pseudo dice [0.6028] 
2025-04-07 11:21:53.783765: Epoch time: 272.67 s 
2025-04-07 11:21:55.641093:  
2025-04-07 11:21:55.641306: Epoch 276 
2025-04-07 11:21:55.641422: Current learning rate: 0.00748 
2025-04-07 11:27:36.500878: train_loss -0.7309 
2025-04-07 11:27:36.509071: val_loss -0.7519 
2025-04-07 11:27:36.509275: Pseudo dice [0.7837] 
2025-04-07 11:27:36.509356: Epoch time: 340.86 s 
2025-04-07 11:27:38.372965:  
2025-04-07 11:27:38.373152: Epoch 277 
2025-04-07 11:27:38.373276: Current learning rate: 0.00747 
2025-04-07 11:32:12.333515: train_loss -0.7005 
2025-04-07 11:32:12.333843: val_loss -0.7381 
2025-04-07 11:32:12.333923: Pseudo dice [0.7521] 
2025-04-07 11:32:12.334010: Epoch time: 273.96 s 
2025-04-07 11:32:14.184851:  
2025-04-07 11:32:14.185042: Epoch 278 
2025-04-07 11:32:14.185215: Current learning rate: 0.00746 
2025-04-07 11:38:06.005127: train_loss -0.7162 
2025-04-07 11:38:06.005840: val_loss -0.7669 
2025-04-07 11:38:06.005973: Pseudo dice [0.769] 
2025-04-07 11:38:06.006069: Epoch time: 351.82 s 
2025-04-07 11:38:07.854029:  
2025-04-07 11:38:07.854244: Epoch 279 
2025-04-07 11:38:07.854369: Current learning rate: 0.00745 
2025-04-07 11:42:43.074629: train_loss -0.7406 
2025-04-07 11:42:43.074933: val_loss -0.7926 
2025-04-07 11:42:43.075017: Pseudo dice [0.8199] 
2025-04-07 11:42:43.075204: Epoch time: 275.22 s 
2025-04-07 11:42:45.246115:  
2025-04-07 11:42:45.246423: Epoch 280 
2025-04-07 11:42:45.246547: Current learning rate: 0.00744 
2025-04-07 11:48:38.453585: train_loss -0.7819 
2025-04-07 11:48:38.454131: val_loss -0.793 
2025-04-07 11:48:38.454292: Pseudo dice [0.785] 
2025-04-07 11:48:38.454376: Epoch time: 353.21 s 
2025-04-07 11:48:40.309526:  
2025-04-07 11:48:40.309762: Epoch 281 
2025-04-07 11:48:40.309932: Current learning rate: 0.00743 
2025-04-07 11:53:13.613750: train_loss -0.7859 
2025-04-07 11:53:13.614106: val_loss -0.7834 
2025-04-07 11:53:13.614192: Pseudo dice [0.7878] 
2025-04-07 11:53:13.614283: Epoch time: 273.31 s 
2025-04-07 11:53:15.475693:  
2025-04-07 11:53:15.475913: Epoch 282 
2025-04-07 11:53:15.476048: Current learning rate: 0.00742 
2025-04-07 11:59:43.740646: train_loss -0.7872 
2025-04-07 11:59:43.741219: val_loss -0.7806 
2025-04-07 11:59:43.741318: Pseudo dice [0.8054] 
2025-04-07 11:59:43.741401: Epoch time: 388.27 s 
2025-04-07 11:59:45.602603:  
2025-04-07 11:59:45.602947: Epoch 283 
2025-04-07 11:59:45.603107: Current learning rate: 0.00741 
2025-04-07 12:04:18.862803: train_loss -0.7813 
2025-04-07 12:04:18.863216: val_loss -0.7794 
2025-04-07 12:04:18.863323: Pseudo dice [0.8057] 
2025-04-07 12:04:18.863426: Epoch time: 273.26 s 
2025-04-07 12:04:20.748841:  
2025-04-07 12:04:20.749051: Epoch 284 
2025-04-07 12:04:20.749167: Current learning rate: 0.0074 
2025-04-07 12:10:15.595256: train_loss -0.7858 
2025-04-07 12:10:15.595829: val_loss -0.7904 
2025-04-07 12:10:15.595933: Pseudo dice [0.7928] 
2025-04-07 12:10:15.596014: Epoch time: 354.85 s 
2025-04-07 12:10:17.457199:  
2025-04-07 12:10:17.457462: Epoch 285 
2025-04-07 12:10:17.457590: Current learning rate: 0.00739 
2025-04-07 12:14:51.300509: train_loss -0.7847 
2025-04-07 12:14:51.300804: val_loss -0.7736 
2025-04-07 12:14:51.300896: Pseudo dice [0.7861] 
2025-04-07 12:14:51.300996: Epoch time: 273.85 s 
2025-04-07 12:14:53.163032:  
2025-04-07 12:14:53.163317: Epoch 286 
2025-04-07 12:14:53.163448: Current learning rate: 0.00738 
2025-04-07 12:19:41.287809: train_loss -0.7791 
2025-04-07 12:19:41.288381: val_loss -0.7665 
2025-04-07 12:19:41.288488: Pseudo dice [0.7759] 
2025-04-07 12:19:41.288574: Epoch time: 288.13 s 
2025-04-07 12:19:43.187119:  
2025-04-07 12:19:43.187336: Epoch 287 
2025-04-07 12:19:43.187527: Current learning rate: 0.00738 
2025-04-07 12:24:17.105695: train_loss -0.7798 
2025-04-07 12:24:17.105995: val_loss -0.7826 
2025-04-07 12:24:17.106105: Pseudo dice [0.7848] 
2025-04-07 12:24:17.106235: Epoch time: 273.92 s 
2025-04-07 12:24:19.292849:  
2025-04-07 12:24:19.293098: Epoch 288 
2025-04-07 12:24:19.293212: Current learning rate: 0.00737 
2025-04-07 12:29:09.512557: train_loss -0.7556 
2025-04-07 12:29:09.513200: val_loss -0.7547 
2025-04-07 12:29:09.513337: Pseudo dice [0.7888] 
2025-04-07 12:29:09.513440: Epoch time: 290.22 s 
2025-04-07 12:29:11.414269:  
2025-04-07 12:29:11.414545: Epoch 289 
2025-04-07 12:29:11.414681: Current learning rate: 0.00736 
2025-04-07 12:33:45.965262: train_loss -0.7495 
2025-04-07 12:33:45.965616: val_loss -0.7932 
2025-04-07 12:33:45.965704: Pseudo dice [0.8143] 
2025-04-07 12:33:45.965797: Epoch time: 274.56 s 
2025-04-07 12:33:48.029719:  
2025-04-07 12:33:48.029975: Epoch 290 
2025-04-07 12:33:48.030114: Current learning rate: 0.00735 
2025-04-07 12:38:21.993644: train_loss -0.7797 
2025-04-07 12:38:21.993987: val_loss -0.7611 
2025-04-07 12:38:21.994225: Pseudo dice [0.7637] 
2025-04-07 12:38:21.994365: Epoch time: 273.97 s 
2025-04-07 12:38:23.940809:  
2025-04-07 12:38:23.941041: Epoch 291 
2025-04-07 12:38:23.941159: Current learning rate: 0.00734 
2025-04-07 12:42:57.877101: train_loss -0.7856 
2025-04-07 12:42:57.877521: val_loss -0.7021 
2025-04-07 12:42:57.877670: Pseudo dice [0.6308] 
2025-04-07 12:42:57.877762: Epoch time: 273.94 s 
2025-04-07 12:42:59.764531:  
2025-04-07 12:42:59.764769: Epoch 292 
2025-04-07 12:42:59.764884: Current learning rate: 0.00733 
2025-04-07 12:47:34.572787: train_loss -0.7711 
2025-04-07 12:47:34.573108: val_loss -0.7783 
2025-04-07 12:47:34.573196: Pseudo dice [0.8076] 
2025-04-07 12:47:34.573293: Epoch time: 274.81 s 
2025-04-07 12:47:36.469363:  
2025-04-07 12:47:36.469560: Epoch 293 
2025-04-07 12:47:36.469685: Current learning rate: 0.00732 
2025-04-07 12:52:11.068671: train_loss -0.7864 
2025-04-07 12:52:11.069077: val_loss -0.7605 
2025-04-07 12:52:11.069182: Pseudo dice [0.7954] 
2025-04-07 12:52:11.069261: Epoch time: 274.6 s 
2025-04-07 12:52:12.970012:  
2025-04-07 12:52:12.970211: Epoch 294 
2025-04-07 12:52:12.970328: Current learning rate: 0.00731 
2025-04-07 12:56:47.365489: train_loss -0.7999 
2025-04-07 12:56:47.365878: val_loss -0.7798 
2025-04-07 12:56:47.365966: Pseudo dice [0.8029] 
2025-04-07 12:56:47.366137: Epoch time: 274.4 s 
2025-04-07 12:56:49.256850:  
2025-04-07 12:56:49.257074: Epoch 295 
2025-04-07 12:56:49.257229: Current learning rate: 0.0073 
2025-04-07 13:01:23.305627: train_loss -0.7761 
2025-04-07 13:01:23.306053: val_loss -0.8 
2025-04-07 13:01:23.306150: Pseudo dice [0.8227] 
2025-04-07 13:01:23.306232: Epoch time: 274.05 s 
2025-04-07 13:01:25.486656:  
2025-04-07 13:01:25.486931: Epoch 296 
2025-04-07 13:01:25.487073: Current learning rate: 0.00729 
2025-04-07 13:05:58.998781: train_loss -0.7842 
2025-04-07 13:05:58.999084: val_loss -0.7803 
2025-04-07 13:05:58.999179: Pseudo dice [0.7843] 
2025-04-07 13:05:58.999270: Epoch time: 273.52 s 
2025-04-07 13:06:00.891432:  
2025-04-07 13:06:00.891635: Epoch 297 
2025-04-07 13:06:00.891788: Current learning rate: 0.00728 
2025-04-07 13:10:35.765094: train_loss -0.7576 
2025-04-07 13:10:35.765437: val_loss -0.7998 
2025-04-07 13:10:35.765521: Pseudo dice [0.808] 
2025-04-07 13:10:35.765620: Epoch time: 274.88 s 
2025-04-07 13:10:37.642001:  
2025-04-07 13:10:37.642230: Epoch 298 
2025-04-07 13:10:37.642396: Current learning rate: 0.00727 
2025-04-07 13:15:11.349864: train_loss -0.7835 
2025-04-07 13:15:11.350261: val_loss -0.7815 
2025-04-07 13:15:11.350371: Pseudo dice [0.8021] 
2025-04-07 13:15:11.350465: Epoch time: 273.71 s 
2025-04-07 13:15:13.233490:  
2025-04-07 13:15:13.233745: Epoch 299 
2025-04-07 13:15:13.233864: Current learning rate: 0.00726 
2025-04-07 13:20:24.951679: train_loss -0.7924 
2025-04-07 13:20:24.952327: val_loss -0.7647 
2025-04-07 13:20:24.952453: Pseudo dice [0.7847] 
2025-04-07 13:20:24.952546: Epoch time: 311.72 s 
2025-04-07 13:20:28.089003:  
2025-04-07 13:20:28.089195: Epoch 300 
2025-04-07 13:20:28.089307: Current learning rate: 0.00725 
2025-04-07 13:25:01.380192: train_loss -0.7522 
2025-04-07 13:25:01.380509: val_loss -0.7854 
2025-04-07 13:25:01.380634: Pseudo dice [0.7804] 
2025-04-07 13:25:01.380733: Epoch time: 273.3 s 
2025-04-07 13:25:03.258135:  
2025-04-07 13:25:03.258368: Epoch 301 
2025-04-07 13:25:03.258520: Current learning rate: 0.00724 
2025-04-07 13:29:44.233920: train_loss -0.7686 
2025-04-07 13:29:44.234240: val_loss -0.7337 
2025-04-07 13:29:44.234331: Pseudo dice [0.7453] 
2025-04-07 13:29:44.234431: Epoch time: 280.98 s 
2025-04-07 13:29:46.166946:  
2025-04-07 13:29:46.167174: Epoch 302 
2025-04-07 13:29:46.167291: Current learning rate: 0.00724 
2025-04-07 13:34:19.416447: train_loss -0.7482 
2025-04-07 13:34:19.416763: val_loss -0.7626 
2025-04-07 13:34:19.416844: Pseudo dice [0.8031] 
2025-04-07 13:34:19.416928: Epoch time: 273.25 s 
2025-04-07 13:34:21.299700:  
2025-04-07 13:34:21.299931: Epoch 303 
2025-04-07 13:34:21.300060: Current learning rate: 0.00723 
2025-04-07 13:39:04.375689: train_loss -0.7477 
2025-04-07 13:39:04.376195: val_loss -0.7604 
2025-04-07 13:39:04.376297: Pseudo dice [0.7892] 
2025-04-07 13:39:04.376378: Epoch time: 283.08 s 
2025-04-07 13:39:06.266045:  
2025-04-07 13:39:06.266249: Epoch 304 
2025-04-07 13:39:06.266368: Current learning rate: 0.00722 
2025-04-07 13:43:39.123518: train_loss -0.763 
2025-04-07 13:43:39.123825: val_loss -0.7546 
2025-04-07 13:43:39.123906: Pseudo dice [0.7189] 
2025-04-07 13:43:39.123994: Epoch time: 272.86 s 
2025-04-07 13:43:41.369982:  
2025-04-07 13:43:41.370180: Epoch 305 
2025-04-07 13:43:41.370340: Current learning rate: 0.00721 
2025-04-07 13:48:18.679206: train_loss -0.7711 
2025-04-07 13:48:18.679509: val_loss -0.7382 
2025-04-07 13:48:18.679596: Pseudo dice [0.7178] 
2025-04-07 13:48:18.679713: Epoch time: 277.31 s 
2025-04-07 13:48:20.582972:  
2025-04-07 13:48:20.583251: Epoch 306 
2025-04-07 13:48:20.583371: Current learning rate: 0.0072 
2025-04-07 13:52:53.345326: train_loss -0.7429 
2025-04-07 13:52:53.345640: val_loss -0.7524 
2025-04-07 13:52:53.345717: Pseudo dice [0.7648] 
2025-04-07 13:52:53.345800: Epoch time: 272.77 s 
2025-04-07 13:52:55.235242:  
2025-04-07 13:52:55.235429: Epoch 307 
2025-04-07 13:52:55.235583: Current learning rate: 0.00719 
2025-04-07 13:57:27.936587: train_loss -0.7714 
2025-04-07 13:57:27.936955: val_loss -0.6558 
2025-04-07 13:57:27.937405: Pseudo dice [0.6703] 
2025-04-07 13:57:27.937496: Epoch time: 272.71 s 
2025-04-07 13:57:29.829814:  
2025-04-07 13:57:29.830065: Epoch 308 
2025-04-07 13:57:29.830199: Current learning rate: 0.00718 
2025-04-07 14:02:04.616463: train_loss -0.7533 
2025-04-07 14:02:04.616989: val_loss -0.7752 
2025-04-07 14:02:04.617092: Pseudo dice [0.8052] 
2025-04-07 14:02:04.617174: Epoch time: 274.79 s 
2025-04-07 14:02:06.501878:  
2025-04-07 14:02:06.502249: Epoch 309 
2025-04-07 14:02:06.502406: Current learning rate: 0.00717 
2025-04-07 14:06:40.558403: train_loss -0.7691 
2025-04-07 14:06:40.558974: val_loss -0.7428 
2025-04-07 14:06:40.559055: Pseudo dice [0.7903] 
2025-04-07 14:06:40.559137: Epoch time: 274.06 s 
2025-04-07 14:06:42.485542:  
2025-04-07 14:06:42.485738: Epoch 310 
2025-04-07 14:06:42.485870: Current learning rate: 0.00716 
2025-04-07 14:11:16.958950: train_loss -0.7363 
2025-04-07 14:11:16.959517: val_loss -0.7064 
2025-04-07 14:11:16.959625: Pseudo dice [0.774] 
2025-04-07 14:11:16.959708: Epoch time: 274.48 s 
2025-04-07 14:11:18.849644:  
2025-04-07 14:11:18.849977: Epoch 311 
2025-04-07 14:11:18.850138: Current learning rate: 0.00715 
2025-04-07 14:15:52.871202: train_loss -0.768 
2025-04-07 14:15:52.871512: val_loss -0.7598 
2025-04-07 14:15:52.871595: Pseudo dice [0.7839] 
2025-04-07 14:15:52.871683: Epoch time: 274.03 s 
2025-04-07 14:15:54.758576:  
2025-04-07 14:15:54.758814: Epoch 312 
2025-04-07 14:15:54.758930: Current learning rate: 0.00714 
2025-04-07 14:21:03.312332: train_loss -0.7658 
2025-04-07 14:21:03.312901: val_loss -0.7898 
2025-04-07 14:21:03.313049: Pseudo dice [0.8153] 
2025-04-07 14:21:03.313157: Epoch time: 308.56 s 
2025-04-07 14:21:05.547422:  
2025-04-07 14:21:05.547655: Epoch 313 
2025-04-07 14:21:05.547783: Current learning rate: 0.00713 
2025-04-07 14:25:38.627759: train_loss -0.7892 
2025-04-07 14:25:38.628126: val_loss -0.776 
2025-04-07 14:25:38.628213: Pseudo dice [0.7973] 
2025-04-07 14:25:38.628309: Epoch time: 273.08 s 
2025-04-07 14:25:40.538585:  
2025-04-07 14:25:40.538895: Epoch 314 
2025-04-07 14:25:40.539071: Current learning rate: 0.00712 
2025-04-07 14:30:14.219208: train_loss -0.8004 
2025-04-07 14:30:14.219860: val_loss -0.7624 
2025-04-07 14:30:14.220049: Pseudo dice [0.7868] 
2025-04-07 14:30:14.220263: Epoch time: 273.68 s 
2025-04-07 14:30:16.110545:  
2025-04-07 14:30:16.110806: Epoch 315 
2025-04-07 14:30:16.110956: Current learning rate: 0.00711 
2025-04-07 14:34:49.636518: train_loss -0.7888 
2025-04-07 14:34:49.636827: val_loss -0.7821 
2025-04-07 14:34:49.636915: Pseudo dice [0.7914] 
2025-04-07 14:34:49.637006: Epoch time: 273.53 s 
2025-04-07 14:34:51.532511:  
2025-04-07 14:34:51.532804: Epoch 316 
2025-04-07 14:34:51.532934: Current learning rate: 0.0071 
2025-04-07 14:39:25.380678: train_loss -0.7732 
2025-04-07 14:39:25.381043: val_loss -0.6626 
2025-04-07 14:39:25.381131: Pseudo dice [0.5922] 
2025-04-07 14:39:25.381223: Epoch time: 273.85 s 
2025-04-07 14:39:27.276023:  
2025-04-07 14:39:27.276242: Epoch 317 
2025-04-07 14:39:27.276368: Current learning rate: 0.0071 
2025-04-07 14:44:02.088668: train_loss -0.7629 
2025-04-07 14:44:02.089019: val_loss -0.7257 
2025-04-07 14:44:02.089158: Pseudo dice [0.6991] 
2025-04-07 14:44:02.089257: Epoch time: 274.82 s 
2025-04-07 14:44:03.999232:  
2025-04-07 14:44:03.999508: Epoch 318 
2025-04-07 14:44:03.999649: Current learning rate: 0.00709 
2025-04-07 14:48:38.581857: train_loss -0.7554 
2025-04-07 14:48:38.582258: val_loss -0.7569 
2025-04-07 14:48:38.582355: Pseudo dice [0.7791] 
2025-04-07 14:48:38.582439: Epoch time: 274.59 s 
2025-04-07 14:48:40.474326:  
2025-04-07 14:48:40.474523: Epoch 319 
2025-04-07 14:48:40.474637: Current learning rate: 0.00708 
2025-04-07 14:53:14.811145: train_loss -0.7676 
2025-04-07 14:53:14.811468: val_loss -0.6156 
2025-04-07 14:53:14.811548: Pseudo dice [0.5393] 
2025-04-07 14:53:14.811632: Epoch time: 274.34 s 
2025-04-07 14:53:16.692637:  
2025-04-07 14:53:16.692844: Epoch 320 
2025-04-07 14:53:16.692962: Current learning rate: 0.00707 
2025-04-07 14:57:50.891670: train_loss -0.7367 
2025-04-07 14:57:50.892012: val_loss -0.7361 
2025-04-07 14:57:50.892131: Pseudo dice [0.7345] 
2025-04-07 14:57:50.892227: Epoch time: 274.2 s 
2025-04-07 14:57:53.086076:  
2025-04-07 14:57:53.086393: Epoch 321 
2025-04-07 14:57:53.086528: Current learning rate: 0.00706 
2025-04-07 15:02:26.967581: train_loss -0.7008 
2025-04-07 15:02:26.967980: val_loss -0.6784 
2025-04-07 15:02:26.968125: Pseudo dice [0.7334] 
2025-04-07 15:02:26.968225: Epoch time: 273.89 s 
2025-04-07 15:02:28.865472:  
2025-04-07 15:02:28.865659: Epoch 322 
2025-04-07 15:02:28.865793: Current learning rate: 0.00705 
2025-04-07 15:07:03.030367: train_loss -0.7054 
2025-04-07 15:07:03.030719: val_loss -0.7251 
2025-04-07 15:07:03.030826: Pseudo dice [0.7936] 
2025-04-07 15:07:03.030924: Epoch time: 274.17 s 
2025-04-07 15:07:04.981852:  
2025-04-07 15:07:04.982064: Epoch 323 
2025-04-07 15:07:04.982180: Current learning rate: 0.00704 
2025-04-07 15:11:39.214988: train_loss -0.7448 
2025-04-07 15:11:39.215549: val_loss -0.7133 
2025-04-07 15:11:39.215656: Pseudo dice [0.7334] 
2025-04-07 15:11:39.215741: Epoch time: 274.24 s 
2025-04-07 15:11:41.163691:  
2025-04-07 15:11:41.163926: Epoch 324 
2025-04-07 15:11:41.164072: Current learning rate: 0.00703 
2025-04-07 15:16:14.456213: train_loss -0.7389 
2025-04-07 15:16:14.456526: val_loss -0.7619 
2025-04-07 15:16:14.456608: Pseudo dice [0.7923] 
2025-04-07 15:16:14.456734: Epoch time: 273.3 s 
2025-04-07 15:16:16.358440:  
2025-04-07 15:16:16.358713: Epoch 325 
2025-04-07 15:16:16.358855: Current learning rate: 0.00702 
2025-04-07 15:20:57.773135: train_loss -0.7707 
2025-04-07 15:20:57.773546: val_loss -0.7506 
2025-04-07 15:20:57.773663: Pseudo dice [0.7974] 
2025-04-07 15:20:57.773745: Epoch time: 281.42 s 
2025-04-07 15:20:59.696903:  
2025-04-07 15:20:59.697105: Epoch 326 
2025-04-07 15:20:59.697219: Current learning rate: 0.00701 
2025-04-07 15:25:32.707576: train_loss -0.7792 
2025-04-07 15:25:32.707901: val_loss -0.7761 
2025-04-07 15:25:32.708064: Pseudo dice [0.7842] 
2025-04-07 15:25:32.708161: Epoch time: 273.01 s 
2025-04-07 15:25:34.611766:  
2025-04-07 15:25:34.612014: Epoch 327 
2025-04-07 15:25:34.612124: Current learning rate: 0.007 
2025-04-07 15:30:08.091176: train_loss -0.7652 
2025-04-07 15:30:08.091720: val_loss -0.7199 
2025-04-07 15:30:08.091903: Pseudo dice [0.6484] 
2025-04-07 15:30:08.091990: Epoch time: 273.48 s 
2025-04-07 15:30:09.991562:  
2025-04-07 15:30:09.991804: Epoch 328 
2025-04-07 15:30:09.991918: Current learning rate: 0.00699 
2025-04-07 15:34:44.088703: train_loss -0.7462 
2025-04-07 15:34:44.089017: val_loss -0.7681 
2025-04-07 15:34:44.089098: Pseudo dice [0.791] 
2025-04-07 15:34:44.089185: Epoch time: 274.1 s 
2025-04-07 15:34:45.985211:  
2025-04-07 15:34:45.985462: Epoch 329 
2025-04-07 15:34:45.985591: Current learning rate: 0.00698 
2025-04-07 15:39:20.290342: train_loss -0.7479 
2025-04-07 15:39:20.290951: val_loss -0.7461 
2025-04-07 15:39:20.291087: Pseudo dice [0.7272] 
2025-04-07 15:39:20.291178: Epoch time: 274.31 s 
2025-04-07 15:39:22.551807:  
2025-04-07 15:39:22.552011: Epoch 330 
2025-04-07 15:39:22.552130: Current learning rate: 0.00697 
2025-04-07 15:43:57.460323: train_loss -0.7394 
2025-04-07 15:43:57.460813: val_loss -0.7537 
2025-04-07 15:43:57.460942: Pseudo dice [0.7902] 
2025-04-07 15:43:57.461021: Epoch time: 274.91 s 
2025-04-07 15:43:59.415498:  
2025-04-07 15:43:59.415726: Epoch 331 
2025-04-07 15:43:59.415849: Current learning rate: 0.00696 
2025-04-07 15:48:33.498726: train_loss -0.7508 
2025-04-07 15:48:33.499031: val_loss -0.7793 
2025-04-07 15:48:33.499113: Pseudo dice [0.7909] 
2025-04-07 15:48:33.499216: Epoch time: 274.09 s 
2025-04-07 15:48:35.408628:  
2025-04-07 15:48:35.408879: Epoch 332 
2025-04-07 15:48:35.409053: Current learning rate: 0.00696 
2025-04-07 15:53:10.035894: train_loss -0.7564 
2025-04-07 15:53:10.036501: val_loss -0.7689 
2025-04-07 15:53:10.036605: Pseudo dice [0.7743] 
2025-04-07 15:53:10.036694: Epoch time: 274.63 s 
2025-04-07 15:53:11.952616:  
2025-04-07 15:53:11.952933: Epoch 333 
2025-04-07 15:53:11.953077: Current learning rate: 0.00695 
2025-04-07 15:57:46.022144: train_loss -0.7703 
2025-04-07 15:57:46.022503: val_loss -0.7829 
2025-04-07 15:57:46.022614: Pseudo dice [0.7975] 
2025-04-07 15:57:46.022709: Epoch time: 274.07 s 
2025-04-07 15:57:47.918316:  
2025-04-07 15:57:47.918639: Epoch 334 
2025-04-07 15:57:47.918803: Current learning rate: 0.00694 
2025-04-07 16:02:54.218698: train_loss -0.763 
2025-04-07 16:02:54.219360: val_loss -0.7597 
2025-04-07 16:02:54.219471: Pseudo dice [0.6976] 
2025-04-07 16:02:54.219574: Epoch time: 306.3 s 
2025-04-07 16:02:56.342057:  
2025-04-07 16:02:56.342403: Epoch 335 
2025-04-07 16:02:56.342529: Current learning rate: 0.00693 
2025-04-07 16:07:30.332279: train_loss -0.7861 
2025-04-07 16:07:30.332619: val_loss -0.7845 
2025-04-07 16:07:30.332703: Pseudo dice [0.7935] 
2025-04-07 16:07:30.332799: Epoch time: 273.99 s 
2025-04-07 16:07:32.260276:  
2025-04-07 16:07:32.260485: Epoch 336 
2025-04-07 16:07:32.260597: Current learning rate: 0.00692 
2025-04-07 16:12:07.218782: train_loss -0.786 
2025-04-07 16:12:07.219593: val_loss -0.7838 
2025-04-07 16:12:07.219698: Pseudo dice [0.7667] 
2025-04-07 16:12:07.219865: Epoch time: 274.96 s 
2025-04-07 16:12:09.150021:  
2025-04-07 16:12:09.150230: Epoch 337 
2025-04-07 16:12:09.150361: Current learning rate: 0.00691 
2025-04-07 16:16:43.672759: train_loss -0.7651 
2025-04-07 16:16:43.673081: val_loss -0.7544 
2025-04-07 16:16:43.673167: Pseudo dice [0.7861] 
2025-04-07 16:16:43.673262: Epoch time: 274.53 s 
2025-04-07 16:16:45.910433:  
2025-04-07 16:16:45.910606: Epoch 338 
2025-04-07 16:16:45.910768: Current learning rate: 0.0069 
2025-04-07 16:21:20.230590: train_loss -0.7712 
2025-04-07 16:21:20.230929: val_loss -0.7824 
2025-04-07 16:21:20.231029: Pseudo dice [0.804] 
2025-04-07 16:21:20.231127: Epoch time: 274.32 s 
2025-04-07 16:21:22.158345:  
2025-04-07 16:21:22.158631: Epoch 339 
2025-04-07 16:21:22.158753: Current learning rate: 0.00689 
2025-04-07 16:25:56.768647: train_loss -0.7878 
2025-04-07 16:25:56.769215: val_loss -0.7528 
2025-04-07 16:25:56.769346: Pseudo dice [0.763] 
2025-04-07 16:25:56.769455: Epoch time: 274.61 s 
2025-04-07 16:25:58.688802:  
2025-04-07 16:25:58.689098: Epoch 340 
2025-04-07 16:25:58.689224: Current learning rate: 0.00688 
2025-04-07 16:30:32.750021: train_loss -0.7829 
2025-04-07 16:30:32.750346: val_loss -0.7571 
2025-04-07 16:30:32.750436: Pseudo dice [0.7705] 
2025-04-07 16:30:32.750535: Epoch time: 274.07 s 
2025-04-07 16:30:34.698049:  
2025-04-07 16:30:34.698325: Epoch 341 
2025-04-07 16:30:34.698452: Current learning rate: 0.00687 
2025-04-07 16:35:10.251020: train_loss -0.7744 
2025-04-07 16:35:10.252374: val_loss -0.7883 
2025-04-07 16:35:10.252476: Pseudo dice [0.7827] 
2025-04-07 16:35:10.252568: Epoch time: 275.56 s 
2025-04-07 16:35:12.178832:  
2025-04-07 16:35:12.179091: Epoch 342 
2025-04-07 16:35:12.179225: Current learning rate: 0.00686 
2025-04-07 16:39:46.312123: train_loss -0.7755 
2025-04-07 16:39:46.312421: val_loss -0.7536 
2025-04-07 16:39:46.313340: Pseudo dice [0.7884] 
2025-04-07 16:39:46.313422: Epoch time: 274.14 s 
2025-04-07 16:39:48.221246:  
2025-04-07 16:39:48.221456: Epoch 343 
2025-04-07 16:39:48.221570: Current learning rate: 0.00685 
2025-04-07 16:45:05.130176: train_loss -0.7978 
2025-04-07 16:45:05.130794: val_loss -0.7639 
2025-04-07 16:45:05.130898: Pseudo dice [0.7969] 
2025-04-07 16:45:05.130987: Epoch time: 316.91 s 
2025-04-07 16:45:07.053883:  
2025-04-07 16:45:07.054088: Epoch 344 
2025-04-07 16:45:07.054196: Current learning rate: 0.00684 
2025-04-07 16:49:54.015024: train_loss -0.7888 
2025-04-07 16:49:54.015642: val_loss -0.7736 
2025-04-07 16:49:54.015747: Pseudo dice [0.7682] 
2025-04-07 16:49:54.015855: Epoch time: 286.96 s 
2025-04-07 16:49:55.939990:  
2025-04-07 16:49:55.940199: Epoch 345 
2025-04-07 16:49:55.940313: Current learning rate: 0.00683 
2025-04-07 16:54:47.013850: train_loss -0.7819 
2025-04-07 16:54:47.014399: val_loss -0.7626 
2025-04-07 16:54:47.014512: Pseudo dice [0.7953] 
2025-04-07 16:54:47.014602: Epoch time: 291.08 s 
2025-04-07 16:54:49.290689:  
2025-04-07 16:54:49.290941: Epoch 346 
2025-04-07 16:54:49.291075: Current learning rate: 0.00682 
2025-04-07 16:59:22.386488: train_loss -0.7991 
2025-04-07 16:59:22.386836: val_loss -0.782 
2025-04-07 16:59:22.386945: Pseudo dice [0.7898] 
2025-04-07 16:59:22.387039: Epoch time: 273.1 s 
2025-04-07 16:59:24.347180:  
2025-04-07 16:59:24.347378: Epoch 347 
2025-04-07 16:59:24.347528: Current learning rate: 0.00681 
2025-04-07 17:03:57.974556: train_loss -0.7881 
2025-04-07 17:03:57.974867: val_loss -0.7864 
2025-04-07 17:03:57.974952: Pseudo dice [0.8105] 
2025-04-07 17:03:57.975052: Epoch time: 273.63 s 
2025-04-07 17:03:59.897237:  
2025-04-07 17:03:59.897459: Epoch 348 
2025-04-07 17:03:59.897573: Current learning rate: 0.0068 
2025-04-07 17:08:33.938775: train_loss -0.7663 
2025-04-07 17:08:33.939346: val_loss -0.7865 
2025-04-07 17:08:33.939456: Pseudo dice [0.7997] 
2025-04-07 17:08:33.939543: Epoch time: 274.05 s 
2025-04-07 17:08:35.861648:  
2025-04-07 17:08:35.861821: Epoch 349 
2025-04-07 17:08:35.861978: Current learning rate: 0.0068 
2025-04-07 17:13:09.481961: train_loss -0.7687 
2025-04-07 17:13:09.482282: val_loss -0.765 
2025-04-07 17:13:09.482368: Pseudo dice [0.7078] 
2025-04-07 17:13:09.482449: Epoch time: 273.62 s 
2025-04-07 17:13:12.646479:  
2025-04-07 17:13:12.646709: Epoch 350 
2025-04-07 17:13:12.646824: Current learning rate: 0.00679 
2025-04-07 17:17:46.020483: train_loss -0.7691 
2025-04-07 17:17:46.020835: val_loss -0.7976 
2025-04-07 17:17:46.020929: Pseudo dice [0.7924] 
2025-04-07 17:17:46.021038: Epoch time: 273.38 s 
2025-04-07 17:17:47.944640:  
2025-04-07 17:17:47.944843: Epoch 351 
2025-04-07 17:17:47.944974: Current learning rate: 0.00678 
2025-04-07 17:22:21.319401: train_loss -0.7674 
2025-04-07 17:22:21.319727: val_loss -0.7589 
2025-04-07 17:22:21.319854: Pseudo dice [0.8049] 
2025-04-07 17:22:21.320035: Epoch time: 273.38 s 
2025-04-07 17:22:23.259340:  
2025-04-07 17:22:23.259560: Epoch 352 
2025-04-07 17:22:23.259680: Current learning rate: 0.00677 
2025-04-07 17:26:56.983375: train_loss -0.7352 
2025-04-07 17:26:56.983621: val_loss -0.7551 
2025-04-07 17:26:56.983703: Pseudo dice [0.7851] 
2025-04-07 17:26:56.983814: Epoch time: 273.73 s 
2025-04-07 17:26:59.190850:  
2025-04-07 17:26:59.191097: Epoch 353 
2025-04-07 17:26:59.191334: Current learning rate: 0.00676 
2025-04-07 17:31:32.731681: train_loss -0.7255 
2025-04-07 17:31:32.732020: val_loss -0.7471 
2025-04-07 17:31:32.732105: Pseudo dice [0.7522] 
2025-04-07 17:31:32.732244: Epoch time: 273.54 s 
2025-04-07 17:31:34.820465:  
2025-04-07 17:31:34.820686: Epoch 354 
2025-04-07 17:31:34.820808: Current learning rate: 0.00675 
2025-04-07 17:36:07.800080: train_loss -0.7504 
2025-04-07 17:36:07.800401: val_loss -0.7712 
2025-04-07 17:36:07.800485: Pseudo dice [0.783] 
2025-04-07 17:36:07.800586: Epoch time: 272.98 s 
2025-04-07 17:36:09.735639:  
2025-04-07 17:36:09.735866: Epoch 355 
2025-04-07 17:36:09.735980: Current learning rate: 0.00674 
2025-04-07 17:40:43.262657: train_loss -0.7398 
2025-04-07 17:40:43.262976: val_loss -0.7766 
2025-04-07 17:40:43.263080: Pseudo dice [0.802] 
2025-04-07 17:40:43.263179: Epoch time: 273.53 s 
2025-04-07 17:40:45.193331:  
2025-04-07 17:40:45.193547: Epoch 356 
2025-04-07 17:40:45.193664: Current learning rate: 0.00673 
2025-04-07 17:45:18.782981: train_loss -0.7755 
2025-04-07 17:45:18.783350: val_loss -0.7613 
2025-04-07 17:45:18.783483: Pseudo dice [0.7914] 
2025-04-07 17:45:18.783563: Epoch time: 273.59 s 
2025-04-07 17:45:20.704216:  
2025-04-07 17:45:20.704413: Epoch 357 
2025-04-07 17:45:20.704526: Current learning rate: 0.00672 
2025-04-07 17:49:55.038635: train_loss -0.7508 
2025-04-07 17:49:55.038966: val_loss -0.7743 
2025-04-07 17:49:55.039101: Pseudo dice [0.7868] 
2025-04-07 17:49:55.039208: Epoch time: 274.34 s 
2025-04-07 17:49:56.969585:  
2025-04-07 17:49:56.969808: Epoch 358 
2025-04-07 17:49:56.969983: Current learning rate: 0.00671 
2025-04-07 17:54:31.236048: train_loss -0.75 
2025-04-07 17:54:31.236365: val_loss -0.7416 
2025-04-07 17:54:31.236443: Pseudo dice [0.737] 
2025-04-07 17:54:31.236531: Epoch time: 274.27 s 
2025-04-07 17:54:33.173117:  
2025-04-07 17:54:33.173309: Epoch 359 
2025-04-07 17:54:33.173422: Current learning rate: 0.0067 
2025-04-07 17:59:07.693270: train_loss -0.6953 
2025-04-07 17:59:07.693638: val_loss -0.7769 
2025-04-07 17:59:07.693731: Pseudo dice [0.7868] 
2025-04-07 17:59:07.693826: Epoch time: 274.52 s 
2025-04-07 17:59:09.626601:  
2025-04-07 17:59:09.626844: Epoch 360 
2025-04-07 17:59:09.626964: Current learning rate: 0.00669 
2025-04-07 18:03:43.470619: train_loss -0.7373 
2025-04-07 18:03:43.470906: val_loss -0.7384 
2025-04-07 18:03:43.470984: Pseudo dice [0.762] 
2025-04-07 18:03:43.471068: Epoch time: 273.85 s 
2025-04-07 18:03:45.716614:  
2025-04-07 18:03:45.716841: Epoch 361 
2025-04-07 18:03:45.716960: Current learning rate: 0.00668 
2025-04-07 18:08:19.238822: train_loss -0.7257 
2025-04-07 18:08:19.239185: val_loss -0.7366 
2025-04-07 18:08:19.239295: Pseudo dice [0.7638] 
2025-04-07 18:08:19.239389: Epoch time: 273.53 s 
2025-04-07 18:08:21.174023:  
2025-04-07 18:08:21.174354: Epoch 362 
2025-04-07 18:08:21.174495: Current learning rate: 0.00667 
2025-04-07 18:12:54.629878: train_loss -0.7562 
2025-04-07 18:12:54.630174: val_loss -0.7566 
2025-04-07 18:12:54.630267: Pseudo dice [0.7892] 
2025-04-07 18:12:54.630355: Epoch time: 273.46 s 
2025-04-07 18:12:56.556679:  
2025-04-07 18:12:56.556975: Epoch 363 
2025-04-07 18:12:56.557093: Current learning rate: 0.00666 
2025-04-07 18:17:29.898215: train_loss -0.779 
2025-04-07 18:17:29.898513: val_loss -0.7732 
2025-04-07 18:17:29.898596: Pseudo dice [0.7903] 
2025-04-07 18:17:29.898682: Epoch time: 273.35 s 
2025-04-07 18:17:31.844732:  
2025-04-07 18:17:31.845005: Epoch 364 
2025-04-07 18:17:31.845122: Current learning rate: 0.00665 
2025-04-07 18:22:05.076376: train_loss -0.7811 
2025-04-07 18:22:05.076760: val_loss -0.7866 
2025-04-07 18:22:05.076864: Pseudo dice [0.7861] 
2025-04-07 18:22:05.076962: Epoch time: 273.24 s 
2025-04-07 18:22:07.040371:  
2025-04-07 18:22:07.040572: Epoch 365 
2025-04-07 18:22:07.040685: Current learning rate: 0.00665 
2025-04-07 18:26:40.592394: train_loss -0.7599 
2025-04-07 18:26:40.592733: val_loss -0.773 
2025-04-07 18:26:40.592821: Pseudo dice [0.8082] 
2025-04-07 18:26:40.592918: Epoch time: 273.56 s 
2025-04-07 18:26:42.579337:  
2025-04-07 18:26:42.579534: Epoch 366 
2025-04-07 18:26:42.579645: Current learning rate: 0.00664 
2025-04-07 18:31:15.918329: train_loss -0.7715 
2025-04-07 18:31:15.918664: val_loss -0.7512 
2025-04-07 18:31:15.918754: Pseudo dice [0.7674] 
2025-04-07 18:31:15.918855: Epoch time: 273.34 s 
2025-04-07 18:31:17.850543:  
2025-04-07 18:31:17.850752: Epoch 367 
2025-04-07 18:31:17.850864: Current learning rate: 0.00663 
2025-04-07 18:35:52.464786: train_loss -0.7354 
2025-04-07 18:35:52.465420: val_loss -0.7997 
2025-04-07 18:35:52.465537: Pseudo dice [0.8053] 
2025-04-07 18:35:52.465627: Epoch time: 274.62 s 
2025-04-07 18:35:54.424256:  
2025-04-07 18:35:54.424488: Epoch 368 
2025-04-07 18:35:54.424616: Current learning rate: 0.00662 
2025-04-07 18:40:28.655704: train_loss -0.7837 
2025-04-07 18:40:28.656053: val_loss -0.7747 
2025-04-07 18:40:28.656152: Pseudo dice [0.7866] 
2025-04-07 18:40:28.656249: Epoch time: 274.24 s 
2025-04-07 18:40:30.903700:  
2025-04-07 18:40:30.903995: Epoch 369 
2025-04-07 18:40:30.904232: Current learning rate: 0.00661 
2025-04-07 18:45:05.373769: train_loss -0.7783 
2025-04-07 18:45:05.374083: val_loss -0.7736 
2025-04-07 18:45:05.374186: Pseudo dice [0.7888] 
2025-04-07 18:45:05.374282: Epoch time: 274.47 s 
2025-04-07 18:45:07.328573:  
2025-04-07 18:45:07.328807: Epoch 370 
2025-04-07 18:45:07.328923: Current learning rate: 0.0066 
2025-04-07 18:49:41.915441: train_loss -0.7818 
2025-04-07 18:49:41.916079: val_loss -0.7898 
2025-04-07 18:49:41.916178: Pseudo dice [0.8011] 
2025-04-07 18:49:41.916262: Epoch time: 274.59 s 
2025-04-07 18:49:43.877619:  
2025-04-07 18:49:43.877826: Epoch 371 
2025-04-07 18:49:43.877937: Current learning rate: 0.00659 
2025-04-07 18:54:17.911883: train_loss -0.7943 
2025-04-07 18:54:17.912206: val_loss -0.7726 
2025-04-07 18:54:17.912291: Pseudo dice [0.78] 
2025-04-07 18:54:17.912386: Epoch time: 274.04 s 
2025-04-07 18:54:19.838379:  
2025-04-07 18:54:19.838539: Epoch 372 
2025-04-07 18:54:19.838686: Current learning rate: 0.00658 
2025-04-07 18:59:22.739838: train_loss -0.7993 
2025-04-07 18:59:22.740399: val_loss -0.8069 
2025-04-07 18:59:22.740508: Pseudo dice [0.8116] 
2025-04-07 18:59:22.740593: Epoch time: 302.91 s 
2025-04-07 18:59:24.680179:  
2025-04-07 18:59:24.680367: Epoch 373 
2025-04-07 18:59:24.680497: Current learning rate: 0.00657 
2025-04-07 19:03:58.692690: train_loss -0.8053 
2025-04-07 19:03:58.693027: val_loss -0.7527 
2025-04-07 19:03:58.693148: Pseudo dice [0.7845] 
2025-04-07 19:03:58.693251: Epoch time: 274.02 s 
2025-04-07 19:04:00.653522:  
2025-04-07 19:04:00.653781: Epoch 374 
2025-04-07 19:04:00.653915: Current learning rate: 0.00656 
2025-04-07 19:08:35.990849: train_loss -0.7818 
2025-04-07 19:08:35.991399: val_loss -0.78 
2025-04-07 19:08:35.991531: Pseudo dice [0.7952] 
2025-04-07 19:08:35.991619: Epoch time: 275.34 s 
2025-04-07 19:08:37.921407:  
2025-04-07 19:08:37.921616: Epoch 375 
2025-04-07 19:08:37.921732: Current learning rate: 0.00655 
2025-04-07 19:13:11.993487: train_loss -0.7975 
2025-04-07 19:13:11.993822: val_loss -0.8027 
2025-04-07 19:13:11.993906: Pseudo dice [0.814] 
2025-04-07 19:13:11.994002: Epoch time: 274.08 s 
2025-04-07 19:13:13.930203:  
2025-04-07 19:13:13.930384: Epoch 376 
2025-04-07 19:13:13.930495: Current learning rate: 0.00654 
2025-04-07 19:17:49.151772: train_loss -0.7733 
2025-04-07 19:17:49.152324: val_loss -0.7922 
2025-04-07 19:17:49.152423: Pseudo dice [0.8199] 
2025-04-07 19:17:49.152511: Epoch time: 275.23 s 
2025-04-07 19:17:51.378845:  
2025-04-07 19:17:51.379053: Epoch 377 
2025-04-07 19:17:51.379179: Current learning rate: 0.00653 
2025-04-07 19:22:26.366334: train_loss -0.8056 
2025-04-07 19:22:26.366685: val_loss -0.7442 
2025-04-07 19:22:26.366771: Pseudo dice [0.7241] 
2025-04-07 19:22:26.366861: Epoch time: 274.99 s 
2025-04-07 19:22:28.317348:  
2025-04-07 19:22:28.317555: Epoch 378 
2025-04-07 19:22:28.317722: Current learning rate: 0.00652 
2025-04-07 19:27:02.915927: train_loss -0.7987 
2025-04-07 19:27:02.916248: val_loss -0.8007 
2025-04-07 19:27:02.916332: Pseudo dice [0.8153] 
2025-04-07 19:27:02.916432: Epoch time: 274.6 s 
2025-04-07 19:27:04.862774:  
2025-04-07 19:27:04.863070: Epoch 379 
2025-04-07 19:27:04.863215: Current learning rate: 0.00651 
2025-04-07 19:31:39.427504: train_loss -0.8117 
2025-04-07 19:31:39.427829: val_loss -0.7561 
2025-04-07 19:31:39.427910: Pseudo dice [0.7853] 
2025-04-07 19:31:39.428002: Epoch time: 274.57 s 
2025-04-07 19:31:41.364855:  
2025-04-07 19:31:41.365095: Epoch 380 
2025-04-07 19:31:41.365206: Current learning rate: 0.0065 
2025-04-07 19:36:16.181742: train_loss -0.8037 
2025-04-07 19:36:16.182057: val_loss -0.7855 
2025-04-07 19:36:16.182151: Pseudo dice [0.8025] 
2025-04-07 19:36:16.182309: Epoch time: 274.82 s 
2025-04-07 19:36:18.113725:  
2025-04-07 19:36:18.113912: Epoch 381 
2025-04-07 19:36:18.114024: Current learning rate: 0.00649 
2025-04-07 19:40:52.385326: train_loss -0.8098 
2025-04-07 19:40:52.385743: val_loss -0.7535 
2025-04-07 19:40:52.385841: Pseudo dice [0.7734] 
2025-04-07 19:40:52.385924: Epoch time: 274.28 s 
2025-04-07 19:40:54.346439:  
2025-04-07 19:40:54.346651: Epoch 382 
2025-04-07 19:40:54.346766: Current learning rate: 0.00648 
2025-04-07 19:45:29.124946: train_loss -0.7605 
2025-04-07 19:45:29.125253: val_loss -0.7394 
2025-04-07 19:45:29.125339: Pseudo dice [0.7875] 
2025-04-07 19:45:29.125496: Epoch time: 274.78 s 
2025-04-07 19:45:31.118619:  
2025-04-07 19:45:31.118847: Epoch 383 
2025-04-07 19:45:31.119015: Current learning rate: 0.00648 
2025-04-07 19:50:06.051178: train_loss -0.7918 
2025-04-07 19:50:06.051705: val_loss -0.7654 
2025-04-07 19:50:06.051820: Pseudo dice [0.7945] 
2025-04-07 19:50:06.051906: Epoch time: 274.94 s 
2025-04-07 19:50:08.064258:  
2025-04-07 19:50:08.064445: Epoch 384 
2025-04-07 19:50:08.064559: Current learning rate: 0.00647 
2025-04-07 19:54:42.168414: train_loss -0.7738 
2025-04-07 19:54:42.168723: val_loss -0.7733 
2025-04-07 19:54:42.168802: Pseudo dice [0.8007] 
2025-04-07 19:54:42.168899: Epoch time: 274.11 s 
2025-04-07 19:54:44.476213:  
2025-04-07 19:54:44.476496: Epoch 385 
2025-04-07 19:54:44.476630: Current learning rate: 0.00646 
2025-04-07 19:59:18.980502: train_loss -0.7499 
2025-04-07 19:59:18.980977: val_loss -0.7802 
2025-04-07 19:59:18.981108: Pseudo dice [0.785] 
2025-04-07 19:59:18.981194: Epoch time: 274.51 s 
2025-04-07 19:59:20.973026:  
2025-04-07 19:59:20.973300: Epoch 386 
2025-04-07 19:59:20.973455: Current learning rate: 0.00645 
2025-04-07 20:03:54.686982: train_loss -0.7505 
2025-04-07 20:03:54.687288: val_loss -0.7607 
2025-04-07 20:03:54.687424: Pseudo dice [0.7925] 
2025-04-07 20:03:54.687523: Epoch time: 273.72 s 
2025-04-07 20:03:56.639286:  
2025-04-07 20:03:56.639531: Epoch 387 
2025-04-07 20:03:56.639646: Current learning rate: 0.00644 
2025-04-07 20:08:29.782600: train_loss -0.7911 
2025-04-07 20:08:29.783136: val_loss -0.7661 
2025-04-07 20:08:29.783484: Pseudo dice [0.7807] 
2025-04-07 20:08:29.783575: Epoch time: 273.15 s 
2025-04-07 20:08:31.759803:  
2025-04-07 20:08:31.760028: Epoch 388 
2025-04-07 20:08:31.760165: Current learning rate: 0.00643 
2025-04-07 20:13:04.751159: train_loss -0.8021 
2025-04-07 20:13:04.751485: val_loss -0.7989 
2025-04-07 20:13:04.751573: Pseudo dice [0.8083] 
2025-04-07 20:13:04.751708: Epoch time: 273.0 s 
2025-04-07 20:13:06.706824:  
2025-04-07 20:13:06.706987: Epoch 389 
2025-04-07 20:13:06.707102: Current learning rate: 0.00642 
2025-04-07 20:17:39.530082: train_loss -0.777 
2025-04-07 20:17:39.530395: val_loss -0.7782 
2025-04-07 20:17:39.530495: Pseudo dice [0.7974] 
2025-04-07 20:17:39.530591: Epoch time: 272.83 s 
2025-04-07 20:17:41.483604:  
2025-04-07 20:17:41.483830: Epoch 390 
2025-04-07 20:17:41.484016: Current learning rate: 0.00641 
2025-04-07 20:22:15.192419: train_loss -0.7717 
2025-04-07 20:22:15.192724: val_loss -0.7958 
2025-04-07 20:22:15.192806: Pseudo dice [0.8067] 
2025-04-07 20:22:15.192899: Epoch time: 273.71 s 
2025-04-07 20:22:17.151943:  
2025-04-07 20:22:17.152196: Epoch 391 
2025-04-07 20:22:17.152360: Current learning rate: 0.0064 
2025-04-07 20:26:49.603676: train_loss -0.8099 
2025-04-07 20:26:49.604265: val_loss -0.8049 
2025-04-07 20:26:49.604375: Pseudo dice [0.8079] 
2025-04-07 20:26:49.604462: Epoch time: 272.46 s 
2025-04-07 20:26:49.604525: Yayy! New best EMA pseudo Dice: 0.7946 
2025-04-07 20:26:52.827009:  
2025-04-07 20:26:52.827234: Epoch 392 
2025-04-07 20:26:52.827349: Current learning rate: 0.00639 
2025-04-07 20:31:25.867826: train_loss -0.7903 
2025-04-07 20:31:25.868422: val_loss -0.756 
2025-04-07 20:31:25.868859: Pseudo dice [0.7747] 
2025-04-07 20:31:25.868946: Epoch time: 273.04 s 
2025-04-07 20:31:27.826055:  
2025-04-07 20:31:27.826293: Epoch 393 
2025-04-07 20:31:27.826424: Current learning rate: 0.00638 
2025-04-07 20:36:01.663083: train_loss -0.7708 
2025-04-07 20:36:01.663403: val_loss -0.7689 
2025-04-07 20:36:01.663493: Pseudo dice [0.7893] 
2025-04-07 20:36:01.663595: Epoch time: 273.84 s 
2025-04-07 20:36:03.618543:  
2025-04-07 20:36:03.618764: Epoch 394 
2025-04-07 20:36:03.618884: Current learning rate: 0.00637 
2025-04-07 20:40:37.308255: train_loss -0.7974 
2025-04-07 20:40:37.308570: val_loss -0.7911 
2025-04-07 20:40:37.308699: Pseudo dice [0.8057] 
2025-04-07 20:40:37.308799: Epoch time: 273.69 s 
2025-04-07 20:40:39.278972:  
2025-04-07 20:40:39.279203: Epoch 395 
2025-04-07 20:40:39.279316: Current learning rate: 0.00636 
2025-04-07 20:45:12.874023: train_loss -0.8008 
2025-04-07 20:45:12.874357: val_loss -0.7879 
2025-04-07 20:45:12.874454: Pseudo dice [0.7934] 
2025-04-07 20:45:12.874538: Epoch time: 273.6 s 
2025-04-07 20:45:14.845737:  
2025-04-07 20:45:14.845943: Epoch 396 
2025-04-07 20:45:14.846063: Current learning rate: 0.00635 
2025-04-07 20:49:49.385575: train_loss -0.7926 
2025-04-07 20:49:49.385936: val_loss -0.784 
2025-04-07 20:49:49.386033: Pseudo dice [0.8023] 
2025-04-07 20:49:49.386129: Epoch time: 274.54 s 
2025-04-07 20:49:51.343568:  
2025-04-07 20:49:51.343772: Epoch 397 
2025-04-07 20:49:51.343921: Current learning rate: 0.00634 
2025-04-07 20:54:25.077821: train_loss -0.7962 
2025-04-07 20:54:25.078175: val_loss -0.7347 
2025-04-07 20:54:25.078350: Pseudo dice [0.7836] 
2025-04-07 20:54:25.078444: Epoch time: 273.74 s 
2025-04-07 20:54:27.061912:  
2025-04-07 20:54:27.062131: Epoch 398 
2025-04-07 20:54:27.062252: Current learning rate: 0.00633 
2025-04-07 20:59:00.447822: train_loss -0.7928 
2025-04-07 20:59:00.448143: val_loss -0.762 
2025-04-07 20:59:00.448243: Pseudo dice [0.7882] 
2025-04-07 20:59:00.448342: Epoch time: 273.39 s 
2025-04-07 20:59:02.461464:  
2025-04-07 20:59:02.461668: Epoch 399 
2025-04-07 20:59:02.461787: Current learning rate: 0.00632 
2025-04-07 21:03:35.898066: train_loss -0.7659 
2025-04-07 21:03:35.898771: val_loss -0.7593 
2025-04-07 21:03:35.898883: Pseudo dice [0.7697] 
2025-04-07 21:03:35.898972: Epoch time: 273.44 s 
2025-04-07 21:03:39.474911:  
2025-04-07 21:03:39.475140: Epoch 400 
2025-04-07 21:03:39.475259: Current learning rate: 0.00631 
2025-04-07 21:08:13.570769: train_loss -0.691 
2025-04-07 21:08:13.571052: val_loss -0.7682 
2025-04-07 21:08:13.571130: Pseudo dice [0.7886] 
2025-04-07 21:08:13.571245: Epoch time: 274.1 s 
2025-04-07 21:08:15.534129:  
2025-04-07 21:08:15.534342: Epoch 401 
2025-04-07 21:08:15.534501: Current learning rate: 0.0063 
2025-04-07 21:12:49.704583: train_loss -0.759 
2025-04-07 21:12:49.704916: val_loss -0.6529 
2025-04-07 21:12:49.705067: Pseudo dice [0.6522] 
2025-04-07 21:12:49.705172: Epoch time: 274.17 s 
2025-04-07 21:12:51.680046:  
2025-04-07 21:12:51.680310: Epoch 402 
2025-04-07 21:12:51.680423: Current learning rate: 0.0063 
2025-04-07 21:17:25.522577: train_loss -0.748 
2025-04-07 21:17:25.522897: val_loss -0.7567 
2025-04-07 21:17:25.523011: Pseudo dice [0.8044] 
2025-04-07 21:17:25.523108: Epoch time: 273.85 s 
2025-04-07 21:17:27.507631:  
2025-04-07 21:17:27.507871: Epoch 403 
2025-04-07 21:17:27.507990: Current learning rate: 0.00629 
2025-04-07 21:22:01.157248: train_loss -0.7642 
2025-04-07 21:22:01.157932: val_loss -0.7718 
2025-04-07 21:22:01.158037: Pseudo dice [0.7971] 
2025-04-07 21:22:01.158125: Epoch time: 273.65 s 
2025-04-07 21:22:03.113963:  
2025-04-07 21:22:03.114257: Epoch 404 
2025-04-07 21:22:03.114411: Current learning rate: 0.00628 
2025-04-07 21:26:37.134548: train_loss -0.7739 
2025-04-07 21:26:37.134832: val_loss -0.7845 
2025-04-07 21:26:37.134908: Pseudo dice [0.7979] 
2025-04-07 21:26:37.134992: Epoch time: 274.02 s 
2025-04-07 21:26:39.083244:  
2025-04-07 21:26:39.083430: Epoch 405 
2025-04-07 21:26:39.083612: Current learning rate: 0.00627 
2025-04-07 21:31:13.383080: train_loss -0.7544 
2025-04-07 21:31:13.383910: val_loss -0.7299 
2025-04-07 21:31:13.384446: Pseudo dice [0.682] 
2025-04-07 21:31:13.384547: Epoch time: 274.3 s 
2025-04-07 21:31:15.365564:  
2025-04-07 21:31:15.365756: Epoch 406 
2025-04-07 21:31:15.365877: Current learning rate: 0.00626 
2025-04-07 21:35:50.076518: train_loss -0.743 
2025-04-07 21:35:50.076901: val_loss -0.7733 
2025-04-07 21:35:50.077003: Pseudo dice [0.7841] 
2025-04-07 21:35:50.077099: Epoch time: 274.71 s 
2025-04-07 21:35:52.047345:  
2025-04-07 21:35:52.047523: Epoch 407 
2025-04-07 21:35:52.047727: Current learning rate: 0.00625 
2025-04-07 21:40:26.320769: train_loss -0.7581 
2025-04-07 21:40:26.321338: val_loss -0.6963 
2025-04-07 21:40:26.321442: Pseudo dice [0.6875] 
2025-04-07 21:40:26.321526: Epoch time: 274.28 s 
2025-04-07 21:40:28.590364:  
2025-04-07 21:40:28.590588: Epoch 408 
2025-04-07 21:40:28.590709: Current learning rate: 0.00624 
2025-04-07 21:45:02.995219: train_loss -0.7491 
2025-04-07 21:45:02.995517: val_loss -0.7269 
2025-04-07 21:45:02.995596: Pseudo dice [0.7553] 
2025-04-07 21:45:02.995700: Epoch time: 274.41 s 
2025-04-07 21:45:04.957497:  
2025-04-07 21:45:04.957747: Epoch 409 
2025-04-07 21:45:04.957938: Current learning rate: 0.00623 
2025-04-07 21:49:50.515066: train_loss -0.7487 
2025-04-07 21:49:50.515634: val_loss -0.7813 
2025-04-07 21:49:50.515747: Pseudo dice [0.7844] 
2025-04-07 21:49:50.515904: Epoch time: 285.56 s 
2025-04-07 21:49:52.472802:  
2025-04-07 21:49:52.473021: Epoch 410 
2025-04-07 21:49:52.473138: Current learning rate: 0.00622 
2025-04-07 21:54:28.006493: train_loss -0.7849 
2025-04-07 21:54:28.006846: val_loss -0.7468 
2025-04-07 21:54:28.006928: Pseudo dice [0.7672] 
2025-04-07 21:54:28.007028: Epoch time: 275.54 s 
2025-04-07 21:54:29.854512:  
2025-04-07 21:54:29.854749: Epoch 411 
2025-04-07 21:54:29.854904: Current learning rate: 0.00621 
2025-04-07 21:59:04.060947: train_loss -0.7353 
2025-04-07 21:59:04.061256: val_loss -0.741 
2025-04-07 21:59:04.061337: Pseudo dice [0.7165] 
2025-04-07 21:59:04.061424: Epoch time: 274.21 s 
2025-04-07 21:59:05.907472:  
2025-04-07 21:59:05.907676: Epoch 412 
2025-04-07 21:59:05.907799: Current learning rate: 0.0062 
2025-04-07 22:03:39.435557: train_loss -0.7497 
2025-04-07 22:03:39.436155: val_loss -0.7513 
2025-04-07 22:03:39.436269: Pseudo dice [0.7919] 
2025-04-07 22:03:39.436363: Epoch time: 273.53 s 
2025-04-07 22:03:41.302442:  
2025-04-07 22:03:41.302627: Epoch 413 
2025-04-07 22:03:41.302744: Current learning rate: 0.00619 
2025-04-07 22:08:14.103956: train_loss -0.7593 
2025-04-07 22:08:14.104314: val_loss -0.7326 
2025-04-07 22:08:14.104440: Pseudo dice [0.7379] 
2025-04-07 22:08:14.104540: Epoch time: 272.81 s 
2025-04-07 22:08:15.951519:  
2025-04-07 22:08:15.951743: Epoch 414 
2025-04-07 22:08:15.951949: Current learning rate: 0.00618 
2025-04-07 22:12:50.935518: train_loss -0.7874 
2025-04-07 22:12:50.936993: val_loss -0.7784 
2025-04-07 22:12:50.937139: Pseudo dice [0.7965] 
2025-04-07 22:12:50.937224: Epoch time: 274.99 s 
2025-04-07 22:12:52.802569:  
2025-04-07 22:12:52.802782: Epoch 415 
2025-04-07 22:12:52.802902: Current learning rate: 0.00617 
2025-04-07 22:17:25.279180: train_loss -0.7969 
2025-04-07 22:17:25.279517: val_loss -0.7852 
2025-04-07 22:17:25.279604: Pseudo dice [0.7984] 
2025-04-07 22:17:25.279728: Epoch time: 272.48 s 
2025-04-07 22:17:27.471815:  
2025-04-07 22:17:27.472015: Epoch 416 
2025-04-07 22:17:27.472141: Current learning rate: 0.00616 
2025-04-07 22:22:02.144116: train_loss -0.7679 
2025-04-07 22:22:02.144952: val_loss -0.7711 
2025-04-07 22:22:02.145176: Pseudo dice [0.7828] 
2025-04-07 22:22:02.145260: Epoch time: 274.68 s 
2025-04-07 22:22:04.011023:  
2025-04-07 22:22:04.011246: Epoch 417 
2025-04-07 22:22:04.011367: Current learning rate: 0.00615 
2025-04-07 22:26:36.402620: train_loss -0.7833 
2025-04-07 22:26:36.402933: val_loss -0.7685 
2025-04-07 22:26:36.403015: Pseudo dice [0.7665] 
2025-04-07 22:26:36.403105: Epoch time: 272.4 s 
2025-04-07 22:26:38.255513:  
2025-04-07 22:26:38.255734: Epoch 418 
2025-04-07 22:26:38.255869: Current learning rate: 0.00614 
2025-04-07 22:31:32.900436: train_loss -0.7736 
2025-04-07 22:31:32.900973: val_loss -0.7739 
2025-04-07 22:31:32.901069: Pseudo dice [0.7985] 
2025-04-07 22:31:32.901164: Epoch time: 294.65 s 
2025-04-07 22:31:35.007929:  
2025-04-07 22:31:35.008174: Epoch 419 
2025-04-07 22:31:35.008299: Current learning rate: 0.00613 
2025-04-07 22:36:27.647928: train_loss -0.7652 
2025-04-07 22:36:27.648329: val_loss -0.7616 
2025-04-07 22:36:27.648437: Pseudo dice [0.8028] 
2025-04-07 22:36:27.648523: Epoch time: 292.64 s 
2025-04-07 22:36:29.518099:  
2025-04-07 22:36:29.518303: Epoch 420 
2025-04-07 22:36:29.518420: Current learning rate: 0.00612 
2025-04-07 22:41:02.961895: train_loss -0.783 
2025-04-07 22:41:02.962202: val_loss -0.7889 
2025-04-07 22:41:02.962277: Pseudo dice [0.7897] 
2025-04-07 22:41:02.962358: Epoch time: 273.45 s 
2025-04-07 22:41:04.816659:  
2025-04-07 22:41:04.816884: Epoch 421 
2025-04-07 22:41:04.817002: Current learning rate: 0.00612 
2025-04-07 22:45:38.933539: train_loss -0.7869 
2025-04-07 22:45:38.933878: val_loss -0.7731 
2025-04-07 22:45:38.934681: Pseudo dice [0.7922] 
2025-04-07 22:45:38.934768: Epoch time: 274.12 s 
2025-04-07 22:45:40.861366:  
2025-04-07 22:45:40.861622: Epoch 422 
2025-04-07 22:45:40.861750: Current learning rate: 0.00611 
2025-04-07 22:50:14.233590: train_loss -0.7868 
2025-04-07 22:50:14.233962: val_loss -0.7836 
2025-04-07 22:50:14.234063: Pseudo dice [0.7976] 
2025-04-07 22:50:14.234155: Epoch time: 273.38 s 
2025-04-07 22:50:16.102799:  
2025-04-07 22:50:16.102981: Epoch 423 
2025-04-07 22:50:16.103102: Current learning rate: 0.0061 
2025-04-07 22:54:50.341158: train_loss -0.7833 
2025-04-07 22:54:50.347040: val_loss -0.7477 
2025-04-07 22:54:50.347160: Pseudo dice [0.7459] 
2025-04-07 22:54:50.347243: Epoch time: 274.24 s 
2025-04-07 22:54:52.256869:  
2025-04-07 22:54:52.257090: Epoch 424 
2025-04-07 22:54:52.257205: Current learning rate: 0.00609 
2025-04-07 22:59:26.386817: train_loss -0.7495 
2025-04-07 22:59:26.387123: val_loss -0.7832 
2025-04-07 22:59:26.387201: Pseudo dice [0.7894] 
2025-04-07 22:59:26.387285: Epoch time: 274.13 s 
2025-04-07 22:59:28.587886:  
2025-04-07 22:59:28.588119: Epoch 425 
2025-04-07 22:59:28.588229: Current learning rate: 0.00608 
2025-04-07 23:04:12.244193: train_loss -0.7443 
2025-04-07 23:04:12.244778: val_loss -0.7874 
2025-04-07 23:04:12.244963: Pseudo dice [0.781] 
2025-04-07 23:04:12.245073: Epoch time: 283.66 s 
2025-04-07 23:04:14.173046:  
2025-04-07 23:04:14.173310: Epoch 426 
2025-04-07 23:04:14.173425: Current learning rate: 0.00607 
2025-04-07 23:08:47.992480: train_loss -0.7694 
2025-04-07 23:08:47.992786: val_loss -0.7507 
2025-04-07 23:08:47.992889: Pseudo dice [0.7658] 
2025-04-07 23:08:47.992977: Epoch time: 273.82 s 
2025-04-07 23:08:49.866874:  
2025-04-07 23:08:49.867097: Epoch 427 
2025-04-07 23:08:49.867229: Current learning rate: 0.00606 
2025-04-07 23:13:23.628820: train_loss -0.7951 
2025-04-07 23:13:23.629403: val_loss -0.776 
2025-04-07 23:13:23.629508: Pseudo dice [0.7991] 
2025-04-07 23:13:23.629590: Epoch time: 273.77 s 
2025-04-07 23:13:25.517728:  
2025-04-07 23:13:25.517905: Epoch 428 
2025-04-07 23:13:25.518017: Current learning rate: 0.00605 
2025-04-07 23:18:00.331384: train_loss -0.7671 
2025-04-07 23:18:00.331784: val_loss -0.6808 
2025-04-07 23:18:00.331954: Pseudo dice [0.6434] 
2025-04-07 23:18:00.332043: Epoch time: 274.82 s 
2025-04-07 23:18:02.198734:  
2025-04-07 23:18:02.198920: Epoch 429 
2025-04-07 23:18:02.199036: Current learning rate: 0.00604 
2025-04-07 23:22:36.719285: train_loss -0.7482 
2025-04-07 23:22:36.719907: val_loss -0.7641 
2025-04-07 23:22:36.720023: Pseudo dice [0.7838] 
2025-04-07 23:22:36.720109: Epoch time: 274.52 s 
2025-04-07 23:22:38.592687:  
2025-04-07 23:22:38.592913: Epoch 430 
2025-04-07 23:22:38.593146: Current learning rate: 0.00603 
2025-04-07 23:27:15.250046: train_loss -0.7777 
2025-04-07 23:27:15.250362: val_loss -0.7954 
2025-04-07 23:27:15.250449: Pseudo dice [0.7948] 
2025-04-07 23:27:15.250539: Epoch time: 276.66 s 
2025-04-07 23:27:17.116463:  
2025-04-07 23:27:17.116714: Epoch 431 
2025-04-07 23:27:17.116862: Current learning rate: 0.00602 
2025-04-07 23:31:51.574677: train_loss -0.7924 
2025-04-07 23:31:51.575381: val_loss -0.7878 
2025-04-07 23:31:51.575487: Pseudo dice [0.7925] 
2025-04-07 23:31:51.575570: Epoch time: 274.46 s 
2025-04-07 23:31:53.433627:  
2025-04-07 23:31:53.433870: Epoch 432 
2025-04-07 23:31:53.434007: Current learning rate: 0.00601 
2025-04-07 23:36:27.457510: train_loss -0.7857 
2025-04-07 23:36:27.457804: val_loss -0.7498 
2025-04-07 23:36:27.457893: Pseudo dice [0.8044] 
2025-04-07 23:36:27.458019: Epoch time: 274.03 s 
2025-04-07 23:36:29.635558:  
2025-04-07 23:36:29.635833: Epoch 433 
2025-04-07 23:36:29.635956: Current learning rate: 0.006 
2025-04-07 23:41:03.087210: train_loss -0.7928 
2025-04-07 23:41:03.087565: val_loss -0.792 
2025-04-07 23:41:03.087674: Pseudo dice [0.7988] 
2025-04-07 23:41:03.087776: Epoch time: 273.46 s 
2025-04-07 23:41:04.972047:  
2025-04-07 23:41:04.972224: Epoch 434 
2025-04-07 23:41:04.972396: Current learning rate: 0.00599 
2025-04-07 23:45:37.829308: train_loss -0.7834 
2025-04-07 23:45:37.829630: val_loss -0.7817 
2025-04-07 23:45:37.829717: Pseudo dice [0.806] 
2025-04-07 23:45:37.829820: Epoch time: 272.86 s 
2025-04-07 23:45:39.688127:  
2025-04-07 23:45:39.688406: Epoch 435 
2025-04-07 23:45:39.688596: Current learning rate: 0.00598 
2025-04-07 23:50:12.181324: train_loss -0.795 
2025-04-07 23:50:12.181647: val_loss -0.7978 
2025-04-07 23:50:12.181732: Pseudo dice [0.7873] 
2025-04-07 23:50:12.181831: Epoch time: 272.5 s 
2025-04-07 23:50:14.051827:  
2025-04-07 23:50:14.052046: Epoch 436 
2025-04-07 23:50:14.052158: Current learning rate: 0.00597 
2025-04-07 23:54:46.930977: train_loss -0.7892 
2025-04-07 23:54:46.931289: val_loss -0.8036 
2025-04-07 23:54:46.931420: Pseudo dice [0.7938] 
2025-04-07 23:54:46.931531: Epoch time: 272.88 s 
2025-04-07 23:54:48.843414:  
2025-04-07 23:54:48.843671: Epoch 437 
2025-04-07 23:54:48.843797: Current learning rate: 0.00596 
2025-04-07 23:59:21.449523: train_loss -0.8037 
2025-04-07 23:59:21.449908: val_loss -0.7855 
2025-04-07 23:59:21.449991: Pseudo dice [0.7831] 
2025-04-07 23:59:21.450081: Epoch time: 272.61 s 
2025-04-07 23:59:23.318815:  
2025-04-07 23:59:23.319024: Epoch 438 
2025-04-07 23:59:23.319143: Current learning rate: 0.00595 
2025-04-08 00:03:56.757206: train_loss -0.793 
2025-04-08 00:03:56.757992: val_loss -0.7659 
2025-04-08 00:03:56.758102: Pseudo dice [0.7595] 
2025-04-08 00:03:56.758189: Epoch time: 273.44 s 
2025-04-08 00:03:58.622086:  
2025-04-08 00:03:58.622257: Epoch 439 
2025-04-08 00:03:58.622374: Current learning rate: 0.00594 
2025-04-08 00:08:31.900867: train_loss -0.7929 
2025-04-08 00:08:31.901226: val_loss -0.7833 
2025-04-08 00:08:31.901310: Pseudo dice [0.8087] 
2025-04-08 00:08:31.901412: Epoch time: 273.28 s 
2025-04-08 00:08:33.782540:  
2025-04-08 00:08:33.782807: Epoch 440 
2025-04-08 00:08:33.782942: Current learning rate: 0.00593 
2025-04-08 00:13:06.816264: train_loss -0.7864 
2025-04-08 00:13:06.816600: val_loss -0.7706 
2025-04-08 00:13:06.816684: Pseudo dice [0.7855] 
2025-04-08 00:13:06.816777: Epoch time: 273.04 s 
2025-04-08 00:13:08.720759:  
2025-04-08 00:13:08.720983: Epoch 441 
2025-04-08 00:13:08.721142: Current learning rate: 0.00592 
2025-04-08 00:17:42.924223: train_loss -0.7529 
2025-04-08 00:17:42.924839: val_loss -0.7425 
2025-04-08 00:17:42.924945: Pseudo dice [0.7721] 
2025-04-08 00:17:42.925028: Epoch time: 274.21 s 
2025-04-08 00:17:45.126274:  
2025-04-08 00:17:45.126504: Epoch 442 
2025-04-08 00:17:45.126642: Current learning rate: 0.00592 
2025-04-08 00:22:19.116084: train_loss -0.7511 
2025-04-08 00:22:19.116427: val_loss -0.7859 
2025-04-08 00:22:19.116513: Pseudo dice [0.8042] 
2025-04-08 00:22:19.116608: Epoch time: 273.99 s 
2025-04-08 00:22:20.977247:  
2025-04-08 00:22:20.977465: Epoch 443 
2025-04-08 00:22:20.977580: Current learning rate: 0.00591 
2025-04-08 00:26:54.774372: train_loss -0.7735 
2025-04-08 00:26:54.774973: val_loss -0.7701 
2025-04-08 00:26:54.775078: Pseudo dice [0.7937] 
2025-04-08 00:26:54.775218: Epoch time: 273.8 s 
2025-04-08 00:26:56.677772:  
2025-04-08 00:26:56.678102: Epoch 444 
2025-04-08 00:26:56.678315: Current learning rate: 0.0059 
2025-04-08 00:31:29.898317: train_loss -0.789 
2025-04-08 00:31:29.898630: val_loss -0.7497 
2025-04-08 00:31:29.898713: Pseudo dice [0.7585] 
2025-04-08 00:31:29.898822: Epoch time: 273.22 s 
2025-04-08 00:31:31.805192:  
2025-04-08 00:31:31.805398: Epoch 445 
2025-04-08 00:31:31.805517: Current learning rate: 0.00589 
2025-04-08 00:36:05.100445: train_loss -0.7926 
2025-04-08 00:36:05.100767: val_loss -0.7843 
2025-04-08 00:36:05.100857: Pseudo dice [0.8049] 
2025-04-08 00:36:05.100961: Epoch time: 273.3 s 
2025-04-08 00:36:06.983988:  
2025-04-08 00:36:06.984218: Epoch 446 
2025-04-08 00:36:06.984349: Current learning rate: 0.00588 
2025-04-08 00:40:40.287953: train_loss -0.7997 
2025-04-08 00:40:40.288245: val_loss -0.7846 
2025-04-08 00:40:40.288327: Pseudo dice [0.7328] 
2025-04-08 00:40:40.288442: Epoch time: 273.31 s 
2025-04-08 00:40:42.152872:  
2025-04-08 00:40:42.153086: Epoch 447 
2025-04-08 00:40:42.153203: Current learning rate: 0.00587 
2025-04-08 00:45:15.940479: train_loss -0.7998 
2025-04-08 00:45:15.941017: val_loss -0.7654 
2025-04-08 00:45:15.941310: Pseudo dice [0.7974] 
2025-04-08 00:45:15.941400: Epoch time: 273.79 s 
2025-04-08 00:45:17.955581:  
2025-04-08 00:45:17.955842: Epoch 448 
2025-04-08 00:45:17.955973: Current learning rate: 0.00586 
2025-04-08 00:49:51.256962: train_loss -0.7912 
2025-04-08 00:49:51.257319: val_loss -0.7568 
2025-04-08 00:49:51.257402: Pseudo dice [0.7974] 
2025-04-08 00:49:51.257496: Epoch time: 273.31 s 
2025-04-08 00:49:53.110925:  
2025-04-08 00:49:53.111143: Epoch 449 
2025-04-08 00:49:53.111281: Current learning rate: 0.00585 
2025-04-08 00:54:26.853309: train_loss -0.7736 
2025-04-08 00:54:26.853948: val_loss -0.7376 
2025-04-08 00:54:26.854105: Pseudo dice [0.7255] 
2025-04-08 00:54:26.854194: Epoch time: 273.75 s 
2025-04-08 00:54:30.276482:  
2025-04-08 00:54:30.276738: Epoch 450 
2025-04-08 00:54:30.276927: Current learning rate: 0.00584 
2025-04-08 00:59:04.361081: train_loss -0.7555 
2025-04-08 00:59:04.367737: val_loss -0.7892 
2025-04-08 00:59:04.367849: Pseudo dice [0.788] 
2025-04-08 00:59:04.367933: Epoch time: 274.09 s 
2025-04-08 00:59:06.223745:  
2025-04-08 00:59:06.224041: Epoch 451 
2025-04-08 00:59:06.224216: Current learning rate: 0.00583 
2025-04-08 01:03:39.913889: train_loss -0.7947 
2025-04-08 01:03:39.914199: val_loss -0.7923 
2025-04-08 01:03:39.914277: Pseudo dice [0.8142] 
2025-04-08 01:03:39.914420: Epoch time: 273.69 s 
2025-04-08 01:03:41.765610:  
2025-04-08 01:03:41.765830: Epoch 452 
2025-04-08 01:03:41.765965: Current learning rate: 0.00582 
2025-04-08 01:08:15.838602: train_loss -0.7819 
2025-04-08 01:08:15.838895: val_loss -0.7712 
2025-04-08 01:08:15.838979: Pseudo dice [0.7849] 
2025-04-08 01:08:15.839063: Epoch time: 274.08 s 
2025-04-08 01:08:17.675914:  
2025-04-08 01:08:17.676161: Epoch 453 
2025-04-08 01:08:17.676322: Current learning rate: 0.00581 
2025-04-08 01:12:51.545533: train_loss -0.7885 
2025-04-08 01:12:51.545846: val_loss -0.7806 
2025-04-08 01:12:51.545951: Pseudo dice [0.7997] 
2025-04-08 01:12:51.546074: Epoch time: 273.87 s 
2025-04-08 01:12:53.402753:  
2025-04-08 01:12:53.402929: Epoch 454 
2025-04-08 01:12:53.403093: Current learning rate: 0.0058 
2025-04-08 01:17:28.541801: train_loss -0.8037 
2025-04-08 01:17:28.542589: val_loss -0.7974 
2025-04-08 01:17:28.542700: Pseudo dice [0.8198] 
2025-04-08 01:17:28.542785: Epoch time: 275.14 s 
2025-04-08 01:17:30.409468:  
2025-04-08 01:17:30.409680: Epoch 455 
2025-04-08 01:17:30.409793: Current learning rate: 0.00579 
2025-04-08 01:22:04.685057: train_loss -0.8046 
2025-04-08 01:22:04.685373: val_loss -0.7318 
2025-04-08 01:22:04.685454: Pseudo dice [0.7678] 
2025-04-08 01:22:04.685542: Epoch time: 274.28 s 
2025-04-08 01:22:06.540462:  
2025-04-08 01:22:06.540676: Epoch 456 
2025-04-08 01:22:06.540801: Current learning rate: 0.00578 
2025-04-08 01:26:40.519962: train_loss -0.8069 
2025-04-08 01:26:40.520211: val_loss -0.7821 
2025-04-08 01:26:40.520295: Pseudo dice [0.7995] 
2025-04-08 01:26:40.520396: Epoch time: 273.98 s 
2025-04-08 01:26:42.457972:  
2025-04-08 01:26:42.458189: Epoch 457 
2025-04-08 01:26:42.458300: Current learning rate: 0.00577 
2025-04-08 01:31:16.389900: train_loss -0.752 
2025-04-08 01:31:16.390204: val_loss -0.7448 
2025-04-08 01:31:16.390288: Pseudo dice [0.7813] 
2025-04-08 01:31:16.390371: Epoch time: 273.94 s 
2025-04-08 01:31:18.244974:  
2025-04-08 01:31:18.245183: Epoch 458 
2025-04-08 01:31:18.245296: Current learning rate: 0.00576 
2025-04-08 01:35:51.961548: train_loss -0.7648 
2025-04-08 01:35:51.961916: val_loss -0.7483 
2025-04-08 01:35:51.961992: Pseudo dice [0.7793] 
2025-04-08 01:35:51.962086: Epoch time: 273.72 s 
2025-04-08 01:35:54.128508:  
2025-04-08 01:35:54.128847: Epoch 459 
2025-04-08 01:35:54.129102: Current learning rate: 0.00575 
2025-04-08 01:40:27.950392: train_loss -0.7834 
2025-04-08 01:40:27.950750: val_loss -0.7845 
2025-04-08 01:40:27.950848: Pseudo dice [0.7967] 
2025-04-08 01:40:27.950953: Epoch time: 273.83 s 
2025-04-08 01:40:29.792941:  
2025-04-08 01:40:29.793169: Epoch 460 
2025-04-08 01:40:29.793285: Current learning rate: 0.00574 
2025-04-08 01:45:16.075905: train_loss -0.8084 
2025-04-08 01:45:16.076488: val_loss -0.7852 
2025-04-08 01:45:16.076595: Pseudo dice [0.7929] 
2025-04-08 01:45:16.076698: Epoch time: 286.29 s 
2025-04-08 01:45:17.943435:  
2025-04-08 01:45:17.943670: Epoch 461 
2025-04-08 01:45:17.943835: Current learning rate: 0.00573 
2025-04-08 01:49:51.582458: train_loss -0.7835 
2025-04-08 01:49:51.582765: val_loss -0.7655 
2025-04-08 01:49:51.582861: Pseudo dice [0.7931] 
2025-04-08 01:49:51.582969: Epoch time: 273.64 s 
2025-04-08 01:49:53.470169:  
2025-04-08 01:49:53.470419: Epoch 462 
2025-04-08 01:49:53.470569: Current learning rate: 0.00572 
2025-04-08 01:54:26.868188: train_loss -0.7967 
2025-04-08 01:54:26.868722: val_loss -0.7631 
2025-04-08 01:54:26.868881: Pseudo dice [0.791] 
2025-04-08 01:54:26.869011: Epoch time: 273.4 s 
2025-04-08 01:54:28.719017:  
2025-04-08 01:54:28.719238: Epoch 463 
2025-04-08 01:54:28.719367: Current learning rate: 0.00571 
2025-04-08 01:59:02.519091: train_loss -0.7866 
2025-04-08 01:59:02.519962: val_loss -0.7714 
2025-04-08 01:59:02.520053: Pseudo dice [0.7858] 
2025-04-08 01:59:02.520244: Epoch time: 273.8 s 
2025-04-08 01:59:04.374526:  
2025-04-08 01:59:04.374851: Epoch 464 
2025-04-08 01:59:04.375013: Current learning rate: 0.0057 
2025-04-08 02:03:38.398874: train_loss -0.7884 
2025-04-08 02:03:38.399475: val_loss -0.769 
2025-04-08 02:03:38.399971: Pseudo dice [0.7906] 
2025-04-08 02:03:38.400063: Epoch time: 274.03 s 
2025-04-08 02:03:40.253235:  
2025-04-08 02:03:40.253495: Epoch 465 
2025-04-08 02:03:40.253609: Current learning rate: 0.0057 
2025-04-08 02:08:14.575016: train_loss -0.7985 
2025-04-08 02:08:14.575554: val_loss -0.7288 
2025-04-08 02:08:14.575657: Pseudo dice [0.7552] 
2025-04-08 02:08:14.575738: Epoch time: 274.33 s 
2025-04-08 02:08:16.445613:  
2025-04-08 02:08:16.445822: Epoch 466 
2025-04-08 02:08:16.445948: Current learning rate: 0.00569 
2025-04-08 02:12:50.501364: train_loss -0.8039 
2025-04-08 02:12:50.501741: val_loss -0.7634 
2025-04-08 02:12:50.501832: Pseudo dice [0.7863] 
2025-04-08 02:12:50.501927: Epoch time: 274.06 s 
2025-04-08 02:12:52.336860:  
2025-04-08 02:12:52.337055: Epoch 467 
2025-04-08 02:12:52.337165: Current learning rate: 0.00568 
2025-04-08 02:17:26.981471: train_loss -0.7473 
2025-04-08 02:17:26.981970: val_loss -0.7672 
2025-04-08 02:17:26.982053: Pseudo dice [0.797] 
2025-04-08 02:17:26.982134: Epoch time: 274.65 s 
2025-04-08 02:17:29.132964:  
2025-04-08 02:17:29.133225: Epoch 468 
2025-04-08 02:17:29.133380: Current learning rate: 0.00567 
2025-04-08 02:22:56.104502: train_loss -0.7713 
2025-04-08 02:22:56.105313: val_loss -0.7727 
2025-04-08 02:22:56.105422: Pseudo dice [0.779] 
2025-04-08 02:22:56.105541: Epoch time: 326.98 s 
2025-04-08 02:22:57.988906:  
2025-04-08 02:22:57.989154: Epoch 469 
2025-04-08 02:22:57.989272: Current learning rate: 0.00566 
2025-04-08 02:27:33.817527: train_loss -0.7956 
2025-04-08 02:27:33.818118: val_loss -0.8028 
2025-04-08 02:27:33.818219: Pseudo dice [0.8107] 
2025-04-08 02:27:33.818303: Epoch time: 275.83 s 
2025-04-08 02:27:35.669832:  
2025-04-08 02:27:35.670031: Epoch 470 
2025-04-08 02:27:35.670186: Current learning rate: 0.00565 
2025-04-08 02:32:09.976262: train_loss -0.8057 
2025-04-08 02:32:09.976688: val_loss -0.7981 
2025-04-08 02:32:09.976814: Pseudo dice [0.7994] 
2025-04-08 02:32:09.976917: Epoch time: 274.31 s 
2025-04-08 02:32:11.841085:  
2025-04-08 02:32:11.841350: Epoch 471 
2025-04-08 02:32:11.841524: Current learning rate: 0.00564 
2025-04-08 02:36:45.760527: train_loss -0.8166 
2025-04-08 02:36:45.760840: val_loss -0.7924 
2025-04-08 02:36:45.760926: Pseudo dice [0.81] 
2025-04-08 02:36:45.761015: Epoch time: 273.92 s 
2025-04-08 02:36:47.598123:  
2025-04-08 02:36:47.598318: Epoch 472 
2025-04-08 02:36:47.598430: Current learning rate: 0.00563 
2025-04-08 02:41:21.593060: train_loss -0.8049 
2025-04-08 02:41:21.593464: val_loss -0.7702 
2025-04-08 02:41:21.593574: Pseudo dice [0.7993] 
2025-04-08 02:41:21.593655: Epoch time: 274.0 s 
2025-04-08 02:41:23.427345:  
2025-04-08 02:41:23.427548: Epoch 473 
2025-04-08 02:41:23.427689: Current learning rate: 0.00562 
2025-04-08 02:45:57.698561: train_loss -0.8124 
2025-04-08 02:45:57.699357: val_loss -0.7682 
2025-04-08 02:45:57.699462: Pseudo dice [0.8023] 
2025-04-08 02:45:57.699548: Epoch time: 274.28 s 
2025-04-08 02:45:59.532409:  
2025-04-08 02:45:59.532642: Epoch 474 
2025-04-08 02:45:59.532866: Current learning rate: 0.00561 
2025-04-08 02:50:34.097073: train_loss -0.8019 
2025-04-08 02:50:34.097429: val_loss -0.7561 
2025-04-08 02:50:34.097534: Pseudo dice [0.795] 
2025-04-08 02:50:34.097627: Epoch time: 274.57 s 
2025-04-08 02:50:35.937487:  
2025-04-08 02:50:35.937736: Epoch 475 
2025-04-08 02:50:35.937860: Current learning rate: 0.0056 
2025-04-08 02:55:09.751634: train_loss -0.7992 
2025-04-08 02:55:09.752000: val_loss -0.7905 
2025-04-08 02:55:09.752083: Pseudo dice [0.802] 
2025-04-08 02:55:09.752176: Epoch time: 273.82 s 
2025-04-08 02:55:11.900680:  
2025-04-08 02:55:11.900982: Epoch 476 
2025-04-08 02:55:11.901130: Current learning rate: 0.00559 
2025-04-08 03:02:34.415002: train_loss -0.8062 
2025-04-08 03:02:34.415642: val_loss -0.7565 
2025-04-08 03:02:34.415730: Pseudo dice [0.7928] 
2025-04-08 03:02:34.415823: Epoch time: 442.52 s 
2025-04-08 03:02:36.900915:  
2025-04-08 03:02:36.901175: Epoch 477 
2025-04-08 03:02:36.901286: Current learning rate: 0.00558 
2025-04-08 03:09:58.170550: train_loss -0.8131 
2025-04-08 03:09:58.171141: val_loss -0.7786 
2025-04-08 03:09:58.171246: Pseudo dice [0.7958] 
2025-04-08 03:09:58.171328: Epoch time: 441.27 s 
2025-04-08 03:10:00.117668:  
2025-04-08 03:10:00.117966: Epoch 478 
2025-04-08 03:10:00.118082: Current learning rate: 0.00557 
2025-04-08 03:14:34.476535: train_loss -0.7973 
2025-04-08 03:14:34.476895: val_loss -0.7889 
2025-04-08 03:14:34.476994: Pseudo dice [0.7993] 
2025-04-08 03:14:34.477084: Epoch time: 274.36 s 
2025-04-08 03:14:34.477140: Yayy! New best EMA pseudo Dice: 0.7947 
2025-04-08 03:14:37.624138:  
2025-04-08 03:14:37.624318: Epoch 479 
2025-04-08 03:14:37.624433: Current learning rate: 0.00556 
2025-04-08 03:19:12.161771: train_loss -0.7994 
2025-04-08 03:19:12.162127: val_loss -0.7761 
2025-04-08 03:19:12.162221: Pseudo dice [0.8] 
2025-04-08 03:19:12.162318: Epoch time: 274.54 s 
2025-04-08 03:19:12.162375: Yayy! New best EMA pseudo Dice: 0.7953 
2025-04-08 03:19:15.396745:  
2025-04-08 03:19:15.396961: Epoch 480 
2025-04-08 03:19:15.397078: Current learning rate: 0.00555 
2025-04-08 03:23:49.877209: train_loss -0.8005 
2025-04-08 03:23:49.877684: val_loss -0.7769 
2025-04-08 03:23:49.877772: Pseudo dice [0.7907] 
2025-04-08 03:23:49.877851: Epoch time: 274.48 s 
2025-04-08 03:23:51.750236:  
2025-04-08 03:23:51.750448: Epoch 481 
2025-04-08 03:23:51.750587: Current learning rate: 0.00554 
2025-04-08 03:28:26.521498: train_loss -0.8012 
2025-04-08 03:28:26.522068: val_loss -0.7701 
2025-04-08 03:28:26.522167: Pseudo dice [0.7876] 
2025-04-08 03:28:26.522251: Epoch time: 274.78 s 
2025-04-08 03:28:28.389344:  
2025-04-08 03:28:28.389594: Epoch 482 
2025-04-08 03:28:28.389741: Current learning rate: 0.00553 
2025-04-08 03:33:02.906984: train_loss -0.7908 
2025-04-08 03:33:02.907289: val_loss -0.7897 
2025-04-08 03:33:02.907388: Pseudo dice [0.8022] 
2025-04-08 03:33:02.907493: Epoch time: 274.52 s 
2025-04-08 03:33:04.784863:  
2025-04-08 03:33:04.785100: Epoch 483 
2025-04-08 03:33:04.785280: Current learning rate: 0.00552 
2025-04-08 03:37:39.902697: train_loss -0.8094 
2025-04-08 03:37:39.903044: val_loss -0.7847 
2025-04-08 03:37:39.903209: Pseudo dice [0.7778] 
2025-04-08 03:37:39.903294: Epoch time: 275.12 s 
2025-04-08 03:37:42.070447:  
2025-04-08 03:37:42.070693: Epoch 484 
2025-04-08 03:37:42.070828: Current learning rate: 0.00551 
2025-04-08 03:42:17.512201: train_loss -0.8154 
2025-04-08 03:42:17.512795: val_loss -0.7872 
2025-04-08 03:42:17.512910: Pseudo dice [0.8092] 
2025-04-08 03:42:17.513000: Epoch time: 275.45 s 
2025-04-08 03:42:19.372252:  
2025-04-08 03:42:19.372542: Epoch 485 
2025-04-08 03:42:19.372659: Current learning rate: 0.0055 
2025-04-08 03:46:54.548507: train_loss -0.8039 
2025-04-08 03:46:54.548824: val_loss -0.7906 
2025-04-08 03:46:54.550141: Pseudo dice [0.7736] 
2025-04-08 03:46:54.550238: Epoch time: 275.18 s 
2025-04-08 03:46:56.410823:  
2025-04-08 03:46:56.411021: Epoch 486 
2025-04-08 03:46:56.411139: Current learning rate: 0.00549 
2025-04-08 03:51:35.091026: train_loss -0.7992 
2025-04-08 03:51:35.091598: val_loss -0.7989 
2025-04-08 03:51:35.091678: Pseudo dice [0.8042] 
2025-04-08 03:51:35.091770: Epoch time: 278.68 s 
2025-04-08 03:51:36.957154:  
2025-04-08 03:51:36.957365: Epoch 487 
2025-04-08 03:51:36.957474: Current learning rate: 0.00548 
2025-04-08 03:56:11.253500: train_loss -0.8024 
2025-04-08 03:56:11.253833: val_loss -0.7961 
2025-04-08 03:56:11.253933: Pseudo dice [0.7998] 
2025-04-08 03:56:11.254032: Epoch time: 274.3 s 
2025-04-08 03:56:13.117263:  
2025-04-08 03:56:13.117475: Epoch 488 
2025-04-08 03:56:13.117590: Current learning rate: 0.00547 
2025-04-08 04:00:46.440354: train_loss -0.7754 
2025-04-08 04:00:46.440723: val_loss -0.7609 
2025-04-08 04:00:46.440816: Pseudo dice [0.7532] 
2025-04-08 04:00:46.440914: Epoch time: 273.33 s 
2025-04-08 04:00:48.335922:  
2025-04-08 04:00:48.336151: Epoch 489 
2025-04-08 04:00:48.336270: Current learning rate: 0.00546 
2025-04-08 04:05:21.366922: train_loss -0.7946 
2025-04-08 04:05:21.367227: val_loss -0.7787 
2025-04-08 04:05:21.367306: Pseudo dice [0.7917] 
2025-04-08 04:05:21.367394: Epoch time: 273.04 s 
2025-04-08 04:05:23.226678:  
2025-04-08 04:05:23.226879: Epoch 490 
2025-04-08 04:05:23.226998: Current learning rate: 0.00546 
2025-04-08 04:09:57.249447: train_loss -0.7749 
2025-04-08 04:09:57.249940: val_loss -0.735 
2025-04-08 04:09:57.250028: Pseudo dice [0.7703] 
2025-04-08 04:09:57.250120: Epoch time: 274.03 s 
2025-04-08 04:09:59.124722:  
2025-04-08 04:09:59.124945: Epoch 491 
2025-04-08 04:09:59.125128: Current learning rate: 0.00545 
2025-04-08 04:14:33.003027: train_loss -0.7973 
2025-04-08 04:14:33.003345: val_loss -0.76 
2025-04-08 04:14:33.003437: Pseudo dice [0.7808] 
2025-04-08 04:14:33.003541: Epoch time: 273.88 s 
2025-04-08 04:14:35.178105:  
2025-04-08 04:14:35.178362: Epoch 492 
2025-04-08 04:14:35.178480: Current learning rate: 0.00544 
2025-04-08 04:19:24.234785: train_loss -0.8112 
2025-04-08 04:19:24.235365: val_loss -0.7839 
2025-04-08 04:19:24.235478: Pseudo dice [0.806] 
2025-04-08 04:19:24.235563: Epoch time: 289.06 s 
2025-04-08 04:19:26.411124:  
2025-04-08 04:19:26.411295: Epoch 493 
2025-04-08 04:19:26.411429: Current learning rate: 0.00543 
2025-04-08 04:24:15.923965: train_loss -0.8074 
2025-04-08 04:24:15.924435: val_loss -0.7761 
2025-04-08 04:24:15.924518: Pseudo dice [0.7914] 
2025-04-08 04:24:15.924604: Epoch time: 289.52 s 
2025-04-08 04:24:17.793425:  
2025-04-08 04:24:17.793670: Epoch 494 
2025-04-08 04:24:17.793841: Current learning rate: 0.00542 
2025-04-08 04:28:51.040002: train_loss -0.8166 
2025-04-08 04:28:51.040335: val_loss -0.7799 
2025-04-08 04:28:51.040426: Pseudo dice [0.7944] 
2025-04-08 04:28:51.040522: Epoch time: 273.25 s 
2025-04-08 04:28:52.901165:  
2025-04-08 04:28:52.901421: Epoch 495 
2025-04-08 04:28:52.901598: Current learning rate: 0.00541 
2025-04-08 04:33:28.311557: train_loss -0.7605 
2025-04-08 04:33:28.312162: val_loss -0.749 
2025-04-08 04:33:28.312272: Pseudo dice [0.7578] 
2025-04-08 04:33:28.312393: Epoch time: 275.41 s 
2025-04-08 04:33:30.231836:  
2025-04-08 04:33:30.232123: Epoch 496 
2025-04-08 04:33:30.232295: Current learning rate: 0.0054 
2025-04-08 04:38:04.292461: train_loss -0.7496 
2025-04-08 04:38:04.292800: val_loss -0.7763 
2025-04-08 04:38:04.293045: Pseudo dice [0.8013] 
2025-04-08 04:38:04.293130: Epoch time: 274.06 s 
2025-04-08 04:38:06.169425:  
2025-04-08 04:38:06.169644: Epoch 497 
2025-04-08 04:38:06.169761: Current learning rate: 0.00539 
2025-04-08 04:42:41.386333: train_loss -0.7631 
2025-04-08 04:42:41.386865: val_loss -0.7854 
2025-04-08 04:42:41.386992: Pseudo dice [0.8042] 
2025-04-08 04:42:41.387091: Epoch time: 275.22 s 
2025-04-08 04:42:43.264169:  
2025-04-08 04:42:43.264380: Epoch 498 
2025-04-08 04:42:43.264500: Current learning rate: 0.00538 
2025-04-08 04:47:17.130764: train_loss -0.7459 
2025-04-08 04:47:17.131104: val_loss -0.7687 
2025-04-08 04:47:17.131191: Pseudo dice [0.7879] 
2025-04-08 04:47:17.131320: Epoch time: 273.87 s 
2025-04-08 04:47:18.998036:  
2025-04-08 04:47:18.998258: Epoch 499 
2025-04-08 04:47:18.998410: Current learning rate: 0.00537 
2025-04-08 04:51:52.918493: train_loss -0.7929 
2025-04-08 04:51:52.919025: val_loss -0.7801 
2025-04-08 04:51:52.919155: Pseudo dice [0.795] 
2025-04-08 04:51:52.919282: Epoch time: 273.92 s 
2025-04-08 04:51:56.366625:  
2025-04-08 04:51:56.366899: Epoch 500 
2025-04-08 04:51:56.367003: Current learning rate: 0.00536 
2025-04-08 04:56:30.043013: train_loss -0.7756 
2025-04-08 04:56:30.043382: val_loss -0.7812 
2025-04-08 04:56:30.043473: Pseudo dice [0.7979] 
2025-04-08 04:56:30.043571: Epoch time: 273.68 s 
2025-04-08 04:56:31.908546:  
2025-04-08 04:56:31.908781: Epoch 501 
2025-04-08 04:56:31.908901: Current learning rate: 0.00535 
2025-04-08 05:01:06.465968: train_loss -0.7351 
2025-04-08 05:01:06.466503: val_loss -0.7395 
2025-04-08 05:01:06.466616: Pseudo dice [0.7827] 
2025-04-08 05:01:06.466702: Epoch time: 274.56 s 
2025-04-08 05:01:08.341377:  
2025-04-08 05:01:08.341616: Epoch 502 
2025-04-08 05:01:08.341760: Current learning rate: 0.00534 
2025-04-08 05:05:42.217873: train_loss -0.7946 
2025-04-08 05:05:42.218279: val_loss -0.7593 
2025-04-08 05:05:42.218380: Pseudo dice [0.7481] 
2025-04-08 05:05:42.218464: Epoch time: 273.88 s 
2025-04-08 05:05:44.085429:  
2025-04-08 05:05:44.085601: Epoch 503 
2025-04-08 05:05:44.085747: Current learning rate: 0.00533 
2025-04-08 05:10:19.108729: train_loss -0.7367 
2025-04-08 05:10:19.109234: val_loss -0.7793 
2025-04-08 05:10:19.109346: Pseudo dice [0.8016] 
2025-04-08 05:10:19.109430: Epoch time: 275.03 s 
2025-04-08 05:10:20.965851:  
2025-04-08 05:10:20.966139: Epoch 504 
2025-04-08 05:10:20.966297: Current learning rate: 0.00532 
2025-04-08 05:14:55.839738: train_loss -0.7591 
2025-04-08 05:14:55.840070: val_loss -0.7836 
2025-04-08 05:14:55.840151: Pseudo dice [0.789] 
2025-04-08 05:14:55.840248: Epoch time: 274.88 s 
2025-04-08 05:14:57.728113:  
2025-04-08 05:14:57.728384: Epoch 505 
2025-04-08 05:14:57.728550: Current learning rate: 0.00531 
2025-04-08 05:19:31.576830: train_loss -0.7954 
2025-04-08 05:19:31.577160: val_loss -0.777 
2025-04-08 05:19:31.577242: Pseudo dice [0.7723] 
2025-04-08 05:19:31.577395: Epoch time: 273.85 s 
2025-04-08 05:19:33.457823:  
2025-04-08 05:19:33.458090: Epoch 506 
2025-04-08 05:19:33.458231: Current learning rate: 0.0053 
2025-04-08 05:24:07.576127: train_loss -0.8011 
2025-04-08 05:24:07.576761: val_loss -0.7722 
2025-04-08 05:24:07.576862: Pseudo dice [0.7802] 
2025-04-08 05:24:07.576948: Epoch time: 274.12 s 
2025-04-08 05:24:09.447437:  
2025-04-08 05:24:09.447618: Epoch 507 
2025-04-08 05:24:09.447731: Current learning rate: 0.00529 
2025-04-08 05:28:42.999503: train_loss -0.7973 
2025-04-08 05:28:42.999863: val_loss -0.7645 
2025-04-08 05:28:42.999954: Pseudo dice [0.7946] 
2025-04-08 05:28:43.000053: Epoch time: 273.56 s 
2025-04-08 05:28:44.860444:  
2025-04-08 05:28:44.860687: Epoch 508 
2025-04-08 05:28:44.860821: Current learning rate: 0.00528 
2025-04-08 05:33:19.334588: train_loss -0.763 
2025-04-08 05:33:19.335150: val_loss -0.7376 
2025-04-08 05:33:19.335258: Pseudo dice [0.7877] 
2025-04-08 05:33:19.335340: Epoch time: 274.48 s 
2025-04-08 05:33:21.553837:  
2025-04-08 05:33:21.554075: Epoch 509 
2025-04-08 05:33:21.554199: Current learning rate: 0.00527 
2025-04-08 05:37:55.982741: train_loss -0.7966 
2025-04-08 05:37:55.983047: val_loss -0.7629 
2025-04-08 05:37:55.983135: Pseudo dice [0.7822] 
2025-04-08 05:37:55.983295: Epoch time: 274.43 s 
2025-04-08 05:37:57.852885:  
2025-04-08 05:37:57.853193: Epoch 510 
2025-04-08 05:37:57.853307: Current learning rate: 0.00526 
2025-04-08 05:42:32.812183: train_loss -0.7832 
2025-04-08 05:42:32.812750: val_loss -0.7655 
2025-04-08 05:42:32.812847: Pseudo dice [0.7843] 
2025-04-08 05:42:32.812928: Epoch time: 274.96 s 
2025-04-08 05:42:34.668155:  
2025-04-08 05:42:34.668417: Epoch 511 
2025-04-08 05:42:34.668535: Current learning rate: 0.00525 
2025-04-08 05:47:09.810304: train_loss -0.7683 
2025-04-08 05:47:09.810770: val_loss -0.7762 
2025-04-08 05:47:09.810902: Pseudo dice [0.7714] 
2025-04-08 05:47:09.811044: Epoch time: 275.15 s 
2025-04-08 05:47:11.759137:  
2025-04-08 05:47:11.759429: Epoch 512 
2025-04-08 05:47:11.759557: Current learning rate: 0.00524 
2025-04-08 05:51:46.401610: train_loss -0.8056 
2025-04-08 05:51:46.402215: val_loss -0.7491 
2025-04-08 05:51:46.402325: Pseudo dice [0.7748] 
2025-04-08 05:51:46.402409: Epoch time: 274.65 s 
2025-04-08 05:51:48.316410:  
2025-04-08 05:51:48.316645: Epoch 513 
2025-04-08 05:51:48.316790: Current learning rate: 0.00523 
2025-04-08 05:56:23.232551: train_loss -0.8137 
2025-04-08 05:56:23.232884: val_loss -0.7739 
2025-04-08 05:56:23.232984: Pseudo dice [0.7657] 
2025-04-08 05:56:23.233085: Epoch time: 274.92 s 
2025-04-08 05:56:25.123261:  
2025-04-08 05:56:25.123523: Epoch 514 
2025-04-08 05:56:25.123637: Current learning rate: 0.00522 
2025-04-08 06:00:59.185125: train_loss -0.7984 
2025-04-08 06:00:59.190305: val_loss -0.8081 
2025-04-08 06:00:59.190410: Pseudo dice [0.8254] 
2025-04-08 06:00:59.190491: Epoch time: 274.07 s 
2025-04-08 06:01:01.086133:  
2025-04-08 06:01:01.086327: Epoch 515 
2025-04-08 06:01:01.086439: Current learning rate: 0.00521 
2025-04-08 06:05:35.918330: train_loss -0.8083 
2025-04-08 06:05:35.918674: val_loss -0.7817 
2025-04-08 06:05:35.918756: Pseudo dice [0.7867] 
2025-04-08 06:05:35.918863: Epoch time: 274.84 s 
2025-04-08 06:05:37.796369:  
2025-04-08 06:05:37.796636: Epoch 516 
2025-04-08 06:05:37.796779: Current learning rate: 0.0052 
2025-04-08 06:10:12.214939: train_loss -0.7729 
2025-04-08 06:10:12.215305: val_loss -0.7267 
2025-04-08 06:10:12.215394: Pseudo dice [0.7724] 
2025-04-08 06:10:12.215488: Epoch time: 274.42 s 
2025-04-08 06:10:14.097122:  
2025-04-08 06:10:14.097411: Epoch 517 
2025-04-08 06:10:14.097530: Current learning rate: 0.00519 
2025-04-08 06:14:48.813275: train_loss -0.7839 
2025-04-08 06:14:48.813888: val_loss -0.7945 
2025-04-08 06:14:48.814012: Pseudo dice [0.8121] 
2025-04-08 06:14:48.814110: Epoch time: 274.72 s 
2025-04-08 06:14:51.004204:  
2025-04-08 06:14:51.004428: Epoch 518 
2025-04-08 06:14:51.004562: Current learning rate: 0.00518 
2025-04-08 06:19:23.936395: train_loss -0.8003 
2025-04-08 06:19:23.936708: val_loss -0.7944 
2025-04-08 06:19:23.936801: Pseudo dice [0.8129] 
2025-04-08 06:19:23.936885: Epoch time: 272.94 s 
2025-04-08 06:19:25.808289:  
2025-04-08 06:19:25.808633: Epoch 519 
2025-04-08 06:19:25.808787: Current learning rate: 0.00518 
2025-04-08 06:23:58.500232: train_loss -0.8077 
2025-04-08 06:23:58.500784: val_loss -0.7622 
2025-04-08 06:23:58.500892: Pseudo dice [0.7824] 
2025-04-08 06:23:58.501047: Epoch time: 272.7 s 
2025-04-08 06:24:00.406958:  
2025-04-08 06:24:00.407177: Epoch 520 
2025-04-08 06:24:00.407295: Current learning rate: 0.00517 
2025-04-08 06:28:33.786168: train_loss -0.8066 
2025-04-08 06:28:33.786442: val_loss -0.7431 
2025-04-08 06:28:33.786560: Pseudo dice [0.7606] 
2025-04-08 06:28:33.786682: Epoch time: 273.38 s 
2025-04-08 06:28:35.671360:  
2025-04-08 06:28:35.671586: Epoch 521 
2025-04-08 06:28:35.671715: Current learning rate: 0.00516 
2025-04-08 06:33:09.988663: train_loss -0.774 
2025-04-08 06:33:09.989025: val_loss -0.7777 
2025-04-08 06:33:09.989106: Pseudo dice [0.7896] 
2025-04-08 06:33:09.989202: Epoch time: 274.32 s 
2025-04-08 06:33:11.894849:  
2025-04-08 06:33:11.895061: Epoch 522 
2025-04-08 06:33:11.895176: Current learning rate: 0.00515 
2025-04-08 06:37:54.138990: train_loss -0.8108 
2025-04-08 06:37:54.139290: val_loss -0.7846 
2025-04-08 06:37:54.139379: Pseudo dice [0.8138] 
2025-04-08 06:37:54.139532: Epoch time: 282.25 s 
2025-04-08 06:37:56.024750:  
2025-04-08 06:37:56.024957: Epoch 523 
2025-04-08 06:37:56.025069: Current learning rate: 0.00514 
2025-04-08 06:42:30.500836: train_loss -0.8133 
2025-04-08 06:42:30.501396: val_loss -0.7719 
2025-04-08 06:42:30.501515: Pseudo dice [0.7991] 
2025-04-08 06:42:30.501602: Epoch time: 274.48 s 
2025-04-08 06:42:32.377367:  
2025-04-08 06:42:32.377591: Epoch 524 
2025-04-08 06:42:32.377737: Current learning rate: 0.00513 
2025-04-08 06:47:07.217951: train_loss -0.7865 
2025-04-08 06:47:07.218278: val_loss -0.7413 
2025-04-08 06:47:07.218357: Pseudo dice [0.7625] 
2025-04-08 06:47:07.218442: Epoch time: 274.84 s 
2025-04-08 06:47:09.100442:  
2025-04-08 06:47:09.100658: Epoch 525 
2025-04-08 06:47:09.100772: Current learning rate: 0.00512 
2025-04-08 06:51:43.604278: train_loss -0.7476 
2025-04-08 06:51:43.604640: val_loss -0.7813 
2025-04-08 06:51:43.604725: Pseudo dice [0.8018] 
2025-04-08 06:51:43.604816: Epoch time: 274.51 s 
2025-04-08 06:51:45.790632:  
2025-04-08 06:51:45.790967: Epoch 526 
2025-04-08 06:51:45.791157: Current learning rate: 0.00511 
2025-04-08 06:56:20.205603: train_loss -0.7602 
2025-04-08 06:56:20.206136: val_loss -0.7858 
2025-04-08 06:56:20.206254: Pseudo dice [0.8046] 
2025-04-08 06:56:20.206366: Epoch time: 274.42 s 
2025-04-08 06:56:22.081197:  
2025-04-08 06:56:22.081422: Epoch 527 
2025-04-08 06:56:22.081539: Current learning rate: 0.0051 
2025-04-08 07:00:55.258261: train_loss -0.7777 
2025-04-08 07:00:55.258645: val_loss -0.7736 
2025-04-08 07:00:55.258730: Pseudo dice [0.7938] 
2025-04-08 07:00:55.258823: Epoch time: 273.18 s 
2025-04-08 07:00:57.148912:  
2025-04-08 07:00:57.149134: Epoch 528 
2025-04-08 07:00:57.149249: Current learning rate: 0.00509 
2025-04-08 07:05:31.524034: train_loss -0.7761 
2025-04-08 07:05:31.524411: val_loss -0.7807 
2025-04-08 07:05:31.524497: Pseudo dice [0.7936] 
2025-04-08 07:05:31.524587: Epoch time: 274.38 s 
2025-04-08 07:05:33.457651:  
2025-04-08 07:05:33.457852: Epoch 529 
2025-04-08 07:05:33.457996: Current learning rate: 0.00508 
2025-04-08 07:10:06.989619: train_loss -0.7916 
2025-04-08 07:10:06.989982: val_loss -0.7392 
2025-04-08 07:10:06.990066: Pseudo dice [0.7644] 
2025-04-08 07:10:06.990160: Epoch time: 273.54 s 
2025-04-08 07:10:08.857030:  
2025-04-08 07:10:08.857249: Epoch 530 
2025-04-08 07:10:08.857363: Current learning rate: 0.00507 
2025-04-08 07:14:42.845168: train_loss -0.7795 
2025-04-08 07:14:42.845513: val_loss -0.7231 
2025-04-08 07:14:42.845598: Pseudo dice [0.7541] 
2025-04-08 07:14:42.845694: Epoch time: 273.99 s 
2025-04-08 07:14:44.724678:  
2025-04-08 07:14:44.724951: Epoch 531 
2025-04-08 07:14:44.725145: Current learning rate: 0.00506 
2025-04-08 07:19:19.112113: train_loss -0.7921 
2025-04-08 07:19:19.112465: val_loss -0.7169 
2025-04-08 07:19:19.112553: Pseudo dice [0.7692] 
2025-04-08 07:19:19.112649: Epoch time: 274.39 s 
2025-04-08 07:19:21.130219:  
2025-04-08 07:19:21.130388: Epoch 532 
2025-04-08 07:19:21.130551: Current learning rate: 0.00505 
2025-04-08 07:23:55.515305: train_loss -0.732 
2025-04-08 07:23:55.515614: val_loss -0.7757 
2025-04-08 07:23:55.515698: Pseudo dice [0.7782] 
2025-04-08 07:23:55.515803: Epoch time: 274.39 s 
2025-04-08 07:23:57.385701:  
2025-04-08 07:23:57.385947: Epoch 533 
2025-04-08 07:23:57.386068: Current learning rate: 0.00504 
2025-04-08 07:28:30.932107: train_loss -0.7833 
2025-04-08 07:28:30.932428: val_loss -0.7963 
2025-04-08 07:28:30.932515: Pseudo dice [0.8204] 
2025-04-08 07:28:30.932694: Epoch time: 273.55 s 
2025-04-08 07:28:32.834329:  
2025-04-08 07:28:32.834584: Epoch 534 
2025-04-08 07:28:32.834697: Current learning rate: 0.00503 
2025-04-08 07:33:06.320966: train_loss -0.7699 
2025-04-08 07:33:06.321295: val_loss -0.722 
2025-04-08 07:33:06.321381: Pseudo dice [0.7729] 
2025-04-08 07:33:06.321477: Epoch time: 273.49 s 
2025-04-08 07:33:08.510186:  
2025-04-08 07:33:08.510439: Epoch 535 
2025-04-08 07:33:08.510552: Current learning rate: 0.00502 
2025-04-08 07:37:42.063232: train_loss -0.7762 
2025-04-08 07:37:42.063833: val_loss -0.7766 
2025-04-08 07:37:42.063943: Pseudo dice [0.8007] 
2025-04-08 07:37:42.064024: Epoch time: 273.56 s 
2025-04-08 07:37:43.944566:  
2025-04-08 07:37:43.944798: Epoch 536 
2025-04-08 07:37:43.944916: Current learning rate: 0.00501 
2025-04-08 07:42:17.526201: train_loss -0.7911 
2025-04-08 07:42:17.526507: val_loss -0.7557 
2025-04-08 07:42:17.526588: Pseudo dice [0.7906] 
2025-04-08 07:42:17.526710: Epoch time: 273.59 s 
2025-04-08 07:42:19.407102:  
2025-04-08 07:42:19.407335: Epoch 537 
2025-04-08 07:42:19.407475: Current learning rate: 0.005 
2025-04-08 07:46:54.609997: train_loss -0.7983 
2025-04-08 07:46:54.611074: val_loss -0.7896 
2025-04-08 07:46:54.611252: Pseudo dice [0.8041] 
2025-04-08 07:46:54.611398: Epoch time: 275.21 s 
2025-04-08 07:46:56.489672:  
2025-04-08 07:46:56.489897: Epoch 538 
2025-04-08 07:46:56.490026: Current learning rate: 0.00499 
2025-04-08 07:51:30.275253: train_loss -0.8172 
2025-04-08 07:51:30.275595: val_loss -0.7744 
2025-04-08 07:51:30.275681: Pseudo dice [0.7985] 
2025-04-08 07:51:30.275787: Epoch time: 273.79 s 
2025-04-08 07:51:32.144196:  
2025-04-08 07:51:32.144420: Epoch 539 
2025-04-08 07:51:32.144562: Current learning rate: 0.00498 
2025-04-08 07:56:11.490194: train_loss -0.7856 
2025-04-08 07:56:11.490768: val_loss -0.7524 
2025-04-08 07:56:11.490874: Pseudo dice [0.7833] 
2025-04-08 07:56:11.490957: Epoch time: 279.35 s 
2025-04-08 07:56:13.395448:  
2025-04-08 07:56:13.395609: Epoch 540 
2025-04-08 07:56:13.395774: Current learning rate: 0.00497 
2025-04-08 08:00:47.142827: train_loss -0.7955 
2025-04-08 08:00:47.143172: val_loss -0.7461 
2025-04-08 08:00:47.143271: Pseudo dice [0.7864] 
2025-04-08 08:00:47.143368: Epoch time: 273.75 s 
2025-04-08 08:00:49.035286:  
2025-04-08 08:00:49.035533: Epoch 541 
2025-04-08 08:00:49.035695: Current learning rate: 0.00496 
2025-04-08 08:05:23.259520: train_loss -0.7889 
2025-04-08 08:05:23.260180: val_loss -0.7901 
2025-04-08 08:05:23.260309: Pseudo dice [0.79] 
2025-04-08 08:05:23.260395: Epoch time: 274.23 s 
2025-04-08 08:05:25.138001:  
2025-04-08 08:05:25.138377: Epoch 542 
2025-04-08 08:05:25.138552: Current learning rate: 0.00495 
2025-04-08 08:09:59.346519: train_loss -0.7732 
2025-04-08 08:09:59.346864: val_loss -0.7379 
2025-04-08 08:09:59.346955: Pseudo dice [0.7475] 
2025-04-08 08:09:59.347053: Epoch time: 274.21 s 
2025-04-08 08:10:01.256717:  
2025-04-08 08:10:01.256968: Epoch 543 
2025-04-08 08:10:01.257096: Current learning rate: 0.00494 
2025-04-08 08:14:35.683901: train_loss -0.7825 
2025-04-08 08:14:35.684426: val_loss -0.6863 
2025-04-08 08:14:35.684508: Pseudo dice [0.7547] 
2025-04-08 08:14:35.684585: Epoch time: 274.43 s 
2025-04-08 08:14:37.567355:  
2025-04-08 08:14:37.567573: Epoch 544 
2025-04-08 08:14:37.567691: Current learning rate: 0.00493 
2025-04-08 08:19:32.774386: train_loss -0.8032 
2025-04-08 08:19:32.774747: val_loss -0.7602 
2025-04-08 08:19:32.774837: Pseudo dice [0.7851] 
2025-04-08 08:19:32.774931: Epoch time: 295.21 s 
2025-04-08 08:19:34.659703:  
2025-04-08 08:19:34.659975: Epoch 545 
2025-04-08 08:19:34.660088: Current learning rate: 0.00492 
2025-04-08 08:24:08.547543: train_loss -0.8106 
2025-04-08 08:24:08.547883: val_loss -0.6797 
2025-04-08 08:24:08.547974: Pseudo dice [0.7446] 
2025-04-08 08:24:08.548071: Epoch time: 273.89 s 
2025-04-08 08:24:10.426528:  
2025-04-08 08:24:10.426808: Epoch 546 
2025-04-08 08:24:10.426951: Current learning rate: 0.00491 
2025-04-08 08:28:44.343692: train_loss -0.8153 
2025-04-08 08:28:44.344245: val_loss -0.7693 
2025-04-08 08:28:44.344347: Pseudo dice [0.7512] 
2025-04-08 08:28:44.344431: Epoch time: 273.92 s 
2025-04-08 08:28:46.211317:  
2025-04-08 08:28:46.211509: Epoch 547 
2025-04-08 08:28:46.211623: Current learning rate: 0.0049 
2025-04-08 08:33:19.491421: train_loss -0.794 
2025-04-08 08:33:19.491781: val_loss -0.7569 
2025-04-08 08:33:19.491870: Pseudo dice [0.8125] 
2025-04-08 08:33:19.491972: Epoch time: 273.28 s 
2025-04-08 08:33:21.385973:  
2025-04-08 08:33:21.386250: Epoch 548 
2025-04-08 08:33:21.386395: Current learning rate: 0.00489 
2025-04-08 08:37:54.389700: train_loss -0.8042 
2025-04-08 08:37:54.390223: val_loss -0.7426 
2025-04-08 08:37:54.390322: Pseudo dice [0.7773] 
2025-04-08 08:37:54.390405: Epoch time: 273.01 s 
2025-04-08 08:37:56.250861:  
2025-04-08 08:37:56.251089: Epoch 549 
2025-04-08 08:37:56.251208: Current learning rate: 0.00488 
2025-04-08 08:42:29.602750: train_loss -0.803 
2025-04-08 08:42:29.603110: val_loss -0.7606 
2025-04-08 08:42:29.603219: Pseudo dice [0.7856] 
2025-04-08 08:42:29.603316: Epoch time: 273.36 s 
2025-04-08 08:42:32.711871:  
2025-04-08 08:42:32.712126: Epoch 550 
2025-04-08 08:42:32.712259: Current learning rate: 0.00487 
2025-04-08 08:47:06.191625: train_loss -0.8114 
2025-04-08 08:47:06.192250: val_loss -0.774 
2025-04-08 08:47:06.192353: Pseudo dice [0.7975] 
2025-04-08 08:47:06.192432: Epoch time: 273.48 s 
2025-04-08 08:47:08.362624:  
2025-04-08 08:47:08.362906: Epoch 551 
2025-04-08 08:47:08.363031: Current learning rate: 0.00486 
2025-04-08 08:51:42.547495: train_loss -0.7736 
2025-04-08 08:51:42.547799: val_loss -0.7577 
2025-04-08 08:51:42.547898: Pseudo dice [0.7606] 
2025-04-08 08:51:42.547992: Epoch time: 274.19 s 
2025-04-08 08:51:44.424521:  
2025-04-08 08:51:44.424791: Epoch 552 
2025-04-08 08:51:44.424922: Current learning rate: 0.00485 
2025-04-08 08:56:36.696874: train_loss -0.7844 
2025-04-08 08:56:36.697214: val_loss -0.771 
2025-04-08 08:56:36.697299: Pseudo dice [0.7708] 
2025-04-08 08:56:36.697396: Epoch time: 292.28 s 
2025-04-08 08:56:38.562336:  
2025-04-08 08:56:38.562557: Epoch 553 
2025-04-08 08:56:38.562669: Current learning rate: 0.00484 
2025-04-08 09:01:13.417058: train_loss -0.7815 
2025-04-08 09:01:13.417367: val_loss -0.7375 
2025-04-08 09:01:13.417457: Pseudo dice [0.7135] 
2025-04-08 09:01:13.417561: Epoch time: 274.86 s 
2025-04-08 09:01:15.297853:  
2025-04-08 09:01:15.298088: Epoch 554 
2025-04-08 09:01:15.298233: Current learning rate: 0.00484 
2025-04-08 09:05:49.977016: train_loss -0.7921 
2025-04-08 09:05:49.977773: val_loss -0.7992 
2025-04-08 09:05:49.977901: Pseudo dice [0.8106] 
2025-04-08 09:05:49.978002: Epoch time: 274.68 s 
2025-04-08 09:05:51.983052:  
2025-04-08 09:05:51.983249: Epoch 555 
2025-04-08 09:05:51.983378: Current learning rate: 0.00483 
2025-04-08 09:10:26.772671: train_loss -0.7852 
2025-04-08 09:10:26.773021: val_loss -0.804 
2025-04-08 09:10:26.773105: Pseudo dice [0.8304] 
2025-04-08 09:10:26.773202: Epoch time: 274.79 s 
2025-04-08 09:10:28.662686:  
2025-04-08 09:10:28.662899: Epoch 556 
2025-04-08 09:10:28.663018: Current learning rate: 0.00482 
2025-04-08 09:15:02.712853: train_loss -0.8223 
2025-04-08 09:15:02.713255: val_loss -0.7637 
2025-04-08 09:15:02.713342: Pseudo dice [0.7923] 
2025-04-08 09:15:02.713427: Epoch time: 274.05 s 
2025-04-08 09:15:04.597592:  
2025-04-08 09:15:04.597774: Epoch 557 
2025-04-08 09:15:04.597928: Current learning rate: 0.00481 
2025-04-08 09:19:38.613651: train_loss -0.813 
2025-04-08 09:19:38.614174: val_loss -0.7877 
2025-04-08 09:19:38.614300: Pseudo dice [0.8064] 
2025-04-08 09:19:38.614388: Epoch time: 274.02 s 
2025-04-08 09:19:40.493733:  
2025-04-08 09:19:40.493962: Epoch 558 
2025-04-08 09:19:40.494087: Current learning rate: 0.0048 
2025-04-08 09:24:14.235147: train_loss -0.807 
2025-04-08 09:24:14.235475: val_loss -0.7813 
2025-04-08 09:24:14.235570: Pseudo dice [0.7903] 
2025-04-08 09:24:14.235674: Epoch time: 273.75 s 
2025-04-08 09:24:16.118189:  
2025-04-08 09:24:16.118423: Epoch 559 
2025-04-08 09:24:16.118541: Current learning rate: 0.00479 
2025-04-08 09:28:50.435665: train_loss -0.8076 
2025-04-08 09:28:50.435994: val_loss -0.7903 
2025-04-08 09:28:50.436085: Pseudo dice [0.809] 
2025-04-08 09:28:50.436208: Epoch time: 274.32 s 
2025-04-08 09:28:52.630623:  
2025-04-08 09:28:52.630855: Epoch 560 
2025-04-08 09:28:52.630977: Current learning rate: 0.00478 
2025-04-08 09:33:27.120190: train_loss -0.8274 
2025-04-08 09:33:27.120554: val_loss -0.7931 
2025-04-08 09:33:27.120648: Pseudo dice [0.7885] 
2025-04-08 09:33:27.120750: Epoch time: 274.49 s 
2025-04-08 09:33:29.000091:  
2025-04-08 09:33:29.000327: Epoch 561 
2025-04-08 09:33:29.000454: Current learning rate: 0.00477 
2025-04-08 09:38:03.862181: train_loss -0.8257 
2025-04-08 09:38:03.862755: val_loss -0.7752 
2025-04-08 09:38:03.862865: Pseudo dice [0.81] 
2025-04-08 09:38:03.862948: Epoch time: 274.87 s 
2025-04-08 09:38:05.750379:  
2025-04-08 09:38:05.750586: Epoch 562 
2025-04-08 09:38:05.750698: Current learning rate: 0.00476 
2025-04-08 09:42:40.353157: train_loss -0.8263 
2025-04-08 09:42:40.353465: val_loss -0.7813 
2025-04-08 09:42:40.353546: Pseudo dice [0.7871] 
2025-04-08 09:42:40.353633: Epoch time: 274.61 s 
2025-04-08 09:42:42.240995:  
2025-04-08 09:42:42.241192: Epoch 563 
2025-04-08 09:42:42.241318: Current learning rate: 0.00475 
2025-04-08 09:47:17.206894: train_loss -0.816 
2025-04-08 09:47:17.207221: val_loss -0.7905 
2025-04-08 09:47:17.207307: Pseudo dice [0.8026] 
2025-04-08 09:47:17.207407: Epoch time: 274.97 s 
2025-04-08 09:47:19.089499:  
2025-04-08 09:47:19.089702: Epoch 564 
2025-04-08 09:47:19.089814: Current learning rate: 0.00474 
2025-04-08 09:51:54.103956: train_loss -0.8286 
2025-04-08 09:51:54.104499: val_loss -0.7809 
2025-04-08 09:51:54.104613: Pseudo dice [0.7949] 
2025-04-08 09:51:54.104700: Epoch time: 275.02 s 
2025-04-08 09:51:55.978275:  
2025-04-08 09:51:55.978515: Epoch 565 
2025-04-08 09:51:55.978679: Current learning rate: 0.00473 
2025-04-08 09:56:30.875547: train_loss -0.8216 
2025-04-08 09:56:30.875932: val_loss -0.771 
2025-04-08 09:56:30.876039: Pseudo dice [0.7855] 
2025-04-08 09:56:30.876133: Epoch time: 274.9 s 
2025-04-08 09:56:32.754169:  
2025-04-08 09:56:32.754434: Epoch 566 
2025-04-08 09:56:32.754598: Current learning rate: 0.00472 
2025-04-08 10:01:08.252619: train_loss -0.8219 
2025-04-08 10:01:08.253227: val_loss -0.7358 
2025-04-08 10:01:08.253329: Pseudo dice [0.7922] 
2025-04-08 10:01:08.253412: Epoch time: 275.5 s 
2025-04-08 10:01:10.136118:  
2025-04-08 10:01:10.136337: Epoch 567 
2025-04-08 10:01:10.136459: Current learning rate: 0.00471 
2025-04-08 10:05:45.066182: train_loss -0.8265 
2025-04-08 10:05:45.066481: val_loss -0.7717 
2025-04-08 10:05:45.066563: Pseudo dice [0.7843] 
2025-04-08 10:05:45.066654: Epoch time: 274.93 s 
2025-04-08 10:05:46.930913:  
2025-04-08 10:05:46.931106: Epoch 568 
2025-04-08 10:05:46.931219: Current learning rate: 0.0047 
2025-04-08 10:10:21.710242: train_loss -0.7937 
2025-04-08 10:10:21.710789: val_loss -0.7551 
2025-04-08 10:10:21.710894: Pseudo dice [0.7672] 
2025-04-08 10:10:21.710987: Epoch time: 274.78 s 
2025-04-08 10:10:23.940974:  
2025-04-08 10:10:23.941246: Epoch 569 
2025-04-08 10:10:23.941429: Current learning rate: 0.00469 
2025-04-08 10:14:57.926441: train_loss -0.7924 
2025-04-08 10:14:57.926771: val_loss -0.7761 
2025-04-08 10:14:57.926854: Pseudo dice [0.7939] 
2025-04-08 10:14:57.926952: Epoch time: 273.99 s 
2025-04-08 10:14:59.812695:  
2025-04-08 10:14:59.812936: Epoch 570 
2025-04-08 10:14:59.813059: Current learning rate: 0.00468 
2025-04-08 10:19:33.716203: train_loss -0.8184 
2025-04-08 10:19:33.716740: val_loss -0.7917 
2025-04-08 10:19:33.716845: Pseudo dice [0.8033] 
2025-04-08 10:19:33.716935: Epoch time: 273.91 s 
2025-04-08 10:19:35.639149:  
2025-04-08 10:19:35.639503: Epoch 571 
2025-04-08 10:19:35.639647: Current learning rate: 0.00467 
2025-04-08 10:24:08.838179: train_loss -0.8251 
2025-04-08 10:24:08.838498: val_loss -0.7827 
2025-04-08 10:24:08.838581: Pseudo dice [0.8043] 
2025-04-08 10:24:08.838666: Epoch time: 273.2 s 
2025-04-08 10:24:10.716932:  
2025-04-08 10:24:10.717211: Epoch 572 
2025-04-08 10:24:10.717408: Current learning rate: 0.00466 
2025-04-08 10:28:44.109165: train_loss -0.8321 
2025-04-08 10:28:44.109707: val_loss -0.8232 
2025-04-08 10:28:44.109822: Pseudo dice [0.8227] 
2025-04-08 10:28:44.109908: Epoch time: 273.4 s 
2025-04-08 10:28:45.998317:  
2025-04-08 10:28:45.998525: Epoch 573 
2025-04-08 10:28:45.998655: Current learning rate: 0.00465 
2025-04-08 10:33:19.827567: train_loss -0.8075 
2025-04-08 10:33:19.827901: val_loss -0.7772 
2025-04-08 10:33:19.827981: Pseudo dice [0.7945] 
2025-04-08 10:33:19.828118: Epoch time: 273.83 s 
2025-04-08 10:33:21.738778:  
2025-04-08 10:33:21.739013: Epoch 574 
2025-04-08 10:33:21.739134: Current learning rate: 0.00464 
2025-04-08 10:37:55.558777: train_loss -0.8064 
2025-04-08 10:37:55.559085: val_loss -0.7455 
2025-04-08 10:37:55.559172: Pseudo dice [0.7706] 
2025-04-08 10:37:55.559267: Epoch time: 273.82 s 
2025-04-08 10:37:57.459213:  
2025-04-08 10:37:57.459427: Epoch 575 
2025-04-08 10:37:57.459544: Current learning rate: 0.00463 
2025-04-08 10:42:32.194558: train_loss -0.8269 
2025-04-08 10:42:32.195190: val_loss -0.7554 
2025-04-08 10:42:32.195353: Pseudo dice [0.788] 
2025-04-08 10:42:32.195442: Epoch time: 274.74 s 
2025-04-08 10:42:34.107617:  
2025-04-08 10:42:34.107903: Epoch 576 
2025-04-08 10:42:34.108043: Current learning rate: 0.00462 
2025-04-08 10:47:08.056219: train_loss -0.8137 
2025-04-08 10:47:08.056514: val_loss -0.7708 
2025-04-08 10:47:08.056596: Pseudo dice [0.7935] 
2025-04-08 10:47:08.056776: Epoch time: 273.95 s 
2025-04-08 10:47:09.954785:  
2025-04-08 10:47:09.954967: Epoch 577 
2025-04-08 10:47:09.955082: Current learning rate: 0.00461 
2025-04-08 10:51:45.331263: train_loss -0.7948 
2025-04-08 10:51:45.331809: val_loss -0.7855 
2025-04-08 10:51:45.331913: Pseudo dice [0.7569] 
2025-04-08 10:51:45.331997: Epoch time: 275.38 s 
2025-04-08 10:51:47.543727:  
2025-04-08 10:51:47.543955: Epoch 578 
2025-04-08 10:51:47.544147: Current learning rate: 0.0046 
2025-04-08 10:56:22.262927: train_loss -0.8168 
2025-04-08 10:56:22.263271: val_loss -0.8024 
2025-04-08 10:56:22.263420: Pseudo dice [0.8103] 
2025-04-08 10:56:22.263533: Epoch time: 274.72 s 
2025-04-08 10:56:24.182461:  
2025-04-08 10:56:24.182710: Epoch 579 
2025-04-08 10:56:24.182827: Current learning rate: 0.00459 
2025-04-08 11:00:58.897299: train_loss -0.8203 
2025-04-08 11:00:58.897964: val_loss -0.7697 
2025-04-08 11:00:58.898084: Pseudo dice [0.7935] 
2025-04-08 11:00:58.898200: Epoch time: 274.72 s 
2025-04-08 11:01:00.821709:  
2025-04-08 11:01:00.821954: Epoch 580 
2025-04-08 11:01:00.822117: Current learning rate: 0.00458 
2025-04-08 11:05:35.264335: train_loss -0.8046 
2025-04-08 11:05:35.264707: val_loss -0.7366 
2025-04-08 11:05:35.264797: Pseudo dice [0.6848] 
2025-04-08 11:05:35.264888: Epoch time: 274.45 s 
2025-04-08 11:05:37.149554:  
2025-04-08 11:05:37.149776: Epoch 581 
2025-04-08 11:05:37.149885: Current learning rate: 0.00457 
2025-04-08 11:10:57.793221: train_loss -0.7859 
2025-04-08 11:10:57.793921: val_loss -0.7532 
2025-04-08 11:10:57.794044: Pseudo dice [0.7674] 
2025-04-08 11:10:57.794130: Epoch time: 320.65 s 
2025-04-08 11:10:59.715235:  
2025-04-08 11:10:59.715517: Epoch 582 
2025-04-08 11:10:59.715630: Current learning rate: 0.00456 
2025-04-08 11:15:33.949865: train_loss -0.7681 
2025-04-08 11:15:33.950269: val_loss -0.7651 
2025-04-08 11:15:33.950364: Pseudo dice [0.79] 
2025-04-08 11:15:33.950442: Epoch time: 274.24 s 
2025-04-08 11:15:35.850615:  
2025-04-08 11:15:35.850816: Epoch 583 
2025-04-08 11:15:35.850930: Current learning rate: 0.00455 
2025-04-08 11:20:10.349891: train_loss -0.7961 
2025-04-08 11:20:10.350547: val_loss -0.7701 
2025-04-08 11:20:10.350665: Pseudo dice [0.7708] 
2025-04-08 11:20:10.350751: Epoch time: 274.5 s 
2025-04-08 11:20:12.244283:  
2025-04-08 11:20:12.244493: Epoch 584 
2025-04-08 11:20:12.244677: Current learning rate: 0.00454 
2025-04-08 11:24:46.102949: train_loss -0.8074 
2025-04-08 11:24:46.103251: val_loss -0.7736 
2025-04-08 11:24:46.103343: Pseudo dice [0.7959] 
2025-04-08 11:24:46.103434: Epoch time: 273.86 s 
2025-04-08 11:24:48.003252:  
2025-04-08 11:24:48.003502: Epoch 585 
2025-04-08 11:24:48.003642: Current learning rate: 0.00453 
2025-04-08 11:29:22.206955: train_loss -0.7997 
2025-04-08 11:29:22.207321: val_loss -0.765 
2025-04-08 11:29:22.207415: Pseudo dice [0.7807] 
2025-04-08 11:29:22.207507: Epoch time: 274.21 s 
2025-04-08 11:29:24.411638:  
2025-04-08 11:29:24.411880: Epoch 586 
2025-04-08 11:29:24.412012: Current learning rate: 0.00452 
2025-04-08 11:33:58.630625: train_loss -0.7963 
2025-04-08 11:33:58.631049: val_loss -0.7838 
2025-04-08 11:33:58.631170: Pseudo dice [0.8002] 
2025-04-08 11:33:58.631256: Epoch time: 274.22 s 
2025-04-08 11:34:00.541086:  
2025-04-08 11:34:00.541295: Epoch 587 
2025-04-08 11:34:00.541413: Current learning rate: 0.00451 
2025-04-08 11:38:34.216866: train_loss -0.8136 
2025-04-08 11:38:34.217188: val_loss -0.7793 
2025-04-08 11:38:34.217283: Pseudo dice [0.8119] 
2025-04-08 11:38:34.217405: Epoch time: 273.68 s 
2025-04-08 11:38:36.099584:  
2025-04-08 11:38:36.099875: Epoch 588 
2025-04-08 11:38:36.100023: Current learning rate: 0.0045 
2025-04-08 11:43:09.045252: train_loss -0.8311 
2025-04-08 11:43:09.045944: val_loss -0.7928 
2025-04-08 11:43:09.046052: Pseudo dice [0.7947] 
2025-04-08 11:43:09.046143: Epoch time: 272.95 s 
2025-04-08 11:43:10.958406:  
2025-04-08 11:43:10.958601: Epoch 589 
2025-04-08 11:43:10.958713: Current learning rate: 0.00449 
2025-04-08 11:47:43.380683: train_loss -0.7973 
2025-04-08 11:47:43.380995: val_loss -0.7683 
2025-04-08 11:47:43.381078: Pseudo dice [0.7841] 
2025-04-08 11:47:43.381165: Epoch time: 272.43 s 
2025-04-08 11:47:45.330399:  
2025-04-08 11:47:45.330609: Epoch 590 
2025-04-08 11:47:45.330746: Current learning rate: 0.00448 
2025-04-08 11:52:19.599313: train_loss -0.7378 
2025-04-08 11:52:19.600155: val_loss -0.7567 
2025-04-08 11:52:19.600279: Pseudo dice [0.7673] 
2025-04-08 11:52:19.600366: Epoch time: 274.27 s 
2025-04-08 11:52:21.515411:  
2025-04-08 11:52:21.515618: Epoch 591 
2025-04-08 11:52:21.515735: Current learning rate: 0.00447 
2025-04-08 11:56:55.492060: train_loss -0.7841 
2025-04-08 11:56:55.492418: val_loss -0.7559 
2025-04-08 11:56:55.492511: Pseudo dice [0.7779] 
2025-04-08 11:56:55.492614: Epoch time: 273.98 s 
2025-04-08 11:56:57.388370:  
2025-04-08 11:56:57.388596: Epoch 592 
2025-04-08 11:56:57.388726: Current learning rate: 0.00446 
2025-04-08 12:01:32.101743: train_loss -0.7633 
2025-04-08 12:01:32.102241: val_loss -0.7521 
2025-04-08 12:01:32.102411: Pseudo dice [0.779] 
2025-04-08 12:01:32.102501: Epoch time: 274.72 s 
2025-04-08 12:01:34.039623:  
2025-04-08 12:01:34.039816: Epoch 593 
2025-04-08 12:01:34.039934: Current learning rate: 0.00445 
2025-04-08 12:06:07.858800: train_loss -0.7999 
2025-04-08 12:06:07.859128: val_loss -0.7793 
2025-04-08 12:06:07.859230: Pseudo dice [0.7724] 
2025-04-08 12:06:07.859332: Epoch time: 273.82 s 
2025-04-08 12:06:09.773976:  
2025-04-08 12:06:09.774126: Epoch 594 
2025-04-08 12:06:09.774238: Current learning rate: 0.00444 
2025-04-08 12:10:43.467168: train_loss -0.7995 
2025-04-08 12:10:43.467869: val_loss -0.7791 
2025-04-08 12:10:43.467992: Pseudo dice [0.7823] 
2025-04-08 12:10:43.468079: Epoch time: 273.7 s 
2025-04-08 12:10:45.677306:  
2025-04-08 12:10:45.677586: Epoch 595 
2025-04-08 12:10:45.677778: Current learning rate: 0.00443 
2025-04-08 12:15:19.375057: train_loss -0.8077 
2025-04-08 12:15:19.375422: val_loss -0.7894 
2025-04-08 12:15:19.375509: Pseudo dice [0.8197] 
2025-04-08 12:15:19.375607: Epoch time: 273.7 s 
2025-04-08 12:15:21.286704:  
2025-04-08 12:15:21.286917: Epoch 596 
2025-04-08 12:15:21.287083: Current learning rate: 0.00442 
2025-04-08 12:19:59.217941: train_loss -0.8031 
2025-04-08 12:19:59.218462: val_loss -0.7828 
2025-04-08 12:19:59.218543: Pseudo dice [0.8031] 
2025-04-08 12:19:59.218622: Epoch time: 277.94 s 
2025-04-08 12:20:01.129761:  
2025-04-08 12:20:01.129988: Epoch 597 
2025-04-08 12:20:01.130170: Current learning rate: 0.00441 
2025-04-08 12:24:36.582019: train_loss -0.8059 
2025-04-08 12:24:36.582326: val_loss -0.7807 
2025-04-08 12:24:36.582429: Pseudo dice [0.7995] 
2025-04-08 12:24:36.582537: Epoch time: 275.46 s 
2025-04-08 12:24:38.502240:  
2025-04-08 12:24:38.502487: Epoch 598 
2025-04-08 12:24:38.502604: Current learning rate: 0.0044 
2025-04-08 12:29:12.826091: train_loss -0.8133 
2025-04-08 12:29:12.826421: val_loss -0.8058 
2025-04-08 12:29:12.826507: Pseudo dice [0.8228] 
2025-04-08 12:29:12.826607: Epoch time: 274.33 s 
2025-04-08 12:29:14.722197:  
2025-04-08 12:29:14.722391: Epoch 599 
2025-04-08 12:29:14.722547: Current learning rate: 0.00439 
2025-04-08 12:33:49.444467: train_loss -0.8321 
2025-04-08 12:33:49.445034: val_loss -0.7716 
2025-04-08 12:33:49.445134: Pseudo dice [0.7994] 
2025-04-08 12:33:49.445217: Epoch time: 274.73 s 
2025-04-08 12:33:52.601599:  
2025-04-08 12:33:52.601864: Epoch 600 
2025-04-08 12:33:52.602012: Current learning rate: 0.00438 
2025-04-08 12:38:26.525643: train_loss -0.8183 
2025-04-08 12:38:26.525940: val_loss -0.7784 
2025-04-08 12:38:26.526019: Pseudo dice [0.7897] 
2025-04-08 12:38:26.526101: Epoch time: 273.93 s 
2025-04-08 12:38:28.425114:  
2025-04-08 12:38:28.425305: Epoch 601 
2025-04-08 12:38:28.425418: Current learning rate: 0.00437 
2025-04-08 12:43:03.521440: train_loss -0.7981 
2025-04-08 12:43:03.521979: val_loss -0.7214 
2025-04-08 12:43:03.522116: Pseudo dice [0.7846] 
2025-04-08 12:43:03.522207: Epoch time: 275.1 s 
2025-04-08 12:43:05.440701:  
2025-04-08 12:43:05.440987: Epoch 602 
2025-04-08 12:43:05.441104: Current learning rate: 0.00436 
2025-04-08 12:47:39.686968: train_loss -0.8053 
2025-04-08 12:47:39.687312: val_loss -0.7817 
2025-04-08 12:47:39.687403: Pseudo dice [0.7959] 
2025-04-08 12:47:39.687506: Epoch time: 274.25 s 
2025-04-08 12:47:41.876075:  
2025-04-08 12:47:41.876284: Epoch 603 
2025-04-08 12:47:41.876409: Current learning rate: 0.00435 
2025-04-08 12:52:16.558371: train_loss -0.7892 
2025-04-08 12:52:16.558954: val_loss -0.7375 
2025-04-08 12:52:16.559066: Pseudo dice [0.759] 
2025-04-08 12:52:16.559147: Epoch time: 274.69 s 
2025-04-08 12:52:18.456284:  
2025-04-08 12:52:18.456488: Epoch 604 
2025-04-08 12:52:18.456608: Current learning rate: 0.00434 
2025-04-08 12:56:52.954826: train_loss -0.8046 
2025-04-08 12:56:52.955150: val_loss -0.7983 
2025-04-08 12:56:52.955229: Pseudo dice [0.8091] 
2025-04-08 12:56:52.955316: Epoch time: 274.5 s 
2025-04-08 12:56:54.828334:  
2025-04-08 12:56:54.828501: Epoch 605 
2025-04-08 12:56:54.828611: Current learning rate: 0.00433 
2025-04-08 13:01:29.722907: train_loss -0.7888 
2025-04-08 13:01:29.723533: val_loss -0.7483 
2025-04-08 13:01:29.723645: Pseudo dice [0.7786] 
2025-04-08 13:01:29.723730: Epoch time: 274.9 s 
2025-04-08 13:01:31.634167:  
2025-04-08 13:01:31.634402: Epoch 606 
2025-04-08 13:01:31.634534: Current learning rate: 0.00432 
2025-04-08 13:06:06.771255: train_loss -0.7951 
2025-04-08 13:06:06.771594: val_loss -0.764 
2025-04-08 13:06:06.771682: Pseudo dice [0.7667] 
2025-04-08 13:06:06.771803: Epoch time: 275.14 s 
2025-04-08 13:06:08.710530:  
2025-04-08 13:06:08.710857: Epoch 607 
2025-04-08 13:06:08.711001: Current learning rate: 0.00431 
2025-04-08 13:10:43.155639: train_loss -0.8062 
2025-04-08 13:10:43.155978: val_loss -0.7781 
2025-04-08 13:10:43.156108: Pseudo dice [0.7928] 
2025-04-08 13:10:43.156215: Epoch time: 274.45 s 
2025-04-08 13:10:45.108513:  
2025-04-08 13:10:45.108723: Epoch 608 
2025-04-08 13:10:45.108836: Current learning rate: 0.0043 
2025-04-08 13:15:18.962947: train_loss -0.8285 
2025-04-08 13:15:18.963558: val_loss -0.7929 
2025-04-08 13:15:18.963664: Pseudo dice [0.8114] 
2025-04-08 13:15:18.963746: Epoch time: 273.86 s 
2025-04-08 13:15:20.862069:  
2025-04-08 13:15:20.862327: Epoch 609 
2025-04-08 13:15:20.862450: Current learning rate: 0.00429 
2025-04-08 13:19:54.907564: train_loss -0.8161 
2025-04-08 13:19:54.907919: val_loss -0.7865 
2025-04-08 13:19:54.908070: Pseudo dice [0.809] 
2025-04-08 13:19:54.908165: Epoch time: 274.05 s 
2025-04-08 13:19:56.817567:  
2025-04-08 13:19:56.817810: Epoch 610 
2025-04-08 13:19:56.817940: Current learning rate: 0.00429 
2025-04-08 13:24:39.737488: train_loss -0.8226 
2025-04-08 13:24:39.738022: val_loss -0.7934 
2025-04-08 13:24:39.738124: Pseudo dice [0.8158] 
2025-04-08 13:24:39.738207: Epoch time: 282.92 s 
2025-04-08 13:24:41.647058:  
2025-04-08 13:24:41.647295: Epoch 611 
2025-04-08 13:24:41.647409: Current learning rate: 0.00428 
2025-04-08 13:29:15.721334: train_loss -0.8286 
2025-04-08 13:29:15.721639: val_loss -0.7736 
2025-04-08 13:29:15.721721: Pseudo dice [0.7981] 
2025-04-08 13:29:15.721807: Epoch time: 274.08 s 
2025-04-08 13:29:17.630676:  
2025-04-08 13:29:17.630967: Epoch 612 
2025-04-08 13:29:17.631083: Current learning rate: 0.00427 
2025-04-08 13:33:51.844674: train_loss -0.8296 
2025-04-08 13:33:51.845224: val_loss -0.7955 
2025-04-08 13:33:51.845323: Pseudo dice [0.7893] 
2025-04-08 13:33:51.845403: Epoch time: 274.22 s 
2025-04-08 13:33:53.817853:  
2025-04-08 13:33:53.818135: Epoch 613 
2025-04-08 13:33:53.818266: Current learning rate: 0.00426 
2025-04-08 13:38:27.956019: train_loss -0.8278 
2025-04-08 13:38:27.956371: val_loss -0.7922 
2025-04-08 13:38:27.956466: Pseudo dice [0.7955] 
2025-04-08 13:38:27.956566: Epoch time: 274.14 s 
2025-04-08 13:38:29.868796:  
2025-04-08 13:38:29.869023: Epoch 614 
2025-04-08 13:38:29.869140: Current learning rate: 0.00425 
2025-04-08 13:43:04.084707: train_loss -0.8241 
2025-04-08 13:43:04.090592: val_loss -0.7838 
2025-04-08 13:43:04.090818: Pseudo dice [0.7948] 
2025-04-08 13:43:04.090903: Epoch time: 274.22 s 
2025-04-08 13:43:05.994288:  
2025-04-08 13:43:05.994511: Epoch 615 
2025-04-08 13:43:05.994654: Current learning rate: 0.00424 
2025-04-08 13:47:40.586049: train_loss -0.8135 
2025-04-08 13:47:40.586371: val_loss -0.8055 
2025-04-08 13:47:40.586453: Pseudo dice [0.8032] 
2025-04-08 13:47:40.586575: Epoch time: 274.6 s 
2025-04-08 13:47:40.586689: Yayy! New best EMA pseudo Dice: 0.7953 
2025-04-08 13:47:43.779806:  
2025-04-08 13:47:43.780016: Epoch 616 
2025-04-08 13:47:43.780131: Current learning rate: 0.00423 
2025-04-08 13:52:18.615811: train_loss -0.8214 
2025-04-08 13:52:18.616363: val_loss -0.8097 
2025-04-08 13:52:18.616498: Pseudo dice [0.8177] 
2025-04-08 13:52:18.616637: Epoch time: 274.84 s 
2025-04-08 13:52:18.616701: Yayy! New best EMA pseudo Dice: 0.7976 
2025-04-08 13:52:21.856515:  
2025-04-08 13:52:21.856780: Epoch 617 
2025-04-08 13:52:21.856954: Current learning rate: 0.00422 
2025-04-08 13:56:56.485537: train_loss -0.8363 
2025-04-08 13:56:56.485941: val_loss -0.7654 
2025-04-08 13:56:56.486043: Pseudo dice [0.7609] 
2025-04-08 13:56:56.486127: Epoch time: 274.63 s 
2025-04-08 13:56:58.746476:  
2025-04-08 13:56:58.746718: Epoch 618 
2025-04-08 13:56:58.746839: Current learning rate: 0.00421 
2025-04-08 14:01:33.421250: train_loss -0.8282 
2025-04-08 14:01:33.421568: val_loss -0.7776 
2025-04-08 14:01:33.421683: Pseudo dice [0.8074] 
2025-04-08 14:01:33.421789: Epoch time: 274.68 s 
2025-04-08 14:01:35.327735:  
2025-04-08 14:01:35.327984: Epoch 619 
2025-04-08 14:01:35.328106: Current learning rate: 0.0042 
2025-04-08 14:06:10.116431: train_loss -0.8319 
2025-04-08 14:06:10.116958: val_loss -0.7777 
2025-04-08 14:06:10.117044: Pseudo dice [0.7945] 
2025-04-08 14:06:10.117160: Epoch time: 274.79 s 
2025-04-08 14:06:12.030855:  
2025-04-08 14:06:12.031085: Epoch 620 
2025-04-08 14:06:12.031218: Current learning rate: 0.00419 
2025-04-08 14:10:46.451443: train_loss -0.8259 
2025-04-08 14:10:46.451770: val_loss -0.7623 
2025-04-08 14:10:46.451865: Pseudo dice [0.7901] 
2025-04-08 14:10:46.451957: Epoch time: 274.42 s 
2025-04-08 14:10:48.366416:  
2025-04-08 14:10:48.366701: Epoch 621 
2025-04-08 14:10:48.366833: Current learning rate: 0.00418 
2025-04-08 14:15:22.671370: train_loss -0.8229 
2025-04-08 14:15:22.672131: val_loss -0.773 
2025-04-08 14:15:22.672253: Pseudo dice [0.7765] 
2025-04-08 14:15:22.672459: Epoch time: 274.31 s 
2025-04-08 14:15:24.629385:  
2025-04-08 14:15:24.629631: Epoch 622 
2025-04-08 14:15:24.629743: Current learning rate: 0.00417 
2025-04-08 14:19:59.126704: train_loss -0.823 
2025-04-08 14:19:59.127063: val_loss -0.7876 
2025-04-08 14:19:59.127146: Pseudo dice [0.7964] 
2025-04-08 14:19:59.127240: Epoch time: 274.5 s 
2025-04-08 14:20:01.033871:  
2025-04-08 14:20:01.034080: Epoch 623 
2025-04-08 14:20:01.034275: Current learning rate: 0.00416 
2025-04-08 14:24:35.396067: train_loss -0.8285 
2025-04-08 14:24:35.396697: val_loss -0.8118 
2025-04-08 14:24:35.396795: Pseudo dice [0.8228] 
2025-04-08 14:24:35.396878: Epoch time: 274.37 s 
2025-04-08 14:24:37.306602:  
2025-04-08 14:24:37.306740: Epoch 624 
2025-04-08 14:24:37.306900: Current learning rate: 0.00415 
2025-04-08 14:29:11.559307: train_loss -0.8242 
2025-04-08 14:29:11.559629: val_loss -0.7495 
2025-04-08 14:29:11.559716: Pseudo dice [0.7798] 
2025-04-08 14:29:11.559832: Epoch time: 274.26 s 
2025-04-08 14:29:13.473255:  
2025-04-08 14:29:13.473634: Epoch 625 
2025-04-08 14:29:13.473849: Current learning rate: 0.00414 
2025-04-08 14:34:59.344394: train_loss -0.8268 
2025-04-08 14:34:59.346480: val_loss -0.803 
2025-04-08 14:34:59.346736: Pseudo dice [0.8058] 
2025-04-08 14:34:59.346841: Epoch time: 345.88 s 
2025-04-08 14:35:01.865136:  
2025-04-08 14:35:01.867607: Epoch 626 
2025-04-08 14:35:01.867902: Current learning rate: 0.00413 
2025-04-08 14:39:44.949133: train_loss -0.8183 
2025-04-08 14:39:44.949439: val_loss -0.7941 
2025-04-08 14:39:44.949524: Pseudo dice [0.7865] 
2025-04-08 14:39:44.949684: Epoch time: 283.09 s 
2025-04-08 14:39:46.848140:  
2025-04-08 14:39:46.848345: Epoch 627 
2025-04-08 14:39:46.848463: Current learning rate: 0.00412 
2025-04-08 14:44:21.401942: train_loss -0.7953 
2025-04-08 14:44:21.402493: val_loss -0.7379 
2025-04-08 14:44:21.402601: Pseudo dice [0.7914] 
2025-04-08 14:44:21.402692: Epoch time: 274.56 s 
2025-04-08 14:44:23.309676:  
2025-04-08 14:44:23.309905: Epoch 628 
2025-04-08 14:44:23.310042: Current learning rate: 0.00411 
2025-04-08 14:48:57.840120: train_loss -0.7846 
2025-04-08 14:48:57.840442: val_loss -0.7584 
2025-04-08 14:48:57.840526: Pseudo dice [0.7667] 
2025-04-08 14:48:57.840644: Epoch time: 274.53 s 
2025-04-08 14:48:59.746014:  
2025-04-08 14:48:59.746228: Epoch 629 
2025-04-08 14:48:59.746339: Current learning rate: 0.0041 
2025-04-08 14:53:33.529392: train_loss -0.7713 
2025-04-08 14:53:33.529896: val_loss -0.7934 
2025-04-08 14:53:33.529975: Pseudo dice [0.7859] 
2025-04-08 14:53:33.530055: Epoch time: 273.79 s 
2025-04-08 14:53:35.448312:  
2025-04-08 14:53:35.448632: Epoch 630 
2025-04-08 14:53:35.448829: Current learning rate: 0.00409 
2025-04-08 14:58:09.456582: train_loss -0.8107 
2025-04-08 14:58:09.456939: val_loss -0.7916 
2025-04-08 14:58:09.457038: Pseudo dice [0.8038] 
2025-04-08 14:58:09.457139: Epoch time: 274.01 s 
2025-04-08 14:58:11.373049:  
2025-04-08 14:58:11.373247: Epoch 631 
2025-04-08 14:58:11.373362: Current learning rate: 0.00408 
2025-04-08 15:02:44.759919: train_loss -0.8192 
2025-04-08 15:02:44.760323: val_loss -0.7722 
2025-04-08 15:02:44.760437: Pseudo dice [0.7824] 
2025-04-08 15:02:44.760517: Epoch time: 273.39 s 
2025-04-08 15:02:46.672426:  
2025-04-08 15:02:46.672732: Epoch 632 
2025-04-08 15:02:46.672880: Current learning rate: 0.00407 
2025-04-08 15:07:20.540870: train_loss -0.8223 
2025-04-08 15:07:20.541554: val_loss -0.781 
2025-04-08 15:07:20.541662: Pseudo dice [0.7976] 
2025-04-08 15:07:20.541751: Epoch time: 273.87 s 
2025-04-08 15:07:22.480830:  
2025-04-08 15:07:22.481037: Epoch 633 
2025-04-08 15:07:22.481164: Current learning rate: 0.00406 
2025-04-08 15:11:56.389215: train_loss -0.8068 
2025-04-08 15:11:56.389534: val_loss -0.7768 
2025-04-08 15:11:56.389636: Pseudo dice [0.7663] 
2025-04-08 15:11:56.389735: Epoch time: 273.91 s 
2025-04-08 15:11:58.325254:  
2025-04-08 15:11:58.325446: Epoch 634 
2025-04-08 15:11:58.325562: Current learning rate: 0.00405 
2025-04-08 15:16:32.160856: train_loss -0.8151 
2025-04-08 15:16:32.161185: val_loss -0.7773 
2025-04-08 15:16:32.161275: Pseudo dice [0.7899] 
2025-04-08 15:16:32.161424: Epoch time: 273.84 s 
2025-04-08 15:16:34.440258:  
2025-04-08 15:16:34.440491: Epoch 635 
2025-04-08 15:16:34.440609: Current learning rate: 0.00404 
2025-04-08 15:21:08.379902: train_loss -0.8218 
2025-04-08 15:21:08.380212: val_loss -0.8018 
2025-04-08 15:21:08.380291: Pseudo dice [0.7983] 
2025-04-08 15:21:08.380386: Epoch time: 273.94 s 
2025-04-08 15:21:10.294378:  
2025-04-08 15:21:10.294643: Epoch 636 
2025-04-08 15:21:10.294759: Current learning rate: 0.00403 
2025-04-08 15:25:56.683105: train_loss -0.828 
2025-04-08 15:25:56.683678: val_loss -0.7512 
2025-04-08 15:25:56.683772: Pseudo dice [0.7776] 
2025-04-08 15:25:56.683879: Epoch time: 286.39 s 
2025-04-08 15:25:58.766738:  
2025-04-08 15:25:58.766964: Epoch 637 
2025-04-08 15:25:58.767105: Current learning rate: 0.00402 
2025-04-08 15:30:33.372282: train_loss -0.8002 
2025-04-08 15:30:33.372583: val_loss -0.7887 
2025-04-08 15:30:33.372671: Pseudo dice [0.8076] 
2025-04-08 15:30:33.372757: Epoch time: 274.61 s 
2025-04-08 15:30:35.289864:  
2025-04-08 15:30:35.290059: Epoch 638 
2025-04-08 15:30:35.290171: Current learning rate: 0.00401 
2025-04-08 15:35:10.555142: train_loss -0.8075 
2025-04-08 15:35:10.555726: val_loss -0.7838 
2025-04-08 15:35:10.555846: Pseudo dice [0.785] 
2025-04-08 15:35:10.555939: Epoch time: 275.27 s 
2025-04-08 15:35:12.476879:  
2025-04-08 15:35:12.477106: Epoch 639 
2025-04-08 15:35:12.477239: Current learning rate: 0.004 
2025-04-08 15:39:47.281839: train_loss -0.8122 
2025-04-08 15:39:47.282203: val_loss -0.789 
2025-04-08 15:39:47.282293: Pseudo dice [0.8026] 
2025-04-08 15:39:47.282389: Epoch time: 274.81 s 
2025-04-08 15:39:49.184069:  
2025-04-08 15:39:49.184324: Epoch 640 
2025-04-08 15:39:49.184465: Current learning rate: 0.00399 
2025-04-08 15:44:23.364056: train_loss -0.8309 
2025-04-08 15:44:23.364368: val_loss -0.7798 
2025-04-08 15:44:23.364456: Pseudo dice [0.7978] 
2025-04-08 15:44:23.364573: Epoch time: 274.18 s 
2025-04-08 15:44:25.272974:  
2025-04-08 15:44:25.273178: Epoch 641 
2025-04-08 15:44:25.273304: Current learning rate: 0.00398 
2025-04-08 15:48:59.444841: train_loss -0.8163 
2025-04-08 15:48:59.445204: val_loss -0.7841 
2025-04-08 15:48:59.445288: Pseudo dice [0.803] 
2025-04-08 15:48:59.445385: Epoch time: 274.18 s 
2025-04-08 15:49:01.351985:  
2025-04-08 15:49:01.352313: Epoch 642 
2025-04-08 15:49:01.352485: Current learning rate: 0.00397 
2025-04-08 15:53:35.743094: train_loss -0.825 
2025-04-08 15:53:35.743620: val_loss -0.7826 
2025-04-08 15:53:35.743800: Pseudo dice [0.801] 
2025-04-08 15:53:35.743889: Epoch time: 274.4 s 
2025-04-08 15:53:37.953470:  
2025-04-08 15:53:37.953684: Epoch 643 
2025-04-08 15:53:37.953800: Current learning rate: 0.00396 
2025-04-08 15:58:12.562662: train_loss -0.8088 
2025-04-08 15:58:12.562972: val_loss -0.7557 
2025-04-08 15:58:12.563074: Pseudo dice [0.7799] 
2025-04-08 15:58:12.563204: Epoch time: 274.61 s 
2025-04-08 15:58:14.477210:  
2025-04-08 15:58:14.477434: Epoch 644 
2025-04-08 15:58:14.477550: Current learning rate: 0.00395 
2025-04-08 16:02:49.058124: train_loss -0.7979 
2025-04-08 16:02:49.058447: val_loss -0.7911 
2025-04-08 16:02:49.058541: Pseudo dice [0.8054] 
2025-04-08 16:02:49.058646: Epoch time: 274.58 s 
2025-04-08 16:02:50.974098:  
2025-04-08 16:02:50.974278: Epoch 645 
2025-04-08 16:02:50.974393: Current learning rate: 0.00394 
2025-04-08 16:07:25.416965: train_loss -0.8199 
2025-04-08 16:07:25.417570: val_loss -0.803 
2025-04-08 16:07:25.417849: Pseudo dice [0.8032] 
2025-04-08 16:07:25.418104: Epoch time: 274.45 s 
2025-04-08 16:07:27.374349:  
2025-04-08 16:07:27.374570: Epoch 646 
2025-04-08 16:07:27.374739: Current learning rate: 0.00393 
2025-04-08 16:12:01.915728: train_loss -0.813 
2025-04-08 16:12:01.916068: val_loss -0.79 
2025-04-08 16:12:01.916158: Pseudo dice [0.8007] 
2025-04-08 16:12:01.916264: Epoch time: 274.55 s 
2025-04-08 16:12:03.846455:  
2025-04-08 16:12:03.846736: Epoch 647 
2025-04-08 16:12:03.846896: Current learning rate: 0.00392 
2025-04-08 16:16:38.051567: train_loss -0.8202 
2025-04-08 16:16:38.051970: val_loss -0.7883 
2025-04-08 16:16:38.052069: Pseudo dice [0.7933] 
2025-04-08 16:16:38.052171: Epoch time: 274.21 s 
2025-04-08 16:16:39.973408:  
2025-04-08 16:16:39.973594: Epoch 648 
2025-04-08 16:16:39.973706: Current learning rate: 0.00391 
2025-04-08 16:21:14.491920: train_loss -0.8238 
2025-04-08 16:21:14.492223: val_loss -0.7235 
2025-04-08 16:21:14.492315: Pseudo dice [0.7015] 
2025-04-08 16:21:14.492419: Epoch time: 274.52 s 
2025-04-08 16:21:16.398642:  
2025-04-08 16:21:16.398869: Epoch 649 
2025-04-08 16:21:16.399013: Current learning rate: 0.0039 
2025-04-08 16:25:50.123601: train_loss -0.8221 
2025-04-08 16:25:50.123978: val_loss -0.7913 
2025-04-08 16:25:50.124096: Pseudo dice [0.813] 
2025-04-08 16:25:50.124197: Epoch time: 273.73 s 
2025-04-08 16:25:53.284684:  
2025-04-08 16:25:53.284915: Epoch 650 
2025-04-08 16:25:53.285043: Current learning rate: 0.00389 
2025-04-08 16:30:27.009676: train_loss -0.8211 
2025-04-08 16:30:27.010023: val_loss -0.7797 
2025-04-08 16:30:27.010106: Pseudo dice [0.799] 
2025-04-08 16:30:27.010206: Epoch time: 273.73 s 
2025-04-08 16:30:28.919817:  
2025-04-08 16:30:28.919993: Epoch 651 
2025-04-08 16:30:28.920136: Current learning rate: 0.00388 
2025-04-08 16:35:02.338459: train_loss -0.8318 
2025-04-08 16:35:02.338769: val_loss -0.773 
2025-04-08 16:35:02.338856: Pseudo dice [0.7754] 
2025-04-08 16:35:02.338954: Epoch time: 273.42 s 
2025-04-08 16:35:04.582315:  
2025-04-08 16:35:04.582553: Epoch 652 
2025-04-08 16:35:04.582672: Current learning rate: 0.00387 
2025-04-08 16:39:38.532184: train_loss -0.8141 
2025-04-08 16:39:38.532552: val_loss -0.7789 
2025-04-08 16:39:38.532651: Pseudo dice [0.7904] 
2025-04-08 16:39:38.532790: Epoch time: 273.95 s 
2025-04-08 16:39:40.434039:  
2025-04-08 16:39:40.434259: Epoch 653 
2025-04-08 16:39:40.434376: Current learning rate: 0.00386 
2025-04-08 16:44:14.605736: train_loss -0.8041 
2025-04-08 16:44:14.606061: val_loss -0.7802 
2025-04-08 16:44:14.606160: Pseudo dice [0.7992] 
2025-04-08 16:44:14.606260: Epoch time: 274.18 s 
2025-04-08 16:44:16.518464:  
2025-04-08 16:44:16.518680: Epoch 654 
2025-04-08 16:44:16.518792: Current learning rate: 0.00385 
2025-04-08 16:48:50.278970: train_loss -0.8171 
2025-04-08 16:48:50.279825: val_loss -0.7794 
2025-04-08 16:48:50.279933: Pseudo dice [0.8064] 
2025-04-08 16:48:50.280018: Epoch time: 273.76 s 
2025-04-08 16:48:52.230704:  
2025-04-08 16:48:52.230914: Epoch 655 
2025-04-08 16:48:52.231036: Current learning rate: 0.00384 
2025-04-08 16:53:26.237841: train_loss -0.8205 
2025-04-08 16:53:26.238192: val_loss -0.807 
2025-04-08 16:53:26.238364: Pseudo dice [0.8119] 
2025-04-08 16:53:26.238463: Epoch time: 274.01 s 
2025-04-08 16:53:28.155056:  
2025-04-08 16:53:28.155287: Epoch 656 
2025-04-08 16:53:28.155400: Current learning rate: 0.00383 
2025-04-08 16:58:01.997147: train_loss -0.831 
2025-04-08 16:58:01.997473: val_loss -0.7813 
2025-04-08 16:58:01.997570: Pseudo dice [0.7846] 
2025-04-08 16:58:01.997669: Epoch time: 273.85 s 
2025-04-08 16:58:03.913256:  
2025-04-08 16:58:03.913477: Epoch 657 
2025-04-08 16:58:03.913605: Current learning rate: 0.00382 
2025-04-08 17:02:38.103475: train_loss -0.8269 
2025-04-08 17:02:38.103832: val_loss -0.7861 
2025-04-08 17:02:38.103918: Pseudo dice [0.7883] 
2025-04-08 17:02:38.104017: Epoch time: 274.19 s 
2025-04-08 17:02:39.995331:  
2025-04-08 17:02:39.995538: Epoch 658 
2025-04-08 17:02:39.995648: Current learning rate: 0.00381 
2025-04-08 17:07:14.652628: train_loss -0.822 
2025-04-08 17:07:14.652922: val_loss -0.8125 
2025-04-08 17:07:14.653022: Pseudo dice [0.8033] 
2025-04-08 17:07:14.653113: Epoch time: 274.66 s 
2025-04-08 17:07:16.563844:  
2025-04-08 17:07:16.564028: Epoch 659 
2025-04-08 17:07:16.564185: Current learning rate: 0.0038 
2025-04-08 17:11:51.439324: train_loss -0.8353 
2025-04-08 17:11:51.439976: val_loss -0.7917 
2025-04-08 17:11:51.440060: Pseudo dice [0.7978] 
2025-04-08 17:11:51.440143: Epoch time: 274.88 s 
2025-04-08 17:11:53.668451:  
2025-04-08 17:11:53.668705: Epoch 660 
2025-04-08 17:11:53.668829: Current learning rate: 0.00379 
2025-04-08 17:16:27.703022: train_loss -0.8389 
2025-04-08 17:16:27.703361: val_loss -0.8074 
2025-04-08 17:16:27.703451: Pseudo dice [0.8066] 
2025-04-08 17:16:27.703546: Epoch time: 274.04 s 
2025-04-08 17:16:29.604977:  
2025-04-08 17:16:29.605200: Epoch 661 
2025-04-08 17:16:29.605315: Current learning rate: 0.00378 
2025-04-08 17:21:04.115266: train_loss -0.8041 
2025-04-08 17:21:04.115656: val_loss -0.8144 
2025-04-08 17:21:04.115781: Pseudo dice [0.8204] 
2025-04-08 17:21:04.115869: Epoch time: 274.51 s 
2025-04-08 17:21:06.039771:  
2025-04-08 17:21:06.039999: Epoch 662 
2025-04-08 17:21:06.040113: Current learning rate: 0.00377 
2025-04-08 17:25:39.808845: train_loss -0.8221 
2025-04-08 17:25:39.809198: val_loss -0.7832 
2025-04-08 17:25:39.809278: Pseudo dice [0.7918] 
2025-04-08 17:25:39.809363: Epoch time: 273.77 s 
2025-04-08 17:25:41.711673:  
2025-04-08 17:25:41.711892: Epoch 663 
2025-04-08 17:25:41.712019: Current learning rate: 0.00376 
2025-04-08 17:30:36.390026: train_loss -0.8099 
2025-04-08 17:30:36.390652: val_loss -0.7811 
2025-04-08 17:30:36.390736: Pseudo dice [0.7961] 
2025-04-08 17:30:36.390816: Epoch time: 294.68 s 
2025-04-08 17:30:38.379141:  
2025-04-08 17:30:38.379355: Epoch 664 
2025-04-08 17:30:38.379480: Current learning rate: 0.00375 
2025-04-08 17:35:12.086479: train_loss -0.8405 
2025-04-08 17:35:12.086948: val_loss -0.7889 
2025-04-08 17:35:12.087037: Pseudo dice [0.8099] 
2025-04-08 17:35:12.087119: Epoch time: 273.71 s 
2025-04-08 17:35:12.087175: Yayy! New best EMA pseudo Dice: 0.7981 
2025-04-08 17:35:15.260636:  
2025-04-08 17:35:15.260940: Epoch 665 
2025-04-08 17:35:15.261054: Current learning rate: 0.00374 
2025-04-08 17:39:49.385282: train_loss -0.814 
2025-04-08 17:39:49.385880: val_loss -0.8105 
2025-04-08 17:39:49.385993: Pseudo dice [0.7979] 
2025-04-08 17:39:49.386083: Epoch time: 274.13 s 
2025-04-08 17:39:51.325939:  
2025-04-08 17:39:51.326182: Epoch 666 
2025-04-08 17:39:51.326310: Current learning rate: 0.00373 
2025-04-08 17:44:25.483644: train_loss -0.8003 
2025-04-08 17:44:25.483979: val_loss -0.7828 
2025-04-08 17:44:25.484066: Pseudo dice [0.7997] 
2025-04-08 17:44:25.484162: Epoch time: 274.16 s 
2025-04-08 17:44:25.484298: Yayy! New best EMA pseudo Dice: 0.7983 
2025-04-08 17:44:28.713990:  
2025-04-08 17:44:28.714183: Epoch 667 
2025-04-08 17:44:28.714318: Current learning rate: 0.00372 
2025-04-08 17:49:03.066182: train_loss -0.8186 
2025-04-08 17:49:03.066827: val_loss -0.7841 
2025-04-08 17:49:03.066952: Pseudo dice [0.8111] 
2025-04-08 17:49:03.067035: Epoch time: 274.36 s 
2025-04-08 17:49:03.067097: Yayy! New best EMA pseudo Dice: 0.7995 
2025-04-08 17:49:06.395501:  
2025-04-08 17:49:06.395697: Epoch 668 
2025-04-08 17:49:06.395928: Current learning rate: 0.00371 
2025-04-08 17:53:40.425228: train_loss -0.8261 
2025-04-08 17:53:40.425570: val_loss -0.803 
2025-04-08 17:53:40.425655: Pseudo dice [0.7943] 
2025-04-08 17:53:40.425758: Epoch time: 274.03 s 
2025-04-08 17:53:42.367248:  
2025-04-08 17:53:42.367424: Epoch 669 
2025-04-08 17:53:42.367571: Current learning rate: 0.0037 
2025-04-08 17:58:16.679859: train_loss -0.8321 
2025-04-08 17:58:16.680211: val_loss -0.758 
2025-04-08 17:58:16.680375: Pseudo dice [0.7711] 
2025-04-08 17:58:16.680457: Epoch time: 274.32 s 
2025-04-08 17:58:18.623149:  
2025-04-08 17:58:18.623361: Epoch 670 
2025-04-08 17:58:18.623516: Current learning rate: 0.00369 
2025-04-08 18:02:53.367183: train_loss -0.8183 
2025-04-08 18:02:53.371303: val_loss -0.7729 
2025-04-08 18:02:53.371430: Pseudo dice [0.7198] 
2025-04-08 18:02:53.371523: Epoch time: 274.75 s 
2025-04-08 18:02:55.316365:  
2025-04-08 18:02:55.316586: Epoch 671 
2025-04-08 18:02:55.316762: Current learning rate: 0.00368 
2025-04-08 18:07:29.822045: train_loss -0.8076 
2025-04-08 18:07:29.822353: val_loss -0.7993 
2025-04-08 18:07:29.822435: Pseudo dice [0.8038] 
2025-04-08 18:07:29.822520: Epoch time: 274.51 s 
2025-04-08 18:07:31.751262:  
2025-04-08 18:07:31.751465: Epoch 672 
2025-04-08 18:07:31.751616: Current learning rate: 0.00367 
2025-04-08 18:12:06.043339: train_loss -0.8292 
2025-04-08 18:12:06.043608: val_loss -0.7873 
2025-04-08 18:12:06.043690: Pseudo dice [0.8042] 
2025-04-08 18:12:06.043818: Epoch time: 274.3 s 
2025-04-08 18:12:07.986006:  
2025-04-08 18:12:07.986228: Epoch 673 
2025-04-08 18:12:07.986343: Current learning rate: 0.00366 
2025-04-08 18:16:42.306429: train_loss -0.8362 
2025-04-08 18:16:42.306736: val_loss -0.7886 
2025-04-08 18:16:42.306816: Pseudo dice [0.7879] 
2025-04-08 18:16:42.306901: Epoch time: 274.32 s 
2025-04-08 18:16:44.247813:  
2025-04-08 18:16:44.248096: Epoch 674 
2025-04-08 18:16:44.248219: Current learning rate: 0.00365 
2025-04-08 18:21:18.564296: train_loss -0.8261 
2025-04-08 18:21:18.564631: val_loss -0.7849 
2025-04-08 18:21:18.564721: Pseudo dice [0.7933] 
2025-04-08 18:21:18.564818: Epoch time: 274.32 s 
2025-04-08 18:21:20.802346:  
2025-04-08 18:21:20.802652: Epoch 675 
2025-04-08 18:21:20.802789: Current learning rate: 0.00364 
2025-04-08 18:25:55.265415: train_loss -0.8398 
2025-04-08 18:25:55.265751: val_loss -0.8121 
2025-04-08 18:25:55.265838: Pseudo dice [0.8262] 
2025-04-08 18:25:55.265939: Epoch time: 274.47 s 
2025-04-08 18:25:57.202775:  
2025-04-08 18:25:57.203095: Epoch 676 
2025-04-08 18:25:57.203211: Current learning rate: 0.00363 
2025-04-08 18:30:31.653314: train_loss -0.8136 
2025-04-08 18:30:31.653859: val_loss -0.7573 
2025-04-08 18:30:31.653960: Pseudo dice [0.7781] 
2025-04-08 18:30:31.654051: Epoch time: 274.45 s 
2025-04-08 18:30:33.614791:  
2025-04-08 18:30:33.615038: Epoch 677 
2025-04-08 18:30:33.615198: Current learning rate: 0.00362 
2025-04-08 18:35:07.778343: train_loss -0.8097 
2025-04-08 18:35:07.778673: val_loss -0.7842 
2025-04-08 18:35:07.778777: Pseudo dice [0.792] 
2025-04-08 18:35:07.778878: Epoch time: 274.17 s 
2025-04-08 18:35:09.707987:  
2025-04-08 18:35:09.708199: Epoch 678 
2025-04-08 18:35:09.708353: Current learning rate: 0.00361 
2025-04-08 18:39:44.013887: train_loss -0.8169 
2025-04-08 18:39:44.014213: val_loss -0.7826 
2025-04-08 18:39:44.014294: Pseudo dice [0.7978] 
2025-04-08 18:39:44.014392: Epoch time: 274.31 s 
2025-04-08 18:39:45.954821:  
2025-04-08 18:39:45.955006: Epoch 679 
2025-04-08 18:39:45.955134: Current learning rate: 0.0036 
2025-04-08 18:44:20.328637: train_loss -0.8062 
2025-04-08 18:44:20.329222: val_loss -0.7819 
2025-04-08 18:44:20.329337: Pseudo dice [0.7973] 
2025-04-08 18:44:20.329418: Epoch time: 274.38 s 
2025-04-08 18:44:22.263730:  
2025-04-08 18:44:22.263952: Epoch 680 
2025-04-08 18:44:22.264079: Current learning rate: 0.00359 
2025-04-08 18:48:56.449615: train_loss -0.8253 
2025-04-08 18:48:56.449947: val_loss -0.7473 
2025-04-08 18:48:56.450036: Pseudo dice [0.7673] 
2025-04-08 18:48:56.450118: Epoch time: 274.19 s 
2025-04-08 18:48:58.416434:  
2025-04-08 18:48:58.416648: Epoch 681 
2025-04-08 18:48:58.416793: Current learning rate: 0.00358 
2025-04-08 18:53:33.428377: train_loss -0.7654 
2025-04-08 18:53:33.428900: val_loss -0.7434 
2025-04-08 18:53:33.429006: Pseudo dice [0.7374] 
2025-04-08 18:53:33.429090: Epoch time: 275.02 s 
2025-04-08 18:53:35.409820:  
2025-04-08 18:53:35.410051: Epoch 682 
2025-04-08 18:53:35.410172: Current learning rate: 0.00357 
2025-04-08 18:58:09.943481: train_loss -0.7789 
2025-04-08 18:58:09.943835: val_loss -0.7744 
2025-04-08 18:58:09.943928: Pseudo dice [0.793] 
2025-04-08 18:58:09.944039: Epoch time: 274.54 s 
2025-04-08 18:58:12.203023:  
2025-04-08 18:58:12.203315: Epoch 683 
2025-04-08 18:58:12.203467: Current learning rate: 0.00356 
2025-04-08 19:02:46.913777: train_loss -0.8087 
2025-04-08 19:02:46.914348: val_loss -0.7662 
2025-04-08 19:02:46.914451: Pseudo dice [0.7725] 
2025-04-08 19:02:46.914536: Epoch time: 274.72 s 
2025-04-08 19:02:48.875369:  
2025-04-08 19:02:48.875646: Epoch 684 
2025-04-08 19:02:48.875805: Current learning rate: 0.00355 
2025-04-08 19:07:23.082132: train_loss -0.817 
2025-04-08 19:07:23.082481: val_loss -0.7793 
2025-04-08 19:07:23.082852: Pseudo dice [0.7885] 
2025-04-08 19:07:23.082936: Epoch time: 274.21 s 
2025-04-08 19:07:25.008278:  
2025-04-08 19:07:25.008531: Epoch 685 
2025-04-08 19:07:25.008672: Current learning rate: 0.00354 
2025-04-08 19:12:00.638114: train_loss -0.8206 
2025-04-08 19:12:00.638717: val_loss -0.7951 
2025-04-08 19:12:00.638828: Pseudo dice [0.8154] 
2025-04-08 19:12:00.638918: Epoch time: 275.63 s 
2025-04-08 19:12:02.618262:  
2025-04-08 19:12:02.618581: Epoch 686 
2025-04-08 19:12:02.618728: Current learning rate: 0.00353 
2025-04-08 19:16:37.141463: train_loss -0.8259 
2025-04-08 19:16:37.141786: val_loss -0.7821 
2025-04-08 19:16:37.141885: Pseudo dice [0.8001] 
2025-04-08 19:16:37.142031: Epoch time: 274.53 s 
2025-04-08 19:16:39.065142:  
2025-04-08 19:16:39.065345: Epoch 687 
2025-04-08 19:16:39.065455: Current learning rate: 0.00352 
2025-04-08 19:21:13.610184: train_loss -0.8364 
2025-04-08 19:21:13.610836: val_loss -0.7744 
2025-04-08 19:21:13.610942: Pseudo dice [0.7905] 
2025-04-08 19:21:13.611029: Epoch time: 274.55 s 
2025-04-08 19:21:15.528541:  
2025-04-08 19:21:15.528683: Epoch 688 
2025-04-08 19:21:15.528793: Current learning rate: 0.00351 
2025-04-08 19:25:50.320135: train_loss -0.8267 
2025-04-08 19:25:50.320460: val_loss -0.8052 
2025-04-08 19:25:50.320540: Pseudo dice [0.8152] 
2025-04-08 19:25:50.320659: Epoch time: 274.8 s 
2025-04-08 19:25:52.271669:  
2025-04-08 19:25:52.271922: Epoch 689 
2025-04-08 19:25:52.272039: Current learning rate: 0.0035 
2025-04-08 19:30:26.629255: train_loss -0.8324 
2025-04-08 19:30:26.629563: val_loss -0.7944 
2025-04-08 19:30:26.629659: Pseudo dice [0.7908] 
2025-04-08 19:30:26.629749: Epoch time: 274.36 s 
2025-04-08 19:30:28.555554:  
2025-04-08 19:30:28.555802: Epoch 690 
2025-04-08 19:30:28.555974: Current learning rate: 0.00349 
2025-04-08 19:35:02.275116: train_loss -0.8465 
2025-04-08 19:35:02.275714: val_loss -0.8157 
2025-04-08 19:35:02.275838: Pseudo dice [0.8128] 
2025-04-08 19:35:02.275928: Epoch time: 273.72 s 
2025-04-08 19:35:04.518772:  
2025-04-08 19:35:04.519012: Epoch 691 
2025-04-08 19:35:04.519125: Current learning rate: 0.00348 
2025-04-08 19:39:38.352673: train_loss -0.8397 
2025-04-08 19:39:38.353006: val_loss -0.7698 
2025-04-08 19:39:38.353134: Pseudo dice [0.7951] 
2025-04-08 19:39:38.353235: Epoch time: 273.84 s 
2025-04-08 19:39:40.296106:  
2025-04-08 19:39:40.296376: Epoch 692 
2025-04-08 19:39:40.296559: Current learning rate: 0.00346 
2025-04-08 19:44:13.848895: train_loss -0.8386 
2025-04-08 19:44:13.849202: val_loss -0.7961 
2025-04-08 19:44:13.849284: Pseudo dice [0.804] 
2025-04-08 19:44:13.849373: Epoch time: 273.56 s 
2025-04-08 19:44:15.787674:  
2025-04-08 19:44:15.787881: Epoch 693 
2025-04-08 19:44:15.787996: Current learning rate: 0.00345 
2025-04-08 19:48:48.742331: train_loss -0.8021 
2025-04-08 19:48:48.742651: val_loss -0.779 
2025-04-08 19:48:48.742737: Pseudo dice [0.8117] 
2025-04-08 19:48:48.742835: Epoch time: 272.96 s 
2025-04-08 19:48:50.678143:  
2025-04-08 19:48:50.678377: Epoch 694 
2025-04-08 19:48:50.678496: Current learning rate: 0.00344 
2025-04-08 19:53:25.055119: train_loss -0.8047 
2025-04-08 19:53:25.055632: val_loss -0.7469 
2025-04-08 19:53:25.055714: Pseudo dice [0.7807] 
2025-04-08 19:53:25.055805: Epoch time: 274.38 s 
2025-04-08 19:53:27.000618:  
2025-04-08 19:53:27.000819: Epoch 695 
2025-04-08 19:53:27.001058: Current learning rate: 0.00343 
2025-04-08 19:58:00.559803: train_loss -0.8187 
2025-04-08 19:58:00.560117: val_loss -0.7858 
2025-04-08 19:58:00.560224: Pseudo dice [0.797] 
2025-04-08 19:58:00.560327: Epoch time: 273.56 s 
2025-04-08 19:58:02.489258:  
2025-04-08 19:58:02.489527: Epoch 696 
2025-04-08 19:58:02.489652: Current learning rate: 0.00342 
2025-04-08 20:02:35.916090: train_loss -0.8327 
2025-04-08 20:02:35.916631: val_loss -0.7796 
2025-04-08 20:02:35.916718: Pseudo dice [0.7747] 
2025-04-08 20:02:35.916817: Epoch time: 273.43 s 
2025-04-08 20:02:37.854573:  
2025-04-08 20:02:37.854820: Epoch 697 
2025-04-08 20:02:37.854946: Current learning rate: 0.00341 
2025-04-08 20:07:11.514745: train_loss -0.8218 
2025-04-08 20:07:11.515123: val_loss -0.7867 
2025-04-08 20:07:11.515234: Pseudo dice [0.8054] 
2025-04-08 20:07:11.515343: Epoch time: 273.66 s 
2025-04-08 20:07:13.461122:  
2025-04-08 20:07:13.461329: Epoch 698 
2025-04-08 20:07:13.461527: Current learning rate: 0.0034 
2025-04-08 20:11:47.667092: train_loss -0.8255 
2025-04-08 20:11:47.667650: val_loss -0.7906 
2025-04-08 20:11:47.667734: Pseudo dice [0.7819] 
2025-04-08 20:11:47.667829: Epoch time: 274.21 s 
2025-04-08 20:11:49.630557:  
2025-04-08 20:11:49.630775: Epoch 699 
2025-04-08 20:11:49.630900: Current learning rate: 0.00339 
2025-04-08 20:16:23.687847: train_loss -0.8305 
2025-04-08 20:16:23.688160: val_loss -0.7911 
2025-04-08 20:16:23.688249: Pseudo dice [0.8022] 
2025-04-08 20:16:23.688338: Epoch time: 274.06 s 
2025-04-08 20:16:26.890100:  
2025-04-08 20:16:26.890331: Epoch 700 
2025-04-08 20:16:26.890444: Current learning rate: 0.00338 
2025-04-08 20:21:00.900099: train_loss -0.8249 
2025-04-08 20:21:00.900417: val_loss -0.7931 
2025-04-08 20:21:00.901581: Pseudo dice [0.8012] 
2025-04-08 20:21:00.901664: Epoch time: 274.01 s 
2025-04-08 20:21:02.842116:  
2025-04-08 20:21:02.842305: Epoch 701 
2025-04-08 20:21:02.842432: Current learning rate: 0.00337 
2025-04-08 20:25:37.265096: train_loss -0.8191 
2025-04-08 20:25:37.265638: val_loss -0.7887 
2025-04-08 20:25:37.265738: Pseudo dice [0.7966] 
2025-04-08 20:25:37.265839: Epoch time: 274.43 s 
2025-04-08 20:25:39.198121:  
2025-04-08 20:25:39.198348: Epoch 702 
2025-04-08 20:25:39.198475: Current learning rate: 0.00336 
2025-04-08 20:30:13.201494: train_loss -0.8309 
2025-04-08 20:30:13.201858: val_loss -0.7928 
2025-04-08 20:30:13.201939: Pseudo dice [0.7941] 
2025-04-08 20:30:13.202063: Epoch time: 274.01 s 
2025-04-08 20:30:15.124406:  
2025-04-08 20:30:15.124583: Epoch 703 
2025-04-08 20:30:15.124694: Current learning rate: 0.00335 
2025-04-08 20:34:49.184927: train_loss -0.831 
2025-04-08 20:34:49.192043: val_loss -0.7947 
2025-04-08 20:34:49.192203: Pseudo dice [0.7964] 
2025-04-08 20:34:49.192287: Epoch time: 274.06 s 
2025-04-08 20:34:51.140517:  
2025-04-08 20:34:51.140730: Epoch 704 
2025-04-08 20:34:51.140839: Current learning rate: 0.00334 
2025-04-08 20:39:24.724736: train_loss -0.8226 
2025-04-08 20:39:24.725101: val_loss -0.7874 
2025-04-08 20:39:24.725189: Pseudo dice [0.7822] 
2025-04-08 20:39:24.725284: Epoch time: 273.59 s 
2025-04-08 20:39:26.649371:  
2025-04-08 20:39:26.649641: Epoch 705 
2025-04-08 20:39:26.649754: Current learning rate: 0.00333 
2025-04-08 20:44:00.330804: train_loss -0.8343 
2025-04-08 20:44:00.331610: val_loss -0.7833 
2025-04-08 20:44:00.331717: Pseudo dice [0.7087] 
2025-04-08 20:44:00.331833: Epoch time: 273.69 s 
2025-04-08 20:44:02.322642:  
2025-04-08 20:44:02.322908: Epoch 706 
2025-04-08 20:44:02.323037: Current learning rate: 0.00332 
2025-04-08 20:48:36.290573: train_loss -0.803 
2025-04-08 20:48:36.290945: val_loss -0.7396 
2025-04-08 20:48:36.291033: Pseudo dice [0.7279] 
2025-04-08 20:48:36.291127: Epoch time: 273.97 s 
2025-04-08 20:48:38.565689:  
2025-04-08 20:48:38.565944: Epoch 707 
2025-04-08 20:48:38.566089: Current learning rate: 0.00331 
2025-04-08 20:55:03.015646: train_loss -0.796 
2025-04-08 20:55:03.016246: val_loss -0.778 
2025-04-08 20:55:03.016349: Pseudo dice [0.7929] 
2025-04-08 20:55:03.016436: Epoch time: 384.45 s 
2025-04-08 20:55:04.956950:  
2025-04-08 20:55:04.957192: Epoch 708 
2025-04-08 20:55:04.957304: Current learning rate: 0.0033 
2025-04-08 20:59:38.399087: train_loss -0.7954 
2025-04-08 20:59:38.399410: val_loss -0.776 
2025-04-08 20:59:38.399498: Pseudo dice [0.7816] 
2025-04-08 20:59:38.399592: Epoch time: 273.45 s 
2025-04-08 20:59:40.339284:  
2025-04-08 20:59:40.339545: Epoch 709 
2025-04-08 20:59:40.339676: Current learning rate: 0.00329 
2025-04-08 21:05:00.290633: train_loss -0.8225 
2025-04-08 21:05:00.291188: val_loss -0.8047 
2025-04-08 21:05:00.291269: Pseudo dice [0.8258] 
2025-04-08 21:05:00.291349: Epoch time: 319.96 s 
2025-04-08 21:05:02.262698:  
2025-04-08 21:05:02.262926: Epoch 710 
2025-04-08 21:05:02.263056: Current learning rate: 0.00328 
2025-04-08 21:09:36.412292: train_loss -0.822 
2025-04-08 21:09:36.412630: val_loss -0.8006 
2025-04-08 21:09:36.412730: Pseudo dice [0.8178] 
2025-04-08 21:09:36.412829: Epoch time: 274.15 s 
2025-04-08 21:09:38.363777:  
2025-04-08 21:09:38.364007: Epoch 711 
2025-04-08 21:09:38.364120: Current learning rate: 0.00327 
2025-04-08 21:14:22.199481: train_loss -0.8281 
2025-04-08 21:14:22.200134: val_loss -0.7986 
2025-04-08 21:14:22.200232: Pseudo dice [0.822] 
2025-04-08 21:14:22.200328: Epoch time: 283.84 s 
2025-04-08 21:14:24.257838:  
2025-04-08 21:14:24.258053: Epoch 712 
2025-04-08 21:14:24.258179: Current learning rate: 0.00326 
2025-04-08 21:19:00.737776: train_loss -0.8104 
2025-04-08 21:19:00.738095: val_loss -0.7722 
2025-04-08 21:19:00.738171: Pseudo dice [0.7859] 
2025-04-08 21:19:00.738266: Epoch time: 276.48 s 
2025-04-08 21:19:02.674574:  
2025-04-08 21:19:02.674772: Epoch 713 
2025-04-08 21:19:02.674893: Current learning rate: 0.00325 
2025-04-08 21:23:37.301640: train_loss -0.795 
2025-04-08 21:23:37.302016: val_loss -0.7434 
2025-04-08 21:23:37.302102: Pseudo dice [0.7716] 
2025-04-08 21:23:37.302195: Epoch time: 274.63 s 
2025-04-08 21:23:39.252736:  
2025-04-08 21:23:39.253011: Epoch 714 
2025-04-08 21:23:39.253159: Current learning rate: 0.00324 
2025-04-08 21:28:13.964683: train_loss -0.8087 
2025-04-08 21:28:13.965358: val_loss -0.7722 
2025-04-08 21:28:13.965486: Pseudo dice [0.7828] 
2025-04-08 21:28:13.965618: Epoch time: 274.72 s 
2025-04-08 21:28:16.234392:  
2025-04-08 21:28:16.234660: Epoch 715 
2025-04-08 21:28:16.234846: Current learning rate: 0.00323 
2025-04-08 21:32:50.784847: train_loss -0.8172 
2025-04-08 21:32:50.785201: val_loss -0.7682 
2025-04-08 21:32:50.785288: Pseudo dice [0.7746] 
2025-04-08 21:32:50.785383: Epoch time: 274.55 s 
2025-04-08 21:32:52.726584:  
2025-04-08 21:32:52.726877: Epoch 716 
2025-04-08 21:32:52.726996: Current learning rate: 0.00322 
2025-04-08 21:38:02.908692: train_loss -0.8252 
2025-04-08 21:38:02.909037: val_loss -0.7946 
2025-04-08 21:38:02.909463: Pseudo dice [0.816] 
2025-04-08 21:38:02.909544: Epoch time: 310.19 s 
2025-04-08 21:38:04.906313:  
2025-04-08 21:38:04.906552: Epoch 717 
2025-04-08 21:38:04.906669: Current learning rate: 0.00321 
2025-04-08 21:42:39.257971: train_loss -0.8349 
2025-04-08 21:42:39.258307: val_loss -0.8122 
2025-04-08 21:42:39.258385: Pseudo dice [0.8111] 
2025-04-08 21:42:39.258482: Epoch time: 274.36 s 
2025-04-08 21:42:41.256678:  
2025-04-08 21:42:41.256894: Epoch 718 
2025-04-08 21:42:41.257009: Current learning rate: 0.0032 
2025-04-08 21:47:16.380605: train_loss -0.8292 
2025-04-08 21:47:16.381873: val_loss -0.7799 
2025-04-08 21:47:16.381985: Pseudo dice [0.7933] 
2025-04-08 21:47:16.382097: Epoch time: 275.13 s 
2025-04-08 21:47:18.331342:  
2025-04-08 21:47:18.331627: Epoch 719 
2025-04-08 21:47:18.331760: Current learning rate: 0.00319 
2025-04-08 21:51:52.408393: train_loss -0.8238 
2025-04-08 21:51:52.408714: val_loss -0.7852 
2025-04-08 21:51:52.408796: Pseudo dice [0.7979] 
2025-04-08 21:51:52.408898: Epoch time: 274.08 s 
2025-04-08 21:51:54.346872:  
2025-04-08 21:51:54.347092: Epoch 720 
2025-04-08 21:51:54.347210: Current learning rate: 0.00318 
2025-04-08 21:56:30.888515: train_loss -0.8501 
2025-04-08 21:56:30.889113: val_loss -0.8084 
2025-04-08 21:56:30.889223: Pseudo dice [0.804] 
2025-04-08 21:56:30.889322: Epoch time: 276.55 s 
2025-04-08 21:56:32.868011:  
2025-04-08 21:56:32.868217: Epoch 721 
2025-04-08 21:56:32.868333: Current learning rate: 0.00317 
2025-04-08 22:01:07.465279: train_loss -0.8418 
2025-04-08 22:01:07.465598: val_loss -0.8064 
2025-04-08 22:01:07.465687: Pseudo dice [0.8119] 
2025-04-08 22:01:07.465830: Epoch time: 274.6 s 
2025-04-08 22:01:09.402009:  
2025-04-08 22:01:09.402246: Epoch 722 
2025-04-08 22:01:09.402367: Current learning rate: 0.00316 
2025-04-08 22:06:26.116312: train_loss -0.8416 
2025-04-08 22:06:26.116923: val_loss -0.7802 
2025-04-08 22:06:26.117023: Pseudo dice [0.8045] 
2025-04-08 22:06:26.117113: Epoch time: 316.72 s 
2025-04-08 22:06:28.131989:  
2025-04-08 22:06:28.132282: Epoch 723 
2025-04-08 22:06:28.132398: Current learning rate: 0.00315 
2025-04-08 22:11:02.022251: train_loss -0.8408 
2025-04-08 22:11:02.022567: val_loss -0.8101 
2025-04-08 22:11:02.022708: Pseudo dice [0.8247] 
2025-04-08 22:11:02.022865: Epoch time: 273.89 s 
2025-04-08 22:11:03.993672:  
2025-04-08 22:11:03.993902: Epoch 724 
2025-04-08 22:11:03.994030: Current learning rate: 0.00314 
2025-04-08 22:15:51.859296: train_loss -0.8403 
2025-04-08 22:15:51.859651: val_loss -0.7866 
2025-04-08 22:15:51.859736: Pseudo dice [0.8073] 
2025-04-08 22:15:51.859847: Epoch time: 287.87 s 
2025-04-08 22:15:51.859908: Yayy! New best EMA pseudo Dice: 0.8003 
2025-04-08 22:15:55.041471:  
2025-04-08 22:15:55.041648: Epoch 725 
2025-04-08 22:15:55.041797: Current learning rate: 0.00313 
2025-04-08 22:20:28.979678: train_loss -0.8401 
2025-04-08 22:20:28.980048: val_loss -0.8078 
2025-04-08 22:20:28.980150: Pseudo dice [0.793] 
2025-04-08 22:20:28.980249: Epoch time: 273.94 s 
2025-04-08 22:20:30.915239:  
2025-04-08 22:20:30.915526: Epoch 726 
2025-04-08 22:20:30.915643: Current learning rate: 0.00312 
2025-04-08 22:25:07.430812: train_loss -0.8244 
2025-04-08 22:25:07.431343: val_loss -0.7931 
2025-04-08 22:25:07.431449: Pseudo dice [0.8055] 
2025-04-08 22:25:07.431534: Epoch time: 276.52 s 
2025-04-08 22:25:09.368022:  
2025-04-08 22:25:09.368271: Epoch 727 
2025-04-08 22:25:09.368398: Current learning rate: 0.00311 
2025-04-08 22:29:43.232301: train_loss -0.8343 
2025-04-08 22:29:43.232651: val_loss -0.7841 
2025-04-08 22:29:43.232744: Pseudo dice [0.8026] 
2025-04-08 22:29:43.232854: Epoch time: 273.87 s 
2025-04-08 22:29:43.232977: Yayy! New best EMA pseudo Dice: 0.8004 
2025-04-08 22:29:46.445338:  
2025-04-08 22:29:46.445539: Epoch 728 
2025-04-08 22:29:46.445653: Current learning rate: 0.0031 
2025-04-08 22:34:19.679182: train_loss -0.8342 
2025-04-08 22:34:19.679507: val_loss -0.7873 
2025-04-08 22:34:19.679594: Pseudo dice [0.7911] 
2025-04-08 22:34:19.679693: Epoch time: 273.24 s 
2025-04-08 22:34:21.627153:  
2025-04-08 22:34:21.627346: Epoch 729 
2025-04-08 22:34:21.627463: Current learning rate: 0.00309 
2025-04-08 22:38:55.545530: train_loss -0.8231 
2025-04-08 22:38:55.546193: val_loss -0.7763 
2025-04-08 22:38:55.546275: Pseudo dice [0.7935] 
2025-04-08 22:38:55.546362: Epoch time: 273.92 s 
2025-04-08 22:38:57.553025:  
2025-04-08 22:38:57.553233: Epoch 730 
2025-04-08 22:38:57.553351: Current learning rate: 0.00308 
2025-04-08 22:43:30.883396: train_loss -0.8361 
2025-04-08 22:43:30.883747: val_loss -0.7814 
2025-04-08 22:43:30.883849: Pseudo dice [0.7915] 
2025-04-08 22:43:30.883955: Epoch time: 273.33 s 
2025-04-08 22:43:33.126243:  
2025-04-08 22:43:33.126504: Epoch 731 
2025-04-08 22:43:33.126626: Current learning rate: 0.00307 
2025-04-08 22:48:12.324511: train_loss -0.8145 
2025-04-08 22:48:12.324822: val_loss -0.8049 
2025-04-08 22:48:12.324899: Pseudo dice [0.8155] 
2025-04-08 22:48:12.324984: Epoch time: 279.2 s 
2025-04-08 22:48:14.274179:  
2025-04-08 22:48:14.274493: Epoch 732 
2025-04-08 22:48:14.274609: Current learning rate: 0.00306 
2025-04-08 22:52:47.963309: train_loss -0.838 
2025-04-08 22:52:47.963647: val_loss -0.7927 
2025-04-08 22:52:47.963727: Pseudo dice [0.8083] 
2025-04-08 22:52:47.963845: Epoch time: 273.69 s 
2025-04-08 22:52:47.963904: Yayy! New best EMA pseudo Dice: 0.8007 
2025-04-08 22:52:51.202784:  
2025-04-08 22:52:51.203046: Epoch 733 
2025-04-08 22:52:51.203201: Current learning rate: 0.00305 
2025-04-08 22:57:24.731941: train_loss -0.8346 
2025-04-08 22:57:24.732467: val_loss -0.7825 
2025-04-08 22:57:24.732580: Pseudo dice [0.7664] 
2025-04-08 22:57:24.732668: Epoch time: 273.53 s 
2025-04-08 22:57:26.754182:  
2025-04-08 22:57:26.754398: Epoch 734 
2025-04-08 22:57:26.754526: Current learning rate: 0.00304 
2025-04-08 23:01:59.618687: train_loss -0.8404 
2025-04-08 23:01:59.618990: val_loss -0.7734 
2025-04-08 23:01:59.619081: Pseudo dice [0.7915] 
2025-04-08 23:01:59.619189: Epoch time: 272.87 s 
2025-04-08 23:02:01.570713:  
2025-04-08 23:02:01.570935: Epoch 735 
2025-04-08 23:02:01.571052: Current learning rate: 0.00303 
2025-04-08 23:06:34.875958: train_loss -0.8265 
2025-04-08 23:06:34.876323: val_loss -0.718 
2025-04-08 23:06:34.876411: Pseudo dice [0.7715] 
2025-04-08 23:06:34.876510: Epoch time: 273.31 s 
2025-04-08 23:06:36.813302:  
2025-04-08 23:06:36.813537: Epoch 736 
2025-04-08 23:06:36.813682: Current learning rate: 0.00302 
2025-04-08 23:11:09.746965: train_loss -0.8241 
2025-04-08 23:11:09.747274: val_loss -0.7781 
2025-04-08 23:11:09.747356: Pseudo dice [0.7726] 
2025-04-08 23:11:09.747444: Epoch time: 272.94 s 
2025-04-08 23:11:11.690454:  
2025-04-08 23:11:11.690662: Epoch 737 
2025-04-08 23:11:11.690774: Current learning rate: 0.00301 
2025-04-08 23:16:07.191110: train_loss -0.8239 
2025-04-08 23:16:07.191758: val_loss -0.7191 
2025-04-08 23:16:07.191849: Pseudo dice [0.745] 
2025-04-08 23:16:07.191936: Epoch time: 295.5 s 
2025-04-08 23:16:09.867164:  
2025-04-08 23:16:09.867371: Epoch 738 
2025-04-08 23:16:09.867487: Current learning rate: 0.003 
2025-04-08 23:21:01.915012: train_loss -0.8106 
2025-04-08 23:21:01.915404: val_loss -0.7977 
2025-04-08 23:21:01.915536: Pseudo dice [0.796] 
2025-04-08 23:21:01.915619: Epoch time: 292.05 s 
2025-04-08 23:21:04.182899:  
2025-04-08 23:21:04.183208: Epoch 739 
2025-04-08 23:21:04.183315: Current learning rate: 0.00299 
2025-04-08 23:25:36.382191: train_loss -0.8307 
2025-04-08 23:25:36.382504: val_loss -0.7827 
2025-04-08 23:25:36.382588: Pseudo dice [0.7805] 
2025-04-08 23:25:36.382686: Epoch time: 272.2 s 
2025-04-08 23:25:38.327851:  
2025-04-08 23:25:38.328060: Epoch 740 
2025-04-08 23:25:38.328200: Current learning rate: 0.00297 
2025-04-08 23:30:12.350067: train_loss -0.7794 
2025-04-08 23:30:12.350723: val_loss -0.7597 
2025-04-08 23:30:12.350837: Pseudo dice [0.7421] 
2025-04-08 23:30:12.351046: Epoch time: 274.03 s 
2025-04-08 23:30:14.290821:  
2025-04-08 23:30:14.291045: Epoch 741 
2025-04-08 23:30:14.291162: Current learning rate: 0.00296 
2025-04-08 23:34:47.197741: train_loss -0.7643 
2025-04-08 23:34:47.198048: val_loss -0.7736 
2025-04-08 23:34:47.198134: Pseudo dice [0.7203] 
2025-04-08 23:34:47.198313: Epoch time: 272.91 s 
2025-04-08 23:34:49.138354:  
2025-04-08 23:34:49.138542: Epoch 742 
2025-04-08 23:34:49.138706: Current learning rate: 0.00295 
2025-04-08 23:39:22.057779: train_loss -0.8173 
2025-04-08 23:39:22.058405: val_loss -0.8086 
2025-04-08 23:39:22.058512: Pseudo dice [0.8252] 
2025-04-08 23:39:22.058597: Epoch time: 272.92 s 
2025-04-08 23:39:24.006166:  
2025-04-08 23:39:24.006463: Epoch 743 
2025-04-08 23:39:24.006579: Current learning rate: 0.00294 
2025-04-08 23:43:55.990791: train_loss -0.8248 
2025-04-08 23:43:55.991155: val_loss -0.7831 
2025-04-08 23:43:55.991252: Pseudo dice [0.8056] 
2025-04-08 23:43:55.991351: Epoch time: 271.99 s 
2025-04-08 23:43:57.932592:  
2025-04-08 23:43:57.932795: Epoch 744 
2025-04-08 23:43:57.932912: Current learning rate: 0.00293 
2025-04-08 23:48:30.432713: train_loss -0.8346 
2025-04-08 23:48:30.433259: val_loss -0.783 
2025-04-08 23:48:30.433367: Pseudo dice [0.7823] 
2025-04-08 23:48:30.433456: Epoch time: 272.5 s 
2025-04-08 23:48:32.408459:  
2025-04-08 23:48:32.408756: Epoch 745 
2025-04-08 23:48:32.408884: Current learning rate: 0.00292 
2025-04-08 23:53:04.551818: train_loss -0.831 
2025-04-08 23:53:04.552222: val_loss -0.7829 
2025-04-08 23:53:04.552349: Pseudo dice [0.788] 
2025-04-08 23:53:04.552438: Epoch time: 272.15 s 
2025-04-08 23:53:06.492521:  
2025-04-08 23:53:06.492794: Epoch 746 
2025-04-08 23:53:06.492949: Current learning rate: 0.00291 
2025-04-08 23:57:39.635468: train_loss -0.8453 
2025-04-08 23:57:39.636043: val_loss -0.786 
2025-04-08 23:57:39.636152: Pseudo dice [0.7937] 
2025-04-08 23:57:39.636237: Epoch time: 273.15 s 
2025-04-08 23:57:41.929108:  
2025-04-08 23:57:41.929398: Epoch 747 
2025-04-08 23:57:41.929536: Current learning rate: 0.0029 
2025-04-09 00:02:14.818897: train_loss -0.8213 
2025-04-09 00:02:14.819210: val_loss -0.8101 
2025-04-09 00:02:14.819292: Pseudo dice [0.8079] 
2025-04-09 00:02:14.819379: Epoch time: 272.89 s 
2025-04-09 00:02:16.756926:  
2025-04-09 00:02:16.757207: Epoch 748 
2025-04-09 00:02:16.757326: Current learning rate: 0.00289 
2025-04-09 00:06:49.650049: train_loss -0.8388 
2025-04-09 00:06:49.650637: val_loss -0.7857 
2025-04-09 00:06:49.650746: Pseudo dice [0.7956] 
2025-04-09 00:06:49.650826: Epoch time: 272.9 s 
2025-04-09 00:06:51.609251:  
2025-04-09 00:06:51.609453: Epoch 749 
2025-04-09 00:06:51.609606: Current learning rate: 0.00288 
2025-04-09 00:11:24.834933: train_loss -0.8432 
2025-04-09 00:11:24.835256: val_loss -0.7891 
2025-04-09 00:11:24.835332: Pseudo dice [0.7884] 
2025-04-09 00:11:24.835413: Epoch time: 273.23 s 
2025-04-09 00:11:28.019402:  
2025-04-09 00:11:28.019599: Epoch 750 
2025-04-09 00:11:28.019712: Current learning rate: 0.00287 
2025-04-09 00:16:00.969544: train_loss -0.8378 
2025-04-09 00:16:00.970006: val_loss -0.7674 
2025-04-09 00:16:00.970105: Pseudo dice [0.7795] 
2025-04-09 00:16:00.970225: Epoch time: 272.95 s 
2025-04-09 00:16:02.944212:  
2025-04-09 00:16:02.944454: Epoch 751 
2025-04-09 00:16:02.944607: Current learning rate: 0.00286 
2025-04-09 00:20:36.288414: train_loss -0.8272 
2025-04-09 00:20:36.289060: val_loss -0.7847 
2025-04-09 00:20:36.289158: Pseudo dice [0.8052] 
2025-04-09 00:20:36.289243: Epoch time: 273.35 s 
2025-04-09 00:20:38.245203:  
2025-04-09 00:20:38.245460: Epoch 752 
2025-04-09 00:20:38.245580: Current learning rate: 0.00285 
2025-04-09 00:25:11.339483: train_loss -0.8155 
2025-04-09 00:25:11.339805: val_loss -0.7329 
2025-04-09 00:25:11.339894: Pseudo dice [0.7582] 
2025-04-09 00:25:11.339994: Epoch time: 273.1 s 
2025-04-09 00:25:13.293861:  
2025-04-09 00:25:13.294064: Epoch 753 
2025-04-09 00:25:13.294176: Current learning rate: 0.00284 
2025-04-09 00:29:47.078075: train_loss -0.8274 
2025-04-09 00:29:47.078405: val_loss -0.7948 
2025-04-09 00:29:47.078512: Pseudo dice [0.7979] 
2025-04-09 00:29:47.078612: Epoch time: 273.79 s 
2025-04-09 00:29:49.360959:  
2025-04-09 00:29:49.361237: Epoch 754 
2025-04-09 00:29:49.361363: Current learning rate: 0.00283 
2025-04-09 00:34:23.364625: train_loss -0.835 
2025-04-09 00:34:23.365098: val_loss -0.7878 
2025-04-09 00:34:23.365206: Pseudo dice [0.7219] 
2025-04-09 00:34:23.365296: Epoch time: 274.01 s 
2025-04-09 00:34:25.303843:  
2025-04-09 00:34:25.304054: Epoch 755 
2025-04-09 00:34:25.304164: Current learning rate: 0.00282 
2025-04-09 00:38:59.843890: train_loss -0.8098 
2025-04-09 00:38:59.844478: val_loss -0.7761 
2025-04-09 00:38:59.844586: Pseudo dice [0.7705] 
2025-04-09 00:38:59.844669: Epoch time: 274.54 s 
2025-04-09 00:39:01.887414:  
2025-04-09 00:39:01.887690: Epoch 756 
2025-04-09 00:39:01.887848: Current learning rate: 0.00281 
2025-04-09 00:43:36.243437: train_loss -0.8184 
2025-04-09 00:43:36.243795: val_loss -0.7579 
2025-04-09 00:43:36.243884: Pseudo dice [0.7658] 
2025-04-09 00:43:36.243983: Epoch time: 274.36 s 
2025-04-09 00:43:38.177675:  
2025-04-09 00:43:38.177969: Epoch 757 
2025-04-09 00:43:38.178096: Current learning rate: 0.0028 
2025-04-09 00:48:12.331462: train_loss -0.8273 
2025-04-09 00:48:12.333360: val_loss -0.8011 
2025-04-09 00:48:12.333451: Pseudo dice [0.7991] 
2025-04-09 00:48:12.333534: Epoch time: 274.16 s 
2025-04-09 00:48:14.300416:  
2025-04-09 00:48:14.300704: Epoch 758 
2025-04-09 00:48:14.300817: Current learning rate: 0.00279 
2025-04-09 00:52:48.729759: train_loss -0.8464 
2025-04-09 00:52:48.730091: val_loss -0.7525 
2025-04-09 00:52:48.730196: Pseudo dice [0.7693] 
2025-04-09 00:52:48.730303: Epoch time: 274.43 s 
2025-04-09 00:52:50.692511:  
2025-04-09 00:52:50.692718: Epoch 759 
2025-04-09 00:52:50.692860: Current learning rate: 0.00278 
2025-04-09 00:57:24.438160: train_loss -0.8396 
2025-04-09 00:57:24.438502: val_loss -0.7584 
2025-04-09 00:57:24.438584: Pseudo dice [0.77] 
2025-04-09 00:57:24.438684: Epoch time: 273.75 s 
2025-04-09 00:57:26.393765:  
2025-04-09 00:57:26.393986: Epoch 760 
2025-04-09 00:57:26.394112: Current learning rate: 0.00277 
2025-04-09 01:02:40.931656: train_loss -0.8077 
2025-04-09 01:02:40.932355: val_loss -0.8022 
2025-04-09 01:02:40.932487: Pseudo dice [0.7803] 
2025-04-09 01:02:40.932590: Epoch time: 314.54 s 
2025-04-09 01:02:42.881136:  
2025-04-09 01:02:42.881414: Epoch 761 
2025-04-09 01:02:42.881568: Current learning rate: 0.00276 
2025-04-09 01:07:17.212491: train_loss -0.8314 
2025-04-09 01:07:17.212802: val_loss -0.7962 
2025-04-09 01:07:17.212898: Pseudo dice [0.7872] 
2025-04-09 01:07:17.213008: Epoch time: 274.34 s 
2025-04-09 01:07:19.534946:  
2025-04-09 01:07:19.535160: Epoch 762 
2025-04-09 01:07:19.535273: Current learning rate: 0.00275 
2025-04-09 01:11:55.379554: train_loss -0.8445 
2025-04-09 01:11:55.380316: val_loss -0.7958 
2025-04-09 01:11:55.380411: Pseudo dice [0.8125] 
2025-04-09 01:11:55.380499: Epoch time: 275.85 s 
2025-04-09 01:11:57.349913:  
2025-04-09 01:11:57.350203: Epoch 763 
2025-04-09 01:11:57.350319: Current learning rate: 0.00274 
2025-04-09 01:16:31.711212: train_loss -0.8502 
2025-04-09 01:16:31.711560: val_loss -0.7938 
2025-04-09 01:16:31.711648: Pseudo dice [0.7962] 
2025-04-09 01:16:31.711743: Epoch time: 274.37 s 
2025-04-09 01:16:33.662786:  
2025-04-09 01:16:33.662977: Epoch 764 
2025-04-09 01:16:33.663090: Current learning rate: 0.00273 
2025-04-09 01:21:08.418433: train_loss -0.8356 
2025-04-09 01:21:08.419106: val_loss -0.8166 
2025-04-09 01:21:08.419212: Pseudo dice [0.8205] 
2025-04-09 01:21:08.419315: Epoch time: 274.76 s 
2025-04-09 01:21:10.429863:  
2025-04-09 01:21:10.430113: Epoch 765 
2025-04-09 01:21:10.430230: Current learning rate: 0.00272 
2025-04-09 01:25:44.202128: train_loss -0.8507 
2025-04-09 01:25:44.202463: val_loss -0.7986 
2025-04-09 01:25:44.202549: Pseudo dice [0.785] 
2025-04-09 01:25:44.202647: Epoch time: 273.78 s 
2025-04-09 01:25:46.164888:  
2025-04-09 01:25:46.165172: Epoch 766 
2025-04-09 01:25:46.165336: Current learning rate: 0.00271 
2025-04-09 01:30:20.977675: train_loss -0.8343 
2025-04-09 01:30:20.978628: val_loss -0.797 
2025-04-09 01:30:20.978724: Pseudo dice [0.7957] 
2025-04-09 01:30:20.980643: Epoch time: 274.82 s 
2025-04-09 01:30:23.590694:  
2025-04-09 01:30:23.590975: Epoch 767 
2025-04-09 01:30:23.591166: Current learning rate: 0.0027 
2025-04-09 01:35:00.355828: train_loss -0.8398 
2025-04-09 01:35:00.356127: val_loss -0.7817 
2025-04-09 01:35:00.356212: Pseudo dice [0.7937] 
2025-04-09 01:35:00.356358: Epoch time: 276.77 s 
2025-04-09 01:35:02.317191:  
2025-04-09 01:35:02.317396: Epoch 768 
2025-04-09 01:35:02.317511: Current learning rate: 0.00268 
2025-04-09 01:39:36.667818: train_loss -0.8157 
2025-04-09 01:39:36.668415: val_loss -0.7877 
2025-04-09 01:39:36.668525: Pseudo dice [0.8044] 
2025-04-09 01:39:36.668607: Epoch time: 274.35 s 
2025-04-09 01:39:38.644742:  
2025-04-09 01:39:38.644952: Epoch 769 
2025-04-09 01:39:38.645079: Current learning rate: 0.00267 
2025-04-09 01:44:12.343463: train_loss -0.8115 
2025-04-09 01:44:12.343786: val_loss -0.8081 
2025-04-09 01:44:12.343881: Pseudo dice [0.7954] 
2025-04-09 01:44:12.343987: Epoch time: 273.7 s 
2025-04-09 01:44:14.627468:  
2025-04-09 01:44:14.627705: Epoch 770 
2025-04-09 01:44:14.627839: Current learning rate: 0.00266 
2025-04-09 01:48:47.851143: train_loss -0.8388 
2025-04-09 01:48:47.851443: val_loss -0.7946 
2025-04-09 01:48:47.851525: Pseudo dice [0.7973] 
2025-04-09 01:48:47.851673: Epoch time: 273.23 s 
2025-04-09 01:48:49.818277:  
2025-04-09 01:48:49.818507: Epoch 771 
2025-04-09 01:48:49.818670: Current learning rate: 0.00265 
2025-04-09 01:53:23.584604: train_loss -0.8317 
2025-04-09 01:53:23.585133: val_loss -0.8021 
2025-04-09 01:53:23.585302: Pseudo dice [0.8079] 
2025-04-09 01:53:23.585391: Epoch time: 273.77 s 
2025-04-09 01:53:25.551701:  
2025-04-09 01:53:25.551990: Epoch 772 
2025-04-09 01:53:25.552124: Current learning rate: 0.00264 
2025-04-09 01:57:59.442841: train_loss -0.8413 
2025-04-09 01:57:59.443202: val_loss -0.804 
2025-04-09 01:57:59.443283: Pseudo dice [0.8093] 
2025-04-09 01:57:59.443376: Epoch time: 273.9 s 
2025-04-09 01:58:01.408641:  
2025-04-09 01:58:01.408844: Epoch 773 
2025-04-09 01:58:01.409006: Current learning rate: 0.00263 
2025-04-09 02:02:35.484072: train_loss -0.8338 
2025-04-09 02:02:35.484626: val_loss -0.7986 
2025-04-09 02:02:35.484784: Pseudo dice [0.8078] 
2025-04-09 02:02:35.484869: Epoch time: 274.08 s 
2025-04-09 02:02:37.462352:  
2025-04-09 02:02:37.462911: Epoch 774 
2025-04-09 02:02:37.463081: Current learning rate: 0.00262 
2025-04-09 02:07:10.871541: train_loss -0.8385 
2025-04-09 02:07:10.871893: val_loss -0.7982 
2025-04-09 02:07:10.871982: Pseudo dice [0.8025] 
2025-04-09 02:07:10.872081: Epoch time: 273.41 s 
2025-04-09 02:07:12.834548:  
2025-04-09 02:07:12.834764: Epoch 775 
2025-04-09 02:07:12.834877: Current learning rate: 0.00261 
2025-04-09 02:12:12.994893: train_loss -0.8497 
2025-04-09 02:12:12.995447: val_loss -0.7758 
2025-04-09 02:12:12.995574: Pseudo dice [0.7972] 
2025-04-09 02:12:12.995662: Epoch time: 300.16 s 
2025-04-09 02:12:15.048276:  
2025-04-09 02:12:15.048523: Epoch 776 
2025-04-09 02:12:15.048666: Current learning rate: 0.0026 
2025-04-09 02:16:48.745492: train_loss -0.8487 
2025-04-09 02:16:48.745793: val_loss -0.8132 
2025-04-09 02:16:48.745877: Pseudo dice [0.8185] 
2025-04-09 02:16:48.745974: Epoch time: 273.7 s 
2025-04-09 02:16:50.722478:  
2025-04-09 02:16:50.722685: Epoch 777 
2025-04-09 02:16:50.722800: Current learning rate: 0.00259 
2025-04-09 02:21:24.769669: train_loss -0.8356 
2025-04-09 02:21:24.777603: val_loss -0.7748 
2025-04-09 02:21:24.777708: Pseudo dice [0.7818] 
2025-04-09 02:21:24.777794: Epoch time: 274.05 s 
2025-04-09 02:21:27.063277:  
2025-04-09 02:21:27.063495: Epoch 778 
2025-04-09 02:21:27.063644: Current learning rate: 0.00258 
2025-04-09 02:26:01.273915: train_loss -0.8176 
2025-04-09 02:26:01.274250: val_loss -0.7712 
2025-04-09 02:26:01.274335: Pseudo dice [0.7557] 
2025-04-09 02:26:01.274430: Epoch time: 274.21 s 
2025-04-09 02:26:03.244900:  
2025-04-09 02:26:03.245129: Epoch 779 
2025-04-09 02:26:03.245265: Current learning rate: 0.00257 
2025-04-09 02:30:37.163544: train_loss -0.8227 
2025-04-09 02:30:37.164102: val_loss -0.7478 
2025-04-09 02:30:37.164190: Pseudo dice [0.7662] 
2025-04-09 02:30:37.164278: Epoch time: 273.92 s 
2025-04-09 02:30:39.134223:  
2025-04-09 02:30:39.134420: Epoch 780 
2025-04-09 02:30:39.134534: Current learning rate: 0.00256 
2025-04-09 02:35:12.331442: train_loss -0.8527 
2025-04-09 02:35:12.331736: val_loss -0.7991 
2025-04-09 02:35:12.331887: Pseudo dice [0.8072] 
2025-04-09 02:35:12.331987: Epoch time: 273.2 s 
2025-04-09 02:35:14.304712:  
2025-04-09 02:35:14.304939: Epoch 781 
2025-04-09 02:35:14.305052: Current learning rate: 0.00255 
2025-04-09 02:39:47.107734: train_loss -0.847 
2025-04-09 02:39:47.108063: val_loss -0.8024 
2025-04-09 02:39:47.108145: Pseudo dice [0.796] 
2025-04-09 02:39:47.108242: Epoch time: 272.81 s 
2025-04-09 02:39:49.074816:  
2025-04-09 02:39:49.074972: Epoch 782 
2025-04-09 02:39:49.075171: Current learning rate: 0.00254 
2025-04-09 02:44:22.686237: train_loss -0.8281 
2025-04-09 02:44:22.686822: val_loss -0.7694 
2025-04-09 02:44:22.686968: Pseudo dice [0.7864] 
2025-04-09 02:44:22.687074: Epoch time: 273.62 s 
2025-04-09 02:44:24.666949:  
2025-04-09 02:44:24.667137: Epoch 783 
2025-04-09 02:44:24.667253: Current learning rate: 0.00253 
2025-04-09 02:49:20.305722: train_loss -0.8159 
2025-04-09 02:49:20.306076: val_loss -0.7986 
2025-04-09 02:49:20.306163: Pseudo dice [0.8095] 
2025-04-09 02:49:20.306268: Epoch time: 295.64 s 
2025-04-09 02:49:22.286621:  
2025-04-09 02:49:22.286891: Epoch 784 
2025-04-09 02:49:22.287004: Current learning rate: 0.00252 
2025-04-09 02:55:16.834844: train_loss -0.8316 
2025-04-09 02:55:16.835395: val_loss -0.7823 
2025-04-09 02:55:16.835501: Pseudo dice [0.7868] 
2025-04-09 02:55:16.835639: Epoch time: 354.55 s 
2025-04-09 02:55:18.802624:  
2025-04-09 02:55:18.802843: Epoch 785 
2025-04-09 02:55:18.802954: Current learning rate: 0.00251 
2025-04-09 02:59:52.160786: train_loss -0.8207 
2025-04-09 02:59:52.161107: val_loss -0.7686 
2025-04-09 02:59:52.161198: Pseudo dice [0.7795] 
2025-04-09 02:59:52.161301: Epoch time: 273.36 s 
2025-04-09 02:59:54.434731:  
2025-04-09 02:59:54.435080: Epoch 786 
2025-04-09 02:59:54.435258: Current learning rate: 0.0025 
2025-04-09 03:05:23.604219: train_loss -0.8347 
2025-04-09 03:05:23.604853: val_loss -0.7895 
2025-04-09 03:05:23.604973: Pseudo dice [0.782] 
2025-04-09 03:05:23.605056: Epoch time: 329.17 s 
2025-04-09 03:05:25.562713:  
2025-04-09 03:05:25.562930: Epoch 787 
2025-04-09 03:05:25.563044: Current learning rate: 0.00249 
2025-04-09 03:09:59.144207: train_loss -0.8466 
2025-04-09 03:09:59.144529: val_loss -0.8006 
2025-04-09 03:09:59.144634: Pseudo dice [0.7915] 
2025-04-09 03:09:59.144731: Epoch time: 273.59 s 
2025-04-09 03:10:01.148945:  
2025-04-09 03:10:01.149145: Epoch 788 
2025-04-09 03:10:01.149272: Current learning rate: 0.00248 
2025-04-09 03:14:35.905798: train_loss -0.8379 
2025-04-09 03:14:35.906495: val_loss -0.7881 
2025-04-09 03:14:35.906651: Pseudo dice [0.7952] 
2025-04-09 03:14:35.906765: Epoch time: 274.76 s 
2025-04-09 03:14:37.863927:  
2025-04-09 03:14:37.864220: Epoch 789 
2025-04-09 03:14:37.864378: Current learning rate: 0.00247 
2025-04-09 03:19:11.976931: train_loss -0.8316 
2025-04-09 03:19:11.977241: val_loss -0.8014 
2025-04-09 03:19:11.977325: Pseudo dice [0.8113] 
2025-04-09 03:19:11.977414: Epoch time: 274.12 s 
2025-04-09 03:19:13.940427:  
2025-04-09 03:19:13.940636: Epoch 790 
2025-04-09 03:19:13.940761: Current learning rate: 0.00245 
2025-04-09 03:24:01.781968: train_loss -0.8402 
2025-04-09 03:24:01.782537: val_loss -0.79 
2025-04-09 03:24:01.782641: Pseudo dice [0.8017] 
2025-04-09 03:24:01.782722: Epoch time: 287.85 s 
2025-04-09 03:24:03.789595:  
2025-04-09 03:24:03.789793: Epoch 791 
2025-04-09 03:24:03.789946: Current learning rate: 0.00244 
2025-04-09 03:28:38.174103: train_loss -0.8281 
2025-04-09 03:28:38.174448: val_loss -0.7802 
2025-04-09 03:28:38.174539: Pseudo dice [0.7909] 
2025-04-09 03:28:38.174630: Epoch time: 274.39 s 
2025-04-09 03:28:40.144089:  
2025-04-09 03:28:40.144336: Epoch 792 
2025-04-09 03:28:40.144450: Current learning rate: 0.00243 
2025-04-09 03:33:14.273731: train_loss -0.8298 
2025-04-09 03:33:14.274098: val_loss -0.8052 
2025-04-09 03:33:14.274242: Pseudo dice [0.8103] 
2025-04-09 03:33:14.274380: Epoch time: 274.13 s 
2025-04-09 03:33:16.243447:  
2025-04-09 03:33:16.243680: Epoch 793 
2025-04-09 03:33:16.243803: Current learning rate: 0.00242 
2025-04-09 03:37:50.181547: train_loss -0.8344 
2025-04-09 03:37:50.181861: val_loss -0.7909 
2025-04-09 03:37:50.181947: Pseudo dice [0.8222] 
2025-04-09 03:37:50.182033: Epoch time: 273.94 s 
2025-04-09 03:37:52.452401:  
2025-04-09 03:37:52.452645: Epoch 794 
2025-04-09 03:37:52.452760: Current learning rate: 0.00241 
2025-04-09 03:42:25.789073: train_loss -0.8382 
2025-04-09 03:42:25.789428: val_loss -0.8032 
2025-04-09 03:42:25.789521: Pseudo dice [0.8001] 
2025-04-09 03:42:25.789629: Epoch time: 273.34 s 
2025-04-09 03:42:27.749082:  
2025-04-09 03:42:27.749385: Epoch 795 
2025-04-09 03:42:27.749499: Current learning rate: 0.0024 
2025-04-09 03:47:01.259295: train_loss -0.841 
2025-04-09 03:47:01.259636: val_loss -0.7928 
2025-04-09 03:47:01.259729: Pseudo dice [0.7857] 
2025-04-09 03:47:01.259871: Epoch time: 273.51 s 
2025-04-09 03:47:03.227979:  
2025-04-09 03:47:03.228217: Epoch 796 
2025-04-09 03:47:03.228340: Current learning rate: 0.00239 
2025-04-09 03:51:37.460268: train_loss -0.8316 
2025-04-09 03:51:37.460698: val_loss -0.7879 
2025-04-09 03:51:37.460795: Pseudo dice [0.7963] 
2025-04-09 03:51:37.460890: Epoch time: 274.24 s 
2025-04-09 03:51:39.423960:  
2025-04-09 03:51:39.424185: Epoch 797 
2025-04-09 03:51:39.424312: Current learning rate: 0.00238 
2025-04-09 03:56:14.025519: train_loss -0.8441 
2025-04-09 03:56:14.025830: val_loss -0.8094 
2025-04-09 03:56:14.025921: Pseudo dice [0.8124] 
2025-04-09 03:56:14.026009: Epoch time: 274.61 s 
2025-04-09 03:56:15.994957:  
2025-04-09 03:56:15.995198: Epoch 798 
2025-04-09 03:56:15.995379: Current learning rate: 0.00237 
2025-04-09 04:00:50.191884: train_loss -0.8479 
2025-04-09 04:00:50.192189: val_loss -0.7834 
2025-04-09 04:00:50.192286: Pseudo dice [0.7972] 
2025-04-09 04:00:50.192403: Epoch time: 274.2 s 
2025-04-09 04:00:52.174850:  
2025-04-09 04:00:52.175069: Epoch 799 
2025-04-09 04:00:52.175189: Current learning rate: 0.00236 
2025-04-09 04:05:26.701407: train_loss -0.8369 
2025-04-09 04:05:26.701715: val_loss -0.7776 
2025-04-09 04:05:26.701801: Pseudo dice [0.7987] 
2025-04-09 04:05:26.701902: Epoch time: 274.53 s 
2025-04-09 04:05:29.953509:  
2025-04-09 04:05:29.953814: Epoch 800 
2025-04-09 04:05:29.953945: Current learning rate: 0.00235 
2025-04-09 04:10:04.533312: train_loss -0.8504 
2025-04-09 04:10:04.533614: val_loss -0.79 
2025-04-09 04:10:04.533697: Pseudo dice [0.7946] 
2025-04-09 04:10:04.533793: Epoch time: 274.58 s 
2025-04-09 04:10:06.512544:  
2025-04-09 04:10:06.512743: Epoch 801 
2025-04-09 04:10:06.512906: Current learning rate: 0.00234 
2025-04-09 04:14:40.999713: train_loss -0.8427 
2025-04-09 04:14:41.000086: val_loss -0.8025 
2025-04-09 04:14:41.000205: Pseudo dice [0.8207] 
2025-04-09 04:14:41.000304: Epoch time: 274.49 s 
2025-04-09 04:14:43.298866:  
2025-04-09 04:14:43.299051: Epoch 802 
2025-04-09 04:14:43.299167: Current learning rate: 0.00233 
2025-04-09 04:19:18.181884: train_loss -0.8524 
2025-04-09 04:19:18.182206: val_loss -0.7947 
2025-04-09 04:19:18.182345: Pseudo dice [0.8289] 
2025-04-09 04:19:18.182445: Epoch time: 274.89 s 
2025-04-09 04:19:18.182504: Yayy! New best EMA pseudo Dice: 0.8031 
2025-04-09 04:19:21.420879:  
2025-04-09 04:19:21.421091: Epoch 803 
2025-04-09 04:19:21.421258: Current learning rate: 0.00232 
2025-04-09 04:23:56.201333: train_loss -0.8489 
2025-04-09 04:23:56.201708: val_loss -0.7831 
2025-04-09 04:23:56.201795: Pseudo dice [0.7911] 
2025-04-09 04:23:56.201886: Epoch time: 274.78 s 
2025-04-09 04:23:58.167588:  
2025-04-09 04:23:58.167791: Epoch 804 
2025-04-09 04:23:58.167942: Current learning rate: 0.00231 
2025-04-09 04:28:33.275426: train_loss -0.8534 
2025-04-09 04:28:33.275847: val_loss -0.7905 
2025-04-09 04:28:33.275942: Pseudo dice [0.8123] 
2025-04-09 04:28:33.276048: Epoch time: 275.11 s 
2025-04-09 04:28:35.258825:  
2025-04-09 04:28:35.259005: Epoch 805 
2025-04-09 04:28:35.259216: Current learning rate: 0.0023 
2025-04-09 04:33:09.947824: train_loss -0.8558 
2025-04-09 04:33:09.948458: val_loss -0.8021 
2025-04-09 04:33:09.948567: Pseudo dice [0.8124] 
2025-04-09 04:33:09.948649: Epoch time: 274.69 s 
2025-04-09 04:33:09.948713: Yayy! New best EMA pseudo Dice: 0.8039 
2025-04-09 04:33:13.279086:  
2025-04-09 04:33:13.279364: Epoch 806 
2025-04-09 04:33:13.279515: Current learning rate: 0.00229 
2025-04-09 04:37:47.416601: train_loss -0.8553 
2025-04-09 04:37:47.416949: val_loss -0.7956 
2025-04-09 04:37:47.417027: Pseudo dice [0.8058] 
2025-04-09 04:37:47.417165: Epoch time: 274.14 s 
2025-04-09 04:37:47.417223: Yayy! New best EMA pseudo Dice: 0.8041 
2025-04-09 04:37:50.742176:  
2025-04-09 04:37:50.742474: Epoch 807 
2025-04-09 04:37:50.742595: Current learning rate: 0.00228 
2025-04-09 04:42:25.094847: train_loss -0.8624 
2025-04-09 04:42:25.095211: val_loss -0.7949 
2025-04-09 04:42:25.095308: Pseudo dice [0.7975] 
2025-04-09 04:42:25.095400: Epoch time: 274.36 s 
2025-04-09 04:42:27.071706:  
2025-04-09 04:42:27.071967: Epoch 808 
2025-04-09 04:42:27.072104: Current learning rate: 0.00226 
2025-04-09 04:47:01.687814: train_loss -0.862 
2025-04-09 04:47:01.688366: val_loss -0.8134 
2025-04-09 04:47:01.688468: Pseudo dice [0.8211] 
2025-04-09 04:47:01.688554: Epoch time: 274.62 s 
2025-04-09 04:47:01.688614: Yayy! New best EMA pseudo Dice: 0.8052 
2025-04-09 04:47:05.292712:  
2025-04-09 04:47:05.292927: Epoch 809 
2025-04-09 04:47:05.293081: Current learning rate: 0.00225 
2025-04-09 04:51:39.403312: train_loss -0.8572 
2025-04-09 04:51:39.403627: val_loss -0.8007 
2025-04-09 04:51:39.403727: Pseudo dice [0.8189] 
2025-04-09 04:51:39.403836: Epoch time: 274.11 s 
2025-04-09 04:51:39.403898: Yayy! New best EMA pseudo Dice: 0.8066 
2025-04-09 04:51:42.773821:  
2025-04-09 04:51:42.774027: Epoch 810 
2025-04-09 04:51:42.774154: Current learning rate: 0.00224 
2025-04-09 04:56:17.467287: train_loss -0.8527 
2025-04-09 04:56:17.467892: val_loss -0.7813 
2025-04-09 04:56:17.468003: Pseudo dice [0.8059] 
2025-04-09 04:56:17.468088: Epoch time: 274.7 s 
2025-04-09 04:56:19.454427:  
2025-04-09 04:56:19.454635: Epoch 811 
2025-04-09 04:56:19.454754: Current learning rate: 0.00223 
2025-04-09 05:00:54.016732: train_loss -0.853 
2025-04-09 05:00:54.017070: val_loss -0.7976 
2025-04-09 05:00:54.017152: Pseudo dice [0.8201] 
2025-04-09 05:00:54.017247: Epoch time: 274.57 s 
2025-04-09 05:00:54.017305: Yayy! New best EMA pseudo Dice: 0.8079 
2025-04-09 05:00:57.359689:  
2025-04-09 05:00:57.359895: Epoch 812 
2025-04-09 05:00:57.360033: Current learning rate: 0.00222 
2025-04-09 05:05:40.487951: train_loss -0.836 
2025-04-09 05:05:40.488553: val_loss -0.768 
2025-04-09 05:05:40.488659: Pseudo dice [0.7806] 
2025-04-09 05:05:40.488739: Epoch time: 283.13 s 
2025-04-09 05:05:42.469604:  
2025-04-09 05:05:42.469819: Epoch 813 
2025-04-09 05:05:42.469991: Current learning rate: 0.00221 
2025-04-09 05:10:17.293494: train_loss -0.8463 
2025-04-09 05:10:17.293834: val_loss -0.7799 
2025-04-09 05:10:17.293919: Pseudo dice [0.8206] 
2025-04-09 05:10:17.294017: Epoch time: 274.83 s 
2025-04-09 05:10:19.272606:  
2025-04-09 05:10:19.272886: Epoch 814 
2025-04-09 05:10:19.273040: Current learning rate: 0.0022 
2025-04-09 05:14:54.079826: train_loss -0.8275 
2025-04-09 05:14:54.080579: val_loss -0.7876 
2025-04-09 05:14:54.080682: Pseudo dice [0.8004] 
2025-04-09 05:14:54.080773: Epoch time: 274.81 s 
2025-04-09 05:14:56.331582:  
2025-04-09 05:14:56.331842: Epoch 815 
2025-04-09 05:14:56.332015: Current learning rate: 0.00219 
2025-04-09 05:19:30.157167: train_loss -0.8552 
2025-04-09 05:19:30.157520: val_loss -0.7738 
2025-04-09 05:19:30.157631: Pseudo dice [0.7887] 
2025-04-09 05:19:30.157762: Epoch time: 273.83 s 
2025-04-09 05:19:32.131008:  
2025-04-09 05:19:32.131238: Epoch 816 
2025-04-09 05:19:32.131392: Current learning rate: 0.00218 
2025-04-09 05:24:05.462278: train_loss -0.854 
2025-04-09 05:24:05.462586: val_loss -0.7292 
2025-04-09 05:24:05.462674: Pseudo dice [0.7873] 
2025-04-09 05:24:05.462774: Epoch time: 273.34 s 
2025-04-09 05:24:07.444682:  
2025-04-09 05:24:07.444965: Epoch 817 
2025-04-09 05:24:07.445091: Current learning rate: 0.00217 
2025-04-09 05:28:41.345540: train_loss -0.8415 
2025-04-09 05:28:41.346109: val_loss -0.7965 
2025-04-09 05:28:41.346216: Pseudo dice [0.8009] 
2025-04-09 05:28:41.346352: Epoch time: 273.91 s 
2025-04-09 05:28:43.320119:  
2025-04-09 05:28:43.320315: Epoch 818 
2025-04-09 05:28:43.320464: Current learning rate: 0.00216 
2025-04-09 05:33:16.371871: train_loss -0.8637 
2025-04-09 05:33:16.372295: val_loss -0.7925 
2025-04-09 05:33:16.372380: Pseudo dice [0.8062] 
2025-04-09 05:33:16.372476: Epoch time: 273.06 s 
2025-04-09 05:33:18.334418:  
2025-04-09 05:33:18.334596: Epoch 819 
2025-04-09 05:33:18.334732: Current learning rate: 0.00215 
2025-04-09 05:38:08.225925: train_loss -0.848 
2025-04-09 05:38:08.226471: val_loss -0.8047 
2025-04-09 05:38:08.226577: Pseudo dice [0.8003] 
2025-04-09 05:38:08.226664: Epoch time: 289.9 s 
2025-04-09 05:38:10.104189:  
2025-04-09 05:38:10.104407: Epoch 820 
2025-04-09 05:38:10.104520: Current learning rate: 0.00214 
2025-04-09 05:42:43.829890: train_loss -0.8556 
2025-04-09 05:42:43.830230: val_loss -0.7776 
2025-04-09 05:42:43.830317: Pseudo dice [0.8042] 
2025-04-09 05:42:43.830440: Epoch time: 273.73 s 
2025-04-09 05:42:45.702134:  
2025-04-09 05:42:45.702290: Epoch 821 
2025-04-09 05:42:45.702404: Current learning rate: 0.00213 
2025-04-09 05:47:26.591657: train_loss -0.841 
2025-04-09 05:47:26.592249: val_loss -0.7956 
2025-04-09 05:47:26.592354: Pseudo dice [0.8089] 
2025-04-09 05:47:26.592440: Epoch time: 280.89 s 
2025-04-09 05:47:28.493783:  
2025-04-09 05:47:28.494036: Epoch 822 
2025-04-09 05:47:28.494165: Current learning rate: 0.00212 
2025-04-09 05:52:02.408562: train_loss -0.8671 
2025-04-09 05:52:02.408889: val_loss -0.7901 
2025-04-09 05:52:02.408973: Pseudo dice [0.807] 
2025-04-09 05:52:02.409133: Epoch time: 273.92 s 
2025-04-09 05:52:04.605563:  
2025-04-09 05:52:04.605861: Epoch 823 
2025-04-09 05:52:04.606011: Current learning rate: 0.0021 
2025-04-09 05:56:39.640688: train_loss -0.8439 
2025-04-09 05:56:39.641239: val_loss -0.7313 
2025-04-09 05:56:39.641338: Pseudo dice [0.7043] 
2025-04-09 05:56:39.641421: Epoch time: 275.04 s 
2025-04-09 05:56:41.521097:  
2025-04-09 05:56:41.521311: Epoch 824 
2025-04-09 05:56:41.521428: Current learning rate: 0.00209 
2025-04-09 06:01:16.004849: train_loss -0.8477 
2025-04-09 06:01:16.005271: val_loss -0.7963 
2025-04-09 06:01:16.005378: Pseudo dice [0.8043] 
2025-04-09 06:01:16.005471: Epoch time: 274.49 s 
2025-04-09 06:01:17.873986:  
2025-04-09 06:01:17.874208: Epoch 825 
2025-04-09 06:01:17.874324: Current learning rate: 0.00208 
2025-04-09 06:05:52.730045: train_loss -0.8378 
2025-04-09 06:05:52.730652: val_loss -0.7684 
2025-04-09 06:05:52.730753: Pseudo dice [0.6922] 
2025-04-09 06:05:52.730841: Epoch time: 274.86 s 
2025-04-09 06:05:54.590588:  
2025-04-09 06:05:54.590765: Epoch 826 
2025-04-09 06:05:54.590930: Current learning rate: 0.00207 
2025-04-09 06:10:29.142474: train_loss -0.8397 
2025-04-09 06:10:29.142769: val_loss -0.7842 
2025-04-09 06:10:29.142860: Pseudo dice [0.7912] 
2025-04-09 06:10:29.142998: Epoch time: 274.56 s 
2025-04-09 06:10:31.029058:  
2025-04-09 06:10:31.029333: Epoch 827 
2025-04-09 06:10:31.029458: Current learning rate: 0.00206 
2025-04-09 06:15:05.417434: train_loss -0.8358 
2025-04-09 06:15:05.417789: val_loss -0.7251 
2025-04-09 06:15:05.417902: Pseudo dice [0.7618] 
2025-04-09 06:15:05.417994: Epoch time: 274.39 s 
2025-04-09 06:15:07.287002:  
2025-04-09 06:15:07.287209: Epoch 828 
2025-04-09 06:15:07.287338: Current learning rate: 0.00205 
2025-04-09 06:19:42.433840: train_loss -0.8425 
2025-04-09 06:19:42.434572: val_loss -0.7916 
2025-04-09 06:19:42.434673: Pseudo dice [0.8008] 
2025-04-09 06:19:42.434803: Epoch time: 275.15 s 
2025-04-09 06:19:44.323069:  
2025-04-09 06:19:44.323320: Epoch 829 
2025-04-09 06:19:44.323474: Current learning rate: 0.00204 
2025-04-09 06:24:18.492988: train_loss -0.8483 
2025-04-09 06:24:18.493352: val_loss -0.7843 
2025-04-09 06:24:18.493437: Pseudo dice [0.7936] 
2025-04-09 06:24:18.493537: Epoch time: 274.17 s 
2025-04-09 06:24:20.361179:  
2025-04-09 06:24:20.361404: Epoch 830 
2025-04-09 06:24:20.361592: Current learning rate: 0.00203 
2025-04-09 06:28:55.023835: train_loss -0.8526 
2025-04-09 06:28:55.024510: val_loss -0.8017 
2025-04-09 06:28:55.024646: Pseudo dice [0.8026] 
2025-04-09 06:28:55.024740: Epoch time: 274.67 s 
2025-04-09 06:28:56.903411:  
2025-04-09 06:28:56.903637: Epoch 831 
2025-04-09 06:28:56.903779: Current learning rate: 0.00202 
2025-04-09 06:33:30.191380: train_loss -0.8604 
2025-04-09 06:33:30.191696: val_loss -0.7959 
2025-04-09 06:33:30.191880: Pseudo dice [0.8197] 
2025-04-09 06:33:30.191962: Epoch time: 273.29 s 
2025-04-09 06:33:32.410805:  
2025-04-09 06:33:32.411076: Epoch 832 
2025-04-09 06:33:32.411212: Current learning rate: 0.00201 
2025-04-09 06:38:06.475618: train_loss -0.8519 
2025-04-09 06:38:06.476202: val_loss -0.7656 
2025-04-09 06:38:06.476307: Pseudo dice [0.7743] 
2025-04-09 06:38:06.476389: Epoch time: 274.07 s 
2025-04-09 06:38:08.403727:  
2025-04-09 06:38:08.403949: Epoch 833 
2025-04-09 06:38:08.404095: Current learning rate: 0.002 
2025-04-09 06:42:42.536771: train_loss -0.8472 
2025-04-09 06:42:42.537114: val_loss -0.7763 
2025-04-09 06:42:42.537212: Pseudo dice [0.7686] 
2025-04-09 06:42:42.537323: Epoch time: 274.14 s 
2025-04-09 06:42:44.474630:  
2025-04-09 06:42:44.474841: Epoch 834 
2025-04-09 06:42:44.474986: Current learning rate: 0.00199 
2025-04-09 06:47:22.104147: train_loss -0.8543 
2025-04-09 06:47:22.104715: val_loss -0.7838 
2025-04-09 06:47:22.104822: Pseudo dice [0.8007] 
2025-04-09 06:47:22.104960: Epoch time: 277.63 s 
2025-04-09 06:47:24.041680:  
2025-04-09 06:47:24.041889: Epoch 835 
2025-04-09 06:47:24.042045: Current learning rate: 0.00198 
2025-04-09 06:51:58.948871: train_loss -0.8562 
2025-04-09 06:51:58.949207: val_loss -0.8106 
2025-04-09 06:51:58.949314: Pseudo dice [0.8075] 
2025-04-09 06:51:58.949427: Epoch time: 274.91 s 
2025-04-09 06:52:00.851445:  
2025-04-09 06:52:00.851690: Epoch 836 
2025-04-09 06:52:00.851848: Current learning rate: 0.00196 
2025-04-09 06:56:35.455710: train_loss -0.8546 
2025-04-09 06:56:35.456069: val_loss -0.7761 
2025-04-09 06:56:35.456161: Pseudo dice [0.7984] 
2025-04-09 06:56:35.456265: Epoch time: 274.61 s 
2025-04-09 06:56:37.347442:  
2025-04-09 06:56:37.347690: Epoch 837 
2025-04-09 06:56:37.347871: Current learning rate: 0.00195 
2025-04-09 07:01:12.216130: train_loss -0.8461 
2025-04-09 07:01:12.216517: val_loss -0.7928 
2025-04-09 07:01:12.216665: Pseudo dice [0.8115] 
2025-04-09 07:01:12.216770: Epoch time: 274.87 s 
2025-04-09 07:01:14.090626:  
2025-04-09 07:01:14.090947: Epoch 838 
2025-04-09 07:01:14.091118: Current learning rate: 0.00194 
2025-04-09 07:05:48.760081: train_loss -0.8546 
2025-04-09 07:05:48.760421: val_loss -0.7911 
2025-04-09 07:05:48.760509: Pseudo dice [0.7958] 
2025-04-09 07:05:48.760605: Epoch time: 274.67 s 
2025-04-09 07:05:50.652158:  
2025-04-09 07:05:50.652464: Epoch 839 
2025-04-09 07:05:50.652584: Current learning rate: 0.00193 
2025-04-09 07:10:25.066321: train_loss -0.8592 
2025-04-09 07:10:25.066856: val_loss -0.7828 
2025-04-09 07:10:25.066964: Pseudo dice [0.7934] 
2025-04-09 07:10:25.067057: Epoch time: 274.42 s 
2025-04-09 07:10:26.937007:  
2025-04-09 07:10:26.937212: Epoch 840 
2025-04-09 07:10:26.937368: Current learning rate: 0.00192 
2025-04-09 07:15:00.863054: train_loss -0.8451 
2025-04-09 07:15:00.863384: val_loss -0.7711 
2025-04-09 07:15:00.863522: Pseudo dice [0.8036] 
2025-04-09 07:15:00.863610: Epoch time: 273.93 s 
2025-04-09 07:15:03.035954:  
2025-04-09 07:15:03.036178: Epoch 841 
2025-04-09 07:15:03.036320: Current learning rate: 0.00191 
2025-04-09 07:19:50.570410: train_loss -0.8548 
2025-04-09 07:19:50.571067: val_loss -0.7856 
2025-04-09 07:19:50.571177: Pseudo dice [0.8008] 
2025-04-09 07:19:50.571261: Epoch time: 287.54 s 
2025-04-09 07:19:52.449698:  
2025-04-09 07:19:52.449915: Epoch 842 
2025-04-09 07:19:52.450032: Current learning rate: 0.0019 
2025-04-09 07:24:27.328974: train_loss -0.8477 
2025-04-09 07:24:27.329390: val_loss -0.7957 
2025-04-09 07:24:27.329502: Pseudo dice [0.8098] 
2025-04-09 07:24:27.329608: Epoch time: 274.88 s 
2025-04-09 07:24:29.226585:  
2025-04-09 07:24:29.226847: Epoch 843 
2025-04-09 07:24:29.226967: Current learning rate: 0.00189 
2025-04-09 07:29:04.005598: train_loss -0.8541 
2025-04-09 07:29:04.005937: val_loss -0.7915 
2025-04-09 07:29:04.006023: Pseudo dice [0.8087] 
2025-04-09 07:29:04.006123: Epoch time: 274.78 s 
2025-04-09 07:29:05.886465:  
2025-04-09 07:29:05.886742: Epoch 844 
2025-04-09 07:29:05.886873: Current learning rate: 0.00188 
2025-04-09 07:33:40.532982: train_loss -0.8515 
2025-04-09 07:33:40.533337: val_loss -0.7953 
2025-04-09 07:33:40.533522: Pseudo dice [0.8219] 
2025-04-09 07:33:40.533631: Epoch time: 274.65 s 
2025-04-09 07:33:42.399771:  
2025-04-09 07:33:42.400022: Epoch 845 
2025-04-09 07:33:42.400145: Current learning rate: 0.00187 
2025-04-09 07:38:16.609305: train_loss -0.8519 
2025-04-09 07:38:16.610105: val_loss -0.7534 
2025-04-09 07:38:16.610252: Pseudo dice [0.779] 
2025-04-09 07:38:16.610386: Epoch time: 274.21 s 
2025-04-09 07:38:18.487037:  
2025-04-09 07:38:18.487232: Epoch 846 
2025-04-09 07:38:18.487349: Current learning rate: 0.00186 
2025-04-09 07:42:52.521275: train_loss -0.8533 
2025-04-09 07:42:52.521616: val_loss -0.7825 
2025-04-09 07:42:52.521701: Pseudo dice [0.7946] 
2025-04-09 07:42:52.521800: Epoch time: 274.04 s 
2025-04-09 07:42:54.487220:  
2025-04-09 07:42:54.487480: Epoch 847 
2025-04-09 07:42:54.487618: Current learning rate: 0.00185 
2025-04-09 07:47:28.490821: train_loss -0.8632 
2025-04-09 07:47:28.491174: val_loss -0.8204 
2025-04-09 07:47:28.491257: Pseudo dice [0.8272] 
2025-04-09 07:47:28.491353: Epoch time: 274.01 s 
2025-04-09 07:47:30.354819:  
2025-04-09 07:47:30.354970: Epoch 848 
2025-04-09 07:47:30.355089: Current learning rate: 0.00184 
2025-04-09 07:52:04.395958: train_loss -0.8502 
2025-04-09 07:52:04.396303: val_loss -0.7884 
2025-04-09 07:52:04.396390: Pseudo dice [0.8042] 
2025-04-09 07:52:04.396489: Epoch time: 274.05 s 
2025-04-09 07:52:06.553107:  
2025-04-09 07:52:06.553343: Epoch 849 
2025-04-09 07:52:06.553479: Current learning rate: 0.00182 
2025-04-09 07:56:40.403429: train_loss -0.8492 
2025-04-09 07:56:40.403785: val_loss -0.793 
2025-04-09 07:56:40.403890: Pseudo dice [0.8015] 
2025-04-09 07:56:40.403982: Epoch time: 273.85 s 
2025-04-09 07:56:43.585993:  
2025-04-09 07:56:43.586276: Epoch 850 
2025-04-09 07:56:43.586399: Current learning rate: 0.00181 
2025-04-09 08:01:52.557869: train_loss -0.8465 
2025-04-09 08:01:52.558415: val_loss -0.793 
2025-04-09 08:01:52.558520: Pseudo dice [0.807] 
2025-04-09 08:01:52.558603: Epoch time: 308.98 s 
2025-04-09 08:01:54.425846:  
2025-04-09 08:01:54.426056: Epoch 851 
2025-04-09 08:01:54.426169: Current learning rate: 0.0018 
2025-04-09 08:06:28.401832: train_loss -0.8526 
2025-04-09 08:06:28.402139: val_loss -0.795 
2025-04-09 08:06:28.402225: Pseudo dice [0.8284] 
2025-04-09 08:06:28.402315: Epoch time: 273.98 s 
2025-04-09 08:06:30.276441:  
2025-04-09 08:06:30.276680: Epoch 852 
2025-04-09 08:06:30.276798: Current learning rate: 0.00179 
2025-04-09 08:11:04.413750: train_loss -0.8383 
2025-04-09 08:11:04.414288: val_loss -0.7974 
2025-04-09 08:11:04.414392: Pseudo dice [0.7863] 
2025-04-09 08:11:04.414481: Epoch time: 274.14 s 
2025-04-09 08:11:06.262742:  
2025-04-09 08:11:06.262926: Epoch 853 
2025-04-09 08:11:06.263072: Current learning rate: 0.00178 
2025-04-09 08:15:39.686197: train_loss -0.8466 
2025-04-09 08:15:39.686539: val_loss -0.8068 
2025-04-09 08:15:39.686622: Pseudo dice [0.8122] 
2025-04-09 08:15:39.686723: Epoch time: 273.43 s 
2025-04-09 08:15:41.537673:  
2025-04-09 08:15:41.537907: Epoch 854 
2025-04-09 08:15:41.538023: Current learning rate: 0.00177 
2025-04-09 08:20:15.149136: train_loss -0.841 
2025-04-09 08:20:15.149695: val_loss -0.797 
2025-04-09 08:20:15.149837: Pseudo dice [0.8094] 
2025-04-09 08:20:15.149925: Epoch time: 273.62 s 
2025-04-09 08:20:17.150424:  
2025-04-09 08:20:17.150771: Epoch 855 
2025-04-09 08:20:17.150937: Current learning rate: 0.00176 
2025-04-09 08:24:50.763601: train_loss -0.8445 
2025-04-09 08:24:50.763942: val_loss -0.7975 
2025-04-09 08:24:50.764034: Pseudo dice [0.8141] 
2025-04-09 08:24:50.764137: Epoch time: 273.62 s 
2025-04-09 08:24:52.620322:  
2025-04-09 08:24:52.620506: Epoch 856 
2025-04-09 08:24:52.620661: Current learning rate: 0.00175 
2025-04-09 08:29:26.209729: train_loss -0.8404 
2025-04-09 08:29:26.210333: val_loss -0.8054 
2025-04-09 08:29:26.210447: Pseudo dice [0.8068] 
2025-04-09 08:29:26.210564: Epoch time: 273.59 s 
2025-04-09 08:29:28.359131:  
2025-04-09 08:29:28.359340: Epoch 857 
2025-04-09 08:29:28.359506: Current learning rate: 0.00174 
2025-04-09 08:34:01.470850: train_loss -0.8444 
2025-04-09 08:34:01.471208: val_loss -0.812 
2025-04-09 08:34:01.471369: Pseudo dice [0.8046] 
2025-04-09 08:34:01.471562: Epoch time: 273.12 s 
2025-04-09 08:34:03.337816:  
2025-04-09 08:34:03.338109: Epoch 858 
2025-04-09 08:34:03.338243: Current learning rate: 0.00173 
2025-04-09 08:38:36.592351: train_loss -0.8515 
2025-04-09 08:38:36.592696: val_loss -0.7928 
2025-04-09 08:38:36.592785: Pseudo dice [0.792] 
2025-04-09 08:38:36.592889: Epoch time: 273.26 s 
2025-04-09 08:38:38.482228:  
2025-04-09 08:38:38.482455: Epoch 859 
2025-04-09 08:38:38.482629: Current learning rate: 0.00172 
2025-04-09 08:44:40.889244: train_loss -0.854 
2025-04-09 08:44:40.890447: val_loss -0.8073 
2025-04-09 08:44:40.890756: Pseudo dice [0.7979] 
2025-04-09 08:44:40.890847: Epoch time: 362.41 s 
2025-04-09 08:44:42.834117:  
2025-04-09 08:44:42.834364: Epoch 860 
2025-04-09 08:44:42.834510: Current learning rate: 0.0017 
2025-04-09 08:49:42.291663: train_loss -0.857 
2025-04-09 08:49:42.292235: val_loss -0.8158 
2025-04-09 08:49:42.292343: Pseudo dice [0.82] 
2025-04-09 08:49:42.292431: Epoch time: 299.46 s 
2025-04-09 08:49:44.175504:  
2025-04-09 08:49:44.175703: Epoch 861 
2025-04-09 08:49:44.175862: Current learning rate: 0.00169 
2025-04-09 08:54:18.338780: train_loss -0.8557 
2025-04-09 08:54:18.339213: val_loss -0.7715 
2025-04-09 08:54:18.339310: Pseudo dice [0.7926] 
2025-04-09 08:54:18.339398: Epoch time: 274.17 s 
2025-04-09 08:54:20.214717:  
2025-04-09 08:54:20.214926: Epoch 862 
2025-04-09 08:54:20.215040: Current learning rate: 0.00168 
2025-04-09 08:58:54.089973: train_loss -0.8593 
2025-04-09 08:58:54.090288: val_loss -0.7655 
2025-04-09 08:58:54.090372: Pseudo dice [0.7763] 
2025-04-09 08:58:54.090468: Epoch time: 273.88 s 
2025-04-09 08:58:55.987360:  
2025-04-09 08:58:55.987664: Epoch 863 
2025-04-09 08:58:55.987828: Current learning rate: 0.00167 
2025-04-09 09:03:30.531370: train_loss -0.851 
2025-04-09 09:03:30.531905: val_loss -0.789 
2025-04-09 09:03:30.532057: Pseudo dice [0.806] 
2025-04-09 09:03:30.532149: Epoch time: 274.55 s 
2025-04-09 09:03:32.387810:  
2025-04-09 09:03:32.388062: Epoch 864 
2025-04-09 09:03:32.388187: Current learning rate: 0.00166 
2025-04-09 09:08:06.695033: train_loss -0.8537 
2025-04-09 09:08:06.695372: val_loss -0.7932 
2025-04-09 09:08:06.695453: Pseudo dice [0.7964] 
2025-04-09 09:08:06.695553: Epoch time: 274.31 s 
2025-04-09 09:08:08.862409:  
2025-04-09 09:08:08.862681: Epoch 865 
2025-04-09 09:08:08.862818: Current learning rate: 0.00165 
2025-04-09 09:12:48.335701: train_loss -0.8519 
2025-04-09 09:12:48.336327: val_loss -0.7554 
2025-04-09 09:12:48.336439: Pseudo dice [0.7801] 
2025-04-09 09:12:48.336524: Epoch time: 279.48 s 
2025-04-09 09:12:50.234763:  
2025-04-09 09:12:50.234986: Epoch 866 
2025-04-09 09:12:50.235118: Current learning rate: 0.00164 
2025-04-09 09:17:24.088243: train_loss -0.8491 
2025-04-09 09:17:24.088570: val_loss -0.781 
2025-04-09 09:17:24.088659: Pseudo dice [0.7864] 
2025-04-09 09:17:24.088750: Epoch time: 273.86 s 
2025-04-09 09:17:25.956124:  
2025-04-09 09:17:25.956336: Epoch 867 
2025-04-09 09:17:25.956450: Current learning rate: 0.00163 
2025-04-09 09:22:54.491052: train_loss -0.8602 
2025-04-09 09:22:54.492558: val_loss -0.8011 
2025-04-09 09:22:54.492664: Pseudo dice [0.8066] 
2025-04-09 09:22:54.492751: Epoch time: 328.54 s 
2025-04-09 09:22:56.357016:  
2025-04-09 09:22:56.357253: Epoch 868 
2025-04-09 09:22:56.357377: Current learning rate: 0.00162 
2025-04-09 09:27:30.546133: train_loss -0.8526 
2025-04-09 09:27:30.546445: val_loss -0.8099 
2025-04-09 09:27:30.546529: Pseudo dice [0.8299] 
2025-04-09 09:27:30.546615: Epoch time: 274.19 s 
2025-04-09 09:27:32.411195:  
2025-04-09 09:27:32.411411: Epoch 869 
2025-04-09 09:27:32.411527: Current learning rate: 0.00161 
2025-04-09 09:32:28.466341: train_loss -0.853 
2025-04-09 09:32:28.466891: val_loss -0.8134 
2025-04-09 09:32:28.467000: Pseudo dice [0.8055] 
2025-04-09 09:32:28.467081: Epoch time: 296.06 s 
2025-04-09 09:32:30.355643:  
2025-04-09 09:32:30.355946: Epoch 870 
2025-04-09 09:32:30.356146: Current learning rate: 0.00159 
2025-04-09 09:37:04.609013: train_loss -0.8622 
2025-04-09 09:37:04.609395: val_loss -0.7845 
2025-04-09 09:37:04.609515: Pseudo dice [0.7883] 
2025-04-09 09:37:04.609596: Epoch time: 274.26 s 
2025-04-09 09:37:06.478178:  
2025-04-09 09:37:06.478479: Epoch 871 
2025-04-09 09:37:06.478612: Current learning rate: 0.00158 
2025-04-09 09:41:42.027519: train_loss -0.8592 
2025-04-09 09:41:42.028060: val_loss -0.7962 
2025-04-09 09:41:42.028203: Pseudo dice [0.8174] 
2025-04-09 09:41:42.028313: Epoch time: 275.55 s 
2025-04-09 09:41:43.907369:  
2025-04-09 09:41:43.907614: Epoch 872 
2025-04-09 09:41:43.907726: Current learning rate: 0.00157 
2025-04-09 09:46:18.933799: train_loss -0.8637 
2025-04-09 09:46:18.934108: val_loss -0.7962 
2025-04-09 09:46:18.934192: Pseudo dice [0.7985] 
2025-04-09 09:46:18.934326: Epoch time: 275.03 s 
2025-04-09 09:46:20.804188:  
2025-04-09 09:46:20.804409: Epoch 873 
2025-04-09 09:46:20.804531: Current learning rate: 0.00156 
2025-04-09 09:50:59.697145: train_loss -0.8519 
2025-04-09 09:50:59.697815: val_loss -0.7207 
2025-04-09 09:50:59.697925: Pseudo dice [0.7659] 
2025-04-09 09:50:59.698058: Epoch time: 278.9 s 
2025-04-09 09:51:02.610837:  
2025-04-09 09:51:02.611017: Epoch 874 
2025-04-09 09:51:02.611247: Current learning rate: 0.00155 
2025-04-09 09:55:51.411777: train_loss -0.8527 
2025-04-09 09:55:51.412102: val_loss -0.7811 
2025-04-09 09:55:51.412194: Pseudo dice [0.8007] 
2025-04-09 09:55:51.412287: Epoch time: 288.81 s 
2025-04-09 09:55:53.280896:  
2025-04-09 09:55:53.281134: Epoch 875 
2025-04-09 09:55:53.281299: Current learning rate: 0.00154 
2025-04-09 10:00:28.107961: train_loss -0.8492 
2025-04-09 10:00:28.108305: val_loss -0.7665 
2025-04-09 10:00:28.108387: Pseudo dice [0.7774] 
2025-04-09 10:00:28.108488: Epoch time: 274.83 s 
2025-04-09 10:00:29.958617:  
2025-04-09 10:00:29.958907: Epoch 876 
2025-04-09 10:00:29.959020: Current learning rate: 0.00153 
2025-04-09 10:05:05.731801: train_loss -0.8632 
2025-04-09 10:05:05.732393: val_loss -0.7436 
2025-04-09 10:05:05.732502: Pseudo dice [0.7888] 
2025-04-09 10:05:05.732628: Epoch time: 275.78 s 
2025-04-09 10:05:07.609326:  
2025-04-09 10:05:07.609537: Epoch 877 
2025-04-09 10:05:07.609751: Current learning rate: 0.00152 
2025-04-09 10:09:42.742507: train_loss -0.8651 
2025-04-09 10:09:42.742894: val_loss -0.7749 
2025-04-09 10:09:42.743002: Pseudo dice [0.8023] 
2025-04-09 10:09:42.743083: Epoch time: 275.14 s 
2025-04-09 10:09:44.607709:  
2025-04-09 10:09:44.607930: Epoch 878 
2025-04-09 10:09:44.608062: Current learning rate: 0.00151 
2025-04-09 10:14:20.433815: train_loss -0.8669 
2025-04-09 10:14:20.434467: val_loss -0.805 
2025-04-09 10:14:20.434595: Pseudo dice [0.8179] 
2025-04-09 10:14:20.434687: Epoch time: 275.83 s 
2025-04-09 10:14:22.295510:  
2025-04-09 10:14:22.295762: Epoch 879 
2025-04-09 10:14:22.295893: Current learning rate: 0.00149 
2025-04-09 10:18:56.880034: train_loss -0.8668 
2025-04-09 10:18:56.880374: val_loss -0.7858 
2025-04-09 10:18:56.880483: Pseudo dice [0.7939] 
2025-04-09 10:18:56.880578: Epoch time: 274.59 s 
2025-04-09 10:18:58.756799:  
2025-04-09 10:18:58.757049: Epoch 880 
2025-04-09 10:18:58.757198: Current learning rate: 0.00148 
2025-04-09 10:24:10.396537: train_loss -0.8675 
2025-04-09 10:24:10.398413: val_loss -0.7959 
2025-04-09 10:24:10.398520: Pseudo dice [0.8167] 
2025-04-09 10:24:10.398605: Epoch time: 311.64 s 
2025-04-09 10:24:12.288700:  
2025-04-09 10:24:12.288908: Epoch 881 
2025-04-09 10:24:12.289049: Current learning rate: 0.00147 
2025-04-09 10:28:46.363273: train_loss -0.8596 
2025-04-09 10:28:46.363656: val_loss -0.8038 
2025-04-09 10:28:46.363782: Pseudo dice [0.8045] 
2025-04-09 10:28:46.363866: Epoch time: 274.08 s 
2025-04-09 10:28:48.236361:  
2025-04-09 10:28:48.236580: Epoch 882 
2025-04-09 10:28:48.236744: Current learning rate: 0.00146 
2025-04-09 10:33:24.428235: train_loss -0.851 
2025-04-09 10:33:24.428819: val_loss -0.7658 
2025-04-09 10:33:24.428925: Pseudo dice [0.7792] 
2025-04-09 10:33:24.429009: Epoch time: 276.2 s 
2025-04-09 10:33:26.614622:  
2025-04-09 10:33:26.614880: Epoch 883 
2025-04-09 10:33:26.614995: Current learning rate: 0.00145 
2025-04-09 10:38:00.332684: train_loss -0.8591 
2025-04-09 10:38:00.332994: val_loss -0.7876 
2025-04-09 10:38:00.333074: Pseudo dice [0.8074] 
2025-04-09 10:38:00.333164: Epoch time: 273.72 s 
2025-04-09 10:38:02.234484:  
2025-04-09 10:38:02.234676: Epoch 884 
2025-04-09 10:38:02.234814: Current learning rate: 0.00144 
2025-04-09 10:42:35.865538: train_loss -0.86 
2025-04-09 10:42:35.865851: val_loss -0.7844 
2025-04-09 10:42:35.865934: Pseudo dice [0.7944] 
2025-04-09 10:42:35.866031: Epoch time: 273.63 s 
2025-04-09 10:42:37.740575:  
2025-04-09 10:42:37.740782: Epoch 885 
2025-04-09 10:42:37.740896: Current learning rate: 0.00143 
2025-04-09 10:47:11.726338: train_loss -0.8551 
2025-04-09 10:47:11.726886: val_loss -0.8089 
2025-04-09 10:47:11.727053: Pseudo dice [0.8076] 
2025-04-09 10:47:11.727157: Epoch time: 273.99 s 
2025-04-09 10:47:13.589342:  
2025-04-09 10:47:13.589537: Epoch 886 
2025-04-09 10:47:13.589649: Current learning rate: 0.00142 
2025-04-09 10:51:47.504999: train_loss -0.8685 
2025-04-09 10:51:47.505334: val_loss -0.7894 
2025-04-09 10:51:47.505436: Pseudo dice [0.8068] 
2025-04-09 10:51:47.505527: Epoch time: 273.92 s 
2025-04-09 10:51:49.371363:  
2025-04-09 10:51:49.371706: Epoch 887 
2025-04-09 10:51:49.371914: Current learning rate: 0.00141 
2025-04-09 10:56:23.543816: train_loss -0.8704 
2025-04-09 10:56:23.544437: val_loss -0.7779 
2025-04-09 10:56:23.544538: Pseudo dice [0.807] 
2025-04-09 10:56:23.544637: Epoch time: 274.18 s 
2025-04-09 10:56:25.427242:  
2025-04-09 10:56:25.427472: Epoch 888 
2025-04-09 10:56:25.427596: Current learning rate: 0.00139 
2025-04-09 11:00:59.159367: train_loss -0.8668 
2025-04-09 11:00:59.159764: val_loss -0.7979 
2025-04-09 11:00:59.159870: Pseudo dice [0.7926] 
2025-04-09 11:00:59.159952: Epoch time: 273.74 s 
2025-04-09 11:01:01.026846:  
2025-04-09 11:01:01.027107: Epoch 889 
2025-04-09 11:01:01.027243: Current learning rate: 0.00138 
2025-04-09 11:06:14.025434: train_loss -0.8655 
2025-04-09 11:06:14.026094: val_loss -0.7672 
2025-04-09 11:06:14.026202: Pseudo dice [0.7897] 
2025-04-09 11:06:14.026288: Epoch time: 313.0 s 
2025-04-09 11:06:15.899592:  
2025-04-09 11:06:15.899820: Epoch 890 
2025-04-09 11:06:15.899953: Current learning rate: 0.00137 
2025-04-09 11:10:50.533558: train_loss -0.8592 
2025-04-09 11:10:50.533856: val_loss -0.7691 
2025-04-09 11:10:50.533951: Pseudo dice [0.7874] 
2025-04-09 11:10:50.534038: Epoch time: 274.64 s 
2025-04-09 11:10:52.390186:  
2025-04-09 11:10:52.390402: Epoch 891 
2025-04-09 11:10:52.390530: Current learning rate: 0.00136 
2025-04-09 11:15:26.929884: train_loss -0.8691 
2025-04-09 11:15:26.930230: val_loss -0.7902 
2025-04-09 11:15:26.930323: Pseudo dice [0.8041] 
2025-04-09 11:15:26.930420: Epoch time: 274.54 s 
2025-04-09 11:15:29.104142:  
2025-04-09 11:15:29.104384: Epoch 892 
2025-04-09 11:15:29.104499: Current learning rate: 0.00135 
2025-04-09 11:20:03.444656: train_loss -0.8537 
2025-04-09 11:20:03.445015: val_loss -0.7861 
2025-04-09 11:20:03.445105: Pseudo dice [0.8086] 
2025-04-09 11:20:03.445203: Epoch time: 274.34 s 
2025-04-09 11:20:05.318448:  
2025-04-09 11:20:05.318895: Epoch 893 
2025-04-09 11:20:05.319083: Current learning rate: 0.00134 
2025-04-09 11:24:39.676553: train_loss -0.8584 
2025-04-09 11:24:39.677103: val_loss -0.7803 
2025-04-09 11:24:39.677205: Pseudo dice [0.7997] 
2025-04-09 11:24:39.677316: Epoch time: 274.36 s 
2025-04-09 11:24:41.539915:  
2025-04-09 11:24:41.540156: Epoch 894 
2025-04-09 11:24:41.540281: Current learning rate: 0.00133 
2025-04-09 11:29:15.776782: train_loss -0.8653 
2025-04-09 11:29:15.777100: val_loss -0.7939 
2025-04-09 11:29:15.777177: Pseudo dice [0.8063] 
2025-04-09 11:29:15.777258: Epoch time: 274.24 s 
2025-04-09 11:29:17.637377:  
2025-04-09 11:29:17.637643: Epoch 895 
2025-04-09 11:29:17.637778: Current learning rate: 0.00132 
2025-04-09 11:34:08.583615: train_loss -0.8608 
2025-04-09 11:34:08.584221: val_loss -0.8236 
2025-04-09 11:34:08.584615: Pseudo dice [0.8364] 
2025-04-09 11:34:08.584706: Epoch time: 290.95 s 
2025-04-09 11:34:10.478788:  
2025-04-09 11:34:10.479014: Epoch 896 
2025-04-09 11:34:10.479125: Current learning rate: 0.0013 
2025-04-09 11:38:44.699245: train_loss -0.8708 
2025-04-09 11:38:44.699567: val_loss -0.7746 
2025-04-09 11:38:44.699650: Pseudo dice [0.7989] 
2025-04-09 11:38:44.699737: Epoch time: 274.22 s 
2025-04-09 11:38:46.567209:  
2025-04-09 11:38:46.567445: Epoch 897 
2025-04-09 11:38:46.567598: Current learning rate: 0.00129 
2025-04-09 11:43:21.012491: train_loss -0.8722 
2025-04-09 11:43:21.012810: val_loss -0.7883 
2025-04-09 11:43:21.012936: Pseudo dice [0.8009] 
2025-04-09 11:43:21.013029: Epoch time: 274.45 s 
2025-04-09 11:43:22.876999:  
2025-04-09 11:43:22.877268: Epoch 898 
2025-04-09 11:43:22.877391: Current learning rate: 0.00128 
2025-04-09 11:47:57.304247: train_loss -0.8636 
2025-04-09 11:47:57.304583: val_loss -0.7766 
2025-04-09 11:47:57.304677: Pseudo dice [0.7947] 
2025-04-09 11:47:57.304777: Epoch time: 274.43 s 
2025-04-09 11:47:59.171568:  
2025-04-09 11:47:59.171854: Epoch 899 
2025-04-09 11:47:59.172005: Current learning rate: 0.00127 
2025-04-09 11:52:33.191368: train_loss -0.8694 
2025-04-09 11:52:33.191684: val_loss -0.7922 
2025-04-09 11:52:33.191785: Pseudo dice [0.799] 
2025-04-09 11:52:33.191891: Epoch time: 274.02 s 
2025-04-09 11:52:36.380158:  
2025-04-09 11:52:36.380441: Epoch 900 
2025-04-09 11:52:36.380569: Current learning rate: 0.00126 
2025-04-09 11:57:10.894280: train_loss -0.8575 
2025-04-09 11:57:10.894662: val_loss -0.7684 
2025-04-09 11:57:10.894780: Pseudo dice [0.7807] 
2025-04-09 11:57:10.894869: Epoch time: 274.52 s 
2025-04-09 11:57:13.070873:  
2025-04-09 11:57:13.071171: Epoch 901 
2025-04-09 11:57:13.071286: Current learning rate: 0.00125 
2025-04-09 12:01:47.396327: train_loss -0.8603 
2025-04-09 12:01:47.396731: val_loss -0.7844 
2025-04-09 12:01:47.396825: Pseudo dice [0.7808] 
2025-04-09 12:01:47.396907: Epoch time: 274.33 s 
2025-04-09 12:01:49.251013:  
2025-04-09 12:01:49.251289: Epoch 902 
2025-04-09 12:01:49.251412: Current learning rate: 0.00124 
2025-04-09 12:07:09.912071: train_loss -0.8613 
2025-04-09 12:07:09.912590: val_loss -0.7938 
2025-04-09 12:07:09.912678: Pseudo dice [0.8064] 
2025-04-09 12:07:09.912763: Epoch time: 320.67 s 
2025-04-09 12:07:11.790187:  
2025-04-09 12:07:11.790412: Epoch 903 
2025-04-09 12:07:11.790527: Current learning rate: 0.00122 
2025-04-09 12:11:46.094412: train_loss -0.8722 
2025-04-09 12:11:46.094779: val_loss -0.7758 
2025-04-09 12:11:46.094946: Pseudo dice [0.7816] 
2025-04-09 12:11:46.095108: Epoch time: 274.31 s 
2025-04-09 12:11:48.010752:  
2025-04-09 12:11:48.011019: Epoch 904 
2025-04-09 12:11:48.011133: Current learning rate: 0.00121 
2025-04-09 12:16:22.794052: train_loss -0.8614 
2025-04-09 12:16:22.794610: val_loss -0.8024 
2025-04-09 12:16:22.794710: Pseudo dice [0.8041] 
2025-04-09 12:16:22.794795: Epoch time: 274.79 s 
2025-04-09 12:16:24.705453:  
2025-04-09 12:16:24.705673: Epoch 905 
2025-04-09 12:16:24.705819: Current learning rate: 0.0012 
2025-04-09 12:20:59.064825: train_loss -0.8692 
2025-04-09 12:20:59.065162: val_loss -0.8092 
2025-04-09 12:20:59.065249: Pseudo dice [0.8215] 
2025-04-09 12:20:59.065342: Epoch time: 274.36 s 
2025-04-09 12:21:00.924985:  
2025-04-09 12:21:00.925202: Epoch 906 
2025-04-09 12:21:00.925318: Current learning rate: 0.00119 
2025-04-09 12:25:35.528343: train_loss -0.8684 
2025-04-09 12:25:35.528668: val_loss -0.7772 
2025-04-09 12:25:35.528755: Pseudo dice [0.7905] 
2025-04-09 12:25:35.528926: Epoch time: 274.61 s 
2025-04-09 12:25:37.409676:  
2025-04-09 12:25:37.409919: Epoch 907 
2025-04-09 12:25:37.410089: Current learning rate: 0.00118 
2025-04-09 12:30:11.915553: train_loss -0.8653 
2025-04-09 12:30:11.915912: val_loss -0.8016 
2025-04-09 12:30:11.916022: Pseudo dice [0.8005] 
2025-04-09 12:30:11.916200: Epoch time: 274.51 s 
2025-04-09 12:30:13.795008:  
2025-04-09 12:30:13.795220: Epoch 908 
2025-04-09 12:30:13.795344: Current learning rate: 0.00117 
2025-04-09 12:34:48.265491: train_loss -0.8646 
2025-04-09 12:34:48.266085: val_loss -0.814 
2025-04-09 12:34:48.266210: Pseudo dice [0.8085] 
2025-04-09 12:34:48.266339: Epoch time: 274.47 s 
2025-04-09 12:34:50.130994:  
2025-04-09 12:34:50.131217: Epoch 909 
2025-04-09 12:34:50.131361: Current learning rate: 0.00116 
2025-04-09 12:39:24.429276: train_loss -0.8686 
2025-04-09 12:39:24.429589: val_loss -0.7886 
2025-04-09 12:39:24.429714: Pseudo dice [0.8096] 
2025-04-09 12:39:24.429799: Epoch time: 274.3 s 
2025-04-09 12:39:26.612045:  
2025-04-09 12:39:26.612275: Epoch 910 
2025-04-09 12:39:26.612396: Current learning rate: 0.00115 
2025-04-09 12:44:00.808639: train_loss -0.8745 
2025-04-09 12:44:00.808955: val_loss -0.7985 
2025-04-09 12:44:00.809036: Pseudo dice [0.7983] 
2025-04-09 12:44:00.809136: Epoch time: 274.2 s 
2025-04-09 12:44:02.689144:  
2025-04-09 12:44:02.689335: Epoch 911 
2025-04-09 12:44:02.689476: Current learning rate: 0.00113 
2025-04-09 12:48:37.037752: train_loss -0.8534 
2025-04-09 12:48:37.038309: val_loss -0.7936 
2025-04-09 12:48:37.038462: Pseudo dice [0.7948] 
2025-04-09 12:48:37.038547: Epoch time: 274.35 s 
2025-04-09 12:48:38.907230:  
2025-04-09 12:48:38.907465: Epoch 912 
2025-04-09 12:48:38.907600: Current learning rate: 0.00112 
2025-04-09 12:53:12.555084: train_loss -0.8646 
2025-04-09 12:53:12.555394: val_loss -0.8036 
2025-04-09 12:53:12.555478: Pseudo dice [0.8027] 
2025-04-09 12:53:12.555577: Epoch time: 273.65 s 
2025-04-09 12:53:14.427438:  
2025-04-09 12:53:14.427648: Epoch 913 
2025-04-09 12:53:14.427808: Current learning rate: 0.00111 
2025-04-09 12:57:48.461573: train_loss -0.8688 
2025-04-09 12:57:48.461885: val_loss -0.8124 
2025-04-09 12:57:48.461966: Pseudo dice [0.8237] 
2025-04-09 12:57:48.462063: Epoch time: 274.04 s 
2025-04-09 12:57:50.317214:  
2025-04-09 12:57:50.317474: Epoch 914 
2025-04-09 12:57:50.317651: Current learning rate: 0.0011 
2025-04-09 13:02:24.112591: train_loss -0.8646 
2025-04-09 13:02:24.112929: val_loss -0.7868 
2025-04-09 13:02:24.113010: Pseudo dice [0.7738] 
2025-04-09 13:02:24.113107: Epoch time: 273.8 s 
2025-04-09 13:02:25.990555:  
2025-04-09 13:02:25.990791: Epoch 915 
2025-04-09 13:02:25.990965: Current learning rate: 0.00109 
2025-04-09 13:06:59.509057: train_loss -0.8636 
2025-04-09 13:06:59.509675: val_loss -0.7752 
2025-04-09 13:06:59.509792: Pseudo dice [0.7745] 
2025-04-09 13:06:59.509884: Epoch time: 273.52 s 
2025-04-09 13:07:01.372493:  
2025-04-09 13:07:01.372698: Epoch 916 
2025-04-09 13:07:01.372808: Current learning rate: 0.00108 
2025-04-09 13:11:34.839914: train_loss -0.8684 
2025-04-09 13:11:34.840231: val_loss -0.7911 
2025-04-09 13:11:34.840314: Pseudo dice [0.7862] 
2025-04-09 13:11:34.840415: Epoch time: 273.47 s 
2025-04-09 13:11:36.719419:  
2025-04-09 13:11:36.719631: Epoch 917 
2025-04-09 13:11:36.719746: Current learning rate: 0.00106 
2025-04-09 13:16:20.327081: train_loss -0.8521 
2025-04-09 13:16:20.327439: val_loss -0.7981 
2025-04-09 13:16:20.327535: Pseudo dice [0.8047] 
2025-04-09 13:16:20.327635: Epoch time: 283.61 s 
2025-04-09 13:16:22.855895:  
2025-04-09 13:16:22.856183: Epoch 918 
2025-04-09 13:16:22.856352: Current learning rate: 0.00105 
2025-04-09 13:20:59.521840: train_loss -0.8679 
2025-04-09 13:20:59.522405: val_loss -0.7882 
2025-04-09 13:20:59.522521: Pseudo dice [0.8023] 
2025-04-09 13:20:59.522607: Epoch time: 276.69 s 
2025-04-09 13:21:01.723553:  
2025-04-09 13:21:01.723746: Epoch 919 
2025-04-09 13:21:01.723894: Current learning rate: 0.00104 
2025-04-09 13:25:35.964996: train_loss -0.8507 
2025-04-09 13:25:35.965338: val_loss -0.7597 
2025-04-09 13:25:35.965464: Pseudo dice [0.7645] 
2025-04-09 13:25:35.965558: Epoch time: 274.25 s 
2025-04-09 13:25:37.821693:  
2025-04-09 13:25:37.821846: Epoch 920 
2025-04-09 13:25:37.822000: Current learning rate: 0.00103 
2025-04-09 13:30:12.108999: train_loss -0.8365 
2025-04-09 13:30:12.109533: val_loss -0.8083 
2025-04-09 13:30:12.109642: Pseudo dice [0.7998] 
2025-04-09 13:30:12.109785: Epoch time: 274.29 s 
2025-04-09 13:30:13.982063:  
2025-04-09 13:30:13.982261: Epoch 921 
2025-04-09 13:30:13.982377: Current learning rate: 0.00102 
2025-04-09 13:34:48.087738: train_loss -0.8606 
2025-04-09 13:34:48.088098: val_loss -0.7978 
2025-04-09 13:34:48.088201: Pseudo dice [0.7895] 
2025-04-09 13:34:48.088285: Epoch time: 274.11 s 
2025-04-09 13:34:49.986763:  
2025-04-09 13:34:49.986942: Epoch 922 
2025-04-09 13:34:49.987056: Current learning rate: 0.00101 
2025-04-09 13:39:24.040391: train_loss -0.8594 
2025-04-09 13:39:24.040713: val_loss -0.8081 
2025-04-09 13:39:24.040800: Pseudo dice [0.8079] 
2025-04-09 13:39:24.040901: Epoch time: 274.06 s 
2025-04-09 13:39:25.909780:  
2025-04-09 13:39:25.910024: Epoch 923 
2025-04-09 13:39:25.910146: Current learning rate: 0.001 
2025-04-09 13:43:59.639226: train_loss -0.8629 
2025-04-09 13:43:59.639536: val_loss -0.7451 
2025-04-09 13:43:59.639623: Pseudo dice [0.7847] 
2025-04-09 13:43:59.639724: Epoch time: 273.73 s 
2025-04-09 13:44:01.521824:  
2025-04-09 13:44:01.522000: Epoch 924 
2025-04-09 13:44:01.522119: Current learning rate: 0.00098 
2025-04-09 13:48:35.498926: train_loss -0.8686 
2025-04-09 13:48:35.499216: val_loss -0.8061 
2025-04-09 13:48:35.499311: Pseudo dice [0.819] 
2025-04-09 13:48:35.499400: Epoch time: 273.98 s 
2025-04-09 13:48:37.387829:  
2025-04-09 13:48:37.388056: Epoch 925 
2025-04-09 13:48:37.388164: Current learning rate: 0.00097 
2025-04-09 13:53:11.375534: train_loss -0.8719 
2025-04-09 13:53:11.375960: val_loss -0.801 
2025-04-09 13:53:11.376058: Pseudo dice [0.8021] 
2025-04-09 13:53:11.376143: Epoch time: 273.99 s 
2025-04-09 13:53:13.242650:  
2025-04-09 13:53:13.242819: Epoch 926 
2025-04-09 13:53:13.242951: Current learning rate: 0.00096 
2025-04-09 13:57:46.910619: train_loss -0.8704 
2025-04-09 13:57:46.910926: val_loss -0.779 
2025-04-09 13:57:46.911053: Pseudo dice [0.792] 
2025-04-09 13:57:46.911181: Epoch time: 273.67 s 
2025-04-09 13:57:49.070705:  
2025-04-09 13:57:49.070955: Epoch 927 
2025-04-09 13:57:49.071085: Current learning rate: 0.00095 
2025-04-09 14:02:22.642418: train_loss -0.8714 
2025-04-09 14:02:22.642728: val_loss -0.7927 
2025-04-09 14:02:22.642813: Pseudo dice [0.8162] 
2025-04-09 14:02:22.642904: Epoch time: 273.58 s 
2025-04-09 14:02:24.524237:  
2025-04-09 14:02:24.524485: Epoch 928 
2025-04-09 14:02:24.524648: Current learning rate: 0.00094 
2025-04-09 14:06:59.288455: train_loss -0.8734 
2025-04-09 14:06:59.288997: val_loss -0.8153 
2025-04-09 14:06:59.289099: Pseudo dice [0.8237] 
2025-04-09 14:06:59.289184: Epoch time: 274.77 s 
2025-04-09 14:07:01.156418:  
2025-04-09 14:07:01.156672: Epoch 929 
2025-04-09 14:07:01.156810: Current learning rate: 0.00092 
2025-04-09 14:11:36.033801: train_loss -0.8634 
2025-04-09 14:11:36.034126: val_loss -0.7893 
2025-04-09 14:11:36.034272: Pseudo dice [0.7933] 
2025-04-09 14:11:36.034364: Epoch time: 274.88 s 
2025-04-09 14:11:37.924219:  
2025-04-09 14:11:37.924464: Epoch 930 
2025-04-09 14:11:37.924624: Current learning rate: 0.00091 
2025-04-09 14:16:12.402086: train_loss -0.8718 
2025-04-09 14:16:12.402494: val_loss -0.813 
2025-04-09 14:16:12.402890: Pseudo dice [0.8015] 
2025-04-09 14:16:12.403022: Epoch time: 274.48 s 
2025-04-09 14:16:14.314951:  
2025-04-09 14:16:14.315164: Epoch 931 
2025-04-09 14:16:14.315276: Current learning rate: 0.0009 
2025-04-09 14:20:48.751922: train_loss -0.8587 
2025-04-09 14:20:48.752495: val_loss -0.7919 
2025-04-09 14:20:48.752594: Pseudo dice [0.8043] 
2025-04-09 14:20:48.752680: Epoch time: 274.44 s 
2025-04-09 14:20:50.616446:  
2025-04-09 14:20:50.616706: Epoch 932 
2025-04-09 14:20:50.616887: Current learning rate: 0.00089 
2025-04-09 14:25:56.431473: train_loss -0.8658 
2025-04-09 14:25:56.431829: val_loss -0.7911 
2025-04-09 14:25:56.431977: Pseudo dice [0.8171] 
2025-04-09 14:25:56.432061: Epoch time: 305.82 s 
2025-04-09 14:25:58.728324:  
2025-04-09 14:25:58.728532: Epoch 933 
2025-04-09 14:25:58.728669: Current learning rate: 0.00088 
2025-04-09 14:31:26.192633: train_loss -0.8705 
2025-04-09 14:31:26.193246: val_loss -0.7953 
2025-04-09 14:31:26.193355: Pseudo dice [0.7951] 
2025-04-09 14:31:26.193440: Epoch time: 327.47 s 
2025-04-09 14:31:28.069410:  
2025-04-09 14:31:28.069883: Epoch 934 
2025-04-09 14:31:28.070219: Current learning rate: 0.00087 
2025-04-09 14:36:01.925251: train_loss -0.8744 
2025-04-09 14:36:01.925564: val_loss -0.7907 
2025-04-09 14:36:01.925686: Pseudo dice [0.7987] 
2025-04-09 14:36:01.925790: Epoch time: 273.86 s 
2025-04-09 14:36:03.787430:  
2025-04-09 14:36:03.787707: Epoch 935 
2025-04-09 14:36:03.787881: Current learning rate: 0.00085 
2025-04-09 14:40:48.656870: train_loss -0.8729 
2025-04-09 14:40:48.657407: val_loss -0.7895 
2025-04-09 14:40:48.657509: Pseudo dice [0.7957] 
2025-04-09 14:40:48.657594: Epoch time: 284.87 s 
2025-04-09 14:40:50.830624:  
2025-04-09 14:40:50.830862: Epoch 936 
2025-04-09 14:40:50.830989: Current learning rate: 0.00084 
2025-04-09 14:45:25.316221: train_loss -0.8628 
2025-04-09 14:45:25.316566: val_loss -0.7864 
2025-04-09 14:45:25.316664: Pseudo dice [0.7908] 
2025-04-09 14:45:25.316763: Epoch time: 274.49 s 
2025-04-09 14:45:27.184325:  
2025-04-09 14:45:27.184549: Epoch 937 
2025-04-09 14:45:27.184732: Current learning rate: 0.00083 
2025-04-09 14:50:06.119077: train_loss -0.8721 
2025-04-09 14:50:06.119395: val_loss -0.8 
2025-04-09 14:50:06.119474: Pseudo dice [0.8109] 
2025-04-09 14:50:06.119570: Epoch time: 278.94 s 
2025-04-09 14:50:08.007339:  
2025-04-09 14:50:08.007592: Epoch 938 
2025-04-09 14:50:08.007731: Current learning rate: 0.00082 
2025-04-09 14:54:42.055925: train_loss -0.8746 
2025-04-09 14:54:42.056253: val_loss -0.7969 
2025-04-09 14:54:42.056336: Pseudo dice [0.8064] 
2025-04-09 14:54:42.056422: Epoch time: 274.05 s 
2025-04-09 14:54:43.919109:  
2025-04-09 14:54:43.919324: Epoch 939 
2025-04-09 14:54:43.919513: Current learning rate: 0.00081 
2025-04-09 14:59:22.368373: train_loss -0.8738 
2025-04-09 14:59:22.369048: val_loss -0.7961 
2025-04-09 14:59:22.369152: Pseudo dice [0.7885] 
2025-04-09 14:59:22.369240: Epoch time: 278.45 s 
2025-04-09 14:59:24.233224:  
2025-04-09 14:59:24.233430: Epoch 940 
2025-04-09 14:59:24.233543: Current learning rate: 0.00079 
2025-04-09 15:03:58.696553: train_loss -0.8701 
2025-04-09 15:03:58.696878: val_loss -0.8035 
2025-04-09 15:03:58.696967: Pseudo dice [0.8075] 
2025-04-09 15:03:58.697069: Epoch time: 274.47 s 
2025-04-09 15:04:00.566000:  
2025-04-09 15:04:00.566249: Epoch 941 
2025-04-09 15:04:00.566363: Current learning rate: 0.00078 
2025-04-09 15:08:38.143442: train_loss -0.8641 
2025-04-09 15:08:38.144005: val_loss -0.7707 
2025-04-09 15:08:38.144106: Pseudo dice [0.782] 
2025-04-09 15:08:38.144188: Epoch time: 277.58 s 
2025-04-09 15:08:40.008892:  
2025-04-09 15:08:40.009081: Epoch 942 
2025-04-09 15:08:40.009240: Current learning rate: 0.00077 
2025-04-09 15:13:14.661708: train_loss -0.8708 
2025-04-09 15:13:14.662038: val_loss -0.8177 
2025-04-09 15:13:14.662163: Pseudo dice [0.8164] 
2025-04-09 15:13:14.662268: Epoch time: 274.66 s 
2025-04-09 15:13:16.531102:  
2025-04-09 15:13:16.531294: Epoch 943 
2025-04-09 15:13:16.531409: Current learning rate: 0.00076 
2025-04-09 15:17:51.130687: train_loss -0.8743 
2025-04-09 15:17:51.131004: val_loss -0.7667 
2025-04-09 15:17:51.131088: Pseudo dice [0.7806] 
2025-04-09 15:17:51.131182: Epoch time: 274.6 s 
2025-04-09 15:17:52.986809:  
2025-04-09 15:17:52.987047: Epoch 944 
2025-04-09 15:17:52.987173: Current learning rate: 0.00075 
2025-04-09 15:22:28.739614: train_loss -0.8732 
2025-04-09 15:22:28.740216: val_loss -0.8012 
2025-04-09 15:22:28.740334: Pseudo dice [0.8241] 
2025-04-09 15:22:28.740423: Epoch time: 275.76 s 
2025-04-09 15:22:30.917357:  
2025-04-09 15:22:30.917507: Epoch 945 
2025-04-09 15:22:30.917627: Current learning rate: 0.00074 
2025-04-09 15:27:05.668243: train_loss -0.8708 
2025-04-09 15:27:05.668571: val_loss -0.7942 
2025-04-09 15:27:05.668664: Pseudo dice [0.8169] 
2025-04-09 15:27:05.668840: Epoch time: 274.75 s 
2025-04-09 15:27:07.531768:  
2025-04-09 15:27:07.532018: Epoch 946 
2025-04-09 15:27:07.532149: Current learning rate: 0.00072 
2025-04-09 15:31:43.536770: train_loss -0.8706 
2025-04-09 15:31:43.537253: val_loss -0.8002 
2025-04-09 15:31:43.537350: Pseudo dice [0.8018] 
2025-04-09 15:31:43.537431: Epoch time: 276.01 s 
2025-04-09 15:31:45.406865:  
2025-04-09 15:31:45.407093: Epoch 947 
2025-04-09 15:31:45.407209: Current learning rate: 0.00071 
2025-04-09 15:36:20.078363: train_loss -0.8764 
2025-04-09 15:36:20.078769: val_loss -0.7868 
2025-04-09 15:36:20.078919: Pseudo dice [0.7954] 
2025-04-09 15:36:20.079003: Epoch time: 274.68 s 
2025-04-09 15:36:21.936521:  
2025-04-09 15:36:21.936716: Epoch 948 
2025-04-09 15:36:21.936893: Current learning rate: 0.0007 
2025-04-09 15:42:16.855435: train_loss -0.8699 
2025-04-09 15:42:16.856054: val_loss -0.8166 
2025-04-09 15:42:16.856154: Pseudo dice [0.8205] 
2025-04-09 15:42:16.856239: Epoch time: 354.92 s 
2025-04-09 15:42:18.727499:  
2025-04-09 15:42:18.727705: Epoch 949 
2025-04-09 15:42:18.727842: Current learning rate: 0.00069 
2025-04-09 15:46:53.913488: train_loss -0.8665 
2025-04-09 15:46:53.913862: val_loss -0.8024 
2025-04-09 15:46:53.913948: Pseudo dice [0.8108] 
2025-04-09 15:46:53.914042: Epoch time: 275.19 s 
2025-04-09 15:46:57.097167:  
2025-04-09 15:46:57.097448: Epoch 950 
2025-04-09 15:46:57.097562: Current learning rate: 0.00067 
2025-04-09 15:52:13.371563: train_loss -0.8688 
2025-04-09 15:52:13.372115: val_loss -0.7952 
2025-04-09 15:52:13.372218: Pseudo dice [0.8091] 
2025-04-09 15:52:13.372391: Epoch time: 316.28 s 
2025-04-09 15:52:15.246922:  
2025-04-09 15:52:15.247122: Epoch 951 
2025-04-09 15:52:15.247237: Current learning rate: 0.00066 
2025-04-09 15:56:50.109259: train_loss -0.8818 
2025-04-09 15:56:50.109622: val_loss -0.7532 
2025-04-09 15:56:50.109787: Pseudo dice [0.7923] 
2025-04-09 15:56:50.109883: Epoch time: 274.87 s 
2025-04-09 15:56:51.987478:  
2025-04-09 15:56:51.987770: Epoch 952 
2025-04-09 15:56:51.987911: Current learning rate: 0.00065 
2025-04-09 16:01:48.162329: train_loss -0.8705 
2025-04-09 16:01:48.162892: val_loss -0.7582 
2025-04-09 16:01:48.162998: Pseudo dice [0.7926] 
2025-04-09 16:01:48.163080: Epoch time: 296.18 s 
2025-04-09 16:01:50.049957:  
2025-04-09 16:01:50.050213: Epoch 953 
2025-04-09 16:01:50.050344: Current learning rate: 0.00064 
2025-04-09 16:06:24.762343: train_loss -0.8709 
2025-04-09 16:06:24.762663: val_loss -0.7942 
2025-04-09 16:06:24.762753: Pseudo dice [0.7986] 
2025-04-09 16:06:24.762843: Epoch time: 274.72 s 
2025-04-09 16:06:26.960611:  
2025-04-09 16:06:26.960847: Epoch 954 
2025-04-09 16:06:26.960971: Current learning rate: 0.00063 
2025-04-09 16:11:02.347915: train_loss -0.8702 
2025-04-09 16:11:02.348496: val_loss -0.7764 
2025-04-09 16:11:02.348607: Pseudo dice [0.8044] 
2025-04-09 16:11:02.348691: Epoch time: 275.39 s 
2025-04-09 16:11:04.238500:  
2025-04-09 16:11:04.238771: Epoch 955 
2025-04-09 16:11:04.238882: Current learning rate: 0.00061 
2025-04-09 16:15:38.647761: train_loss -0.8704 
2025-04-09 16:15:38.648165: val_loss -0.8028 
2025-04-09 16:15:38.648269: Pseudo dice [0.809] 
2025-04-09 16:15:38.648353: Epoch time: 274.41 s 
2025-04-09 16:15:40.545882:  
2025-04-09 16:15:40.546082: Epoch 956 
2025-04-09 16:15:40.546199: Current learning rate: 0.0006 
2025-04-09 16:20:25.687315: train_loss -0.8704 
2025-04-09 16:20:25.688090: val_loss -0.7772 
2025-04-09 16:20:25.688552: Pseudo dice [0.7997] 
2025-04-09 16:20:25.688814: Epoch time: 285.15 s 
2025-04-09 16:20:27.742912:  
2025-04-09 16:20:27.743220: Epoch 957 
2025-04-09 16:20:27.743367: Current learning rate: 0.00059 
2025-04-09 16:25:10.420496: train_loss -0.8637 
2025-04-09 16:25:10.421139: val_loss -0.7771 
2025-04-09 16:25:10.421259: Pseudo dice [0.7767] 
2025-04-09 16:25:10.421343: Epoch time: 282.68 s 
2025-04-09 16:25:12.313453:  
2025-04-09 16:25:12.313671: Epoch 958 
2025-04-09 16:25:12.313785: Current learning rate: 0.00058 
2025-04-09 16:29:47.153953: train_loss -0.8708 
2025-04-09 16:29:47.154271: val_loss -0.7732 
2025-04-09 16:29:47.154355: Pseudo dice [0.8048] 
2025-04-09 16:29:47.154462: Epoch time: 274.84 s 
2025-04-09 16:29:49.060552:  
2025-04-09 16:29:49.060748: Epoch 959 
2025-04-09 16:29:49.060925: Current learning rate: 0.00056 
2025-04-09 16:34:23.873005: train_loss -0.8739 
2025-04-09 16:34:23.873577: val_loss -0.7967 
2025-04-09 16:34:23.873680: Pseudo dice [0.8135] 
2025-04-09 16:34:23.873763: Epoch time: 274.82 s 
2025-04-09 16:34:25.754181:  
2025-04-09 16:34:25.754399: Epoch 960 
2025-04-09 16:34:25.754519: Current learning rate: 0.00055 
2025-04-09 16:39:00.006147: train_loss -0.8707 
2025-04-09 16:39:00.006505: val_loss -0.7838 
2025-04-09 16:39:00.006594: Pseudo dice [0.7895] 
2025-04-09 16:39:00.006714: Epoch time: 274.26 s 
2025-04-09 16:39:01.912774:  
2025-04-09 16:39:01.913116: Epoch 961 
2025-04-09 16:39:01.913284: Current learning rate: 0.00054 
2025-04-09 16:43:52.133626: train_loss -0.87 
2025-04-09 16:43:52.134897: val_loss -0.7706 
2025-04-09 16:43:52.135000: Pseudo dice [0.7956] 
2025-04-09 16:43:52.135081: Epoch time: 290.23 s 
2025-04-09 16:43:54.323346:  
2025-04-09 16:43:54.323563: Epoch 962 
2025-04-09 16:43:54.323675: Current learning rate: 0.00053 
2025-04-09 16:48:28.681143: train_loss -0.8684 
2025-04-09 16:48:28.681512: val_loss -0.7575 
2025-04-09 16:48:28.681615: Pseudo dice [0.7811] 
2025-04-09 16:48:28.681775: Epoch time: 274.36 s 
2025-04-09 16:48:30.566566:  
2025-04-09 16:48:30.566747: Epoch 963 
2025-04-09 16:48:30.566865: Current learning rate: 0.00051 
2025-04-09 16:53:35.779618: train_loss -0.875 
2025-04-09 16:53:35.780169: val_loss -0.7809 
2025-04-09 16:53:35.780305: Pseudo dice [0.7466] 
2025-04-09 16:53:35.780399: Epoch time: 305.22 s 
2025-04-09 16:53:37.675072:  
2025-04-09 16:53:37.675379: Epoch 964 
2025-04-09 16:53:37.675496: Current learning rate: 0.0005 
2025-04-09 16:58:12.347849: train_loss -0.8661 
2025-04-09 16:58:12.348190: val_loss -0.8024 
2025-04-09 16:58:12.348269: Pseudo dice [0.8042] 
2025-04-09 16:58:12.348353: Epoch time: 274.68 s 
2025-04-09 16:58:14.243228:  
2025-04-09 16:58:14.243428: Epoch 965 
2025-04-09 16:58:14.243554: Current learning rate: 0.00049 
2025-04-09 17:02:48.537109: train_loss -0.869 
2025-04-09 17:02:48.537450: val_loss -0.7681 
2025-04-09 17:02:48.537554: Pseudo dice [0.7868] 
2025-04-09 17:02:48.537662: Epoch time: 274.3 s 
2025-04-09 17:02:50.427249:  
2025-04-09 17:02:50.427444: Epoch 966 
2025-04-09 17:02:50.427597: Current learning rate: 0.00048 
2025-04-09 17:07:24.376936: train_loss -0.8672 
2025-04-09 17:07:24.377283: val_loss -0.756 
2025-04-09 17:07:24.377370: Pseudo dice [0.7903] 
2025-04-09 17:07:24.377472: Epoch time: 273.95 s 
2025-04-09 17:07:26.281727:  
2025-04-09 17:07:26.281981: Epoch 967 
2025-04-09 17:07:26.282120: Current learning rate: 0.00046 
2025-04-09 17:12:00.180570: train_loss -0.8717 
2025-04-09 17:12:00.181144: val_loss -0.7895 
2025-04-09 17:12:00.181242: Pseudo dice [0.8121] 
2025-04-09 17:12:00.181329: Epoch time: 273.9 s 
2025-04-09 17:12:02.087631:  
2025-04-09 17:12:02.087839: Epoch 968 
2025-04-09 17:12:02.087996: Current learning rate: 0.00045 
2025-04-09 17:16:35.966648: train_loss -0.868 
2025-04-09 17:16:35.967103: val_loss -0.7955 
2025-04-09 17:16:35.967212: Pseudo dice [0.8033] 
2025-04-09 17:16:35.967296: Epoch time: 273.88 s 
2025-04-09 17:16:37.867460:  
2025-04-09 17:16:37.867623: Epoch 969 
2025-04-09 17:16:37.867791: Current learning rate: 0.00044 
2025-04-09 17:21:11.633881: train_loss -0.8772 
2025-04-09 17:21:11.634203: val_loss -0.789 
2025-04-09 17:21:11.634301: Pseudo dice [0.8] 
2025-04-09 17:21:11.634424: Epoch time: 273.77 s 
2025-04-09 17:21:13.525294:  
2025-04-09 17:21:13.525486: Epoch 970 
2025-04-09 17:21:13.525600: Current learning rate: 0.00043 
2025-04-09 17:25:47.263282: train_loss -0.8719 
2025-04-09 17:25:47.263649: val_loss -0.8054 
2025-04-09 17:25:47.263742: Pseudo dice [0.807] 
2025-04-09 17:25:47.263880: Epoch time: 273.74 s 
2025-04-09 17:25:49.477377:  
2025-04-09 17:25:49.477727: Epoch 971 
2025-04-09 17:25:49.477863: Current learning rate: 0.00041 
2025-04-09 17:30:23.510204: train_loss -0.865 
2025-04-09 17:30:23.510535: val_loss -0.7652 
2025-04-09 17:30:23.510622: Pseudo dice [0.7927] 
2025-04-09 17:30:23.510723: Epoch time: 274.04 s 
2025-04-09 17:30:25.430279:  
2025-04-09 17:30:25.430476: Epoch 972 
2025-04-09 17:30:25.430627: Current learning rate: 0.0004 
2025-04-09 17:34:59.379633: train_loss -0.8679 
2025-04-09 17:34:59.379934: val_loss -0.7852 
2025-04-09 17:34:59.380020: Pseudo dice [0.7956] 
2025-04-09 17:34:59.380113: Epoch time: 273.95 s 
2025-04-09 17:35:01.287031:  
2025-04-09 17:35:01.287194: Epoch 973 
2025-04-09 17:35:01.287314: Current learning rate: 0.00039 
2025-04-09 17:39:35.593326: train_loss -0.8771 
2025-04-09 17:39:35.593677: val_loss -0.8076 
2025-04-09 17:39:35.593757: Pseudo dice [0.8055] 
2025-04-09 17:39:35.593839: Epoch time: 274.31 s 
2025-04-09 17:39:37.501302:  
2025-04-09 17:39:37.501508: Epoch 974 
2025-04-09 17:39:37.501626: Current learning rate: 0.00037 
2025-04-09 17:44:12.122703: train_loss -0.8759 
2025-04-09 17:44:12.123302: val_loss -0.7929 
2025-04-09 17:44:12.123410: Pseudo dice [0.7976] 
2025-04-09 17:44:12.123504: Epoch time: 274.63 s 
2025-04-09 17:44:14.066877:  
2025-04-09 17:44:14.067096: Epoch 975 
2025-04-09 17:44:14.067208: Current learning rate: 0.00036 
2025-04-09 17:48:48.418238: train_loss -0.8733 
2025-04-09 17:48:48.418562: val_loss -0.8041 
2025-04-09 17:48:48.418649: Pseudo dice [0.8072] 
2025-04-09 17:48:48.418752: Epoch time: 274.36 s 
2025-04-09 17:48:50.310630:  
2025-04-09 17:48:50.310853: Epoch 976 
2025-04-09 17:48:50.310997: Current learning rate: 0.00035 
2025-04-09 17:53:24.794540: train_loss -0.8781 
2025-04-09 17:53:24.794845: val_loss -0.7886 
2025-04-09 17:53:24.794942: Pseudo dice [0.7985] 
2025-04-09 17:53:24.795034: Epoch time: 274.49 s 
2025-04-09 17:53:26.677376:  
2025-04-09 17:53:26.677567: Epoch 977 
2025-04-09 17:53:26.677712: Current learning rate: 0.00034 
2025-04-09 17:58:01.182389: train_loss -0.8778 
2025-04-09 17:58:01.182703: val_loss -0.8044 
2025-04-09 17:58:01.182849: Pseudo dice [0.8043] 
2025-04-09 17:58:01.182951: Epoch time: 274.51 s 
2025-04-09 17:58:03.074919:  
2025-04-09 17:58:03.075080: Epoch 978 
2025-04-09 17:58:03.075195: Current learning rate: 0.00032 
2025-04-09 18:02:47.345935: train_loss -0.8798 
2025-04-09 18:02:47.346349: val_loss -0.8049 
2025-04-09 18:02:47.346498: Pseudo dice [0.8176] 
2025-04-09 18:02:47.346588: Epoch time: 284.28 s 
2025-04-09 18:02:50.018646:  
2025-04-09 18:02:50.019134: Epoch 979 
2025-04-09 18:02:50.019387: Current learning rate: 0.00031 
2025-04-09 18:07:38.213771: train_loss -0.8673 
2025-04-09 18:07:38.214088: val_loss -0.7718 
2025-04-09 18:07:38.214173: Pseudo dice [0.795] 
2025-04-09 18:07:38.214272: Epoch time: 288.21 s 
2025-04-09 18:07:40.416214:  
2025-04-09 18:07:40.416424: Epoch 980 
2025-04-09 18:07:40.416592: Current learning rate: 0.0003 
2025-04-09 18:12:14.208739: train_loss -0.8802 
2025-04-09 18:12:14.209337: val_loss -0.7898 
2025-04-09 18:12:14.209435: Pseudo dice [0.8017] 
2025-04-09 18:12:14.209519: Epoch time: 273.8 s 
2025-04-09 18:12:16.110857:  
2025-04-09 18:12:16.111053: Epoch 981 
2025-04-09 18:12:16.111165: Current learning rate: 0.00028 
2025-04-09 18:16:50.283566: train_loss -0.8737 
2025-04-09 18:16:50.283995: val_loss -0.8297 
2025-04-09 18:16:50.284112: Pseudo dice [0.8354] 
2025-04-09 18:16:50.284197: Epoch time: 274.18 s 
2025-04-09 18:16:52.209058:  
2025-04-09 18:16:52.209265: Epoch 982 
2025-04-09 18:16:52.209396: Current learning rate: 0.00027 
2025-04-09 18:21:25.985810: train_loss -0.876 
2025-04-09 18:21:25.986112: val_loss -0.7918 
2025-04-09 18:21:25.986200: Pseudo dice [0.7963] 
2025-04-09 18:21:25.986312: Epoch time: 273.78 s 
2025-04-09 18:21:27.904023:  
2025-04-09 18:21:27.904283: Epoch 983 
2025-04-09 18:21:27.904398: Current learning rate: 0.00026 
2025-04-09 18:26:01.838556: train_loss -0.8806 
2025-04-09 18:26:01.839145: val_loss -0.799 
2025-04-09 18:26:01.839607: Pseudo dice [0.8117] 
2025-04-09 18:26:01.839698: Epoch time: 273.94 s 
2025-04-09 18:26:03.777796:  
2025-04-09 18:26:03.778034: Epoch 984 
2025-04-09 18:26:03.778146: Current learning rate: 0.00024 
2025-04-09 18:30:37.426346: train_loss -0.8776 
2025-04-09 18:30:37.426687: val_loss -0.8166 
2025-04-09 18:30:37.426772: Pseudo dice [0.8238] 
2025-04-09 18:30:37.426877: Epoch time: 273.65 s 
2025-04-09 18:30:39.422770:  
2025-04-09 18:30:39.422980: Epoch 985 
2025-04-09 18:30:39.423096: Current learning rate: 0.00023 
2025-04-09 18:35:39.229234: train_loss -0.8754 
2025-04-09 18:35:39.229762: val_loss -0.8071 
2025-04-09 18:35:39.229864: Pseudo dice [0.8127] 
2025-04-09 18:35:39.229980: Epoch time: 299.81 s 
2025-04-09 18:35:41.132412:  
2025-04-09 18:35:41.132626: Epoch 986 
2025-04-09 18:35:41.132740: Current learning rate: 0.00021 
2025-04-09 18:40:14.838913: train_loss -0.8813 
2025-04-09 18:40:14.839333: val_loss -0.8108 
2025-04-09 18:40:14.839456: Pseudo dice [0.8208] 
2025-04-09 18:40:14.839556: Epoch time: 273.71 s 
2025-04-09 18:40:14.839651: Yayy! New best EMA pseudo Dice: 0.8081 
2025-04-09 18:40:18.045027:  
2025-04-09 18:40:18.045234: Epoch 987 
2025-04-09 18:40:18.045389: Current learning rate: 0.0002 
2025-04-09 18:44:52.711549: train_loss -0.8755 
2025-04-09 18:44:52.712106: val_loss -0.8143 
2025-04-09 18:44:52.712297: Pseudo dice [0.8095] 
2025-04-09 18:44:52.712424: Epoch time: 274.67 s 
2025-04-09 18:44:52.712501: Yayy! New best EMA pseudo Dice: 0.8083 
2025-04-09 18:44:56.284736:  
2025-04-09 18:44:56.284979: Epoch 988 
2025-04-09 18:44:56.285108: Current learning rate: 0.00019 
2025-04-09 18:49:30.512209: train_loss -0.8708 
2025-04-09 18:49:30.512554: val_loss -0.8007 
2025-04-09 18:49:30.512644: Pseudo dice [0.8067] 
2025-04-09 18:49:30.512744: Epoch time: 274.23 s 
2025-04-09 18:49:32.415520:  
2025-04-09 18:49:32.415762: Epoch 989 
2025-04-09 18:49:32.415919: Current learning rate: 0.00017 
2025-04-09 18:54:06.814831: train_loss -0.8707 
2025-04-09 18:54:06.815131: val_loss -0.7888 
2025-04-09 18:54:06.815215: Pseudo dice [0.8074] 
2025-04-09 18:54:06.815354: Epoch time: 274.4 s 
2025-04-09 18:54:08.709181:  
2025-04-09 18:54:08.709385: Epoch 990 
2025-04-09 18:54:08.709531: Current learning rate: 0.00016 
2025-04-09 18:58:42.933018: train_loss -0.8708 
2025-04-09 18:58:42.933606: val_loss -0.789 
2025-04-09 18:58:42.933707: Pseudo dice [0.8121] 
2025-04-09 18:58:42.933787: Epoch time: 274.23 s 
2025-04-09 18:58:42.933846: Yayy! New best EMA pseudo Dice: 0.8084 
2025-04-09 18:58:46.228758:  
2025-04-09 18:58:46.228987: Epoch 991 
2025-04-09 18:58:46.229100: Current learning rate: 0.00014 
2025-04-09 19:03:20.356704: train_loss -0.877 
2025-04-09 19:03:20.357023: val_loss -0.8047 
2025-04-09 19:03:20.357105: Pseudo dice [0.804] 
2025-04-09 19:03:20.357209: Epoch time: 274.13 s 
2025-04-09 19:03:22.262708:  
2025-04-09 19:03:22.262965: Epoch 992 
2025-04-09 19:03:22.263076: Current learning rate: 0.00013 
2025-04-09 19:07:56.566067: train_loss -0.877 
2025-04-09 19:07:56.566383: val_loss -0.7782 
2025-04-09 19:07:56.566465: Pseudo dice [0.7928] 
2025-04-09 19:07:56.566552: Epoch time: 274.31 s 
2025-04-09 19:07:58.477753:  
2025-04-09 19:07:58.478020: Epoch 993 
2025-04-09 19:07:58.478203: Current learning rate: 0.00011 
2025-04-09 19:12:32.729231: train_loss -0.8722 
2025-04-09 19:12:32.729575: val_loss -0.8161 
2025-04-09 19:12:32.729690: Pseudo dice [0.8135] 
2025-04-09 19:12:32.729839: Epoch time: 274.26 s 
2025-04-09 19:12:34.645251:  
2025-04-09 19:12:34.645473: Epoch 994 
2025-04-09 19:12:34.645589: Current learning rate: 0.0001 
2025-04-09 19:17:09.034331: train_loss -0.8755 
2025-04-09 19:17:09.034617: val_loss -0.7848 
2025-04-09 19:17:09.034730: Pseudo dice [0.7919] 
2025-04-09 19:17:09.034816: Epoch time: 274.39 s 
2025-04-09 19:17:10.920469:  
2025-04-09 19:17:10.920713: Epoch 995 
2025-04-09 19:17:10.920830: Current learning rate: 8e-05 
2025-04-09 19:21:45.623394: train_loss -0.8695 
2025-04-09 19:21:45.623689: val_loss -0.7688 
2025-04-09 19:21:45.623777: Pseudo dice [0.7935] 
2025-04-09 19:21:45.623866: Epoch time: 274.71 s 
2025-04-09 19:21:47.823365:  
2025-04-09 19:21:47.823625: Epoch 996 
2025-04-09 19:21:47.823784: Current learning rate: 7e-05 
2025-04-09 19:26:21.987151: train_loss -0.8762 
2025-04-09 19:26:21.987496: val_loss -0.8022 
2025-04-09 19:26:21.987588: Pseudo dice [0.8111] 
2025-04-09 19:26:21.987685: Epoch time: 274.17 s 
2025-04-09 19:26:23.928615:  
2025-04-09 19:26:23.928813: Epoch 997 
2025-04-09 19:26:23.928944: Current learning rate: 5e-05 
2025-04-09 19:30:58.311983: train_loss -0.8726 
2025-04-09 19:30:58.312306: val_loss -0.8083 
2025-04-09 19:30:58.312392: Pseudo dice [0.8044] 
2025-04-09 19:30:58.312478: Epoch time: 274.39 s 
2025-04-09 19:31:00.212305:  
2025-04-09 19:31:00.212611: Epoch 998 
2025-04-09 19:31:00.212791: Current learning rate: 4e-05 
2025-04-09 19:35:34.670059: train_loss -0.874 
2025-04-09 19:35:34.670439: val_loss -0.8023 
2025-04-09 19:35:34.670544: Pseudo dice [0.8091] 
2025-04-09 19:35:34.670627: Epoch time: 274.46 s 
2025-04-09 19:35:36.577684:  
2025-04-09 19:35:36.577915: Epoch 999 
2025-04-09 19:35:36.578029: Current learning rate: 2e-05 
2025-04-09 19:40:10.874625: train_loss -0.8715 
2025-04-09 19:40:10.875165: val_loss -0.7828 
2025-04-09 19:40:10.875271: Pseudo dice [0.7913] 
2025-04-09 19:40:10.875355: Epoch time: 274.3 s 
2025-04-09 19:40:13.965593: Training done. 
2025-04-09 19:40:14.008069: Using splits from existing split file: /mrhung_nguyen_minh_quang_108/workspace/train/nnUNet_preprocessed/Dataset015_lungTumor/splits_final.json 
2025-04-09 19:40:14.010813: The split file contains 5 splits. 
2025-04-09 19:40:14.010895: Desired fold for training: 4 
2025-04-09 19:40:14.010940: This split has 92 training and 23 validation cases. 
2025-04-09 19:40:14.011137: predicting lung_003 
2025-04-09 19:40:15.047430: lung_003, shape torch.Size([1, 288, 614, 614]), rank 0 
2025-04-09 19:46:31.116125: predicting lung_013 
2025-04-09 19:46:31.559025: lung_013, shape torch.Size([1, 241, 438, 438]), rank 0 
2025-04-09 19:49:03.850218: predicting lung_016 
2025-04-09 19:49:04.600962: lung_016, shape torch.Size([1, 277, 538, 538]), rank 0 
2025-04-09 19:52:52.491724: predicting lung_017 
2025-04-09 19:52:52.973397: lung_017, shape torch.Size([1, 228, 509, 509]), rank 0 
2025-04-09 19:56:02.789509: predicting lung_020 
2025-04-09 19:56:03.049117: lung_020, shape torch.Size([1, 258, 430, 430]), rank 0 
2025-04-09 19:58:35.125876: predicting lung_040 
2025-04-09 19:58:36.054042: lung_040, shape torch.Size([1, 316, 584, 584]), rank 0 
2025-04-09 20:04:48.538944: predicting lung_045 
2025-04-09 20:04:49.430920: lung_045, shape torch.Size([1, 282, 563, 563]), rank 0 
2025-04-09 20:09:59.878129: predicting lung_047 
2025-04-09 20:10:00.617153: lung_047, shape torch.Size([1, 226, 512, 512]), rank 0 
2025-04-09 20:13:10.545529: predicting lung_049 
2025-04-09 20:13:11.315234: lung_049, shape torch.Size([1, 258, 534, 534]), rank 0 
2025-04-09 20:16:59.493193: predicting lung_053 
2025-04-09 20:16:59.781031: lung_053, shape torch.Size([1, 238, 407, 407]), rank 0 
2025-04-09 20:19:06.436429: predicting lung_056 
2025-04-09 20:19:07.088001: lung_056, shape torch.Size([1, 242, 538, 538]), rank 0 
2025-04-09 20:22:55.092526: predicting lung_079 
2025-04-09 20:22:55.345567: lung_079, shape torch.Size([1, 230, 396, 396]), rank 0 
2025-04-09 20:24:36.758790: predicting lung_096 
2025-04-09 20:24:37.587112: lung_096, shape torch.Size([1, 241, 512, 512]), rank 0 
2025-04-09 20:28:25.609782: predicting lung_100 
2025-04-09 20:28:26.085519: lung_100, shape torch.Size([1, 230, 448, 448]), rank 0 
2025-04-09 20:30:32.818648: predicting lung_103 
2025-04-09 20:30:33.436010: lung_103, shape torch.Size([1, 243, 507, 507]), rank 0 
2025-04-09 20:34:21.235956: predicting lung_104 
2025-04-09 20:34:21.935725: lung_104, shape torch.Size([1, 259, 520, 520]), rank 0 
2025-04-09 20:38:09.962466: predicting lung_106 
2025-04-09 20:38:10.518453: lung_106, shape torch.Size([1, 266, 532, 532]), rank 0 
2025-04-09 20:41:58.507619: predicting lung_117 
2025-04-09 20:41:59.013347: lung_117, shape torch.Size([1, 222, 461, 461]), rank 0 
2025-04-09 20:44:05.754858: predicting lung_124 
2025-04-09 20:44:32.747864: lung_124, shape torch.Size([1, 251, 640, 640]), rank 0 
2025-04-09 20:49:51.058136: predicting lung_127 
2025-04-09 20:49:51.881826: lung_127, shape torch.Size([1, 241, 452, 452]), rank 0 
2025-04-09 20:52:24.172894: predicting lung_138 
2025-04-09 20:52:24.783824: lung_138, shape torch.Size([1, 239, 465, 465]), rank 0 
2025-04-09 20:54:31.593462: predicting lung_139 
2025-04-09 20:54:32.344935: lung_139, shape torch.Size([1, 257, 538, 538]), rank 0 
2025-04-09 20:58:20.250125: predicting lung_142 
2025-04-09 20:58:21.097696: lung_142, shape torch.Size([1, 331, 475, 475]), rank 0 
2025-04-09 21:03:43.498699: Validation complete 
2025-04-09 21:03:43.498835: Mean Validation Dice:  0.8074408162338906 
