
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-18 08:23:41.479942: Using torch.compile... 
2025-03-18 08:23:41.485318: do_dummy_2d_data_aug: False 
2025-03-18 08:23:41.486451: Using splits from existing split file: /mrhung_nguyen_minh_quang_108/workspace/train/nnUNet_preprocessed/Dataset015_lungTumor/splits_final.json 
2025-03-18 08:23:41.486676: The split file contains 5 splits. 
2025-03-18 08:23:41.486720: Desired fold for training: 1 
2025-03-18 08:23:41.486758: This split has 92 training and 23 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [251.0, 512.0, 512.0], 'spacing': [1.25, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset015_lungTumor', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [1.25, 0.78125, 0.78125], 'original_median_shape_after_transp': [251, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2750.0, 'mean': -292.26348876953125, 'median': -205.0, 'min': -1270.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 308.0, 'std': 352.5594787597656}}} 
 
2025-03-18 08:23:43.203792: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-03-18 08:23:43.247132:  
2025-03-18 08:23:43.247615: Epoch 0 
2025-03-18 08:23:43.247923: Current learning rate: 0.01 
2025-03-18 08:28:32.089395: train_loss 0.0585 
2025-03-18 08:28:32.089642: val_loss -0.0207 
2025-03-18 08:28:32.089720: Pseudo dice [0.0] 
2025-03-18 08:28:32.089846: Epoch time: 288.85 s 
2025-03-18 08:28:32.089942: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-18 08:28:35.382346:  
2025-03-18 08:28:35.382614: Epoch 1 
2025-03-18 08:28:35.382790: Current learning rate: 0.00999 
2025-03-18 08:33:12.717320: train_loss -0.1841 
2025-03-18 08:33:12.717640: val_loss -0.3273 
2025-03-18 08:33:12.717720: Pseudo dice [0.4669] 
2025-03-18 08:33:12.717813: Epoch time: 277.34 s 
2025-03-18 08:33:12.717876: Yayy! New best EMA pseudo Dice: 0.0467 
2025-03-18 08:33:15.785349:  
2025-03-18 08:33:15.785553: Epoch 2 
2025-03-18 08:33:15.785667: Current learning rate: 0.00998 
2025-03-18 08:37:54.286134: train_loss -0.264 
2025-03-18 08:37:54.286430: val_loss -0.4039 
2025-03-18 08:37:54.286518: Pseudo dice [0.3664] 
2025-03-18 08:37:54.286606: Epoch time: 278.5 s 
2025-03-18 08:37:54.286720: Yayy! New best EMA pseudo Dice: 0.0787 
2025-03-18 08:37:57.448147:  
2025-03-18 08:37:57.448371: Epoch 3 
2025-03-18 08:37:57.448492: Current learning rate: 0.00997 
2025-03-18 08:42:33.495716: train_loss -0.3554 
2025-03-18 08:42:33.496116: val_loss -0.3976 
2025-03-18 08:42:33.496215: Pseudo dice [0.4802] 
2025-03-18 08:42:33.496297: Epoch time: 276.05 s 
2025-03-18 08:42:33.496356: Yayy! New best EMA pseudo Dice: 0.1188 
2025-03-18 08:42:36.714874:  
2025-03-18 08:42:36.715095: Epoch 4 
2025-03-18 08:42:36.715212: Current learning rate: 0.00996 
2025-03-18 08:47:12.570323: train_loss -0.4744 
2025-03-18 08:47:12.570689: val_loss -0.5133 
2025-03-18 08:47:12.570847: Pseudo dice [0.5093] 
2025-03-18 08:47:12.570930: Epoch time: 275.86 s 
2025-03-18 08:47:12.570989: Yayy! New best EMA pseudo Dice: 0.1579 
2025-03-18 08:47:15.756448:  
2025-03-18 08:47:15.756759: Epoch 5 
2025-03-18 08:47:15.756948: Current learning rate: 0.00995 
2025-03-18 08:51:51.480133: train_loss -0.4802 
2025-03-18 08:51:51.480590: val_loss -0.5883 
2025-03-18 08:51:51.480685: Pseudo dice [0.5243] 
2025-03-18 08:51:51.480764: Epoch time: 275.73 s 
2025-03-18 08:51:51.480824: Yayy! New best EMA pseudo Dice: 0.1945 
2025-03-18 08:51:54.607760:  
2025-03-18 08:51:54.607970: Epoch 6 
2025-03-18 08:51:54.608090: Current learning rate: 0.00995 
2025-03-18 08:56:30.555383: train_loss -0.5607 
2025-03-18 08:56:30.555679: val_loss -0.5244 
2025-03-18 08:56:30.555777: Pseudo dice [0.4766] 
2025-03-18 08:56:30.555883: Epoch time: 275.95 s 
2025-03-18 08:56:30.555940: Yayy! New best EMA pseudo Dice: 0.2227 
2025-03-18 08:56:33.670088:  
2025-03-18 08:56:33.670349: Epoch 7 
2025-03-18 08:56:33.670462: Current learning rate: 0.00994 
2025-03-18 09:01:09.083227: train_loss -0.5206 
2025-03-18 09:01:09.083536: val_loss -0.5664 
2025-03-18 09:01:09.083634: Pseudo dice [0.5531] 
2025-03-18 09:01:09.083731: Epoch time: 275.42 s 
2025-03-18 09:01:09.083807: Yayy! New best EMA pseudo Dice: 0.2557 
2025-03-18 09:01:12.527963:  
2025-03-18 09:01:12.528165: Epoch 8 
2025-03-18 09:01:12.528276: Current learning rate: 0.00993 
2025-03-18 09:05:48.390934: train_loss -0.4601 
2025-03-18 09:05:48.391225: val_loss -0.5858 
2025-03-18 09:05:48.391300: Pseudo dice [0.5676] 
2025-03-18 09:05:48.391384: Epoch time: 275.87 s 
2025-03-18 09:05:48.391455: Yayy! New best EMA pseudo Dice: 0.2869 
2025-03-18 09:05:51.613719:  
2025-03-18 09:05:51.613955: Epoch 9 
2025-03-18 09:05:51.614081: Current learning rate: 0.00992 
2025-03-18 09:10:27.255968: train_loss -0.5186 
2025-03-18 09:10:27.256258: val_loss -0.5282 
2025-03-18 09:10:27.256348: Pseudo dice [0.4813] 
2025-03-18 09:10:27.256435: Epoch time: 275.65 s 
2025-03-18 09:10:27.256504: Yayy! New best EMA pseudo Dice: 0.3064 
2025-03-18 09:10:30.342621:  
2025-03-18 09:10:30.342872: Epoch 10 
2025-03-18 09:10:30.343004: Current learning rate: 0.00991 
2025-03-18 09:15:05.889782: train_loss -0.5475 
2025-03-18 09:15:05.890095: val_loss -0.4999 
2025-03-18 09:15:05.890181: Pseudo dice [0.5837] 
2025-03-18 09:15:05.890274: Epoch time: 275.55 s 
2025-03-18 09:15:05.890343: Yayy! New best EMA pseudo Dice: 0.3341 
2025-03-18 09:15:08.965933:  
2025-03-18 09:15:08.966081: Epoch 11 
2025-03-18 09:15:08.966248: Current learning rate: 0.0099 
2025-03-18 09:19:44.252170: train_loss -0.5772 
2025-03-18 09:19:44.252470: val_loss -0.6147 
2025-03-18 09:19:44.252556: Pseudo dice [0.6554] 
2025-03-18 09:19:44.252645: Epoch time: 275.29 s 
2025-03-18 09:19:44.252712: Yayy! New best EMA pseudo Dice: 0.3662 
2025-03-18 09:19:47.386623:  
2025-03-18 09:19:47.386785: Epoch 12 
2025-03-18 09:19:47.386898: Current learning rate: 0.00989 
2025-03-18 09:24:22.924475: train_loss -0.5808 
2025-03-18 09:24:22.924774: val_loss -0.6025 
2025-03-18 09:24:22.924872: Pseudo dice [0.6427] 
2025-03-18 09:24:22.924965: Epoch time: 275.54 s 
2025-03-18 09:24:22.925030: Yayy! New best EMA pseudo Dice: 0.3939 
2025-03-18 09:24:26.103994:  
2025-03-18 09:24:26.104190: Epoch 13 
2025-03-18 09:24:26.104314: Current learning rate: 0.00988 
2025-03-18 09:29:01.309297: train_loss -0.6062 
2025-03-18 09:29:01.309601: val_loss -0.6577 
2025-03-18 09:29:01.309680: Pseudo dice [0.6854] 
2025-03-18 09:29:01.309763: Epoch time: 275.21 s 
2025-03-18 09:29:01.309834: Yayy! New best EMA pseudo Dice: 0.423 
2025-03-18 09:29:04.740491:  
2025-03-18 09:29:04.740702: Epoch 14 
2025-03-18 09:29:04.740819: Current learning rate: 0.00987 
2025-03-18 09:33:40.094951: train_loss -0.5886 
2025-03-18 09:33:40.095284: val_loss -0.5852 
2025-03-18 09:33:40.095383: Pseudo dice [0.6842] 
2025-03-18 09:33:40.095483: Epoch time: 275.36 s 
2025-03-18 09:33:40.095538: Yayy! New best EMA pseudo Dice: 0.4491 
2025-03-18 09:33:43.275044:  
2025-03-18 09:33:43.275262: Epoch 15 
2025-03-18 09:33:43.275397: Current learning rate: 0.00986 
2025-03-18 09:38:20.029194: train_loss -0.5883 
2025-03-18 09:38:20.029529: val_loss -0.6225 
2025-03-18 09:38:20.029614: Pseudo dice [0.7068] 
2025-03-18 09:38:20.029714: Epoch time: 276.76 s 
2025-03-18 09:38:20.029769: Yayy! New best EMA pseudo Dice: 0.4749 
2025-03-18 09:38:23.303582:  
2025-03-18 09:38:23.303867: Epoch 16 
2025-03-18 09:38:23.304019: Current learning rate: 0.00986 
2025-03-18 09:42:59.996271: train_loss -0.594 
2025-03-18 09:42:59.996613: val_loss -0.6101 
2025-03-18 09:42:59.996700: Pseudo dice [0.6545] 
2025-03-18 09:42:59.996798: Epoch time: 276.7 s 
2025-03-18 09:42:59.996857: Yayy! New best EMA pseudo Dice: 0.4929 
2025-03-18 09:43:03.289162:  
2025-03-18 09:43:03.289394: Epoch 17 
2025-03-18 09:43:03.289549: Current learning rate: 0.00985 
2025-03-18 09:47:39.760517: train_loss -0.6534 
2025-03-18 09:47:39.760851: val_loss -0.65 
2025-03-18 09:47:39.760949: Pseudo dice [0.6723] 
2025-03-18 09:47:39.761044: Epoch time: 276.48 s 
2025-03-18 09:47:39.761097: Yayy! New best EMA pseudo Dice: 0.5108 
2025-03-18 09:47:42.995288:  
2025-03-18 09:47:42.995522: Epoch 18 
2025-03-18 09:47:42.995683: Current learning rate: 0.00984 
2025-03-18 09:52:19.530976: train_loss -0.5356 
2025-03-18 09:52:19.531340: val_loss -0.5669 
2025-03-18 09:52:19.531502: Pseudo dice [0.5355] 
2025-03-18 09:52:19.531585: Epoch time: 276.54 s 
2025-03-18 09:52:19.531646: Yayy! New best EMA pseudo Dice: 0.5133 
2025-03-18 09:52:22.782541:  
2025-03-18 09:52:22.782744: Epoch 19 
2025-03-18 09:52:22.782882: Current learning rate: 0.00983 
2025-03-18 09:56:59.418549: train_loss -0.5843 
2025-03-18 09:56:59.418841: val_loss -0.6758 
2025-03-18 09:56:59.419001: Pseudo dice [0.6584] 
2025-03-18 09:56:59.419101: Epoch time: 276.64 s 
2025-03-18 09:56:59.419161: Yayy! New best EMA pseudo Dice: 0.5278 
2025-03-18 09:57:02.615792:  
2025-03-18 09:57:02.616019: Epoch 20 
2025-03-18 09:57:02.616165: Current learning rate: 0.00982 
2025-03-18 10:01:39.366344: train_loss -0.5963 
2025-03-18 10:01:39.366697: val_loss -0.6637 
2025-03-18 10:01:39.366858: Pseudo dice [0.6095] 
2025-03-18 10:01:39.366945: Epoch time: 276.75 s 
2025-03-18 10:01:39.367001: Yayy! New best EMA pseudo Dice: 0.536 
2025-03-18 10:01:42.597051:  
2025-03-18 10:01:42.597275: Epoch 21 
2025-03-18 10:01:42.597394: Current learning rate: 0.00981 
2025-03-18 10:06:19.180716: train_loss -0.6227 
2025-03-18 10:06:19.181088: val_loss -0.6584 
2025-03-18 10:06:19.181237: Pseudo dice [0.6964] 
2025-03-18 10:06:19.181324: Epoch time: 276.59 s 
2025-03-18 10:06:19.181384: Yayy! New best EMA pseudo Dice: 0.552 
2025-03-18 10:06:22.608930:  
2025-03-18 10:06:22.609183: Epoch 22 
2025-03-18 10:06:22.609326: Current learning rate: 0.0098 
2025-03-18 10:10:59.262077: train_loss -0.6529 
2025-03-18 10:10:59.262378: val_loss -0.6339 
2025-03-18 10:10:59.262462: Pseudo dice [0.621] 
2025-03-18 10:10:59.262590: Epoch time: 276.66 s 
2025-03-18 10:10:59.262655: Yayy! New best EMA pseudo Dice: 0.5589 
2025-03-18 10:11:02.420615:  
2025-03-18 10:11:02.420868: Epoch 23 
2025-03-18 10:11:02.420997: Current learning rate: 0.00979 
2025-03-18 10:15:39.478965: train_loss -0.6341 
2025-03-18 10:15:39.479312: val_loss -0.6593 
2025-03-18 10:15:39.479392: Pseudo dice [0.6539] 
2025-03-18 10:15:39.479508: Epoch time: 277.06 s 
2025-03-18 10:15:39.479563: Yayy! New best EMA pseudo Dice: 0.5684 
2025-03-18 10:15:42.611653:  
2025-03-18 10:15:42.611859: Epoch 24 
2025-03-18 10:15:42.611979: Current learning rate: 0.00978 
2025-03-18 10:20:20.612425: train_loss -0.6232 
2025-03-18 10:20:20.612754: val_loss -0.6588 
2025-03-18 10:20:20.612838: Pseudo dice [0.7476] 
2025-03-18 10:20:20.612930: Epoch time: 278.0 s 
2025-03-18 10:20:20.612986: Yayy! New best EMA pseudo Dice: 0.5863 
2025-03-18 10:20:23.819525:  
2025-03-18 10:20:23.819773: Epoch 25 
2025-03-18 10:20:23.819902: Current learning rate: 0.00977 
2025-03-18 10:25:00.002164: train_loss -0.6119 
2025-03-18 10:25:00.002490: val_loss -0.7005 
2025-03-18 10:25:00.002589: Pseudo dice [0.7537] 
2025-03-18 10:25:00.002688: Epoch time: 276.19 s 
2025-03-18 10:25:00.002743: Yayy! New best EMA pseudo Dice: 0.603 
2025-03-18 10:25:03.159084:  
2025-03-18 10:25:03.159293: Epoch 26 
2025-03-18 10:25:03.159406: Current learning rate: 0.00977 
2025-03-18 10:29:38.326257: train_loss -0.6366 
2025-03-18 10:29:38.326555: val_loss -0.6341 
2025-03-18 10:29:38.326639: Pseudo dice [0.6153] 
2025-03-18 10:29:38.326720: Epoch time: 275.17 s 
2025-03-18 10:29:38.326788: Yayy! New best EMA pseudo Dice: 0.6043 
2025-03-18 10:29:41.472235:  
2025-03-18 10:29:41.472414: Epoch 27 
2025-03-18 10:29:41.472542: Current learning rate: 0.00976 
2025-03-18 10:34:16.519480: train_loss -0.6818 
2025-03-18 10:34:16.520037: val_loss -0.7193 
2025-03-18 10:34:16.520114: Pseudo dice [0.6979] 
2025-03-18 10:34:16.520214: Epoch time: 275.05 s 
2025-03-18 10:34:16.520275: Yayy! New best EMA pseudo Dice: 0.6136 
2025-03-18 10:34:19.756861:  
2025-03-18 10:34:19.757151: Epoch 28 
2025-03-18 10:34:19.757264: Current learning rate: 0.00975 
2025-03-18 10:38:54.799683: train_loss -0.6553 
2025-03-18 10:38:54.800071: val_loss -0.6734 
2025-03-18 10:38:54.800156: Pseudo dice [0.6674] 
2025-03-18 10:38:54.800245: Epoch time: 275.05 s 
2025-03-18 10:38:54.800299: Yayy! New best EMA pseudo Dice: 0.619 
2025-03-18 10:38:58.294075:  
2025-03-18 10:38:58.294297: Epoch 29 
2025-03-18 10:38:58.294408: Current learning rate: 0.00974 
2025-03-18 10:43:33.608704: train_loss -0.6232 
2025-03-18 10:43:33.609050: val_loss -0.7257 
2025-03-18 10:43:33.609136: Pseudo dice [0.7432] 
2025-03-18 10:43:33.609234: Epoch time: 275.32 s 
2025-03-18 10:43:33.609290: Yayy! New best EMA pseudo Dice: 0.6314 
2025-03-18 10:43:36.844346:  
2025-03-18 10:43:36.844527: Epoch 30 
2025-03-18 10:43:36.844678: Current learning rate: 0.00973 
2025-03-18 10:48:12.325834: train_loss -0.5662 
2025-03-18 10:48:12.326141: val_loss -0.6288 
2025-03-18 10:48:12.326234: Pseudo dice [0.6386] 
2025-03-18 10:48:12.326331: Epoch time: 275.49 s 
2025-03-18 10:48:12.326386: Yayy! New best EMA pseudo Dice: 0.6321 
2025-03-18 10:48:15.528516:  
2025-03-18 10:48:15.528828: Epoch 31 
2025-03-18 10:48:15.528961: Current learning rate: 0.00972 
2025-03-18 10:52:50.857650: train_loss -0.6012 
2025-03-18 10:52:50.857984: val_loss -0.5958 
2025-03-18 10:52:50.858118: Pseudo dice [0.6522] 
2025-03-18 10:52:50.858218: Epoch time: 275.33 s 
2025-03-18 10:52:50.858302: Yayy! New best EMA pseudo Dice: 0.6341 
2025-03-18 10:52:54.066310:  
2025-03-18 10:52:54.066572: Epoch 32 
2025-03-18 10:52:54.066696: Current learning rate: 0.00971 
2025-03-18 10:57:29.119207: train_loss -0.6183 
2025-03-18 10:57:29.119529: val_loss -0.6631 
2025-03-18 10:57:29.119615: Pseudo dice [0.6993] 
2025-03-18 10:57:29.119704: Epoch time: 275.06 s 
2025-03-18 10:57:29.119781: Yayy! New best EMA pseudo Dice: 0.6407 
2025-03-18 10:57:32.331693:  
2025-03-18 10:57:32.331989: Epoch 33 
2025-03-18 10:57:32.332137: Current learning rate: 0.0097 
2025-03-18 11:02:07.476504: train_loss -0.6413 
2025-03-18 11:02:07.476842: val_loss -0.6844 
2025-03-18 11:02:07.476935: Pseudo dice [0.7649] 
2025-03-18 11:02:07.477054: Epoch time: 275.15 s 
2025-03-18 11:02:07.477112: Yayy! New best EMA pseudo Dice: 0.6531 
2025-03-18 11:02:10.644043:  
2025-03-18 11:02:10.644215: Epoch 34 
2025-03-18 11:02:10.644340: Current learning rate: 0.00969 
2025-03-18 11:06:47.373283: train_loss -0.6482 
2025-03-18 11:06:47.373624: val_loss -0.6494 
2025-03-18 11:06:47.373725: Pseudo dice [0.7316] 
2025-03-18 11:06:47.373822: Epoch time: 276.73 s 
2025-03-18 11:06:47.373883: Yayy! New best EMA pseudo Dice: 0.6609 
2025-03-18 11:06:50.612111:  
2025-03-18 11:06:50.612337: Epoch 35 
2025-03-18 11:06:50.612507: Current learning rate: 0.00968 
2025-03-18 11:11:26.668312: train_loss -0.7048 
2025-03-18 11:11:26.668679: val_loss -0.7065 
2025-03-18 11:11:26.668801: Pseudo dice [0.7196] 
2025-03-18 11:11:26.668896: Epoch time: 276.06 s 
2025-03-18 11:11:26.668953: Yayy! New best EMA pseudo Dice: 0.6668 
2025-03-18 11:11:30.108715:  
2025-03-18 11:11:30.109088: Epoch 36 
2025-03-18 11:11:30.109201: Current learning rate: 0.00968 
2025-03-18 11:16:05.778954: train_loss -0.6287 
2025-03-18 11:16:05.779294: val_loss -0.6089 
2025-03-18 11:16:05.779435: Pseudo dice [0.6493] 
2025-03-18 11:16:05.779532: Epoch time: 275.67 s 
2025-03-18 11:16:07.628741:  
2025-03-18 11:16:07.628959: Epoch 37 
2025-03-18 11:16:07.629086: Current learning rate: 0.00967 
2025-03-18 11:20:43.367244: train_loss -0.6503 
2025-03-18 11:20:43.367600: val_loss -0.683 
2025-03-18 11:20:43.367695: Pseudo dice [0.7536] 
2025-03-18 11:20:43.367799: Epoch time: 275.74 s 
2025-03-18 11:20:43.367870: Yayy! New best EMA pseudo Dice: 0.6739 
2025-03-18 11:20:46.525388:  
2025-03-18 11:20:46.525635: Epoch 38 
2025-03-18 11:20:46.525767: Current learning rate: 0.00966 
2025-03-18 11:25:22.203409: train_loss -0.6652 
2025-03-18 11:25:22.203804: val_loss -0.5868 
2025-03-18 11:25:22.203889: Pseudo dice [0.5656] 
2025-03-18 11:25:22.203991: Epoch time: 275.68 s 
2025-03-18 11:25:24.072947:  
2025-03-18 11:25:24.073136: Epoch 39 
2025-03-18 11:25:24.073338: Current learning rate: 0.00965 
2025-03-18 11:29:59.407591: train_loss -0.7046 
2025-03-18 11:29:59.407938: val_loss -0.7168 
2025-03-18 11:29:59.408021: Pseudo dice [0.7275] 
2025-03-18 11:29:59.408190: Epoch time: 275.34 s 
2025-03-18 11:30:01.303341:  
2025-03-18 11:30:01.303610: Epoch 40 
2025-03-18 11:30:01.303796: Current learning rate: 0.00964 
2025-03-18 11:34:36.977723: train_loss -0.6824 
2025-03-18 11:34:36.978127: val_loss -0.5013 
2025-03-18 11:34:36.978273: Pseudo dice [0.3909] 
2025-03-18 11:34:36.978363: Epoch time: 275.68 s 
2025-03-18 11:34:38.865195:  
2025-03-18 11:34:38.865491: Epoch 41 
2025-03-18 11:34:38.865609: Current learning rate: 0.00963 
2025-03-18 11:39:14.657932: train_loss -0.5936 
2025-03-18 11:39:14.658313: val_loss -0.6521 
2025-03-18 11:39:14.658409: Pseudo dice [0.6953] 
2025-03-18 11:39:14.658520: Epoch time: 275.8 s 
2025-03-18 11:39:16.442220:  
2025-03-18 11:39:16.442417: Epoch 42 
2025-03-18 11:39:16.442527: Current learning rate: 0.00962 
2025-03-18 11:43:52.092780: train_loss -0.6405 
2025-03-18 11:43:52.093107: val_loss -0.7287 
2025-03-18 11:43:52.093215: Pseudo dice [0.7681] 
2025-03-18 11:43:52.093308: Epoch time: 275.65 s 
2025-03-18 11:43:53.878308:  
2025-03-18 11:43:53.878533: Epoch 43 
2025-03-18 11:43:53.878705: Current learning rate: 0.00961 
2025-03-18 11:48:30.075202: train_loss -0.629 
2025-03-18 11:48:30.075583: val_loss -0.656 
2025-03-18 11:48:30.075670: Pseudo dice [0.6927] 
2025-03-18 11:48:30.075774: Epoch time: 276.2 s 
2025-03-18 11:48:32.179301:  
2025-03-18 11:48:32.179652: Epoch 44 
2025-03-18 11:48:32.179834: Current learning rate: 0.0096 
2025-03-18 11:53:08.634587: train_loss -0.6555 
2025-03-18 11:53:08.634968: val_loss -0.6556 
2025-03-18 11:53:08.635413: Pseudo dice [0.6929] 
2025-03-18 11:53:08.635496: Epoch time: 276.46 s 
2025-03-18 11:53:10.424906:  
2025-03-18 11:53:10.425133: Epoch 45 
2025-03-18 11:53:10.425250: Current learning rate: 0.00959 
2025-03-18 11:57:47.167150: train_loss -0.697 
2025-03-18 11:57:47.167455: val_loss -0.6721 
2025-03-18 11:57:47.167550: Pseudo dice [0.6993] 
2025-03-18 11:57:47.167642: Epoch time: 276.75 s 
2025-03-18 11:57:48.953405:  
2025-03-18 11:57:48.953606: Epoch 46 
2025-03-18 11:57:48.953717: Current learning rate: 0.00959 
2025-03-18 12:02:25.599895: train_loss -0.6871 
2025-03-18 12:02:25.600303: val_loss -0.6915 
2025-03-18 12:02:25.600443: Pseudo dice [0.7607] 
2025-03-18 12:02:25.600554: Epoch time: 276.65 s 
2025-03-18 12:02:25.600630: Yayy! New best EMA pseudo Dice: 0.6781 
2025-03-18 12:02:28.750693:  
2025-03-18 12:02:28.750932: Epoch 47 
2025-03-18 12:02:28.751081: Current learning rate: 0.00958 
2025-03-18 12:07:05.303646: train_loss -0.6791 
2025-03-18 12:07:05.303964: val_loss -0.7113 
2025-03-18 12:07:05.304053: Pseudo dice [0.7743] 
2025-03-18 12:07:05.304252: Epoch time: 276.56 s 
2025-03-18 12:07:05.304327: Yayy! New best EMA pseudo Dice: 0.6877 
2025-03-18 12:07:08.377951:  
2025-03-18 12:07:08.378201: Epoch 48 
2025-03-18 12:07:08.378329: Current learning rate: 0.00957 
2025-03-18 12:11:44.653152: train_loss -0.6849 
2025-03-18 12:11:44.653479: val_loss -0.7287 
2025-03-18 12:11:44.653560: Pseudo dice [0.7765] 
2025-03-18 12:11:44.653730: Epoch time: 276.28 s 
2025-03-18 12:11:44.653819: Yayy! New best EMA pseudo Dice: 0.6966 
2025-03-18 12:11:47.805958:  
2025-03-18 12:11:47.806166: Epoch 49 
2025-03-18 12:11:47.806307: Current learning rate: 0.00956 
2025-03-18 12:16:23.984027: train_loss -0.605 
2025-03-18 12:16:23.984376: val_loss -0.6657 
2025-03-18 12:16:23.984470: Pseudo dice [0.6426] 
2025-03-18 12:16:23.984575: Epoch time: 276.18 s 
2025-03-18 12:16:26.723574:  
2025-03-18 12:16:26.723799: Epoch 50 
2025-03-18 12:16:26.723946: Current learning rate: 0.00955 
2025-03-18 12:21:02.224113: train_loss -0.6937 
2025-03-18 12:21:02.224531: val_loss -0.6717 
2025-03-18 12:21:02.224638: Pseudo dice [0.7109] 
2025-03-18 12:21:02.224717: Epoch time: 275.5 s 
2025-03-18 12:21:04.098418:  
2025-03-18 12:21:04.098631: Epoch 51 
2025-03-18 12:21:04.098745: Current learning rate: 0.00954 
2025-03-18 12:25:40.241983: train_loss -0.695 
2025-03-18 12:25:40.242290: val_loss -0.6507 
2025-03-18 12:25:40.242376: Pseudo dice [0.6284] 
2025-03-18 12:25:40.242479: Epoch time: 276.15 s 
2025-03-18 12:25:42.353091:  
2025-03-18 12:25:42.353270: Epoch 52 
2025-03-18 12:25:42.353382: Current learning rate: 0.00953 
2025-03-18 12:30:18.334370: train_loss -0.6769 
2025-03-18 12:30:18.334683: val_loss -0.649 
2025-03-18 12:30:18.334767: Pseudo dice [0.5788] 
2025-03-18 12:30:18.334857: Epoch time: 275.99 s 
2025-03-18 12:30:20.128443:  
2025-03-18 12:30:20.128623: Epoch 53 
2025-03-18 12:30:20.128740: Current learning rate: 0.00952 
2025-03-18 12:34:55.946618: train_loss -0.6876 
2025-03-18 12:34:55.947002: val_loss -0.6499 
2025-03-18 12:34:55.947118: Pseudo dice [0.5712] 
2025-03-18 12:34:55.947212: Epoch time: 275.82 s 
2025-03-18 12:34:57.810594:  
2025-03-18 12:34:57.810794: Epoch 54 
2025-03-18 12:34:57.810910: Current learning rate: 0.00951 
2025-03-18 12:39:33.643887: train_loss -0.6863 
2025-03-18 12:39:33.644238: val_loss -0.7171 
2025-03-18 12:39:33.644334: Pseudo dice [0.7747] 
2025-03-18 12:39:33.644435: Epoch time: 275.84 s 
2025-03-18 12:39:35.464016:  
2025-03-18 12:39:35.464219: Epoch 55 
2025-03-18 12:39:35.464333: Current learning rate: 0.0095 
2025-03-18 12:44:11.401578: train_loss -0.6889 
2025-03-18 12:44:11.401893: val_loss -0.6312 
2025-03-18 12:44:11.401973: Pseudo dice [0.6321] 
2025-03-18 12:44:11.402064: Epoch time: 275.94 s 
2025-03-18 12:44:13.216192:  
2025-03-18 12:44:13.216416: Epoch 56 
2025-03-18 12:44:13.216577: Current learning rate: 0.00949 
2025-03-18 12:48:49.919567: train_loss -0.6958 
2025-03-18 12:48:49.919868: val_loss -0.6736 
2025-03-18 12:48:49.919975: Pseudo dice [0.7136] 
2025-03-18 12:48:49.920085: Epoch time: 276.71 s 
2025-03-18 12:48:51.739133:  
2025-03-18 12:48:51.739329: Epoch 57 
2025-03-18 12:48:51.739511: Current learning rate: 0.00949 
2025-03-18 12:53:27.815670: train_loss -0.6995 
2025-03-18 12:53:27.816044: val_loss -0.6501 
2025-03-18 12:53:27.816134: Pseudo dice [0.6774] 
2025-03-18 12:53:27.816232: Epoch time: 276.08 s 
2025-03-18 12:53:29.632667:  
2025-03-18 12:53:29.632875: Epoch 58 
2025-03-18 12:53:29.633040: Current learning rate: 0.00948 
2025-03-18 12:58:06.455727: train_loss -0.7009 
2025-03-18 12:58:06.456071: val_loss -0.761 
2025-03-18 12:58:06.456160: Pseudo dice [0.7409] 
2025-03-18 12:58:06.456258: Epoch time: 276.83 s 
2025-03-18 12:58:08.279248:  
2025-03-18 12:58:08.279509: Epoch 59 
2025-03-18 12:58:08.279644: Current learning rate: 0.00947 
2025-03-18 13:02:44.942269: train_loss -0.7077 
2025-03-18 13:02:44.942592: val_loss -0.7153 
2025-03-18 13:02:44.942680: Pseudo dice [0.7486] 
2025-03-18 13:02:44.942766: Epoch time: 276.67 s 
2025-03-18 13:02:47.062916:  
2025-03-18 13:02:47.063159: Epoch 60 
2025-03-18 13:02:47.063311: Current learning rate: 0.00946 
2025-03-18 13:07:23.158391: train_loss -0.7138 
2025-03-18 13:07:23.158692: val_loss -0.7295 
2025-03-18 13:07:23.158766: Pseudo dice [0.7901] 
2025-03-18 13:07:23.158881: Epoch time: 276.1 s 
2025-03-18 13:07:23.158949: Yayy! New best EMA pseudo Dice: 0.6994 
2025-03-18 13:07:26.479497:  
2025-03-18 13:07:26.479772: Epoch 61 
2025-03-18 13:07:26.479953: Current learning rate: 0.00945 
2025-03-18 13:12:02.674831: train_loss -0.7304 
2025-03-18 13:12:02.675142: val_loss -0.7472 
2025-03-18 13:12:02.675253: Pseudo dice [0.7831] 
2025-03-18 13:12:02.675355: Epoch time: 276.2 s 
2025-03-18 13:12:02.675411: Yayy! New best EMA pseudo Dice: 0.7077 
2025-03-18 13:12:05.888535:  
2025-03-18 13:12:05.888778: Epoch 62 
2025-03-18 13:12:05.888946: Current learning rate: 0.00944 
2025-03-18 13:16:42.013085: train_loss -0.7372 
2025-03-18 13:16:42.013442: val_loss -0.6939 
2025-03-18 13:16:42.013578: Pseudo dice [0.7352] 
2025-03-18 13:16:42.013673: Epoch time: 276.13 s 
2025-03-18 13:16:42.013732: Yayy! New best EMA pseudo Dice: 0.7105 
2025-03-18 13:16:45.173885:  
2025-03-18 13:16:45.174166: Epoch 63 
2025-03-18 13:16:45.174292: Current learning rate: 0.00943 
2025-03-18 13:21:21.479304: train_loss -0.703 
2025-03-18 13:21:21.479612: val_loss -0.6598 
2025-03-18 13:21:21.479690: Pseudo dice [0.6157] 
2025-03-18 13:21:21.479782: Epoch time: 276.31 s 
2025-03-18 13:21:23.299031:  
2025-03-18 13:21:23.299243: Epoch 64 
2025-03-18 13:21:23.299359: Current learning rate: 0.00942 
2025-03-18 13:25:59.449560: train_loss -0.7176 
2025-03-18 13:25:59.449851: val_loss -0.7345 
2025-03-18 13:25:59.449931: Pseudo dice [0.7198] 
2025-03-18 13:25:59.450016: Epoch time: 276.15 s 
2025-03-18 13:26:01.264330:  
2025-03-18 13:26:01.264605: Epoch 65 
2025-03-18 13:26:01.264765: Current learning rate: 0.00941 
2025-03-18 13:30:37.138659: train_loss -0.7064 
2025-03-18 13:30:37.138956: val_loss -0.7163 
2025-03-18 13:30:37.139061: Pseudo dice [0.7399] 
2025-03-18 13:30:37.139154: Epoch time: 275.88 s 
2025-03-18 13:30:38.971569:  
2025-03-18 13:30:38.971734: Epoch 66 
2025-03-18 13:30:38.971913: Current learning rate: 0.0094 
2025-03-18 13:35:15.277021: train_loss -0.6824 
2025-03-18 13:35:15.277400: val_loss -0.6913 
2025-03-18 13:35:15.277505: Pseudo dice [0.7243] 
2025-03-18 13:35:15.277598: Epoch time: 276.31 s 
2025-03-18 13:35:17.408875:  
2025-03-18 13:35:17.409198: Epoch 67 
2025-03-18 13:35:17.409358: Current learning rate: 0.00939 
2025-03-18 13:39:53.915281: train_loss -0.6902 
2025-03-18 13:39:53.915583: val_loss -0.7261 
2025-03-18 13:39:53.915669: Pseudo dice [0.7495] 
2025-03-18 13:39:53.915776: Epoch time: 276.51 s 
2025-03-18 13:39:53.915838: Yayy! New best EMA pseudo Dice: 0.7125 
2025-03-18 13:39:57.131632:  
2025-03-18 13:39:57.131930: Epoch 68 
2025-03-18 13:39:57.132061: Current learning rate: 0.00939 
2025-03-18 13:44:33.609853: train_loss -0.7157 
2025-03-18 13:44:33.610222: val_loss -0.6383 
2025-03-18 13:44:33.610320: Pseudo dice [0.5454] 
2025-03-18 13:44:33.610421: Epoch time: 276.48 s 
2025-03-18 13:44:35.469288:  
2025-03-18 13:44:35.469476: Epoch 69 
2025-03-18 13:44:35.469591: Current learning rate: 0.00938 
2025-03-18 13:49:11.558663: train_loss -0.7158 
2025-03-18 13:49:11.559065: val_loss -0.718 
2025-03-18 13:49:11.559172: Pseudo dice [0.7505] 
2025-03-18 13:49:11.559255: Epoch time: 276.09 s 
2025-03-18 13:49:13.418595:  
2025-03-18 13:49:13.418821: Epoch 70 
2025-03-18 13:49:13.418939: Current learning rate: 0.00937 
2025-03-18 13:53:49.098061: train_loss -0.7585 
2025-03-18 13:53:49.098443: val_loss -0.6887 
2025-03-18 13:53:49.098537: Pseudo dice [0.7179] 
2025-03-18 13:53:49.098629: Epoch time: 275.68 s 
2025-03-18 13:53:50.959902:  
2025-03-18 13:53:50.960162: Epoch 71 
2025-03-18 13:53:50.960296: Current learning rate: 0.00936 
2025-03-18 13:58:27.155991: train_loss -0.7254 
2025-03-18 13:58:27.156303: val_loss -0.6914 
2025-03-18 13:58:27.156392: Pseudo dice [0.6986] 
2025-03-18 13:58:27.156492: Epoch time: 276.2 s 
2025-03-18 13:58:29.049940:  
2025-03-18 13:58:29.050179: Epoch 72 
2025-03-18 13:58:29.050302: Current learning rate: 0.00935 
2025-03-18 14:03:05.280652: train_loss -0.7062 
2025-03-18 14:03:05.280978: val_loss -0.7423 
2025-03-18 14:03:05.281061: Pseudo dice [0.7729] 
2025-03-18 14:03:05.281145: Epoch time: 276.23 s 
2025-03-18 14:03:07.147681:  
2025-03-18 14:03:07.147887: Epoch 73 
2025-03-18 14:03:07.148003: Current learning rate: 0.00934 
2025-03-18 14:07:43.030069: train_loss -0.7275 
2025-03-18 14:07:43.030374: val_loss -0.7044 
2025-03-18 14:07:43.030462: Pseudo dice [0.7891] 
2025-03-18 14:07:43.030552: Epoch time: 275.89 s 
2025-03-18 14:07:43.030625: Yayy! New best EMA pseudo Dice: 0.7175 
2025-03-18 14:07:46.293649:  
2025-03-18 14:07:46.293872: Epoch 74 
2025-03-18 14:07:46.293997: Current learning rate: 0.00933 
2025-03-18 14:12:22.415088: train_loss -0.706 
2025-03-18 14:12:22.415417: val_loss -0.6841 
2025-03-18 14:12:22.415499: Pseudo dice [0.6969] 
2025-03-18 14:12:22.415596: Epoch time: 276.13 s 
2025-03-18 14:12:24.633968:  
2025-03-18 14:12:24.634242: Epoch 75 
2025-03-18 14:12:24.634358: Current learning rate: 0.00932 
2025-03-18 14:17:00.392022: train_loss -0.6985 
2025-03-18 14:17:00.392426: val_loss -0.6911 
2025-03-18 14:17:00.392516: Pseudo dice [0.7314] 
2025-03-18 14:17:00.392610: Epoch time: 275.76 s 
2025-03-18 14:17:02.263638:  
2025-03-18 14:17:02.263943: Epoch 76 
2025-03-18 14:17:02.264068: Current learning rate: 0.00931 
2025-03-18 14:21:38.833043: train_loss -0.6678 
2025-03-18 14:21:38.833362: val_loss -0.5521 
2025-03-18 14:21:38.833447: Pseudo dice [0.425] 
2025-03-18 14:21:38.833549: Epoch time: 276.57 s 
2025-03-18 14:21:40.687937:  
2025-03-18 14:21:40.688147: Epoch 77 
2025-03-18 14:21:40.688266: Current learning rate: 0.0093 
2025-03-18 14:26:17.042185: train_loss -0.734 
2025-03-18 14:26:17.042494: val_loss -0.6422 
2025-03-18 14:26:17.042588: Pseudo dice [0.7039] 
2025-03-18 14:26:17.042686: Epoch time: 276.36 s 
2025-03-18 14:26:18.927645:  
2025-03-18 14:26:18.927932: Epoch 78 
2025-03-18 14:26:18.928063: Current learning rate: 0.0093 
2025-03-18 14:30:55.417554: train_loss -0.697 
2025-03-18 14:30:55.417895: val_loss -0.6066 
2025-03-18 14:30:55.417987: Pseudo dice [0.6777] 
2025-03-18 14:30:55.418086: Epoch time: 276.49 s 
2025-03-18 14:30:57.312947:  
2025-03-18 14:30:57.313165: Epoch 79 
2025-03-18 14:30:57.313284: Current learning rate: 0.00929 
2025-03-18 14:35:33.583325: train_loss -0.6582 
2025-03-18 14:35:33.583638: val_loss -0.7097 
2025-03-18 14:35:33.583720: Pseudo dice [0.6777] 
2025-03-18 14:35:33.583830: Epoch time: 276.27 s 
2025-03-18 14:35:35.480123:  
2025-03-18 14:35:35.480385: Epoch 80 
2025-03-18 14:35:35.480528: Current learning rate: 0.00928 
2025-03-18 14:40:11.345468: train_loss -0.7294 
2025-03-18 14:40:11.345792: val_loss -0.6904 
2025-03-18 14:40:11.345880: Pseudo dice [0.7154] 
2025-03-18 14:40:11.345979: Epoch time: 275.87 s 
2025-03-18 14:40:13.233366:  
2025-03-18 14:40:13.233573: Epoch 81 
2025-03-18 14:40:13.233703: Current learning rate: 0.00927 
2025-03-18 14:44:49.333012: train_loss -0.7025 
2025-03-18 14:44:49.333347: val_loss -0.5966 
2025-03-18 14:44:49.333443: Pseudo dice [0.5277] 
2025-03-18 14:44:49.333539: Epoch time: 276.1 s 
2025-03-18 14:44:51.213825:  
2025-03-18 14:44:51.213969: Epoch 82 
2025-03-18 14:44:51.214088: Current learning rate: 0.00926 
2025-03-18 14:49:27.294705: train_loss -0.6845 
2025-03-18 14:49:27.295035: val_loss -0.7407 
2025-03-18 14:49:27.295141: Pseudo dice [0.7605] 
2025-03-18 14:49:27.295244: Epoch time: 276.08 s 
2025-03-18 14:49:29.094180:  
2025-03-18 14:49:29.094396: Epoch 83 
2025-03-18 14:49:29.094570: Current learning rate: 0.00925 
2025-03-18 14:54:04.972821: train_loss -0.7208 
2025-03-18 14:54:04.973170: val_loss -0.688 
2025-03-18 14:54:04.973257: Pseudo dice [0.7371] 
2025-03-18 14:54:04.973404: Epoch time: 275.88 s 
2025-03-18 14:54:06.771842:  
2025-03-18 14:54:06.772064: Epoch 84 
2025-03-18 14:54:06.772180: Current learning rate: 0.00924 
2025-03-18 14:58:42.804473: train_loss -0.7097 
2025-03-18 14:58:42.804814: val_loss -0.7082 
2025-03-18 14:58:42.804948: Pseudo dice [0.7716] 
2025-03-18 14:58:42.805048: Epoch time: 276.04 s 
2025-03-18 14:58:44.584029:  
2025-03-18 14:58:44.584283: Epoch 85 
2025-03-18 14:58:44.584447: Current learning rate: 0.00923 
2025-03-18 15:03:20.922289: train_loss -0.719 
2025-03-18 15:03:20.922635: val_loss -0.7407 
2025-03-18 15:03:20.922742: Pseudo dice [0.775] 
2025-03-18 15:03:20.922843: Epoch time: 276.34 s 
2025-03-18 15:03:22.717407:  
2025-03-18 15:03:22.717589: Epoch 86 
2025-03-18 15:03:22.717705: Current learning rate: 0.00922 
2025-03-18 15:07:59.339896: train_loss -0.731 
2025-03-18 15:07:59.340252: val_loss -0.751 
2025-03-18 15:07:59.340343: Pseudo dice [0.7902] 
2025-03-18 15:07:59.340446: Epoch time: 276.63 s 
2025-03-18 15:08:01.136175:  
2025-03-18 15:08:01.136399: Epoch 87 
2025-03-18 15:08:01.136511: Current learning rate: 0.00921 
2025-03-18 15:12:37.552188: train_loss -0.7544 
2025-03-18 15:12:37.552482: val_loss -0.732 
2025-03-18 15:12:37.552579: Pseudo dice [0.751] 
2025-03-18 15:12:37.552742: Epoch time: 276.42 s 
2025-03-18 15:12:39.342343:  
2025-03-18 15:12:39.342634: Epoch 88 
2025-03-18 15:12:39.342768: Current learning rate: 0.0092 
2025-03-18 15:17:15.635470: train_loss -0.7345 
2025-03-18 15:17:15.635924: val_loss -0.7125 
2025-03-18 15:17:15.636019: Pseudo dice [0.734] 
2025-03-18 15:17:15.636099: Epoch time: 276.3 s 
2025-03-18 15:17:15.636157: Yayy! New best EMA pseudo Dice: 0.7183 
2025-03-18 15:17:18.754634:  
2025-03-18 15:17:18.754916: Epoch 89 
2025-03-18 15:17:18.755065: Current learning rate: 0.0092 
2025-03-18 15:21:54.795333: train_loss -0.6749 
2025-03-18 15:21:54.795662: val_loss -0.7024 
2025-03-18 15:21:54.795762: Pseudo dice [0.7048] 
2025-03-18 15:21:54.795865: Epoch time: 276.04 s 
2025-03-18 15:21:56.600256:  
2025-03-18 15:21:56.600454: Epoch 90 
2025-03-18 15:21:56.600569: Current learning rate: 0.00919 
2025-03-18 15:26:34.021246: train_loss -0.6542 
2025-03-18 15:26:34.021578: val_loss -0.7146 
2025-03-18 15:26:34.021661: Pseudo dice [0.7756] 
2025-03-18 15:26:34.021750: Epoch time: 277.42 s 
2025-03-18 15:26:34.021823: Yayy! New best EMA pseudo Dice: 0.7228 
2025-03-18 15:26:37.454233:  
2025-03-18 15:26:37.454476: Epoch 91 
2025-03-18 15:26:37.454596: Current learning rate: 0.00918 
2025-03-18 15:31:14.683951: train_loss -0.7168 
2025-03-18 15:31:14.684279: val_loss -0.6821 
2025-03-18 15:31:14.684364: Pseudo dice [0.7507] 
2025-03-18 15:31:14.684458: Epoch time: 277.23 s 
2025-03-18 15:31:14.684514: Yayy! New best EMA pseudo Dice: 0.7256 
2025-03-18 15:31:17.814140:  
2025-03-18 15:31:17.814364: Epoch 92 
2025-03-18 15:31:17.814478: Current learning rate: 0.00917 
2025-03-18 15:35:54.811295: train_loss -0.7144 
2025-03-18 15:35:54.811690: val_loss -0.6163 
2025-03-18 15:35:54.811831: Pseudo dice [0.4805] 
2025-03-18 15:35:54.811920: Epoch time: 277.0 s 
2025-03-18 15:35:56.613037:  
2025-03-18 15:35:56.613253: Epoch 93 
2025-03-18 15:35:56.613383: Current learning rate: 0.00916 
2025-03-18 15:40:34.169755: train_loss -0.7006 
2025-03-18 15:40:34.170067: val_loss -0.7275 
2025-03-18 15:40:34.170153: Pseudo dice [0.7851] 
2025-03-18 15:40:34.170250: Epoch time: 277.56 s 
2025-03-18 15:40:35.984746:  
2025-03-18 15:40:35.984998: Epoch 94 
2025-03-18 15:40:35.985111: Current learning rate: 0.00915 
2025-03-18 15:45:11.843329: train_loss -0.7359 
2025-03-18 15:45:11.843645: val_loss -0.754 
2025-03-18 15:45:11.843727: Pseudo dice [0.8114] 
2025-03-18 15:45:11.843834: Epoch time: 275.86 s 
2025-03-18 15:45:13.627643:  
2025-03-18 15:45:13.627907: Epoch 95 
2025-03-18 15:45:13.628040: Current learning rate: 0.00914 
2025-03-18 15:49:47.921691: train_loss -0.7216 
2025-03-18 15:49:47.922042: val_loss -0.7177 
2025-03-18 15:49:47.922130: Pseudo dice [0.7263] 
2025-03-18 15:49:47.922230: Epoch time: 274.3 s 
2025-03-18 15:49:49.703884:  
2025-03-18 15:49:49.704093: Epoch 96 
2025-03-18 15:49:49.704211: Current learning rate: 0.00913 
2025-03-18 15:54:23.752053: train_loss -0.6877 
2025-03-18 15:54:23.752394: val_loss -0.7057 
2025-03-18 15:54:23.752488: Pseudo dice [0.6494] 
2025-03-18 15:54:23.752590: Epoch time: 274.05 s 
2025-03-18 15:54:25.566944:  
2025-03-18 15:54:25.567212: Epoch 97 
2025-03-18 15:54:25.567367: Current learning rate: 0.00912 
2025-03-18 15:59:04.532241: train_loss -0.6919 
2025-03-18 15:59:04.532795: val_loss -0.6584 
2025-03-18 15:59:04.532906: Pseudo dice [0.7026] 
2025-03-18 15:59:04.532988: Epoch time: 278.97 s 
2025-03-18 15:59:06.615116:  
2025-03-18 15:59:06.615303: Epoch 98 
2025-03-18 15:59:06.615450: Current learning rate: 0.00911 
2025-03-18 16:03:41.036153: train_loss -0.7133 
2025-03-18 16:03:41.036463: val_loss -0.7256 
2025-03-18 16:03:41.036591: Pseudo dice [0.7034] 
2025-03-18 16:03:41.036687: Epoch time: 274.42 s 
2025-03-18 16:03:42.854028:  
2025-03-18 16:03:42.854274: Epoch 99 
2025-03-18 16:03:42.854448: Current learning rate: 0.0091 
2025-03-18 16:08:17.366681: train_loss -0.6796 
2025-03-18 16:08:17.366978: val_loss -0.6842 
2025-03-18 16:08:17.367057: Pseudo dice [0.7505] 
2025-03-18 16:08:17.367146: Epoch time: 274.52 s 
2025-03-18 16:08:20.355578:  
2025-03-18 16:08:20.355798: Epoch 100 
2025-03-18 16:08:20.355976: Current learning rate: 0.0091 
2025-03-18 16:12:54.829266: train_loss -0.7025 
2025-03-18 16:12:54.829593: val_loss -0.7361 
2025-03-18 16:12:54.829683: Pseudo dice [0.7214] 
2025-03-18 16:12:54.829889: Epoch time: 274.48 s 
2025-03-18 16:12:56.646734:  
2025-03-18 16:12:56.646944: Epoch 101 
2025-03-18 16:12:56.647055: Current learning rate: 0.00909 
2025-03-18 16:17:31.039842: train_loss -0.7562 
2025-03-18 16:17:31.040147: val_loss -0.7088 
2025-03-18 16:17:31.040224: Pseudo dice [0.6766] 
2025-03-18 16:17:31.040326: Epoch time: 274.4 s 
2025-03-18 16:17:32.840621:  
2025-03-18 16:17:32.840806: Epoch 102 
2025-03-18 16:17:32.840951: Current learning rate: 0.00908 
2025-03-18 16:22:07.364232: train_loss -0.7543 
2025-03-18 16:22:07.364581: val_loss -0.6309 
2025-03-18 16:22:07.364675: Pseudo dice [0.6131] 
2025-03-18 16:22:07.364802: Epoch time: 274.53 s 
2025-03-18 16:22:09.179720:  
2025-03-18 16:22:09.179978: Epoch 103 
2025-03-18 16:22:09.180130: Current learning rate: 0.00907 
2025-03-18 16:26:51.641087: train_loss -0.718 
2025-03-18 16:26:51.641400: val_loss -0.5481 
2025-03-18 16:26:51.641539: Pseudo dice [0.483] 
2025-03-18 16:26:51.641637: Epoch time: 282.47 s 
2025-03-18 16:26:53.471906:  
2025-03-18 16:26:53.472086: Epoch 104 
2025-03-18 16:26:53.472199: Current learning rate: 0.00906 
2025-03-18 16:31:27.941128: train_loss -0.6807 
2025-03-18 16:31:27.941467: val_loss -0.6807 
2025-03-18 16:31:27.941554: Pseudo dice [0.7581] 
2025-03-18 16:31:27.941656: Epoch time: 274.47 s 
2025-03-18 16:31:29.779204:  
2025-03-18 16:31:29.779390: Epoch 105 
2025-03-18 16:31:29.779504: Current learning rate: 0.00905 
2025-03-18 16:36:05.381752: train_loss -0.7074 
2025-03-18 16:36:05.382106: val_loss -0.6208 
2025-03-18 16:36:05.382195: Pseudo dice [0.6743] 
2025-03-18 16:36:05.382293: Epoch time: 275.61 s 
2025-03-18 16:36:07.175810:  
2025-03-18 16:36:07.176008: Epoch 106 
2025-03-18 16:36:07.176120: Current learning rate: 0.00904 
2025-03-18 16:40:42.156708: train_loss -0.7035 
2025-03-18 16:40:42.157064: val_loss -0.7561 
2025-03-18 16:40:42.157150: Pseudo dice [0.7777] 
2025-03-18 16:40:42.157287: Epoch time: 274.98 s 
2025-03-18 16:40:44.284680:  
2025-03-18 16:40:44.284913: Epoch 107 
2025-03-18 16:40:44.285089: Current learning rate: 0.00903 
2025-03-18 16:45:18.689892: train_loss -0.7267 
2025-03-18 16:45:18.690211: val_loss -0.7539 
2025-03-18 16:45:18.690295: Pseudo dice [0.8398] 
2025-03-18 16:45:18.690450: Epoch time: 274.41 s 
2025-03-18 16:45:20.482956:  
2025-03-18 16:45:20.483150: Epoch 108 
2025-03-18 16:45:20.483306: Current learning rate: 0.00902 
2025-03-18 16:49:54.513944: train_loss -0.7509 
2025-03-18 16:49:54.514283: val_loss -0.7669 
2025-03-18 16:49:54.514376: Pseudo dice [0.8193] 
2025-03-18 16:49:54.514455: Epoch time: 274.03 s 
2025-03-18 16:49:56.350156:  
2025-03-18 16:49:56.350367: Epoch 109 
2025-03-18 16:49:56.350532: Current learning rate: 0.00901 
2025-03-18 16:54:30.948674: train_loss -0.7569 
2025-03-18 16:54:30.949034: val_loss -0.7306 
2025-03-18 16:54:30.949129: Pseudo dice [0.7176] 
2025-03-18 16:54:30.949226: Epoch time: 274.6 s 
2025-03-18 16:54:32.747314:  
2025-03-18 16:54:32.747560: Epoch 110 
2025-03-18 16:54:32.747675: Current learning rate: 0.009 
2025-03-18 16:59:07.443897: train_loss -0.7127 
2025-03-18 16:59:07.444252: val_loss -0.7182 
2025-03-18 16:59:07.444344: Pseudo dice [0.7362] 
2025-03-18 16:59:07.444446: Epoch time: 274.7 s 
2025-03-18 16:59:09.287817:  
2025-03-18 16:59:09.288064: Epoch 111 
2025-03-18 16:59:09.288182: Current learning rate: 0.009 
2025-03-18 17:03:44.840653: train_loss -0.7041 
2025-03-18 17:03:44.841004: val_loss -0.7741 
2025-03-18 17:03:44.841100: Pseudo dice [0.8251] 
2025-03-18 17:03:44.841255: Epoch time: 275.56 s 
2025-03-18 17:03:44.841314: Yayy! New best EMA pseudo Dice: 0.7325 
2025-03-18 17:03:47.920768:  
2025-03-18 17:03:47.921093: Epoch 112 
2025-03-18 17:03:47.921232: Current learning rate: 0.00899 
2025-03-18 17:08:23.279037: train_loss -0.7106 
2025-03-18 17:08:23.279332: val_loss -0.7157 
2025-03-18 17:08:23.279458: Pseudo dice [0.7777] 
2025-03-18 17:08:23.279591: Epoch time: 275.36 s 
2025-03-18 17:08:23.279657: Yayy! New best EMA pseudo Dice: 0.737 
2025-03-18 17:08:26.414687:  
2025-03-18 17:08:26.414849: Epoch 113 
2025-03-18 17:08:26.414968: Current learning rate: 0.00898 
2025-03-18 17:13:01.713300: train_loss -0.7434 
2025-03-18 17:13:01.713600: val_loss -0.7583 
2025-03-18 17:13:01.713679: Pseudo dice [0.8048] 
2025-03-18 17:13:01.713768: Epoch time: 275.3 s 
2025-03-18 17:13:01.713841: Yayy! New best EMA pseudo Dice: 0.7438 
2025-03-18 17:13:04.832397:  
2025-03-18 17:13:04.832574: Epoch 114 
2025-03-18 17:13:04.832716: Current learning rate: 0.00897 
2025-03-18 17:17:40.107879: train_loss -0.7183 
2025-03-18 17:17:40.108227: val_loss -0.7444 
2025-03-18 17:17:40.108312: Pseudo dice [0.8079] 
2025-03-18 17:17:40.108412: Epoch time: 275.28 s 
2025-03-18 17:17:40.108473: Yayy! New best EMA pseudo Dice: 0.7502 
2025-03-18 17:17:43.585660:  
2025-03-18 17:17:43.585893: Epoch 115 
2025-03-18 17:17:43.586008: Current learning rate: 0.00896 
2025-03-18 17:22:19.002749: train_loss -0.7427 
2025-03-18 17:22:19.003186: val_loss -0.7342 
2025-03-18 17:22:19.003286: Pseudo dice [0.7421] 
2025-03-18 17:22:19.003366: Epoch time: 275.42 s 
2025-03-18 17:22:20.831842:  
2025-03-18 17:22:20.832081: Epoch 116 
2025-03-18 17:22:20.832208: Current learning rate: 0.00895 
2025-03-18 17:26:56.641832: train_loss -0.7027 
2025-03-18 17:26:56.642147: val_loss -0.6406 
2025-03-18 17:26:56.642231: Pseudo dice [0.6398] 
2025-03-18 17:26:56.642334: Epoch time: 275.81 s 
2025-03-18 17:26:58.468650:  
2025-03-18 17:26:58.468894: Epoch 117 
2025-03-18 17:26:58.469037: Current learning rate: 0.00894 
2025-03-18 17:31:33.819330: train_loss -0.7422 
2025-03-18 17:31:33.819676: val_loss -0.7424 
2025-03-18 17:31:33.819783: Pseudo dice [0.7736] 
2025-03-18 17:31:33.819883: Epoch time: 275.35 s 
2025-03-18 17:31:35.664782:  
2025-03-18 17:31:35.665088: Epoch 118 
2025-03-18 17:31:35.665250: Current learning rate: 0.00893 
2025-03-18 17:36:11.206917: train_loss -0.7419 
2025-03-18 17:36:11.207215: val_loss -0.7353 
2025-03-18 17:36:11.207365: Pseudo dice [0.82] 
2025-03-18 17:36:11.207463: Epoch time: 275.55 s 
2025-03-18 17:36:13.031538:  
2025-03-18 17:36:13.031813: Epoch 119 
2025-03-18 17:36:13.031992: Current learning rate: 0.00892 
2025-03-18 17:40:48.855447: train_loss -0.7332 
2025-03-18 17:40:48.855837: val_loss -0.7568 
2025-03-18 17:40:48.855930: Pseudo dice [0.7905] 
2025-03-18 17:40:48.856054: Epoch time: 275.83 s 
2025-03-18 17:40:48.856113: Yayy! New best EMA pseudo Dice: 0.7538 
2025-03-18 17:40:51.992195:  
2025-03-18 17:40:51.992379: Epoch 120 
2025-03-18 17:40:51.992524: Current learning rate: 0.00891 
