
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-30 14:09:22.990454: Using torch.compile... 
2025-03-30 14:09:22.995260: do_dummy_2d_data_aug: False 
2025-03-30 14:09:22.996442: Using splits from existing split file: /mrhung_nguyen_minh_quang_108/workspace/train/nnUNet_preprocessed/Dataset015_lungTumor/splits_final.json 
2025-03-30 14:09:22.996835: The split file contains 5 splits. 
2025-03-30 14:09:22.996885: Desired fold for training: 2 
2025-03-30 14:09:22.996920: This split has 92 training and 23 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [251.0, 512.0, 512.0], 'spacing': [1.25, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset015_lungTumor', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [1.25, 0.78125, 0.78125], 'original_median_shape_after_transp': [251, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2750.0, 'mean': -292.26348876953125, 'median': -205.0, 'min': -1270.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 308.0, 'std': 352.5594787597656}}} 
 
2025-03-30 14:09:32.147642: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-03-30 14:09:32.190072:  
2025-03-30 14:09:32.190446: Epoch 0 
2025-03-30 14:09:32.190657: Current learning rate: 0.01 
2025-03-30 14:14:22.724112: train_loss -0.0197 
2025-03-30 14:14:22.724364: val_loss -0.13 
2025-03-30 14:14:22.724490: Pseudo dice [0.0] 
2025-03-30 14:14:22.724605: Epoch time: 290.54 s 
2025-03-30 14:14:22.724733: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-30 14:14:25.530796:  
2025-03-30 14:14:25.530992: Epoch 1 
2025-03-30 14:14:25.531110: Current learning rate: 0.00999 
2025-03-30 14:19:00.799193: train_loss -0.2987 
2025-03-30 14:19:00.799576: val_loss -0.2831 
2025-03-30 14:19:00.799669: Pseudo dice [0.2695] 
2025-03-30 14:19:00.799767: Epoch time: 275.27 s 
2025-03-30 14:19:00.799858: Yayy! New best EMA pseudo Dice: 0.027 
2025-03-30 14:19:03.988893:  
2025-03-30 14:19:03.989108: Epoch 2 
2025-03-30 14:19:03.989225: Current learning rate: 0.00998 
2025-03-30 14:23:38.611064: train_loss -0.4532 
2025-03-30 14:23:38.611398: val_loss -0.3893 
2025-03-30 14:23:38.611484: Pseudo dice [0.3237] 
2025-03-30 14:23:38.611579: Epoch time: 274.63 s 
2025-03-30 14:23:38.611635: Yayy! New best EMA pseudo Dice: 0.0566 
2025-03-30 14:23:41.838709:  
2025-03-30 14:23:41.838894: Epoch 3 
2025-03-30 14:23:41.839020: Current learning rate: 0.00997 
2025-03-30 14:28:16.189010: train_loss -0.4828 
2025-03-30 14:28:16.189403: val_loss -0.3225 
2025-03-30 14:28:16.189500: Pseudo dice [0.1789] 
2025-03-30 14:28:16.189584: Epoch time: 274.35 s 
2025-03-30 14:28:16.189670: Yayy! New best EMA pseudo Dice: 0.0689 
2025-03-30 14:28:19.332934:  
2025-03-30 14:28:19.333113: Epoch 4 
2025-03-30 14:28:19.333244: Current learning rate: 0.00996 
2025-03-30 14:32:53.485929: train_loss -0.5537 
2025-03-30 14:32:53.486228: val_loss -0.4378 
2025-03-30 14:32:53.486313: Pseudo dice [0.3443] 
2025-03-30 14:32:53.486419: Epoch time: 274.16 s 
2025-03-30 14:32:53.486492: Yayy! New best EMA pseudo Dice: 0.0964 
2025-03-30 14:32:56.708874:  
2025-03-30 14:32:56.709105: Epoch 5 
2025-03-30 14:32:56.709249: Current learning rate: 0.00995 
2025-03-30 14:37:30.918308: train_loss -0.5147 
2025-03-30 14:37:30.918606: val_loss -0.4073 
2025-03-30 14:37:30.918689: Pseudo dice [0.281] 
2025-03-30 14:37:30.918779: Epoch time: 274.21 s 
2025-03-30 14:37:30.918852: Yayy! New best EMA pseudo Dice: 0.1149 
2025-03-30 14:37:34.114933:  
2025-03-30 14:37:34.115174: Epoch 6 
2025-03-30 14:37:34.115316: Current learning rate: 0.00995 
2025-03-30 14:42:08.148605: train_loss -0.5352 
2025-03-30 14:42:08.148942: val_loss -0.4286 
2025-03-30 14:42:08.149037: Pseudo dice [0.3734] 
2025-03-30 14:42:08.149129: Epoch time: 274.04 s 
2025-03-30 14:42:08.149189: Yayy! New best EMA pseudo Dice: 0.1407 
2025-03-30 14:42:11.316518:  
2025-03-30 14:42:11.316707: Epoch 7 
2025-03-30 14:42:11.316823: Current learning rate: 0.00994 
2025-03-30 14:46:45.498387: train_loss -0.5486 
2025-03-30 14:46:45.498723: val_loss -0.4445 
2025-03-30 14:46:45.498812: Pseudo dice [0.3565] 
2025-03-30 14:46:45.498912: Epoch time: 274.19 s 
2025-03-30 14:46:45.498980: Yayy! New best EMA pseudo Dice: 0.1623 
2025-03-30 14:46:48.687870:  
2025-03-30 14:46:48.688066: Epoch 8 
2025-03-30 14:46:48.688184: Current learning rate: 0.00993 
2025-03-30 14:51:23.202952: train_loss -0.5342 
2025-03-30 14:51:23.203297: val_loss -0.4874 
2025-03-30 14:51:23.203457: Pseudo dice [0.3718] 
2025-03-30 14:51:23.203579: Epoch time: 274.52 s 
2025-03-30 14:51:23.203639: Yayy! New best EMA pseudo Dice: 0.1832 
2025-03-30 14:51:26.467420:  
2025-03-30 14:51:26.467620: Epoch 9 
2025-03-30 14:51:26.467739: Current learning rate: 0.00992 
2025-03-30 14:56:00.732790: train_loss -0.5712 
2025-03-30 14:56:00.733111: val_loss -0.2752 
2025-03-30 14:56:00.733196: Pseudo dice [0.3282] 
2025-03-30 14:56:00.733279: Epoch time: 274.27 s 
2025-03-30 14:56:00.733347: Yayy! New best EMA pseudo Dice: 0.1977 
2025-03-30 14:56:03.918697:  
2025-03-30 14:56:03.918886: Epoch 10 
2025-03-30 14:56:03.919041: Current learning rate: 0.00991 
2025-03-30 15:00:38.627110: train_loss -0.5901 
2025-03-30 15:00:38.627428: val_loss -0.4827 
2025-03-30 15:00:38.627520: Pseudo dice [0.3634] 
2025-03-30 15:00:38.627631: Epoch time: 274.71 s 
2025-03-30 15:00:38.627694: Yayy! New best EMA pseudo Dice: 0.2143 
2025-03-30 15:00:41.810838:  
2025-03-30 15:00:41.811102: Epoch 11 
2025-03-30 15:00:41.811252: Current learning rate: 0.0099 
2025-03-30 15:05:17.104799: train_loss -0.5813 
2025-03-30 15:05:17.105169: val_loss -0.474 
2025-03-30 15:05:17.105259: Pseudo dice [0.2575] 
2025-03-30 15:05:17.105349: Epoch time: 275.3 s 
2025-03-30 15:05:17.105408: Yayy! New best EMA pseudo Dice: 0.2186 
2025-03-30 15:05:20.239798:  
2025-03-30 15:05:20.239996: Epoch 12 
2025-03-30 15:05:20.240108: Current learning rate: 0.00989 
2025-03-30 15:09:54.235303: train_loss -0.6067 
2025-03-30 15:09:54.235620: val_loss -0.4555 
2025-03-30 15:09:54.235722: Pseudo dice [0.4094] 
2025-03-30 15:09:54.235820: Epoch time: 274.0 s 
2025-03-30 15:09:54.235893: Yayy! New best EMA pseudo Dice: 0.2377 
2025-03-30 15:09:57.401526:  
2025-03-30 15:09:57.401743: Epoch 13 
2025-03-30 15:09:57.401863: Current learning rate: 0.00988 
2025-03-30 15:14:31.292129: train_loss -0.61 
2025-03-30 15:14:31.292450: val_loss -0.4777 
2025-03-30 15:14:31.292552: Pseudo dice [0.3281] 
2025-03-30 15:14:31.292753: Epoch time: 273.89 s 
2025-03-30 15:14:31.292867: Yayy! New best EMA pseudo Dice: 0.2467 
2025-03-30 15:14:34.454168:  
2025-03-30 15:14:34.454424: Epoch 14 
2025-03-30 15:14:34.454588: Current learning rate: 0.00987 
2025-03-30 15:19:08.213832: train_loss -0.6457 
2025-03-30 15:19:08.214121: val_loss -0.4175 
2025-03-30 15:19:08.214206: Pseudo dice [0.3347] 
2025-03-30 15:19:08.214287: Epoch time: 273.76 s 
2025-03-30 15:19:08.214356: Yayy! New best EMA pseudo Dice: 0.2555 
2025-03-30 15:19:11.672391:  
2025-03-30 15:19:11.672624: Epoch 15 
2025-03-30 15:19:11.672804: Current learning rate: 0.00986 
2025-03-30 15:23:45.287717: train_loss -0.6643 
2025-03-30 15:23:45.288082: val_loss -0.4353 
2025-03-30 15:23:45.288171: Pseudo dice [0.2883] 
2025-03-30 15:23:45.288284: Epoch time: 273.62 s 
2025-03-30 15:23:45.288368: Yayy! New best EMA pseudo Dice: 0.2588 
2025-03-30 15:23:48.477378:  
2025-03-30 15:23:48.477776: Epoch 16 
2025-03-30 15:23:48.477937: Current learning rate: 0.00986 
2025-03-30 15:28:22.926422: train_loss -0.677 
2025-03-30 15:28:22.926734: val_loss -0.4962 
2025-03-30 15:28:22.926829: Pseudo dice [0.3962] 
2025-03-30 15:28:22.926917: Epoch time: 274.45 s 
2025-03-30 15:28:22.926992: Yayy! New best EMA pseudo Dice: 0.2726 
2025-03-30 15:28:26.176515:  
2025-03-30 15:28:26.176712: Epoch 17 
2025-03-30 15:28:26.176831: Current learning rate: 0.00985 
2025-03-30 15:33:00.791818: train_loss -0.6484 
2025-03-30 15:33:00.792138: val_loss -0.3784 
2025-03-30 15:33:00.792228: Pseudo dice [0.2627] 
2025-03-30 15:33:00.792327: Epoch time: 274.62 s 
2025-03-30 15:33:02.706164:  
2025-03-30 15:33:02.706377: Epoch 18 
2025-03-30 15:33:02.706532: Current learning rate: 0.00984 
2025-03-30 15:37:37.262435: train_loss -0.634 
2025-03-30 15:37:37.262733: val_loss -0.4369 
2025-03-30 15:37:37.262810: Pseudo dice [0.4348] 
2025-03-30 15:37:37.262892: Epoch time: 274.56 s 
2025-03-30 15:37:37.262982: Yayy! New best EMA pseudo Dice: 0.2879 
2025-03-30 15:37:40.464573:  
2025-03-30 15:37:40.464782: Epoch 19 
2025-03-30 15:37:40.464964: Current learning rate: 0.00983 
2025-03-30 15:42:15.094780: train_loss -0.6531 
2025-03-30 15:42:15.095332: val_loss -0.6037 
2025-03-30 15:42:15.095417: Pseudo dice [0.5471] 
2025-03-30 15:42:15.095507: Epoch time: 274.63 s 
2025-03-30 15:42:15.095640: Yayy! New best EMA pseudo Dice: 0.3138 
2025-03-30 15:42:18.308051:  
2025-03-30 15:42:18.308253: Epoch 20 
2025-03-30 15:42:18.308381: Current learning rate: 0.00982 
2025-03-30 15:46:51.893428: train_loss -0.6679 
2025-03-30 15:46:51.893775: val_loss -0.509 
2025-03-30 15:46:51.893868: Pseudo dice [0.4455] 
2025-03-30 15:46:51.893976: Epoch time: 273.59 s 
2025-03-30 15:46:51.894037: Yayy! New best EMA pseudo Dice: 0.327 
2025-03-30 15:46:55.118802:  
2025-03-30 15:46:55.119069: Epoch 21 
2025-03-30 15:46:55.119185: Current learning rate: 0.00981 
2025-03-30 15:51:28.459585: train_loss -0.6416 
2025-03-30 15:51:28.459983: val_loss -0.4897 
2025-03-30 15:51:28.460085: Pseudo dice [0.4144] 
2025-03-30 15:51:28.460180: Epoch time: 273.34 s 
2025-03-30 15:51:28.460240: Yayy! New best EMA pseudo Dice: 0.3357 
2025-03-30 15:51:31.888253:  
2025-03-30 15:51:31.888443: Epoch 22 
2025-03-30 15:51:31.888563: Current learning rate: 0.0098 
2025-03-30 15:56:05.193286: train_loss -0.6455 
2025-03-30 15:56:05.193716: val_loss -0.5057 
2025-03-30 15:56:05.193817: Pseudo dice [0.4192] 
2025-03-30 15:56:05.193913: Epoch time: 273.31 s 
2025-03-30 15:56:05.193996: Yayy! New best EMA pseudo Dice: 0.3441 
2025-03-30 15:56:08.351517:  
2025-03-30 15:56:08.351773: Epoch 23 
2025-03-30 15:56:08.351913: Current learning rate: 0.00979 
2025-03-30 16:00:41.838708: train_loss -0.6788 
2025-03-30 16:00:41.839029: val_loss -0.4618 
2025-03-30 16:00:41.839112: Pseudo dice [0.4737] 
2025-03-30 16:00:41.839229: Epoch time: 273.49 s 
2025-03-30 16:00:41.839291: Yayy! New best EMA pseudo Dice: 0.357 
2025-03-30 16:00:44.994564:  
2025-03-30 16:00:44.994788: Epoch 24 
2025-03-30 16:00:44.994920: Current learning rate: 0.00978 
2025-03-30 16:05:19.146341: train_loss -0.6731 
2025-03-30 16:05:19.146646: val_loss -0.394 
2025-03-30 16:05:19.146735: Pseudo dice [0.2533] 
2025-03-30 16:05:19.146824: Epoch time: 274.16 s 
2025-03-30 16:05:21.001516:  
2025-03-30 16:05:21.001680: Epoch 25 
2025-03-30 16:05:21.001798: Current learning rate: 0.00977 
2025-03-30 16:09:55.541473: train_loss -0.6529 
2025-03-30 16:09:55.541845: val_loss -0.5031 
2025-03-30 16:09:55.541935: Pseudo dice [0.3252] 
2025-03-30 16:09:55.542030: Epoch time: 274.54 s 
2025-03-30 16:09:57.375173:  
2025-03-30 16:09:57.375375: Epoch 26 
2025-03-30 16:09:57.375534: Current learning rate: 0.00977 
2025-03-30 16:14:31.176918: train_loss -0.6334 
2025-03-30 16:14:31.177222: val_loss -0.3818 
2025-03-30 16:14:31.177306: Pseudo dice [0.3467] 
2025-03-30 16:14:31.177396: Epoch time: 273.81 s 
2025-03-30 16:14:33.036085:  
2025-03-30 16:14:33.036275: Epoch 27 
2025-03-30 16:14:33.036507: Current learning rate: 0.00976 
2025-03-30 16:19:07.027090: train_loss -0.6514 
2025-03-30 16:19:07.027406: val_loss -0.5746 
2025-03-30 16:19:07.027500: Pseudo dice [0.601] 
2025-03-30 16:19:07.027616: Epoch time: 273.99 s 
2025-03-30 16:19:07.027676: Yayy! New best EMA pseudo Dice: 0.3704 
2025-03-30 16:19:10.216323:  
2025-03-30 16:19:10.216572: Epoch 28 
2025-03-30 16:19:10.216737: Current learning rate: 0.00975 
2025-03-30 16:23:44.311050: train_loss -0.6956 
2025-03-30 16:23:44.311404: val_loss -0.5684 
2025-03-30 16:23:44.311493: Pseudo dice [0.4348] 
2025-03-30 16:23:44.311593: Epoch time: 274.1 s 
2025-03-30 16:23:44.311649: Yayy! New best EMA pseudo Dice: 0.3768 
2025-03-30 16:23:47.504572:  
2025-03-30 16:23:47.504807: Epoch 29 
2025-03-30 16:23:47.504978: Current learning rate: 0.00974 
2025-03-30 16:28:21.641144: train_loss -0.6923 
2025-03-30 16:28:21.641529: val_loss -0.4729 
2025-03-30 16:28:21.641621: Pseudo dice [0.4582] 
2025-03-30 16:28:21.641709: Epoch time: 274.14 s 
2025-03-30 16:28:21.641785: Yayy! New best EMA pseudo Dice: 0.3849 
2025-03-30 16:28:24.836764:  
2025-03-30 16:28:24.837048: Epoch 30 
2025-03-30 16:28:24.837175: Current learning rate: 0.00973 
2025-03-30 16:32:59.152083: train_loss -0.6844 
2025-03-30 16:32:59.152440: val_loss -0.2873 
2025-03-30 16:32:59.152531: Pseudo dice [0.2637] 
2025-03-30 16:32:59.152623: Epoch time: 274.32 s 
2025-03-30 16:33:01.022190:  
2025-03-30 16:33:01.022486: Epoch 31 
2025-03-30 16:33:01.022614: Current learning rate: 0.00972 
2025-03-30 16:37:35.239143: train_loss -0.6776 
2025-03-30 16:37:35.239446: val_loss -0.4762 
2025-03-30 16:37:35.239534: Pseudo dice [0.3321] 
2025-03-30 16:37:35.239624: Epoch time: 274.22 s 
2025-03-30 16:37:37.107238:  
2025-03-30 16:37:37.107441: Epoch 32 
2025-03-30 16:37:37.107558: Current learning rate: 0.00971 
2025-03-30 16:42:11.508002: train_loss -0.6736 
2025-03-30 16:42:11.508302: val_loss -0.4313 
2025-03-30 16:42:11.508389: Pseudo dice [0.3668] 
2025-03-30 16:42:11.508491: Epoch time: 274.4 s 
2025-03-30 16:42:13.394317:  
2025-03-30 16:42:13.394514: Epoch 33 
2025-03-30 16:42:13.394628: Current learning rate: 0.0097 
2025-03-30 16:46:47.155739: train_loss -0.6925 
2025-03-30 16:46:47.156074: val_loss -0.4597 
2025-03-30 16:46:47.156379: Pseudo dice [0.3289] 
2025-03-30 16:46:47.156464: Epoch time: 273.77 s 
2025-03-30 16:46:49.027805:  
2025-03-30 16:46:49.028016: Epoch 34 
2025-03-30 16:46:49.028140: Current learning rate: 0.00969 
2025-03-30 16:51:23.313892: train_loss -0.6863 
2025-03-30 16:51:23.314246: val_loss -0.4883 
2025-03-30 16:51:23.314332: Pseudo dice [0.4668] 
2025-03-30 16:51:23.314497: Epoch time: 274.29 s 
2025-03-30 16:51:25.204184:  
2025-03-30 16:51:25.204417: Epoch 35 
2025-03-30 16:51:25.204553: Current learning rate: 0.00968 
2025-03-30 16:55:59.688345: train_loss -0.6648 
2025-03-30 16:55:59.688683: val_loss -0.3476 
2025-03-30 16:55:59.688775: Pseudo dice [0.3362] 
2025-03-30 16:55:59.688892: Epoch time: 274.49 s 
2025-03-30 16:56:01.581613:  
2025-03-30 16:56:01.581798: Epoch 36 
2025-03-30 16:56:01.581909: Current learning rate: 0.00968 
2025-03-30 17:00:36.232511: train_loss -0.7023 
2025-03-30 17:00:36.232839: val_loss -0.4604 
2025-03-30 17:00:36.232927: Pseudo dice [0.41] 
2025-03-30 17:00:36.233035: Epoch time: 274.65 s 
2025-03-30 17:00:38.434715:  
2025-03-30 17:00:38.434964: Epoch 37 
2025-03-30 17:00:38.435110: Current learning rate: 0.00967 
2025-03-30 17:05:13.306962: train_loss -0.6694 
2025-03-30 17:05:13.307311: val_loss -0.5782 
2025-03-30 17:05:13.307390: Pseudo dice [0.5814] 
2025-03-30 17:05:13.307505: Epoch time: 274.88 s 
2025-03-30 17:05:13.307561: Yayy! New best EMA pseudo Dice: 0.3955 
2025-03-30 17:05:16.567894:  
2025-03-30 17:05:16.568203: Epoch 38 
2025-03-30 17:05:16.568347: Current learning rate: 0.00966 
2025-03-30 17:09:50.971645: train_loss -0.7151 
2025-03-30 17:09:50.971969: val_loss -0.5097 
2025-03-30 17:09:50.972054: Pseudo dice [0.4985] 
2025-03-30 17:09:50.972152: Epoch time: 274.41 s 
2025-03-30 17:09:50.972212: Yayy! New best EMA pseudo Dice: 0.4058 
2025-03-30 17:09:54.210778:  
2025-03-30 17:09:54.210992: Epoch 39 
2025-03-30 17:09:54.211116: Current learning rate: 0.00965 
2025-03-30 17:14:28.121015: train_loss -0.7045 
2025-03-30 17:14:28.121470: val_loss -0.5205 
2025-03-30 17:14:28.121597: Pseudo dice [0.4532] 
2025-03-30 17:14:28.121683: Epoch time: 273.91 s 
2025-03-30 17:14:28.121745: Yayy! New best EMA pseudo Dice: 0.4106 
2025-03-30 17:14:31.422201:  
2025-03-30 17:14:31.422503: Epoch 40 
2025-03-30 17:14:31.422660: Current learning rate: 0.00964 
2025-03-30 17:19:05.727951: train_loss -0.7046 
2025-03-30 17:19:05.728267: val_loss -0.5778 
2025-03-30 17:19:05.728580: Pseudo dice [0.5553] 
2025-03-30 17:19:05.728665: Epoch time: 274.31 s 
2025-03-30 17:19:05.728728: Yayy! New best EMA pseudo Dice: 0.425 
2025-03-30 17:19:08.996632:  
2025-03-30 17:19:08.996828: Epoch 41 
2025-03-30 17:19:08.996946: Current learning rate: 0.00963 
2025-03-30 17:23:43.396464: train_loss -0.6789 
2025-03-30 17:23:43.396784: val_loss -0.507 
2025-03-30 17:23:43.396882: Pseudo dice [0.534] 
2025-03-30 17:23:43.396993: Epoch time: 274.4 s 
2025-03-30 17:23:43.397083: Yayy! New best EMA pseudo Dice: 0.4359 
2025-03-30 17:23:46.563516:  
2025-03-30 17:23:46.563758: Epoch 42 
2025-03-30 17:23:46.563915: Current learning rate: 0.00962 
2025-03-30 17:28:20.689322: train_loss -0.7061 
2025-03-30 17:28:20.689656: val_loss -0.5423 
2025-03-30 17:28:20.689742: Pseudo dice [0.4268] 
2025-03-30 17:28:20.689846: Epoch time: 274.13 s 
2025-03-30 17:28:22.519691:  
2025-03-30 17:28:22.519902: Epoch 43 
2025-03-30 17:28:22.520020: Current learning rate: 0.00961 
2025-03-30 17:32:56.731665: train_loss -0.6891 
2025-03-30 17:32:56.732034: val_loss -0.5886 
2025-03-30 17:32:56.732122: Pseudo dice [0.6292] 
2025-03-30 17:32:56.732222: Epoch time: 274.22 s 
2025-03-30 17:32:56.732281: Yayy! New best EMA pseudo Dice: 0.4544 
2025-03-30 17:33:00.181268:  
2025-03-30 17:33:00.181507: Epoch 44 
2025-03-30 17:33:00.181658: Current learning rate: 0.0096 
2025-03-30 17:37:34.310528: train_loss -0.707 
2025-03-30 17:37:34.310863: val_loss -0.5181 
2025-03-30 17:37:34.310956: Pseudo dice [0.4539] 
2025-03-30 17:37:34.311060: Epoch time: 274.13 s 
2025-03-30 17:37:36.135739:  
2025-03-30 17:37:36.135968: Epoch 45 
2025-03-30 17:37:36.136091: Current learning rate: 0.00959 
2025-03-30 17:42:10.345997: train_loss -0.7025 
2025-03-30 17:42:10.346302: val_loss -0.5146 
2025-03-30 17:42:10.346387: Pseudo dice [0.3899] 
2025-03-30 17:42:10.346483: Epoch time: 274.21 s 
2025-03-30 17:42:12.185043:  
2025-03-30 17:42:12.185290: Epoch 46 
2025-03-30 17:42:12.185420: Current learning rate: 0.00959 
2025-03-30 17:46:46.648927: train_loss -0.6925 
2025-03-30 17:46:46.649263: val_loss -0.3879 
2025-03-30 17:46:46.649368: Pseudo dice [0.2827] 
2025-03-30 17:46:46.649472: Epoch time: 274.47 s 
2025-03-30 17:46:48.481625:  
2025-03-30 17:46:48.481961: Epoch 47 
2025-03-30 17:46:48.482172: Current learning rate: 0.00958 
2025-03-30 17:51:22.614257: train_loss -0.711 
2025-03-30 17:51:22.614610: val_loss -0.5059 
2025-03-30 17:51:22.614708: Pseudo dice [0.438] 
2025-03-30 17:51:22.614854: Epoch time: 274.14 s 
2025-03-30 17:51:24.432336:  
2025-03-30 17:51:24.432515: Epoch 48 
2025-03-30 17:51:24.432672: Current learning rate: 0.00957 
2025-03-30 17:55:58.627213: train_loss -0.6941 
2025-03-30 17:55:58.627607: val_loss -0.3916 
2025-03-30 17:55:58.627709: Pseudo dice [0.278] 
2025-03-30 17:55:58.627816: Epoch time: 274.2 s 
2025-03-30 17:56:00.476874:  
2025-03-30 17:56:00.477117: Epoch 49 
2025-03-30 17:56:00.477232: Current learning rate: 0.00956 
2025-03-30 18:00:34.891526: train_loss -0.6724 
2025-03-30 18:00:34.891905: val_loss -0.4917 
2025-03-30 18:00:34.892004: Pseudo dice [0.4912] 
2025-03-30 18:00:34.892111: Epoch time: 274.42 s 
2025-03-30 18:00:37.666805:  
2025-03-30 18:00:37.667051: Epoch 50 
2025-03-30 18:00:37.667280: Current learning rate: 0.00955 
2025-03-30 18:05:11.832834: train_loss -0.7199 
2025-03-30 18:05:11.833213: val_loss -0.2644 
2025-03-30 18:05:11.833303: Pseudo dice [0.1612] 
2025-03-30 18:05:11.833428: Epoch time: 274.17 s 
2025-03-30 18:05:13.671450:  
2025-03-30 18:05:13.671644: Epoch 51 
2025-03-30 18:05:13.671782: Current learning rate: 0.00954 
2025-03-30 18:09:47.847301: train_loss -0.6923 
2025-03-30 18:09:47.847591: val_loss -0.4613 
2025-03-30 18:09:47.847697: Pseudo dice [0.3625] 
2025-03-30 18:09:47.847875: Epoch time: 274.18 s 
2025-03-30 18:09:49.993918:  
2025-03-30 18:09:49.994196: Epoch 52 
2025-03-30 18:09:49.994350: Current learning rate: 0.00953 
2025-03-30 18:14:24.469713: train_loss -0.706 
2025-03-30 18:14:24.470092: val_loss -0.4557 
2025-03-30 18:14:24.470183: Pseudo dice [0.4826] 
2025-03-30 18:14:24.470273: Epoch time: 274.48 s 
2025-03-30 18:14:26.319469:  
2025-03-30 18:14:26.319661: Epoch 53 
2025-03-30 18:14:26.319794: Current learning rate: 0.00952 
2025-03-30 18:19:00.473371: train_loss -0.7347 
2025-03-30 18:19:00.473731: val_loss -0.5606 
2025-03-30 18:19:00.474053: Pseudo dice [0.566] 
2025-03-30 18:19:00.474141: Epoch time: 274.16 s 
2025-03-30 18:19:02.338476:  
2025-03-30 18:19:02.338734: Epoch 54 
2025-03-30 18:19:02.338868: Current learning rate: 0.00951 
2025-03-30 18:23:36.784767: train_loss -0.7235 
2025-03-30 18:23:36.785086: val_loss -0.5412 
2025-03-30 18:23:36.785174: Pseudo dice [0.4239] 
2025-03-30 18:23:36.785319: Epoch time: 274.45 s 
2025-03-30 18:23:38.649500:  
2025-03-30 18:23:38.649643: Epoch 55 
2025-03-30 18:23:38.649754: Current learning rate: 0.0095 
2025-03-30 18:28:13.148252: train_loss -0.6845 
2025-03-30 18:28:13.148570: val_loss -0.5404 
2025-03-30 18:28:13.148659: Pseudo dice [0.4161] 
2025-03-30 18:28:13.148763: Epoch time: 274.5 s 
2025-03-30 18:28:14.998888:  
2025-03-30 18:28:14.999113: Epoch 56 
2025-03-30 18:28:14.999254: Current learning rate: 0.00949 
2025-03-30 18:32:49.337317: train_loss -0.7392 
2025-03-30 18:32:49.337623: val_loss -0.4659 
2025-03-30 18:32:49.337711: Pseudo dice [0.4281] 
2025-03-30 18:32:49.337799: Epoch time: 274.34 s 
2025-03-30 18:32:51.207150:  
2025-03-30 18:32:51.207356: Epoch 57 
2025-03-30 18:32:51.207475: Current learning rate: 0.00949 
2025-03-30 18:37:25.268070: train_loss -0.7318 
2025-03-30 18:37:25.268450: val_loss -0.4677 
2025-03-30 18:37:25.268556: Pseudo dice [0.4282] 
2025-03-30 18:37:25.268641: Epoch time: 274.06 s 
2025-03-30 18:37:27.121690:  
2025-03-30 18:37:27.122011: Epoch 58 
2025-03-30 18:37:27.122183: Current learning rate: 0.00948 
2025-03-30 18:42:01.460222: train_loss -0.7263 
2025-03-30 18:42:01.460607: val_loss -0.5511 
2025-03-30 18:42:01.460700: Pseudo dice [0.5791] 
2025-03-30 18:42:01.460816: Epoch time: 274.34 s 
2025-03-30 18:42:03.338295:  
2025-03-30 18:42:03.338481: Epoch 59 
2025-03-30 18:42:03.338638: Current learning rate: 0.00947 
2025-03-30 18:46:37.271640: train_loss -0.755 
2025-03-30 18:46:37.272018: val_loss -0.5997 
2025-03-30 18:46:37.272109: Pseudo dice [0.6386] 
2025-03-30 18:46:37.272216: Epoch time: 273.94 s 
2025-03-30 18:46:37.272279: Yayy! New best EMA pseudo Dice: 0.4571 
2025-03-30 18:46:40.776178:  
2025-03-30 18:46:40.776394: Epoch 60 
2025-03-30 18:46:40.776509: Current learning rate: 0.00946 
2025-03-30 18:51:14.991448: train_loss -0.7293 
2025-03-30 18:51:14.991765: val_loss -0.6549 
2025-03-30 18:51:14.991856: Pseudo dice [0.7065] 
2025-03-30 18:51:14.992024: Epoch time: 274.22 s 
2025-03-30 18:51:14.992084: Yayy! New best EMA pseudo Dice: 0.482 
2025-03-30 18:51:18.204185:  
2025-03-30 18:51:18.204343: Epoch 61 
2025-03-30 18:51:18.204467: Current learning rate: 0.00945 
2025-03-30 18:55:52.590863: train_loss -0.7166 
2025-03-30 18:55:52.591215: val_loss -0.5101 
2025-03-30 18:55:52.591310: Pseudo dice [0.451] 
2025-03-30 18:55:52.591462: Epoch time: 274.39 s 
2025-03-30 18:55:54.470234:  
2025-03-30 18:55:54.470445: Epoch 62 
2025-03-30 18:55:54.470578: Current learning rate: 0.00944 
2025-03-30 19:00:28.907081: train_loss -0.7113 
2025-03-30 19:00:28.907383: val_loss -0.5243 
2025-03-30 19:00:28.907470: Pseudo dice [0.4264] 
2025-03-30 19:00:28.907559: Epoch time: 274.44 s 
2025-03-30 19:00:30.772979:  
2025-03-30 19:00:30.773299: Epoch 63 
2025-03-30 19:00:30.773439: Current learning rate: 0.00943 
2025-03-30 19:05:05.336543: train_loss -0.7337 
2025-03-30 19:05:05.336875: val_loss -0.5454 
2025-03-30 19:05:05.336958: Pseudo dice [0.5674] 
2025-03-30 19:05:05.337056: Epoch time: 274.57 s 
2025-03-30 19:05:05.337111: Yayy! New best EMA pseudo Dice: 0.4831 
2025-03-30 19:05:08.564627:  
2025-03-30 19:05:08.564807: Epoch 64 
2025-03-30 19:05:08.564928: Current learning rate: 0.00942 
2025-03-30 19:09:43.540741: train_loss -0.7274 
2025-03-30 19:09:43.541062: val_loss -0.5617 
2025-03-30 19:09:43.541160: Pseudo dice [0.5512] 
2025-03-30 19:09:43.541253: Epoch time: 274.98 s 
2025-03-30 19:09:43.541309: Yayy! New best EMA pseudo Dice: 0.4899 
2025-03-30 19:09:46.761275:  
2025-03-30 19:09:46.761456: Epoch 65 
2025-03-30 19:09:46.761610: Current learning rate: 0.00941 
2025-03-30 19:14:21.528483: train_loss -0.7239 
2025-03-30 19:14:21.528867: val_loss -0.5638 
2025-03-30 19:14:21.529014: Pseudo dice [0.4522] 
2025-03-30 19:14:21.529207: Epoch time: 274.77 s 
2025-03-30 19:14:23.419780:  
2025-03-30 19:14:23.420103: Epoch 66 
2025-03-30 19:14:23.420285: Current learning rate: 0.0094 
2025-03-30 19:18:58.302663: train_loss -0.7283 
2025-03-30 19:18:58.302989: val_loss -0.5652 
2025-03-30 19:18:58.303103: Pseudo dice [0.4523] 
2025-03-30 19:18:58.303271: Epoch time: 274.89 s 
2025-03-30 19:19:00.477823:  
2025-03-30 19:19:00.478034: Epoch 67 
2025-03-30 19:19:00.478157: Current learning rate: 0.00939 
2025-03-30 19:23:34.921817: train_loss -0.7607 
2025-03-30 19:23:34.922157: val_loss -0.5463 
2025-03-30 19:23:34.922245: Pseudo dice [0.4981] 
2025-03-30 19:23:34.922345: Epoch time: 274.45 s 
2025-03-30 19:23:36.832043:  
2025-03-30 19:23:36.832252: Epoch 68 
2025-03-30 19:23:36.832366: Current learning rate: 0.00939 
2025-03-30 19:28:11.278591: train_loss -0.7485 
2025-03-30 19:28:11.278930: val_loss -0.4082 
2025-03-30 19:28:11.279016: Pseudo dice [0.3465] 
2025-03-30 19:28:11.279110: Epoch time: 274.45 s 
2025-03-30 19:28:13.212250:  
2025-03-30 19:28:13.212486: Epoch 69 
2025-03-30 19:28:13.212601: Current learning rate: 0.00938 
2025-03-30 19:32:47.773523: train_loss -0.7325 
2025-03-30 19:32:47.773869: val_loss -0.5425 
2025-03-30 19:32:47.773955: Pseudo dice [0.5484] 
2025-03-30 19:32:47.774052: Epoch time: 274.57 s 
2025-03-30 19:32:49.685076:  
2025-03-30 19:32:49.685314: Epoch 70 
2025-03-30 19:32:49.685485: Current learning rate: 0.00937 
2025-03-30 19:37:23.785746: train_loss -0.7367 
2025-03-30 19:37:23.786141: val_loss -0.6042 
2025-03-30 19:37:23.786242: Pseudo dice [0.5091] 
2025-03-30 19:37:23.786333: Epoch time: 274.1 s 
2025-03-30 19:37:25.694551:  
2025-03-30 19:37:25.694801: Epoch 71 
2025-03-30 19:37:25.694972: Current learning rate: 0.00936 
2025-03-30 19:41:59.561899: train_loss -0.7543 
2025-03-30 19:41:59.562228: val_loss -0.508 
2025-03-30 19:41:59.562313: Pseudo dice [0.3681] 
2025-03-30 19:41:59.562414: Epoch time: 273.87 s 
2025-03-30 19:42:01.485671:  
2025-03-30 19:42:01.485839: Epoch 72 
2025-03-30 19:42:01.485955: Current learning rate: 0.00935 
2025-03-30 19:46:35.356021: train_loss -0.7555 
2025-03-30 19:46:35.356323: val_loss -0.6189 
2025-03-30 19:46:35.356406: Pseudo dice [0.5852] 
2025-03-30 19:46:35.356493: Epoch time: 273.87 s 
2025-03-30 19:46:37.281375:  
2025-03-30 19:46:37.281665: Epoch 73 
2025-03-30 19:46:37.281792: Current learning rate: 0.00934 
2025-03-30 19:51:11.198387: train_loss -0.7323 
2025-03-30 19:51:11.198700: val_loss -0.4703 
2025-03-30 19:51:11.198782: Pseudo dice [0.3172] 
2025-03-30 19:51:11.198867: Epoch time: 273.92 s 
2025-03-30 19:51:13.116415:  
2025-03-30 19:51:13.116658: Epoch 74 
2025-03-30 19:51:13.116777: Current learning rate: 0.00933 
2025-03-30 19:55:47.232280: train_loss -0.7282 
2025-03-30 19:55:47.232655: val_loss -0.5734 
2025-03-30 19:55:47.232757: Pseudo dice [0.4282] 
2025-03-30 19:55:47.232854: Epoch time: 274.12 s 
2025-03-30 19:55:49.463760:  
2025-03-30 19:55:49.463975: Epoch 75 
2025-03-30 19:55:49.464180: Current learning rate: 0.00932 
2025-03-30 20:00:23.210432: train_loss -0.7568 
2025-03-30 20:00:23.210741: val_loss -0.6148 
2025-03-30 20:00:23.210862: Pseudo dice [0.6327] 
2025-03-30 20:00:23.210963: Epoch time: 273.75 s 
2025-03-30 20:00:25.150625:  
2025-03-30 20:00:25.150864: Epoch 76 
2025-03-30 20:00:25.150985: Current learning rate: 0.00931 
2025-03-30 20:04:59.171135: train_loss -0.7244 
2025-03-30 20:04:59.171571: val_loss -0.5903 
2025-03-30 20:04:59.171668: Pseudo dice [0.5813] 
2025-03-30 20:04:59.171773: Epoch time: 274.02 s 
2025-03-30 20:05:01.085373:  
2025-03-30 20:05:01.085595: Epoch 77 
2025-03-30 20:05:01.085729: Current learning rate: 0.0093 
2025-03-30 20:09:35.304927: train_loss -0.746 
2025-03-30 20:09:35.305432: val_loss -0.491 
2025-03-30 20:09:35.305739: Pseudo dice [0.434] 
2025-03-30 20:09:35.305826: Epoch time: 274.22 s 
2025-03-30 20:09:37.259773:  
2025-03-30 20:09:37.259985: Epoch 78 
2025-03-30 20:09:37.260126: Current learning rate: 0.0093 
2025-03-30 20:14:11.940653: train_loss -0.723 
2025-03-30 20:14:11.941011: val_loss -0.5203 
2025-03-30 20:14:11.941111: Pseudo dice [0.424] 
2025-03-30 20:14:11.941208: Epoch time: 274.69 s 
2025-03-30 20:14:13.900002:  
2025-03-30 20:14:13.900206: Epoch 79 
2025-03-30 20:14:13.900318: Current learning rate: 0.00929 
2025-03-30 20:18:48.376234: train_loss -0.7031 
2025-03-30 20:18:48.376545: val_loss -0.519 
2025-03-30 20:18:48.376632: Pseudo dice [0.4965] 
2025-03-30 20:18:48.376733: Epoch time: 274.48 s 
2025-03-30 20:18:50.315609:  
2025-03-30 20:18:50.315802: Epoch 80 
2025-03-30 20:18:50.315939: Current learning rate: 0.00928 
2025-03-30 20:23:24.915534: train_loss -0.7257 
2025-03-30 20:23:24.915880: val_loss -0.5689 
2025-03-30 20:23:24.915966: Pseudo dice [0.5207] 
2025-03-30 20:23:24.916060: Epoch time: 274.6 s 
2025-03-30 20:23:26.871107:  
2025-03-30 20:23:26.871328: Epoch 81 
2025-03-30 20:23:26.871513: Current learning rate: 0.00927 
2025-03-30 20:28:00.831239: train_loss -0.7084 
2025-03-30 20:28:00.831569: val_loss -0.4124 
2025-03-30 20:28:00.831661: Pseudo dice [0.298] 
2025-03-30 20:28:00.831770: Epoch time: 273.96 s 
2025-03-30 20:28:03.074270:  
2025-03-30 20:28:03.074486: Epoch 82 
2025-03-30 20:28:03.074599: Current learning rate: 0.00926 
2025-03-30 20:32:36.462038: train_loss -0.7232 
2025-03-30 20:32:36.462334: val_loss -0.542 
2025-03-30 20:32:36.462420: Pseudo dice [0.6278] 
2025-03-30 20:32:36.462536: Epoch time: 273.39 s 
2025-03-30 20:32:38.306994:  
2025-03-30 20:32:38.307228: Epoch 83 
2025-03-30 20:32:38.307370: Current learning rate: 0.00925 
2025-03-30 20:37:11.287850: train_loss -0.7227 
2025-03-30 20:37:11.288234: val_loss -0.4979 
2025-03-30 20:37:11.288335: Pseudo dice [0.5269] 
2025-03-30 20:37:11.288420: Epoch time: 272.98 s 
2025-03-30 20:37:13.140589:  
2025-03-30 20:37:13.140768: Epoch 84 
2025-03-30 20:37:13.140902: Current learning rate: 0.00924 
2025-03-30 20:41:46.448873: train_loss -0.7299 
2025-03-30 20:41:46.449212: val_loss -0.6093 
2025-03-30 20:41:46.449310: Pseudo dice [0.6259] 
2025-03-30 20:41:46.449411: Epoch time: 273.31 s 
2025-03-30 20:41:46.449466: Yayy! New best EMA pseudo Dice: 0.4998 
2025-03-30 20:41:49.689696:  
2025-03-30 20:41:49.689915: Epoch 85 
2025-03-30 20:41:49.690033: Current learning rate: 0.00923 
2025-03-30 20:46:23.013946: train_loss -0.7446 
2025-03-30 20:46:23.014294: val_loss -0.4347 
2025-03-30 20:46:23.014445: Pseudo dice [0.5202] 
2025-03-30 20:46:23.014543: Epoch time: 273.33 s 
2025-03-30 20:46:23.014606: Yayy! New best EMA pseudo Dice: 0.5018 
2025-03-30 20:46:26.303767:  
2025-03-30 20:46:26.304028: Epoch 86 
2025-03-30 20:46:26.304195: Current learning rate: 0.00922 
2025-03-30 20:50:59.694781: train_loss -0.6998 
2025-03-30 20:50:59.695121: val_loss -0.5492 
2025-03-30 20:50:59.695335: Pseudo dice [0.5359] 
2025-03-30 20:50:59.695440: Epoch time: 273.4 s 
2025-03-30 20:50:59.695504: Yayy! New best EMA pseudo Dice: 0.5052 
2025-03-30 20:51:02.948354:  
2025-03-30 20:51:02.948579: Epoch 87 
2025-03-30 20:51:02.948695: Current learning rate: 0.00921 
2025-03-30 20:55:36.430164: train_loss -0.6932 
2025-03-30 20:55:36.430694: val_loss -0.4857 
2025-03-30 20:55:36.430783: Pseudo dice [0.2913] 
2025-03-30 20:55:36.430876: Epoch time: 273.49 s 
2025-03-30 20:55:38.301437:  
2025-03-30 20:55:38.301645: Epoch 88 
2025-03-30 20:55:38.301765: Current learning rate: 0.0092 
2025-03-30 21:00:11.559175: train_loss -0.7028 
2025-03-30 21:00:11.559561: val_loss -0.5322 
2025-03-30 21:00:11.559645: Pseudo dice [0.3133] 
2025-03-30 21:00:11.559733: Epoch time: 273.26 s 
2025-03-30 21:00:13.437358:  
2025-03-30 21:00:13.437598: Epoch 89 
2025-03-30 21:00:13.437720: Current learning rate: 0.0092 
2025-03-30 21:04:46.694251: train_loss -0.7005 
2025-03-30 21:04:46.694579: val_loss -0.563 
2025-03-30 21:04:46.694663: Pseudo dice [0.5297] 
2025-03-30 21:04:46.694762: Epoch time: 273.26 s 
2025-03-30 21:04:48.890742:  
2025-03-30 21:04:48.890939: Epoch 90 
2025-03-30 21:04:48.891086: Current learning rate: 0.00919 
2025-03-30 21:09:23.125853: train_loss -0.687 
2025-03-30 21:09:23.126209: val_loss -0.5142 
2025-03-30 21:09:23.126293: Pseudo dice [0.4374] 
2025-03-30 21:09:23.126389: Epoch time: 274.24 s 
2025-03-30 21:09:24.972127:  
2025-03-30 21:09:24.972335: Epoch 91 
2025-03-30 21:09:24.972450: Current learning rate: 0.00918 
2025-03-30 21:13:59.017097: train_loss -0.7091 
2025-03-30 21:13:59.017445: val_loss -0.5682 
2025-03-30 21:13:59.017548: Pseudo dice [0.5491] 
2025-03-30 21:13:59.017643: Epoch time: 274.05 s 
2025-03-30 21:14:00.853362:  
2025-03-30 21:14:00.853639: Epoch 92 
2025-03-30 21:14:00.853843: Current learning rate: 0.00917 
2025-03-30 21:18:34.932545: train_loss -0.7285 
2025-03-30 21:18:34.932889: val_loss -0.5959 
2025-03-30 21:18:34.932979: Pseudo dice [0.4828] 
2025-03-30 21:18:34.933110: Epoch time: 274.08 s 
2025-03-30 21:18:36.775351:  
2025-03-30 21:18:36.775557: Epoch 93 
2025-03-30 21:18:36.775672: Current learning rate: 0.00916 
2025-03-30 21:23:10.332078: train_loss -0.7578 
2025-03-30 21:23:10.332393: val_loss -0.5675 
2025-03-30 21:23:10.332534: Pseudo dice [0.6161] 
2025-03-30 21:23:10.332659: Epoch time: 273.56 s 
2025-03-30 21:23:12.162628:  
2025-03-30 21:23:12.162840: Epoch 94 
2025-03-30 21:23:12.162965: Current learning rate: 0.00915 
2025-03-30 21:27:45.816942: train_loss -0.7522 
2025-03-30 21:27:45.817257: val_loss -0.6225 
2025-03-30 21:27:45.817348: Pseudo dice [0.5456] 
2025-03-30 21:27:45.817446: Epoch time: 273.66 s 
2025-03-30 21:27:47.668666:  
2025-03-30 21:27:47.668875: Epoch 95 
2025-03-30 21:27:47.668994: Current learning rate: 0.00914 
2025-03-30 21:32:21.508476: train_loss -0.7265 
2025-03-30 21:32:21.508805: val_loss -0.5407 
2025-03-30 21:32:21.509370: Pseudo dice [0.4986] 
2025-03-30 21:32:21.509464: Epoch time: 273.84 s 
2025-03-30 21:32:23.349629:  
2025-03-30 21:32:23.349868: Epoch 96 
2025-03-30 21:32:23.350029: Current learning rate: 0.00913 
2025-03-30 21:36:57.134988: train_loss -0.7458 
2025-03-30 21:36:57.135295: val_loss -0.6488 
2025-03-30 21:36:57.135390: Pseudo dice [0.6217] 
2025-03-30 21:36:57.135527: Epoch time: 273.79 s 
2025-03-30 21:36:57.135592: Yayy! New best EMA pseudo Dice: 0.5098 
2025-03-30 21:37:00.377869:  
2025-03-30 21:37:00.378080: Epoch 97 
2025-03-30 21:37:00.378194: Current learning rate: 0.00912 
2025-03-30 21:41:34.152332: train_loss -0.7247 
2025-03-30 21:41:34.152672: val_loss -0.5963 
2025-03-30 21:41:34.152774: Pseudo dice [0.5962] 
2025-03-30 21:41:34.152873: Epoch time: 273.78 s 
2025-03-30 21:41:34.152932: Yayy! New best EMA pseudo Dice: 0.5184 
2025-03-30 21:41:37.639723:  
2025-03-30 21:41:37.639973: Epoch 98 
2025-03-30 21:41:37.640091: Current learning rate: 0.00911 
2025-03-30 21:46:12.119747: train_loss -0.7504 
2025-03-30 21:46:12.120072: val_loss -0.6344 
2025-03-30 21:46:12.120157: Pseudo dice [0.6134] 
2025-03-30 21:46:12.120280: Epoch time: 274.48 s 
2025-03-30 21:46:12.120343: Yayy! New best EMA pseudo Dice: 0.5279 
2025-03-30 21:46:15.340661:  
2025-03-30 21:46:15.340867: Epoch 99 
2025-03-30 21:46:15.341000: Current learning rate: 0.0091 
2025-03-30 21:50:49.929542: train_loss -0.757 
2025-03-30 21:50:49.929868: val_loss -0.5479 
2025-03-30 21:50:49.930012: Pseudo dice [0.4129] 
2025-03-30 21:50:49.930110: Epoch time: 274.59 s 
2025-03-30 21:50:53.096296:  
2025-03-30 21:50:53.096627: Epoch 100 
2025-03-30 21:50:53.096743: Current learning rate: 0.0091 
2025-03-30 21:55:26.997092: train_loss -0.6894 
2025-03-30 21:55:26.997434: val_loss -0.5534 
2025-03-30 21:55:26.997594: Pseudo dice [0.3952] 
2025-03-30 21:55:26.997693: Epoch time: 273.9 s 
2025-03-30 21:55:28.849199:  
2025-03-30 21:55:28.849378: Epoch 101 
2025-03-30 21:55:28.849491: Current learning rate: 0.00909 
2025-03-30 22:00:02.285028: train_loss -0.7148 
2025-03-30 22:00:02.285388: val_loss -0.4701 
2025-03-30 22:00:02.285478: Pseudo dice [0.3023] 
2025-03-30 22:00:02.285574: Epoch time: 273.44 s 
2025-03-30 22:00:04.160417:  
2025-03-30 22:00:04.160671: Epoch 102 
2025-03-30 22:00:04.160810: Current learning rate: 0.00908 
2025-03-30 22:04:37.711162: train_loss -0.7563 
2025-03-30 22:04:37.711535: val_loss -0.5125 
2025-03-30 22:04:37.711648: Pseudo dice [0.5462] 
2025-03-30 22:04:37.711741: Epoch time: 273.55 s 
2025-03-30 22:04:39.573372:  
2025-03-30 22:04:39.573584: Epoch 103 
2025-03-30 22:04:39.573699: Current learning rate: 0.00907 
2025-03-30 22:09:12.582473: train_loss -0.7357 
2025-03-30 22:09:12.582892: val_loss -0.4981 
2025-03-30 22:09:12.582979: Pseudo dice [0.3512] 
2025-03-30 22:09:12.583073: Epoch time: 273.01 s 
2025-03-30 22:09:14.435540:  
2025-03-30 22:09:14.435852: Epoch 104 
2025-03-30 22:09:14.435988: Current learning rate: 0.00906 
2025-03-30 22:13:47.850354: train_loss -0.7257 
2025-03-30 22:13:47.850725: val_loss -0.5577 
2025-03-30 22:13:47.850816: Pseudo dice [0.4875] 
2025-03-30 22:13:47.850914: Epoch time: 273.42 s 
2025-03-30 22:13:49.725741:  
2025-03-30 22:13:49.725943: Epoch 105 
2025-03-30 22:13:49.726058: Current learning rate: 0.00905 
2025-03-30 22:18:22.791502: train_loss -0.7591 
2025-03-30 22:18:22.791853: val_loss -0.6215 
2025-03-30 22:18:22.791946: Pseudo dice [0.6709] 
2025-03-30 22:18:22.792046: Epoch time: 273.07 s 
2025-03-30 22:18:24.947277:  
2025-03-30 22:18:24.947476: Epoch 106 
2025-03-30 22:18:24.947624: Current learning rate: 0.00904 
2025-03-30 22:22:57.574707: train_loss -0.7662 
2025-03-30 22:22:57.575037: val_loss -0.6007 
2025-03-30 22:22:57.575123: Pseudo dice [0.6304] 
2025-03-30 22:22:57.575223: Epoch time: 272.63 s 
2025-03-30 22:22:59.453061:  
2025-03-30 22:22:59.453380: Epoch 107 
2025-03-30 22:22:59.453530: Current learning rate: 0.00903 
2025-03-30 22:27:32.297878: train_loss -0.7785 
2025-03-30 22:27:32.298218: val_loss -0.5895 
2025-03-30 22:27:32.298303: Pseudo dice [0.4934] 
2025-03-30 22:27:32.298396: Epoch time: 272.85 s 
2025-03-30 22:27:34.175028:  
2025-03-30 22:27:34.175304: Epoch 108 
2025-03-30 22:27:34.175432: Current learning rate: 0.00902 
2025-03-30 22:32:06.958782: train_loss -0.7751 
2025-03-30 22:32:06.959123: val_loss -0.5629 
2025-03-30 22:32:06.959226: Pseudo dice [0.3774] 
2025-03-30 22:32:06.959309: Epoch time: 272.79 s 
2025-03-30 22:32:08.826907:  
2025-03-30 22:32:08.827166: Epoch 109 
2025-03-30 22:32:08.827312: Current learning rate: 0.00901 
2025-03-30 22:36:41.728106: train_loss -0.7479 
2025-03-30 22:36:41.728413: val_loss -0.645 
2025-03-30 22:36:41.728502: Pseudo dice [0.6148] 
2025-03-30 22:36:41.728606: Epoch time: 272.91 s 
2025-03-30 22:36:43.616553:  
2025-03-30 22:36:43.616752: Epoch 110 
2025-03-30 22:36:43.616899: Current learning rate: 0.009 
2025-03-30 22:41:17.061382: train_loss -0.7533 
2025-03-30 22:41:17.061692: val_loss -0.4256 
2025-03-30 22:41:17.061794: Pseudo dice [0.267] 
2025-03-30 22:41:17.061943: Epoch time: 273.45 s 
2025-03-30 22:41:18.943330:  
2025-03-30 22:41:18.943521: Epoch 111 
2025-03-30 22:41:18.943640: Current learning rate: 0.009 
2025-03-30 22:45:52.274207: train_loss -0.7726 
2025-03-30 22:45:52.274564: val_loss -0.5489 
2025-03-30 22:45:52.274646: Pseudo dice [0.4189] 
2025-03-30 22:45:52.274745: Epoch time: 273.33 s 
2025-03-30 22:45:54.147413:  
2025-03-30 22:45:54.147617: Epoch 112 
2025-03-30 22:45:54.147739: Current learning rate: 0.00899 
2025-03-30 22:50:27.375232: train_loss -0.7828 
2025-03-30 22:50:27.375659: val_loss -0.5673 
2025-03-30 22:50:27.376324: Pseudo dice [0.5731] 
2025-03-30 22:50:27.376420: Epoch time: 273.23 s 
2025-03-30 22:50:29.241253:  
2025-03-30 22:50:29.241456: Epoch 113 
2025-03-30 22:50:29.241572: Current learning rate: 0.00898 
2025-03-30 22:55:03.021642: train_loss -0.7535 
2025-03-30 22:55:03.022047: val_loss -0.6426 
2025-03-30 22:55:03.022142: Pseudo dice [0.5368] 
2025-03-30 22:55:03.022224: Epoch time: 273.78 s 
2025-03-30 22:55:05.194520:  
2025-03-30 22:55:05.194732: Epoch 114 
2025-03-30 22:55:05.194854: Current learning rate: 0.00897 
2025-03-30 22:59:39.182452: train_loss -0.7143 
2025-03-30 22:59:39.182761: val_loss -0.5459 
2025-03-30 22:59:39.182855: Pseudo dice [0.3838] 
2025-03-30 22:59:39.182946: Epoch time: 273.99 s 
2025-03-30 22:59:41.080756:  
2025-03-30 22:59:41.081042: Epoch 115 
2025-03-30 22:59:41.081176: Current learning rate: 0.00896 
2025-03-30 23:04:15.262531: train_loss -0.7265 
2025-03-30 23:04:15.262845: val_loss -0.6326 
2025-03-30 23:04:15.262930: Pseudo dice [0.6538] 
2025-03-30 23:04:15.263019: Epoch time: 274.19 s 
2025-03-30 23:04:17.173956:  
2025-03-30 23:04:17.174176: Epoch 116 
2025-03-30 23:04:17.174294: Current learning rate: 0.00895 
2025-03-30 23:08:50.913038: train_loss -0.7298 
2025-03-30 23:08:50.913411: val_loss -0.5986 
2025-03-30 23:08:50.913510: Pseudo dice [0.4882] 
2025-03-30 23:08:50.913610: Epoch time: 273.74 s 
2025-03-30 23:08:52.833091:  
2025-03-30 23:08:52.833322: Epoch 117 
2025-03-30 23:08:52.833441: Current learning rate: 0.00894 
2025-03-30 23:13:26.574275: train_loss -0.76 
2025-03-30 23:13:26.574616: val_loss -0.5369 
2025-03-30 23:13:26.575328: Pseudo dice [0.4941] 
2025-03-30 23:13:26.575465: Epoch time: 273.75 s 
2025-03-30 23:13:28.487665:  
2025-03-30 23:13:28.487968: Epoch 118 
2025-03-30 23:13:28.488084: Current learning rate: 0.00893 
2025-03-30 23:18:02.688968: train_loss -0.6952 
2025-03-30 23:18:02.689279: val_loss -0.5211 
2025-03-30 23:18:02.689371: Pseudo dice [0.3884] 
2025-03-30 23:18:02.689475: Epoch time: 274.21 s 
2025-03-30 23:18:04.602037:  
2025-03-30 23:18:04.602256: Epoch 119 
2025-03-30 23:18:04.602386: Current learning rate: 0.00892 
2025-03-30 23:22:39.054283: train_loss -0.7355 
2025-03-30 23:22:39.054633: val_loss -0.4998 
2025-03-30 23:22:39.054729: Pseudo dice [0.2895] 
2025-03-30 23:22:39.054934: Epoch time: 274.46 s 
2025-03-30 23:22:40.979238:  
2025-03-30 23:22:40.979428: Epoch 120 
2025-03-30 23:22:40.979543: Current learning rate: 0.00891 
2025-03-30 23:27:14.798169: train_loss -0.7378 
2025-03-30 23:27:14.798559: val_loss -0.5661 
2025-03-30 23:27:14.798653: Pseudo dice [0.4268] 
2025-03-30 23:27:14.798751: Epoch time: 273.82 s 
2025-03-30 23:27:16.710577:  
2025-03-30 23:27:16.710779: Epoch 121 
2025-03-30 23:27:16.710914: Current learning rate: 0.0089 
2025-03-30 23:31:50.780960: train_loss -0.7396 
2025-03-30 23:31:50.781342: val_loss -0.698 
2025-03-30 23:31:50.781877: Pseudo dice [0.6062] 
2025-03-30 23:31:50.782096: Epoch time: 274.07 s 
2025-03-30 23:31:53.065479:  
2025-03-30 23:31:53.065745: Epoch 122 
2025-03-30 23:31:53.065982: Current learning rate: 0.00889 
2025-03-30 23:36:26.781512: train_loss -0.7635 
2025-03-30 23:36:26.781908: val_loss -0.6251 
2025-03-30 23:36:26.782026: Pseudo dice [0.5672] 
2025-03-30 23:36:26.782124: Epoch time: 273.72 s 
2025-03-30 23:36:28.760106:  
2025-03-30 23:36:28.760424: Epoch 123 
2025-03-30 23:36:28.760546: Current learning rate: 0.00889 
2025-03-30 23:41:02.574446: train_loss -0.7651 
2025-03-30 23:41:02.574767: val_loss -0.6796 
2025-03-30 23:41:02.574854: Pseudo dice [0.6368] 
2025-03-30 23:41:02.574960: Epoch time: 273.82 s 
2025-03-30 23:41:04.540776:  
2025-03-30 23:41:04.540976: Epoch 124 
2025-03-30 23:41:04.541090: Current learning rate: 0.00888 
2025-03-30 23:45:38.596018: train_loss -0.7591 
2025-03-30 23:45:38.596421: val_loss -0.5617 
2025-03-30 23:45:38.596520: Pseudo dice [0.4762] 
2025-03-30 23:45:38.596599: Epoch time: 274.06 s 
2025-03-30 23:45:40.520469:  
2025-03-30 23:45:40.520715: Epoch 125 
2025-03-30 23:45:40.520831: Current learning rate: 0.00887 
2025-03-30 23:50:14.078243: train_loss -0.7665 
2025-03-30 23:50:14.078607: val_loss -0.6289 
2025-03-30 23:50:14.078691: Pseudo dice [0.6075] 
2025-03-30 23:50:14.078791: Epoch time: 273.56 s 
2025-03-30 23:50:15.986194:  
2025-03-30 23:50:15.986495: Epoch 126 
2025-03-30 23:50:15.986635: Current learning rate: 0.00886 
2025-03-30 23:54:49.824996: train_loss -0.7669 
2025-03-30 23:54:49.825325: val_loss -0.5236 
2025-03-30 23:54:49.825432: Pseudo dice [0.5077] 
2025-03-30 23:54:49.825531: Epoch time: 273.84 s 
2025-03-30 23:54:51.741376:  
2025-03-30 23:54:51.741567: Epoch 127 
2025-03-30 23:54:51.741691: Current learning rate: 0.00885 
2025-03-30 23:59:25.248824: train_loss -0.773 
2025-03-30 23:59:25.249171: val_loss -0.5792 
2025-03-30 23:59:25.249255: Pseudo dice [0.5614] 
2025-03-30 23:59:25.249358: Epoch time: 273.51 s 
2025-03-30 23:59:27.156021:  
2025-03-30 23:59:27.156198: Epoch 128 
2025-03-30 23:59:27.156324: Current learning rate: 0.00884 
2025-03-31 00:04:01.594641: train_loss -0.7699 
2025-03-31 00:04:01.594897: val_loss -0.5547 
2025-03-31 00:04:01.595015: Pseudo dice [0.438] 
2025-03-31 00:04:01.595114: Epoch time: 274.44 s 
2025-03-31 00:04:03.530714:  
2025-03-31 00:04:03.530879: Epoch 129 
2025-03-31 00:04:03.531000: Current learning rate: 0.00883 
2025-03-31 00:08:37.898436: train_loss -0.7466 
2025-03-31 00:08:37.898832: val_loss -0.6041 
2025-03-31 00:08:37.898927: Pseudo dice [0.5485] 
2025-03-31 00:08:37.899028: Epoch time: 274.37 s 
2025-03-31 00:08:40.132961:  
2025-03-31 00:08:40.133250: Epoch 130 
2025-03-31 00:08:40.133422: Current learning rate: 0.00882 
2025-03-31 00:13:14.494026: train_loss -0.7739 
2025-03-31 00:13:14.494472: val_loss -0.6038 
2025-03-31 00:13:14.494592: Pseudo dice [0.6912] 
2025-03-31 00:13:14.494677: Epoch time: 274.37 s 
2025-03-31 00:13:14.494737: Yayy! New best EMA pseudo Dice: 0.529 
2025-03-31 00:13:17.777778:  
2025-03-31 00:13:17.777994: Epoch 131 
2025-03-31 00:13:17.778112: Current learning rate: 0.00881 
2025-03-31 00:17:51.826190: train_loss -0.768 
2025-03-31 00:17:51.826517: val_loss -0.6884 
2025-03-31 00:17:51.826604: Pseudo dice [0.7201] 
2025-03-31 00:17:51.826709: Epoch time: 274.05 s 
2025-03-31 00:17:51.826764: Yayy! New best EMA pseudo Dice: 0.5481 
2025-03-31 00:17:55.088081:  
2025-03-31 00:17:55.088307: Epoch 132 
2025-03-31 00:17:55.088451: Current learning rate: 0.0088 
2025-03-31 00:22:29.132181: train_loss -0.7316 
2025-03-31 00:22:29.132516: val_loss -0.5996 
2025-03-31 00:22:29.132617: Pseudo dice [0.6106] 
2025-03-31 00:22:29.132718: Epoch time: 274.05 s 
2025-03-31 00:22:29.132778: Yayy! New best EMA pseudo Dice: 0.5543 
2025-03-31 00:22:32.400369:  
2025-03-31 00:22:32.400608: Epoch 133 
2025-03-31 00:22:32.400749: Current learning rate: 0.00879 
2025-03-31 00:27:06.085115: train_loss -0.753 
2025-03-31 00:27:06.085479: val_loss -0.5523 
2025-03-31 00:27:06.085594: Pseudo dice [0.4019] 
2025-03-31 00:27:06.085694: Epoch time: 273.69 s 
2025-03-31 00:27:08.017286:  
2025-03-31 00:27:08.017530: Epoch 134 
2025-03-31 00:27:08.017696: Current learning rate: 0.00879 
2025-03-31 00:31:42.022426: train_loss -0.7548 
2025-03-31 00:31:42.022830: val_loss -0.5204 
2025-03-31 00:31:42.022945: Pseudo dice [0.6003] 
2025-03-31 00:31:42.023032: Epoch time: 274.01 s 
2025-03-31 00:31:43.968167:  
2025-03-31 00:31:43.968425: Epoch 135 
2025-03-31 00:31:43.968552: Current learning rate: 0.00878 
2025-03-31 00:36:17.878281: train_loss -0.7112 
2025-03-31 00:36:17.878624: val_loss -0.5423 
2025-03-31 00:36:17.878750: Pseudo dice [0.3739] 
2025-03-31 00:36:17.878857: Epoch time: 273.91 s 
2025-03-31 00:36:19.827958:  
2025-03-31 00:36:19.828145: Epoch 136 
2025-03-31 00:36:19.828300: Current learning rate: 0.00877 
2025-03-31 00:40:52.674726: train_loss -0.7522 
2025-03-31 00:40:52.675062: val_loss -0.5648 
2025-03-31 00:40:52.675161: Pseudo dice [0.5236] 
2025-03-31 00:40:52.675251: Epoch time: 272.85 s 
2025-03-31 00:40:54.902295:  
2025-03-31 00:40:54.902538: Epoch 137 
2025-03-31 00:40:54.902680: Current learning rate: 0.00876 
2025-03-31 00:45:27.820470: train_loss -0.7464 
2025-03-31 00:45:27.820806: val_loss -0.6016 
2025-03-31 00:45:27.820892: Pseudo dice [0.4974] 
2025-03-31 00:45:27.820991: Epoch time: 272.92 s 
2025-03-31 00:45:29.913198:  
2025-03-31 00:45:29.913432: Epoch 138 
2025-03-31 00:45:29.913569: Current learning rate: 0.00875 
2025-03-31 00:50:03.899412: train_loss -0.7113 
2025-03-31 00:50:03.899875: val_loss -0.6321 
2025-03-31 00:50:03.899979: Pseudo dice [0.5506] 
2025-03-31 00:50:03.900068: Epoch time: 273.99 s 
2025-03-31 00:50:05.846954:  
2025-03-31 00:50:05.847170: Epoch 139 
2025-03-31 00:50:05.847286: Current learning rate: 0.00874 
2025-03-31 00:54:39.215683: train_loss -0.7401 
2025-03-31 00:54:39.216029: val_loss -0.6252 
2025-03-31 00:54:39.216130: Pseudo dice [0.5234] 
2025-03-31 00:54:39.216231: Epoch time: 273.37 s 
2025-03-31 00:54:41.173977:  
2025-03-31 00:54:41.174234: Epoch 140 
2025-03-31 00:54:41.174468: Current learning rate: 0.00873 
2025-03-31 00:59:14.462795: train_loss -0.7412 
2025-03-31 00:59:14.463115: val_loss -0.6217 
2025-03-31 00:59:14.463274: Pseudo dice [0.5972] 
2025-03-31 00:59:14.463367: Epoch time: 273.29 s 
2025-03-31 00:59:16.415374:  
2025-03-31 00:59:16.415572: Epoch 141 
2025-03-31 00:59:16.415687: Current learning rate: 0.00872 
2025-03-31 01:03:49.603161: train_loss -0.7728 
2025-03-31 01:03:49.603473: val_loss -0.4362 
2025-03-31 01:03:49.603583: Pseudo dice [0.4255] 
2025-03-31 01:03:49.603686: Epoch time: 273.19 s 
2025-03-31 01:03:51.529665:  
2025-03-31 01:03:51.529848: Epoch 142 
2025-03-31 01:03:51.530018: Current learning rate: 0.00871 
2025-03-31 01:08:24.367146: train_loss -0.7707 
2025-03-31 01:08:24.367443: val_loss -0.6545 
2025-03-31 01:08:24.367532: Pseudo dice [0.6739] 
2025-03-31 01:08:24.367615: Epoch time: 272.84 s 
2025-03-31 01:08:26.299778:  
2025-03-31 01:08:26.300005: Epoch 143 
2025-03-31 01:08:26.300118: Current learning rate: 0.0087 
2025-03-31 01:12:59.751653: train_loss -0.765 
2025-03-31 01:12:59.751995: val_loss -0.5652 
2025-03-31 01:12:59.752086: Pseudo dice [0.6139] 
2025-03-31 01:12:59.752189: Epoch time: 273.46 s 
2025-03-31 01:13:01.707235:  
2025-03-31 01:13:01.707469: Epoch 144 
2025-03-31 01:13:01.707627: Current learning rate: 0.00869 
2025-03-31 01:17:35.360650: train_loss -0.6779 
2025-03-31 01:17:35.360954: val_loss -0.6862 
2025-03-31 01:17:35.361036: Pseudo dice [0.6862] 
2025-03-31 01:17:35.361165: Epoch time: 273.66 s 
2025-03-31 01:17:35.361224: Yayy! New best EMA pseudo Dice: 0.5597 
2025-03-31 01:17:38.980608:  
2025-03-31 01:17:38.980878: Epoch 145 
2025-03-31 01:17:38.981000: Current learning rate: 0.00868 
2025-03-31 01:22:12.293920: train_loss -0.7382 
2025-03-31 01:22:12.294291: val_loss -0.5812 
2025-03-31 01:22:12.294381: Pseudo dice [0.5741] 
2025-03-31 01:22:12.294476: Epoch time: 273.32 s 
2025-03-31 01:22:12.294532: Yayy! New best EMA pseudo Dice: 0.5612 
2025-03-31 01:22:15.596741:  
2025-03-31 01:22:15.596980: Epoch 146 
2025-03-31 01:22:15.597099: Current learning rate: 0.00868 
2025-03-31 01:26:48.669472: train_loss -0.757 
2025-03-31 01:26:48.669790: val_loss -0.5682 
2025-03-31 01:26:48.670118: Pseudo dice [0.4441] 
2025-03-31 01:26:48.670208: Epoch time: 273.08 s 
2025-03-31 01:26:50.616991:  
2025-03-31 01:26:50.617269: Epoch 147 
2025-03-31 01:26:50.617402: Current learning rate: 0.00867 
2025-03-31 01:31:24.053172: train_loss -0.7644 
2025-03-31 01:31:24.053483: val_loss -0.5655 
2025-03-31 01:31:24.053563: Pseudo dice [0.4026] 
2025-03-31 01:31:24.053664: Epoch time: 273.44 s 
2025-03-31 01:31:26.001635:  
2025-03-31 01:31:26.001840: Epoch 148 
2025-03-31 01:31:26.001955: Current learning rate: 0.00866 
2025-03-31 01:35:59.342283: train_loss -0.753 
2025-03-31 01:35:59.342522: val_loss -0.4894 
2025-03-31 01:35:59.342605: Pseudo dice [0.487] 
2025-03-31 01:35:59.342699: Epoch time: 273.34 s 
2025-03-31 01:36:01.316199:  
2025-03-31 01:36:01.316404: Epoch 149 
2025-03-31 01:36:01.316517: Current learning rate: 0.00865 
2025-03-31 01:40:35.221482: train_loss -0.6777 
2025-03-31 01:40:35.221835: val_loss -0.6062 
2025-03-31 01:40:35.221927: Pseudo dice [0.5663] 
2025-03-31 01:40:35.222022: Epoch time: 273.91 s 
2025-03-31 01:40:38.591761:  
2025-03-31 01:40:38.591938: Epoch 150 
2025-03-31 01:40:38.592088: Current learning rate: 0.00864 
2025-03-31 01:45:12.328382: train_loss -0.7243 
2025-03-31 01:45:12.328692: val_loss -0.6499 
2025-03-31 01:45:12.328802: Pseudo dice [0.5776] 
2025-03-31 01:45:12.328908: Epoch time: 273.74 s 
2025-03-31 01:45:14.284990:  
2025-03-31 01:45:14.285222: Epoch 151 
2025-03-31 01:45:14.285376: Current learning rate: 0.00863 
2025-03-31 01:49:47.750888: train_loss -0.753 
2025-03-31 01:49:47.751247: val_loss -0.6126 
2025-03-31 01:49:47.751338: Pseudo dice [0.6695] 
2025-03-31 01:49:47.751439: Epoch time: 273.47 s 
2025-03-31 01:49:50.044512:  
2025-03-31 01:49:50.044787: Epoch 152 
2025-03-31 01:49:50.044939: Current learning rate: 0.00862 
2025-03-31 01:54:23.892834: train_loss -0.7626 
2025-03-31 01:54:23.893151: val_loss -0.5786 
2025-03-31 01:54:23.893437: Pseudo dice [0.5258] 
2025-03-31 01:54:23.893552: Epoch time: 273.85 s 
2025-03-31 01:54:25.905490:  
2025-03-31 01:54:25.905756: Epoch 153 
2025-03-31 01:54:25.905878: Current learning rate: 0.00861 
2025-03-31 01:58:59.979681: train_loss -0.7645 
2025-03-31 01:58:59.980016: val_loss -0.6607 
2025-03-31 01:58:59.980137: Pseudo dice [0.7232] 
2025-03-31 01:58:59.980235: Epoch time: 274.08 s 
2025-03-31 01:58:59.980293: Yayy! New best EMA pseudo Dice: 0.5661 
2025-03-31 01:59:03.410891:  
2025-03-31 01:59:03.411070: Epoch 154 
2025-03-31 01:59:03.411194: Current learning rate: 0.0086 
2025-03-31 02:03:37.522433: train_loss -0.7618 
2025-03-31 02:03:37.522770: val_loss -0.535 
2025-03-31 02:03:37.522852: Pseudo dice [0.5724] 
2025-03-31 02:03:37.523022: Epoch time: 274.12 s 
2025-03-31 02:03:37.523079: Yayy! New best EMA pseudo Dice: 0.5667 
2025-03-31 02:03:40.879322:  
2025-03-31 02:03:40.879695: Epoch 155 
2025-03-31 02:03:40.879830: Current learning rate: 0.00859 
2025-03-31 02:08:15.169605: train_loss -0.7187 
2025-03-31 02:08:15.169976: val_loss -0.5702 
2025-03-31 02:08:15.170096: Pseudo dice [0.5673] 
2025-03-31 02:08:15.170181: Epoch time: 274.29 s 
2025-03-31 02:08:15.170241: Yayy! New best EMA pseudo Dice: 0.5668 
2025-03-31 02:08:18.575298:  
2025-03-31 02:08:18.575507: Epoch 156 
2025-03-31 02:08:18.575636: Current learning rate: 0.00858 
2025-03-31 02:12:52.385634: train_loss -0.7678 
2025-03-31 02:12:52.385972: val_loss -0.5532 
2025-03-31 02:12:52.386288: Pseudo dice [0.5615] 
2025-03-31 02:12:52.386376: Epoch time: 273.81 s 
2025-03-31 02:12:54.384143:  
2025-03-31 02:12:54.384356: Epoch 157 
2025-03-31 02:12:54.384469: Current learning rate: 0.00858 
2025-03-31 02:17:28.629990: train_loss -0.7385 
2025-03-31 02:17:28.630358: val_loss -0.6292 
2025-03-31 02:17:28.630458: Pseudo dice [0.6367] 
2025-03-31 02:17:28.630561: Epoch time: 274.25 s 
2025-03-31 02:17:28.630670: Yayy! New best EMA pseudo Dice: 0.5733 
2025-03-31 02:17:31.948231:  
2025-03-31 02:17:31.948478: Epoch 158 
2025-03-31 02:17:31.948628: Current learning rate: 0.00857 
2025-03-31 02:22:05.965973: train_loss -0.7795 
2025-03-31 02:22:05.966282: val_loss -0.577 
2025-03-31 02:22:05.966368: Pseudo dice [0.5756] 
2025-03-31 02:22:05.966469: Epoch time: 274.02 s 
2025-03-31 02:22:05.966529: Yayy! New best EMA pseudo Dice: 0.5735 
2025-03-31 02:22:09.714534:  
2025-03-31 02:22:09.714795: Epoch 159 
2025-03-31 02:22:09.714937: Current learning rate: 0.00856 
2025-03-31 02:26:43.914482: train_loss -0.7387 
2025-03-31 02:26:43.914826: val_loss -0.6512 
2025-03-31 02:26:43.914916: Pseudo dice [0.6254] 
2025-03-31 02:26:43.915072: Epoch time: 274.2 s 
2025-03-31 02:26:43.915135: Yayy! New best EMA pseudo Dice: 0.5787 
2025-03-31 02:26:47.311401:  
2025-03-31 02:26:47.311677: Epoch 160 
2025-03-31 02:26:47.311825: Current learning rate: 0.00855 
2025-03-31 02:31:21.714210: train_loss -0.7685 
2025-03-31 02:31:21.714574: val_loss -0.5454 
2025-03-31 02:31:21.714664: Pseudo dice [0.4319] 
2025-03-31 02:31:21.714761: Epoch time: 274.41 s 
2025-03-31 02:31:23.728292:  
2025-03-31 02:31:23.728505: Epoch 161 
2025-03-31 02:31:23.728644: Current learning rate: 0.00854 
2025-03-31 02:35:58.023467: train_loss -0.7636 
2025-03-31 02:35:58.023851: val_loss -0.5294 
2025-03-31 02:35:58.023942: Pseudo dice [0.6406] 
2025-03-31 02:35:58.024036: Epoch time: 274.3 s 
2025-03-31 02:36:00.059197:  
2025-03-31 02:36:00.059472: Epoch 162 
2025-03-31 02:36:00.059601: Current learning rate: 0.00853 
2025-03-31 02:40:34.474011: train_loss -0.7553 
2025-03-31 02:40:34.474350: val_loss -0.4697 
2025-03-31 02:40:34.474447: Pseudo dice [0.4212] 
2025-03-31 02:40:34.474548: Epoch time: 274.42 s 
2025-03-31 02:40:36.512227:  
2025-03-31 02:40:36.512453: Epoch 163 
2025-03-31 02:40:36.512591: Current learning rate: 0.00852 
2025-03-31 02:45:10.441086: train_loss -0.784 
2025-03-31 02:45:10.441466: val_loss -0.6598 
2025-03-31 02:45:10.441566: Pseudo dice [0.696] 
2025-03-31 02:45:10.441691: Epoch time: 273.93 s 
2025-03-31 02:45:12.487185:  
2025-03-31 02:45:12.487380: Epoch 164 
2025-03-31 02:45:12.487549: Current learning rate: 0.00851 
2025-03-31 02:49:46.608524: train_loss -0.7615 
2025-03-31 02:49:46.608829: val_loss -0.67 
2025-03-31 02:49:46.608915: Pseudo dice [0.6242] 
2025-03-31 02:49:46.609001: Epoch time: 274.13 s 
2025-03-31 02:49:48.598448:  
2025-03-31 02:49:48.598633: Epoch 165 
2025-03-31 02:49:48.598775: Current learning rate: 0.0085 
2025-03-31 02:54:22.426480: train_loss -0.7816 
2025-03-31 02:54:22.426805: val_loss -0.5955 
2025-03-31 02:54:22.426902: Pseudo dice [0.5231] 
2025-03-31 02:54:22.426988: Epoch time: 273.83 s 
2025-03-31 02:54:24.641876:  
2025-03-31 02:54:24.642211: Epoch 166 
2025-03-31 02:54:24.642472: Current learning rate: 0.00849 
2025-03-31 02:58:58.604091: train_loss -0.789 
2025-03-31 02:58:58.604420: val_loss -0.5391 
2025-03-31 02:58:58.604509: Pseudo dice [0.4701] 
2025-03-31 02:58:58.604643: Epoch time: 273.97 s 
2025-03-31 02:59:00.553337:  
2025-03-31 02:59:00.553715: Epoch 167 
2025-03-31 02:59:00.553851: Current learning rate: 0.00848 
2025-03-31 03:03:34.611126: train_loss -0.7896 
2025-03-31 03:03:34.611526: val_loss -0.6713 
2025-03-31 03:03:34.611622: Pseudo dice [0.6646] 
2025-03-31 03:03:34.611719: Epoch time: 274.06 s 
2025-03-31 03:03:36.597039:  
2025-03-31 03:03:36.597302: Epoch 168 
2025-03-31 03:03:36.597494: Current learning rate: 0.00847 
2025-03-31 03:08:10.908759: train_loss -0.728 
2025-03-31 03:08:10.909100: val_loss -0.6065 
2025-03-31 03:08:10.909189: Pseudo dice [0.6605] 
2025-03-31 03:08:10.909304: Epoch time: 274.32 s 
2025-03-31 03:08:10.909396: Yayy! New best EMA pseudo Dice: 0.5799 
2025-03-31 03:08:14.270359:  
2025-03-31 03:08:14.270582: Epoch 169 
2025-03-31 03:08:14.270696: Current learning rate: 0.00847 
2025-03-31 03:12:47.672932: train_loss -0.7656 
2025-03-31 03:12:47.673308: val_loss -0.5778 
2025-03-31 03:12:47.673406: Pseudo dice [0.5551] 
2025-03-31 03:12:47.673506: Epoch time: 273.41 s 
2025-03-31 03:12:49.639599:  
2025-03-31 03:12:49.639860: Epoch 170 
2025-03-31 03:12:49.639978: Current learning rate: 0.00846 
2025-03-31 03:17:22.915411: train_loss -0.7928 
2025-03-31 03:17:22.915720: val_loss -0.5382 
2025-03-31 03:17:22.915821: Pseudo dice [0.4797] 
2025-03-31 03:17:22.915921: Epoch time: 273.28 s 
2025-03-31 03:17:24.879610:  
2025-03-31 03:17:24.879912: Epoch 171 
2025-03-31 03:17:24.880119: Current learning rate: 0.00845 
2025-03-31 03:21:58.740956: train_loss -0.6644 
2025-03-31 03:21:58.741258: val_loss -0.4321 
2025-03-31 03:21:58.741356: Pseudo dice [0.2956] 
2025-03-31 03:21:58.741468: Epoch time: 273.87 s 
2025-03-31 03:22:00.751786:  
2025-03-31 03:22:00.752069: Epoch 172 
2025-03-31 03:22:00.752203: Current learning rate: 0.00844 
2025-03-31 03:26:34.553602: train_loss -0.7302 
2025-03-31 03:26:34.553884: val_loss -0.6046 
2025-03-31 03:26:34.553966: Pseudo dice [0.3907] 
2025-03-31 03:26:34.554062: Epoch time: 273.81 s 
2025-03-31 03:26:36.850815:  
2025-03-31 03:26:36.851093: Epoch 173 
2025-03-31 03:26:36.851262: Current learning rate: 0.00843 
2025-03-31 03:31:11.183646: train_loss -0.7483 
2025-03-31 03:31:11.184000: val_loss -0.6758 
2025-03-31 03:31:11.184119: Pseudo dice [0.6539] 
2025-03-31 03:31:11.184289: Epoch time: 274.34 s 
2025-03-31 03:31:13.306006:  
2025-03-31 03:31:13.306274: Epoch 174 
2025-03-31 03:31:13.306416: Current learning rate: 0.00842 
2025-03-31 03:35:47.285609: train_loss -0.7464 
2025-03-31 03:35:47.285946: val_loss -0.4442 
2025-03-31 03:35:47.286033: Pseudo dice [0.2712] 
2025-03-31 03:35:47.286129: Epoch time: 273.98 s 
2025-03-31 03:35:49.277553:  
2025-03-31 03:35:49.277757: Epoch 175 
2025-03-31 03:35:49.277904: Current learning rate: 0.00841 
2025-03-31 03:40:23.473961: train_loss -0.7014 
2025-03-31 03:40:23.474307: val_loss -0.4664 
2025-03-31 03:40:23.474400: Pseudo dice [0.3921] 
2025-03-31 03:40:23.474496: Epoch time: 274.2 s 
2025-03-31 03:40:25.446690:  
2025-03-31 03:40:25.446891: Epoch 176 
2025-03-31 03:40:25.447007: Current learning rate: 0.0084 
2025-03-31 03:44:59.567569: train_loss -0.7487 
2025-03-31 03:44:59.567932: val_loss -0.605 
2025-03-31 03:44:59.568053: Pseudo dice [0.5449] 
2025-03-31 03:44:59.568147: Epoch time: 274.12 s 
2025-03-31 03:45:01.557347:  
2025-03-31 03:45:01.557681: Epoch 177 
2025-03-31 03:45:01.557840: Current learning rate: 0.00839 
2025-03-31 03:49:36.048543: train_loss -0.7706 
2025-03-31 03:49:36.048865: val_loss -0.5384 
2025-03-31 03:49:36.048955: Pseudo dice [0.392] 
2025-03-31 03:49:36.049055: Epoch time: 274.5 s 
2025-03-31 03:49:38.019889:  
2025-03-31 03:49:38.020063: Epoch 178 
2025-03-31 03:49:38.020215: Current learning rate: 0.00838 
2025-03-31 03:54:12.448970: train_loss -0.7884 
2025-03-31 03:54:12.449630: val_loss -0.5517 
2025-03-31 03:54:12.449773: Pseudo dice [0.4642] 
2025-03-31 03:54:12.449859: Epoch time: 274.43 s 
2025-03-31 03:54:14.423483:  
2025-03-31 03:54:14.423720: Epoch 179 
2025-03-31 03:54:14.423845: Current learning rate: 0.00837 
2025-03-31 03:58:49.007659: train_loss -0.7524 
2025-03-31 03:58:49.008027: val_loss -0.5829 
2025-03-31 03:58:49.008114: Pseudo dice [0.5294] 
2025-03-31 03:58:49.008206: Epoch time: 274.59 s 
2025-03-31 03:58:50.976334:  
2025-03-31 03:58:50.976550: Epoch 180 
2025-03-31 03:58:50.976678: Current learning rate: 0.00836 
2025-03-31 04:03:25.511462: train_loss -0.7734 
2025-03-31 04:03:25.511988: val_loss -0.5464 
2025-03-31 04:03:25.512074: Pseudo dice [0.5487] 
2025-03-31 04:03:25.512226: Epoch time: 274.54 s 
2025-03-31 04:03:27.802411:  
2025-03-31 04:03:27.802619: Epoch 181 
2025-03-31 04:03:27.802735: Current learning rate: 0.00836 
2025-03-31 04:08:01.957000: train_loss -0.7807 
2025-03-31 04:08:01.957305: val_loss -0.5893 
2025-03-31 04:08:01.957396: Pseudo dice [0.6072] 
2025-03-31 04:08:01.957545: Epoch time: 274.16 s 
2025-03-31 04:08:03.919098:  
2025-03-31 04:08:03.919360: Epoch 182 
2025-03-31 04:08:03.919506: Current learning rate: 0.00835 
2025-03-31 04:12:38.480302: train_loss -0.8076 
2025-03-31 04:12:38.480624: val_loss -0.6073 
2025-03-31 04:12:38.480726: Pseudo dice [0.5973] 
2025-03-31 04:12:38.480825: Epoch time: 274.57 s 
2025-03-31 04:12:40.452464:  
2025-03-31 04:12:40.452729: Epoch 183 
2025-03-31 04:12:40.452892: Current learning rate: 0.00834 
2025-03-31 04:17:14.651727: train_loss -0.7848 
2025-03-31 04:17:14.652096: val_loss -0.4617 
2025-03-31 04:17:14.652209: Pseudo dice [0.3346] 
2025-03-31 04:17:14.652356: Epoch time: 274.2 s 
2025-03-31 04:17:16.629855:  
2025-03-31 04:17:16.630055: Epoch 184 
2025-03-31 04:17:16.630172: Current learning rate: 0.00833 
2025-03-31 04:21:51.409389: train_loss -0.7926 
2025-03-31 04:21:51.409728: val_loss -0.589 
2025-03-31 04:21:51.409814: Pseudo dice [0.605] 
2025-03-31 04:21:51.409917: Epoch time: 274.78 s 
2025-03-31 04:21:53.388819:  
2025-03-31 04:21:53.389053: Epoch 185 
2025-03-31 04:21:53.389167: Current learning rate: 0.00832 
2025-03-31 04:26:28.165337: train_loss -0.7826 
2025-03-31 04:26:28.165985: val_loss -0.5869 
2025-03-31 04:26:28.166091: Pseudo dice [0.5653] 
2025-03-31 04:26:28.166179: Epoch time: 274.78 s 
2025-03-31 04:26:30.128650:  
2025-03-31 04:26:30.128832: Epoch 186 
2025-03-31 04:26:30.128978: Current learning rate: 0.00831 
2025-03-31 04:31:05.001476: train_loss -0.7869 
2025-03-31 04:31:05.001889: val_loss -0.6095 
2025-03-31 04:31:05.001985: Pseudo dice [0.6111] 
2025-03-31 04:31:05.002069: Epoch time: 274.88 s 
2025-03-31 04:31:06.982435:  
2025-03-31 04:31:06.982692: Epoch 187 
2025-03-31 04:31:06.982816: Current learning rate: 0.0083 
2025-03-31 04:35:42.457511: train_loss -0.7469 
2025-03-31 04:35:42.463869: val_loss -0.63 
2025-03-31 04:35:42.463980: Pseudo dice [0.6995] 
2025-03-31 04:35:42.464069: Epoch time: 275.48 s 
2025-03-31 04:35:44.440622:  
2025-03-31 04:35:44.440827: Epoch 188 
2025-03-31 04:35:44.440975: Current learning rate: 0.00829 
2025-03-31 04:40:18.849713: train_loss -0.788 
2025-03-31 04:40:18.850052: val_loss -0.6596 
2025-03-31 04:40:18.850175: Pseudo dice [0.6432] 
2025-03-31 04:40:18.850300: Epoch time: 274.41 s 
2025-03-31 04:40:21.150978:  
2025-03-31 04:40:21.151253: Epoch 189 
2025-03-31 04:40:21.151377: Current learning rate: 0.00828 
2025-03-31 04:44:55.890326: train_loss -0.7682 
2025-03-31 04:44:55.890639: val_loss -0.4669 
2025-03-31 04:44:55.890726: Pseudo dice [0.5255] 
2025-03-31 04:44:55.890818: Epoch time: 274.74 s 
2025-03-31 04:44:57.850735:  
2025-03-31 04:44:57.850941: Epoch 190 
2025-03-31 04:44:57.851073: Current learning rate: 0.00827 
2025-03-31 04:49:33.097672: train_loss -0.7743 
2025-03-31 04:49:33.097982: val_loss -0.6187 
2025-03-31 04:49:33.098061: Pseudo dice [0.605] 
2025-03-31 04:49:33.098145: Epoch time: 275.25 s 
2025-03-31 04:49:35.067696:  
2025-03-31 04:49:35.067957: Epoch 191 
2025-03-31 04:49:35.068122: Current learning rate: 0.00826 
2025-03-31 04:54:08.978809: train_loss -0.8005 
2025-03-31 04:54:08.979112: val_loss -0.6501 
2025-03-31 04:54:08.979203: Pseudo dice [0.677] 
2025-03-31 04:54:08.979291: Epoch time: 273.91 s 
2025-03-31 04:54:10.975024:  
2025-03-31 04:54:10.975256: Epoch 192 
2025-03-31 04:54:10.975444: Current learning rate: 0.00825 
2025-03-31 04:58:43.703207: train_loss -0.7868 
2025-03-31 04:58:43.703570: val_loss -0.5897 
2025-03-31 04:58:43.703672: Pseudo dice [0.6432] 
2025-03-31 04:58:43.703884: Epoch time: 272.73 s 
2025-03-31 04:58:45.697842:  
2025-03-31 04:58:45.698108: Epoch 193 
2025-03-31 04:58:45.698272: Current learning rate: 0.00824 
2025-03-31 05:03:18.522138: train_loss -0.7694 
2025-03-31 05:03:18.522521: val_loss -0.6075 
2025-03-31 05:03:18.522636: Pseudo dice [0.5399] 
2025-03-31 05:03:18.522827: Epoch time: 272.83 s 
2025-03-31 05:03:20.525487:  
2025-03-31 05:03:20.525769: Epoch 194 
2025-03-31 05:03:20.525912: Current learning rate: 0.00824 
2025-03-31 05:07:53.692856: train_loss -0.7634 
2025-03-31 05:07:53.693203: val_loss -0.5969 
2025-03-31 05:07:53.693303: Pseudo dice [0.4978] 
2025-03-31 05:07:53.693416: Epoch time: 273.17 s 
2025-03-31 05:07:55.723144:  
2025-03-31 05:07:55.723401: Epoch 195 
2025-03-31 05:07:55.723539: Current learning rate: 0.00823 
2025-03-31 05:12:28.928596: train_loss -0.7488 
2025-03-31 05:12:28.928941: val_loss -0.5772 
2025-03-31 05:12:28.929025: Pseudo dice [0.4638] 
2025-03-31 05:12:28.929124: Epoch time: 273.21 s 
2025-03-31 05:12:31.207430:  
2025-03-31 05:12:31.207678: Epoch 196 
2025-03-31 05:12:31.207803: Current learning rate: 0.00822 
2025-03-31 05:17:04.395111: train_loss -0.7731 
2025-03-31 05:17:04.395406: val_loss -0.6236 
2025-03-31 05:17:04.395488: Pseudo dice [0.5998] 
2025-03-31 05:17:04.395570: Epoch time: 273.19 s 
2025-03-31 05:17:06.377082:  
2025-03-31 05:17:06.377324: Epoch 197 
2025-03-31 05:17:06.377479: Current learning rate: 0.00821 
2025-03-31 05:21:39.385360: train_loss -0.7879 
2025-03-31 05:21:39.385668: val_loss -0.5705 
2025-03-31 05:21:39.385754: Pseudo dice [0.472] 
2025-03-31 05:21:39.385845: Epoch time: 273.01 s 
2025-03-31 05:21:41.370862:  
2025-03-31 05:21:41.371150: Epoch 198 
2025-03-31 05:21:41.371265: Current learning rate: 0.0082 
2025-03-31 05:26:14.978458: train_loss -0.7747 
2025-03-31 05:26:14.978754: val_loss -0.5832 
2025-03-31 05:26:14.978859: Pseudo dice [0.5307] 
2025-03-31 05:26:14.978946: Epoch time: 273.61 s 
2025-03-31 05:26:16.973207:  
2025-03-31 05:26:16.973435: Epoch 199 
2025-03-31 05:26:16.973571: Current learning rate: 0.00819 
2025-03-31 05:30:50.719616: train_loss -0.7817 
2025-03-31 05:30:50.719987: val_loss -0.6148 
2025-03-31 05:30:50.720314: Pseudo dice [0.618] 
2025-03-31 05:30:50.720432: Epoch time: 273.75 s 
2025-03-31 05:30:53.936878:  
2025-03-31 05:30:53.937113: Epoch 200 
2025-03-31 05:30:53.937230: Current learning rate: 0.00818 
2025-03-31 05:35:27.823236: train_loss -0.7849 
2025-03-31 05:35:27.823474: val_loss -0.6389 
2025-03-31 05:35:27.823613: Pseudo dice [0.5947] 
2025-03-31 05:35:27.823712: Epoch time: 273.89 s 
2025-03-31 05:35:29.824034:  
2025-03-31 05:35:29.824234: Epoch 201 
2025-03-31 05:35:29.824351: Current learning rate: 0.00817 
2025-03-31 05:40:03.655159: train_loss -0.7764 
2025-03-31 05:40:03.655509: val_loss -0.5256 
2025-03-31 05:40:03.655654: Pseudo dice [0.543] 
2025-03-31 05:40:03.655754: Epoch time: 273.84 s 
2025-03-31 05:40:05.646295:  
2025-03-31 05:40:05.646560: Epoch 202 
2025-03-31 05:40:05.646712: Current learning rate: 0.00816 
2025-03-31 05:44:39.491659: train_loss -0.8003 
2025-03-31 05:44:39.491995: val_loss -0.525 
2025-03-31 05:44:39.492085: Pseudo dice [0.4036] 
2025-03-31 05:44:39.492185: Epoch time: 273.85 s 
2025-03-31 05:44:41.788369:  
2025-03-31 05:44:41.788584: Epoch 203 
2025-03-31 05:44:41.788709: Current learning rate: 0.00815 
2025-03-31 05:49:15.141803: train_loss -0.7979 
2025-03-31 05:49:15.142152: val_loss -0.6651 
2025-03-31 05:49:15.142240: Pseudo dice [0.6566] 
2025-03-31 05:49:15.142336: Epoch time: 273.36 s 
2025-03-31 05:49:17.137101:  
2025-03-31 05:49:17.137378: Epoch 204 
2025-03-31 05:49:17.137508: Current learning rate: 0.00814 
2025-03-31 05:53:51.251583: train_loss -0.7758 
2025-03-31 05:53:51.251942: val_loss -0.5827 
2025-03-31 05:53:51.252057: Pseudo dice [0.4862] 
2025-03-31 05:53:51.252153: Epoch time: 274.12 s 
2025-03-31 05:53:53.224543:  
2025-03-31 05:53:53.224807: Epoch 205 
2025-03-31 05:53:53.224945: Current learning rate: 0.00813 
2025-03-31 05:58:26.763666: train_loss -0.7469 
2025-03-31 05:58:26.764032: val_loss -0.415 
2025-03-31 05:58:26.764128: Pseudo dice [0.3123] 
2025-03-31 05:58:26.764229: Epoch time: 273.54 s 
2025-03-31 05:58:28.662601:  
2025-03-31 05:58:28.662799: Epoch 206 
2025-03-31 05:58:28.662948: Current learning rate: 0.00813 
2025-03-31 06:03:02.173539: train_loss -0.7276 
2025-03-31 06:03:02.173946: val_loss -0.5557 
2025-03-31 06:03:02.174047: Pseudo dice [0.5686] 
2025-03-31 06:03:02.174133: Epoch time: 273.51 s 
2025-03-31 06:03:04.090299:  
2025-03-31 06:03:04.090621: Epoch 207 
2025-03-31 06:03:04.090861: Current learning rate: 0.00812 
2025-03-31 06:07:37.452249: train_loss -0.7703 
2025-03-31 06:07:37.452572: val_loss -0.6085 
2025-03-31 06:07:37.452666: Pseudo dice [0.5945] 
2025-03-31 06:07:37.452768: Epoch time: 273.37 s 
2025-03-31 06:07:39.343548:  
2025-03-31 06:07:39.343838: Epoch 208 
2025-03-31 06:07:39.343957: Current learning rate: 0.00811 
2025-03-31 06:12:12.719821: train_loss -0.7879 
2025-03-31 06:12:12.720186: val_loss -0.6369 
2025-03-31 06:12:12.720337: Pseudo dice [0.6275] 
2025-03-31 06:12:12.720434: Epoch time: 273.38 s 
2025-03-31 06:12:14.606746:  
2025-03-31 06:12:14.606913: Epoch 209 
2025-03-31 06:12:14.607056: Current learning rate: 0.0081 
2025-03-31 06:16:47.946057: train_loss -0.7866 
2025-03-31 06:16:47.946475: val_loss -0.5241 
2025-03-31 06:16:47.946564: Pseudo dice [0.5154] 
2025-03-31 06:16:47.946658: Epoch time: 273.34 s 
2025-03-31 06:16:49.826418:  
2025-03-31 06:16:49.826619: Epoch 210 
2025-03-31 06:16:49.826734: Current learning rate: 0.00809 
2025-03-31 06:21:23.409729: train_loss -0.7875 
2025-03-31 06:21:23.410095: val_loss -0.5698 
2025-03-31 06:21:23.410184: Pseudo dice [0.5496] 
2025-03-31 06:21:23.410276: Epoch time: 273.59 s 
2025-03-31 06:21:25.634058:  
2025-03-31 06:21:25.634279: Epoch 211 
2025-03-31 06:21:25.634413: Current learning rate: 0.00808 
2025-03-31 06:25:59.306551: train_loss -0.7745 
2025-03-31 06:25:59.306850: val_loss -0.6479 
2025-03-31 06:25:59.306930: Pseudo dice [0.5868] 
2025-03-31 06:25:59.307018: Epoch time: 273.68 s 
2025-03-31 06:26:01.210775:  
2025-03-31 06:26:01.211069: Epoch 212 
2025-03-31 06:26:01.211214: Current learning rate: 0.00807 
2025-03-31 06:30:34.926475: train_loss -0.7828 
2025-03-31 06:30:34.926808: val_loss -0.6921 
2025-03-31 06:30:34.926923: Pseudo dice [0.664] 
2025-03-31 06:30:34.927032: Epoch time: 273.72 s 
2025-03-31 06:30:36.826182:  
2025-03-31 06:30:36.826427: Epoch 213 
2025-03-31 06:30:36.826550: Current learning rate: 0.00806 
2025-03-31 06:35:10.740905: train_loss -0.7913 
2025-03-31 06:35:10.741224: val_loss -0.5304 
2025-03-31 06:35:10.741319: Pseudo dice [0.472] 
2025-03-31 06:35:10.741424: Epoch time: 273.92 s 
2025-03-31 06:35:12.664472:  
2025-03-31 06:35:12.664689: Epoch 214 
2025-03-31 06:35:12.664803: Current learning rate: 0.00805 
2025-03-31 06:39:46.941078: train_loss -0.7752 
2025-03-31 06:39:46.941455: val_loss -0.5672 
2025-03-31 06:39:46.941561: Pseudo dice [0.4367] 
2025-03-31 06:39:46.941658: Epoch time: 274.28 s 
2025-03-31 06:39:48.850271:  
2025-03-31 06:39:48.850445: Epoch 215 
2025-03-31 06:39:48.850581: Current learning rate: 0.00804 
2025-03-31 06:44:22.912283: train_loss -0.7972 
2025-03-31 06:44:22.912783: val_loss -0.6397 
2025-03-31 06:44:22.912859: Pseudo dice [0.6355] 
2025-03-31 06:44:22.912941: Epoch time: 274.07 s 
2025-03-31 06:44:24.787880:  
2025-03-31 06:44:24.788069: Epoch 216 
2025-03-31 06:44:24.788185: Current learning rate: 0.00803 
2025-03-31 06:48:58.110789: train_loss -0.7818 
2025-03-31 06:48:58.111126: val_loss -0.5652 
2025-03-31 06:48:58.111214: Pseudo dice [0.416] 
2025-03-31 06:48:58.111311: Epoch time: 273.33 s 
2025-03-31 06:49:00.005271:  
2025-03-31 06:49:00.005470: Epoch 217 
2025-03-31 06:49:00.005586: Current learning rate: 0.00802 
2025-03-31 06:53:33.569677: train_loss -0.7825 
2025-03-31 06:53:33.569990: val_loss -0.4656 
2025-03-31 06:53:33.570077: Pseudo dice [0.2879] 
2025-03-31 06:53:33.570163: Epoch time: 273.57 s 
2025-03-31 06:53:35.534456:  
2025-03-31 06:53:35.534645: Epoch 218 
2025-03-31 06:53:35.534760: Current learning rate: 0.00801 
2025-03-31 06:58:12.026922: train_loss -0.7672 
2025-03-31 06:58:12.027474: val_loss -0.5939 
2025-03-31 06:58:12.027588: Pseudo dice [0.6183] 
2025-03-31 06:58:12.027675: Epoch time: 276.5 s 
2025-03-31 06:58:14.287426:  
2025-03-31 06:58:14.287657: Epoch 219 
2025-03-31 06:58:14.287803: Current learning rate: 0.00801 
2025-03-31 07:02:48.489870: train_loss -0.7129 
2025-03-31 07:02:48.490237: val_loss -0.63 
2025-03-31 07:02:48.490402: Pseudo dice [0.5704] 
2025-03-31 07:02:48.490494: Epoch time: 274.21 s 
2025-03-31 07:02:50.421064:  
2025-03-31 07:02:50.421334: Epoch 220 
2025-03-31 07:02:50.421471: Current learning rate: 0.008 
2025-03-31 07:07:24.430811: train_loss -0.7627 
2025-03-31 07:07:24.431345: val_loss -0.5675 
2025-03-31 07:07:24.431426: Pseudo dice [0.3735] 
2025-03-31 07:07:24.431509: Epoch time: 274.01 s 
2025-03-31 07:07:26.375533:  
2025-03-31 07:07:26.375768: Epoch 221 
2025-03-31 07:07:26.375924: Current learning rate: 0.00799 
2025-03-31 07:12:00.485737: train_loss -0.7443 
2025-03-31 07:12:00.486114: val_loss -0.6299 
2025-03-31 07:12:00.486278: Pseudo dice [0.6196] 
2025-03-31 07:12:00.486364: Epoch time: 274.11 s 
2025-03-31 07:12:02.446080:  
2025-03-31 07:12:02.446289: Epoch 222 
2025-03-31 07:12:02.446418: Current learning rate: 0.00798 
2025-03-31 07:16:37.665027: train_loss -0.747 
2025-03-31 07:16:37.665444: val_loss -0.6072 
2025-03-31 07:16:37.665542: Pseudo dice [0.552] 
2025-03-31 07:16:37.665625: Epoch time: 275.22 s 
2025-03-31 07:16:39.565953:  
2025-03-31 07:16:39.566242: Epoch 223 
2025-03-31 07:16:39.566460: Current learning rate: 0.00797 
2025-03-31 07:21:13.496940: train_loss -0.7662 
2025-03-31 07:21:13.497333: val_loss -0.6429 
2025-03-31 07:21:13.497422: Pseudo dice [0.7049] 
2025-03-31 07:21:13.497531: Epoch time: 273.93 s 
2025-03-31 07:21:15.420395:  
2025-03-31 07:21:15.420647: Epoch 224 
2025-03-31 07:21:15.420835: Current learning rate: 0.00796 
2025-03-31 07:25:50.125948: train_loss -0.7355 
2025-03-31 07:25:50.126569: val_loss -0.5655 
2025-03-31 07:25:50.126714: Pseudo dice [0.6165] 
2025-03-31 07:25:50.126813: Epoch time: 274.71 s 
2025-03-31 07:25:52.039767:  
2025-03-31 07:25:52.040023: Epoch 225 
2025-03-31 07:25:52.040142: Current learning rate: 0.00795 
2025-03-31 07:30:26.493514: train_loss -0.7654 
2025-03-31 07:30:26.493906: val_loss -0.6827 
2025-03-31 07:30:26.493995: Pseudo dice [0.6529] 
2025-03-31 07:30:26.494092: Epoch time: 274.46 s 
2025-03-31 07:30:28.374132:  
2025-03-31 07:30:28.374323: Epoch 226 
2025-03-31 07:30:28.374438: Current learning rate: 0.00794 
2025-03-31 07:35:02.780082: train_loss -0.7713 
2025-03-31 07:35:02.780578: val_loss -0.5524 
2025-03-31 07:35:02.780663: Pseudo dice [0.538] 
2025-03-31 07:35:02.780748: Epoch time: 274.41 s 
2025-03-31 07:35:04.662117:  
2025-03-31 07:35:04.662327: Epoch 227 
2025-03-31 07:35:04.662484: Current learning rate: 0.00793 
2025-03-31 07:39:38.449371: train_loss -0.7819 
2025-03-31 07:39:38.449697: val_loss -0.6169 
2025-03-31 07:39:38.449852: Pseudo dice [0.5875] 
2025-03-31 07:39:38.449950: Epoch time: 273.79 s 
2025-03-31 07:39:40.346474:  
2025-03-31 07:39:40.346833: Epoch 228 
2025-03-31 07:39:40.346980: Current learning rate: 0.00792 
2025-03-31 07:44:13.810938: train_loss -0.7804 
2025-03-31 07:44:13.811247: val_loss -0.5901 
2025-03-31 07:44:13.811333: Pseudo dice [0.4039] 
2025-03-31 07:44:13.811425: Epoch time: 273.47 s 
2025-03-31 07:44:15.701417:  
2025-03-31 07:44:15.701621: Epoch 229 
2025-03-31 07:44:15.701762: Current learning rate: 0.00791 
2025-03-31 07:48:49.077282: train_loss -0.7831 
2025-03-31 07:48:49.077672: val_loss -0.6009 
2025-03-31 07:48:49.077770: Pseudo dice [0.6028] 
2025-03-31 07:48:49.077855: Epoch time: 273.38 s 
2025-03-31 07:48:50.969730:  
2025-03-31 07:48:50.969981: Epoch 230 
2025-03-31 07:48:50.970142: Current learning rate: 0.0079 
2025-03-31 07:53:24.649514: train_loss -0.772 
2025-03-31 07:53:24.649822: val_loss -0.5012 
2025-03-31 07:53:24.649910: Pseudo dice [0.3407] 
2025-03-31 07:53:24.650022: Epoch time: 273.68 s 
2025-03-31 07:53:26.549033:  
2025-03-31 07:53:26.549278: Epoch 231 
2025-03-31 07:53:26.549432: Current learning rate: 0.00789 
2025-03-31 07:57:59.605755: train_loss -0.7911 
2025-03-31 07:57:59.606097: val_loss -0.5617 
2025-03-31 07:57:59.606248: Pseudo dice [0.4067] 
2025-03-31 07:57:59.606361: Epoch time: 273.06 s 
2025-03-31 07:58:01.486865:  
2025-03-31 07:58:01.487152: Epoch 232 
2025-03-31 07:58:01.487334: Current learning rate: 0.00789 
2025-03-31 08:02:35.373575: train_loss -0.7429 
2025-03-31 08:02:35.373941: val_loss -0.5424 
2025-03-31 08:02:35.374048: Pseudo dice [0.4599] 
2025-03-31 08:02:35.374146: Epoch time: 273.89 s 
2025-03-31 08:02:37.262103:  
2025-03-31 08:02:37.262299: Epoch 233 
2025-03-31 08:02:37.262417: Current learning rate: 0.00788 
2025-03-31 08:07:10.890527: train_loss -0.774 
2025-03-31 08:07:10.890859: val_loss -0.6367 
2025-03-31 08:07:10.891001: Pseudo dice [0.6883] 
2025-03-31 08:07:10.891095: Epoch time: 273.63 s 
2025-03-31 08:07:12.785339:  
2025-03-31 08:07:12.785572: Epoch 234 
2025-03-31 08:07:12.785721: Current learning rate: 0.00787 
2025-03-31 08:11:46.323987: train_loss -0.7984 
2025-03-31 08:11:46.324389: val_loss -0.6608 
2025-03-31 08:11:46.325036: Pseudo dice [0.7241] 
2025-03-31 08:11:46.325123: Epoch time: 273.54 s 
2025-03-31 08:11:48.192116:  
2025-03-31 08:11:48.192320: Epoch 235 
2025-03-31 08:11:48.192434: Current learning rate: 0.00786 
2025-03-31 08:16:21.795792: train_loss -0.7676 
2025-03-31 08:16:21.796176: val_loss -0.6167 
2025-03-31 08:16:21.796265: Pseudo dice [0.6328] 
2025-03-31 08:16:21.796376: Epoch time: 273.61 s 
2025-03-31 08:16:23.975981:  
2025-03-31 08:16:23.976185: Epoch 236 
2025-03-31 08:16:23.976302: Current learning rate: 0.00785 
2025-03-31 08:20:58.456513: train_loss -0.7515 
2025-03-31 08:20:58.456827: val_loss -0.6043 
2025-03-31 08:20:58.456924: Pseudo dice [0.4273] 
2025-03-31 08:20:58.457036: Epoch time: 274.48 s 
2025-03-31 08:21:00.367231:  
2025-03-31 08:21:00.367494: Epoch 237 
2025-03-31 08:21:00.367661: Current learning rate: 0.00784 
2025-03-31 08:25:34.784168: train_loss -0.7406 
2025-03-31 08:25:34.784473: val_loss -0.6478 
2025-03-31 08:25:34.784556: Pseudo dice [0.5849] 
2025-03-31 08:25:34.784646: Epoch time: 274.42 s 
2025-03-31 08:25:36.668458:  
2025-03-31 08:25:36.668674: Epoch 238 
2025-03-31 08:25:36.668789: Current learning rate: 0.00783 
2025-03-31 08:30:10.956300: train_loss -0.7779 
2025-03-31 08:30:10.956653: val_loss -0.6236 
2025-03-31 08:30:10.956815: Pseudo dice [0.6163] 
2025-03-31 08:30:10.956903: Epoch time: 274.29 s 
2025-03-31 08:30:12.844617:  
2025-03-31 08:30:12.844886: Epoch 239 
2025-03-31 08:30:12.845002: Current learning rate: 0.00782 
2025-03-31 08:34:46.724212: train_loss -0.7751 
2025-03-31 08:34:46.724560: val_loss -0.5893 
2025-03-31 08:34:46.724680: Pseudo dice [0.6201] 
2025-03-31 08:34:46.724816: Epoch time: 273.88 s 
2025-03-31 08:34:48.650676:  
2025-03-31 08:34:48.650900: Epoch 240 
2025-03-31 08:34:48.651019: Current learning rate: 0.00781 
2025-03-31 08:39:22.775217: train_loss -0.7229 
2025-03-31 08:39:22.775576: val_loss -0.6581 
2025-03-31 08:39:22.775671: Pseudo dice [0.6991] 
2025-03-31 08:39:22.775786: Epoch time: 274.13 s 
2025-03-31 08:39:24.691056:  
2025-03-31 08:39:24.691278: Epoch 241 
2025-03-31 08:39:24.691394: Current learning rate: 0.0078 
2025-03-31 08:43:58.121424: train_loss -0.7886 
2025-03-31 08:43:58.121789: val_loss -0.6379 
2025-03-31 08:43:58.121867: Pseudo dice [0.5781] 
2025-03-31 08:43:58.121968: Epoch time: 273.43 s 
2025-03-31 08:44:00.045540:  
2025-03-31 08:44:00.045778: Epoch 242 
2025-03-31 08:44:00.045893: Current learning rate: 0.00779 
2025-03-31 08:48:33.264496: train_loss -0.7562 
2025-03-31 08:48:33.264803: val_loss -0.5795 
2025-03-31 08:48:33.264883: Pseudo dice [0.538] 
2025-03-31 08:48:33.264970: Epoch time: 273.22 s 
2025-03-31 08:48:35.175790:  
2025-03-31 08:48:35.176024: Epoch 243 
2025-03-31 08:48:35.176149: Current learning rate: 0.00778 
2025-03-31 08:53:08.213172: train_loss -0.8079 
2025-03-31 08:53:08.213474: val_loss -0.6405 
2025-03-31 08:53:08.213560: Pseudo dice [0.6535] 
2025-03-31 08:53:08.213673: Epoch time: 273.04 s 
2025-03-31 08:53:08.213745: Yayy! New best EMA pseudo Dice: 0.5801 
2025-03-31 08:53:11.733439:  
2025-03-31 08:53:11.733660: Epoch 244 
2025-03-31 08:53:11.733824: Current learning rate: 0.00777 
2025-03-31 08:57:44.740296: train_loss -0.7926 
2025-03-31 08:57:44.740665: val_loss -0.6289 
2025-03-31 08:57:44.740773: Pseudo dice [0.6348] 
2025-03-31 08:57:44.740877: Epoch time: 273.01 s 
2025-03-31 08:57:44.740939: Yayy! New best EMA pseudo Dice: 0.5856 
2025-03-31 08:57:48.025854:  
2025-03-31 08:57:48.026103: Epoch 245 
2025-03-31 08:57:48.026237: Current learning rate: 0.00777 
2025-03-31 09:02:21.065994: train_loss -0.7864 
2025-03-31 09:02:21.066327: val_loss -0.6635 
2025-03-31 09:02:21.066436: Pseudo dice [0.6014] 
2025-03-31 09:02:21.066570: Epoch time: 273.04 s 
2025-03-31 09:02:21.066633: Yayy! New best EMA pseudo Dice: 0.5871 
2025-03-31 09:02:24.389140:  
2025-03-31 09:02:24.389342: Epoch 246 
2025-03-31 09:02:24.389457: Current learning rate: 0.00776 
2025-03-31 09:06:57.689148: train_loss -0.7656 
2025-03-31 09:06:57.689529: val_loss -0.6693 
2025-03-31 09:06:57.689654: Pseudo dice [0.7157] 
2025-03-31 09:06:57.689754: Epoch time: 273.3 s 
2025-03-31 09:06:57.689811: Yayy! New best EMA pseudo Dice: 0.6 
2025-03-31 09:07:00.998843:  
2025-03-31 09:07:00.999154: Epoch 247 
2025-03-31 09:07:00.999322: Current learning rate: 0.00775 
2025-03-31 09:11:34.125335: train_loss -0.7733 
2025-03-31 09:11:34.125659: val_loss -0.6758 
2025-03-31 09:11:34.125740: Pseudo dice [0.7131] 
2025-03-31 09:11:34.125824: Epoch time: 273.13 s 
2025-03-31 09:11:34.125890: Yayy! New best EMA pseudo Dice: 0.6113 
2025-03-31 09:11:37.452425:  
2025-03-31 09:11:37.452633: Epoch 248 
2025-03-31 09:11:37.452781: Current learning rate: 0.00774 
2025-03-31 09:16:10.999630: train_loss -0.7783 
2025-03-31 09:16:10.999971: val_loss -0.594 
2025-03-31 09:16:11.000052: Pseudo dice [0.5927] 
2025-03-31 09:16:11.000162: Epoch time: 273.55 s 
2025-03-31 09:16:12.928617:  
2025-03-31 09:16:12.928761: Epoch 249 
2025-03-31 09:16:12.928889: Current learning rate: 0.00773 
2025-03-31 09:20:46.723498: train_loss -0.7798 
2025-03-31 09:20:46.723818: val_loss -0.5492 
2025-03-31 09:20:46.723965: Pseudo dice [0.4308] 
2025-03-31 09:20:46.724088: Epoch time: 273.8 s 
2025-03-31 09:20:49.960114:  
2025-03-31 09:20:49.960306: Epoch 250 
2025-03-31 09:20:49.960420: Current learning rate: 0.00772 
2025-03-31 09:25:23.679843: train_loss -0.745 
2025-03-31 09:25:23.680197: val_loss -0.6394 
2025-03-31 09:25:23.680286: Pseudo dice [0.4483] 
2025-03-31 09:25:23.680388: Epoch time: 273.72 s 
2025-03-31 09:25:25.608483:  
2025-03-31 09:25:25.608723: Epoch 251 
2025-03-31 09:25:25.608852: Current learning rate: 0.00771 
2025-03-31 09:29:59.616482: train_loss -0.7647 
2025-03-31 09:29:59.616823: val_loss -0.56 
2025-03-31 09:29:59.616923: Pseudo dice [0.4897] 
2025-03-31 09:29:59.617022: Epoch time: 274.01 s 
2025-03-31 09:30:01.565895:  
2025-03-31 09:30:01.566105: Epoch 252 
2025-03-31 09:30:01.566246: Current learning rate: 0.0077 
2025-03-31 09:34:35.425803: train_loss -0.7791 
2025-03-31 09:34:35.426141: val_loss -0.6174 
2025-03-31 09:34:35.426229: Pseudo dice [0.603] 
2025-03-31 09:34:35.426327: Epoch time: 273.86 s 
2025-03-31 09:34:37.328098:  
2025-03-31 09:34:37.328315: Epoch 253 
2025-03-31 09:34:37.328431: Current learning rate: 0.00769 
2025-03-31 09:39:11.407492: train_loss -0.7938 
2025-03-31 09:39:11.407896: val_loss -0.6927 
2025-03-31 09:39:11.408029: Pseudo dice [0.6907] 
2025-03-31 09:39:11.408111: Epoch time: 274.08 s 
2025-03-31 09:39:13.349462:  
2025-03-31 09:39:13.349679: Epoch 254 
2025-03-31 09:39:13.349810: Current learning rate: 0.00768 
2025-03-31 09:43:47.165329: train_loss -0.7995 
2025-03-31 09:43:47.165668: val_loss -0.6066 
2025-03-31 09:43:47.165755: Pseudo dice [0.5929] 
2025-03-31 09:43:47.165854: Epoch time: 273.82 s 
2025-03-31 09:43:49.081792:  
2025-03-31 09:43:49.082066: Epoch 255 
2025-03-31 09:43:49.082198: Current learning rate: 0.00767 
2025-03-31 09:48:22.232522: train_loss -0.7926 
2025-03-31 09:48:22.232873: val_loss -0.501 
2025-03-31 09:48:22.233490: Pseudo dice [0.5708] 
2025-03-31 09:48:22.233610: Epoch time: 273.15 s 
2025-03-31 09:48:24.148596:  
2025-03-31 09:48:24.148820: Epoch 256 
2025-03-31 09:48:24.148934: Current learning rate: 0.00766 
2025-03-31 09:52:57.444787: train_loss -0.767 
2025-03-31 09:52:57.445117: val_loss -0.6604 
2025-03-31 09:52:57.445201: Pseudo dice [0.6144] 
2025-03-31 09:52:57.445321: Epoch time: 273.3 s 
2025-03-31 09:52:59.362332:  
2025-03-31 09:52:59.362582: Epoch 257 
2025-03-31 09:52:59.362805: Current learning rate: 0.00765 
2025-03-31 09:57:32.353857: train_loss -0.7805 
2025-03-31 09:57:32.354187: val_loss -0.7124 
2025-03-31 09:57:32.354331: Pseudo dice [0.6695] 
2025-03-31 09:57:32.354425: Epoch time: 273.0 s 
2025-03-31 09:57:34.276748:  
2025-03-31 09:57:34.277033: Epoch 258 
2025-03-31 09:57:34.277165: Current learning rate: 0.00764 
2025-03-31 10:02:06.588889: train_loss -0.785 
2025-03-31 10:02:06.589210: val_loss -0.5906 
2025-03-31 10:02:06.589293: Pseudo dice [0.5845] 
2025-03-31 10:02:06.589375: Epoch time: 272.32 s 
2025-03-31 10:02:08.786860:  
2025-03-31 10:02:08.787067: Epoch 259 
2025-03-31 10:02:08.787188: Current learning rate: 0.00764 
2025-03-31 10:06:41.386272: train_loss -0.7908 
2025-03-31 10:06:41.386640: val_loss -0.6839 
2025-03-31 10:06:41.386730: Pseudo dice [0.5555] 
2025-03-31 10:06:41.386826: Epoch time: 272.6 s 
2025-03-31 10:06:43.309984:  
2025-03-31 10:06:43.310174: Epoch 260 
2025-03-31 10:06:43.310292: Current learning rate: 0.00763 
2025-03-31 10:11:15.871287: train_loss -0.7857 
2025-03-31 10:11:15.871602: val_loss -0.5721 
2025-03-31 10:11:15.871688: Pseudo dice [0.5142] 
2025-03-31 10:11:15.871858: Epoch time: 272.57 s 
2025-03-31 10:11:17.799152:  
2025-03-31 10:11:17.799377: Epoch 261 
2025-03-31 10:11:17.799494: Current learning rate: 0.00762 
2025-03-31 10:15:50.561511: train_loss -0.8026 
2025-03-31 10:15:50.561873: val_loss -0.6249 
2025-03-31 10:15:50.561967: Pseudo dice [0.4313] 
2025-03-31 10:15:50.562115: Epoch time: 272.77 s 
2025-03-31 10:15:52.481826:  
2025-03-31 10:15:52.482033: Epoch 262 
2025-03-31 10:15:52.482148: Current learning rate: 0.00761 
2025-03-31 10:20:24.951892: train_loss -0.8015 
2025-03-31 10:20:24.952208: val_loss -0.6367 
2025-03-31 10:20:24.952300: Pseudo dice [0.4349] 
2025-03-31 10:20:24.952407: Epoch time: 272.47 s 
2025-03-31 10:20:26.872562:  
2025-03-31 10:20:26.872947: Epoch 263 
2025-03-31 10:20:26.873086: Current learning rate: 0.0076 
2025-03-31 10:24:59.989973: train_loss -0.8062 
2025-03-31 10:24:59.990345: val_loss -0.6527 
2025-03-31 10:24:59.990470: Pseudo dice [0.6649] 
2025-03-31 10:24:59.990571: Epoch time: 273.12 s 
2025-03-31 10:25:01.918350:  
2025-03-31 10:25:01.918692: Epoch 264 
2025-03-31 10:25:01.918862: Current learning rate: 0.00759 
2025-03-31 10:29:35.734841: train_loss -0.7927 
2025-03-31 10:29:35.735199: val_loss -0.6093 
2025-03-31 10:29:35.735287: Pseudo dice [0.5713] 
2025-03-31 10:29:35.735387: Epoch time: 273.82 s 
2025-03-31 10:29:37.662902:  
2025-03-31 10:29:37.663102: Epoch 265 
2025-03-31 10:29:37.663216: Current learning rate: 0.00758 
2025-03-31 10:34:11.269982: train_loss -0.7519 
2025-03-31 10:34:11.270297: val_loss -0.6622 
2025-03-31 10:34:11.270384: Pseudo dice [0.6664] 
2025-03-31 10:34:11.270477: Epoch time: 273.61 s 
2025-03-31 10:34:13.498739:  
2025-03-31 10:34:13.499017: Epoch 266 
2025-03-31 10:34:13.499208: Current learning rate: 0.00757 
2025-03-31 10:38:47.548487: train_loss -0.7739 
2025-03-31 10:38:47.548811: val_loss -0.5862 
2025-03-31 10:38:47.548899: Pseudo dice [0.5681] 
2025-03-31 10:38:47.549000: Epoch time: 274.05 s 
2025-03-31 10:38:49.486527:  
2025-03-31 10:38:49.486804: Epoch 267 
2025-03-31 10:38:49.486992: Current learning rate: 0.00756 
2025-03-31 10:43:23.541812: train_loss -0.7591 
2025-03-31 10:43:23.542115: val_loss -0.6566 
2025-03-31 10:43:23.542196: Pseudo dice [0.6745] 
2025-03-31 10:43:23.542287: Epoch time: 274.06 s 
2025-03-31 10:43:25.473488:  
2025-03-31 10:43:25.473698: Epoch 268 
2025-03-31 10:43:25.473825: Current learning rate: 0.00755 
2025-03-31 10:47:59.072690: train_loss -0.767 
2025-03-31 10:47:59.072965: val_loss -0.6178 
2025-03-31 10:47:59.073052: Pseudo dice [0.4095] 
2025-03-31 10:47:59.073183: Epoch time: 273.6 s 
2025-03-31 10:48:01.021113:  
2025-03-31 10:48:01.021334: Epoch 269 
2025-03-31 10:48:01.021449: Current learning rate: 0.00754 
2025-03-31 10:52:34.724512: train_loss -0.7554 
2025-03-31 10:52:34.724828: val_loss -0.6205 
2025-03-31 10:52:34.724930: Pseudo dice [0.5203] 
2025-03-31 10:52:34.725052: Epoch time: 273.71 s 
2025-03-31 10:52:36.671109:  
2025-03-31 10:52:36.671349: Epoch 270 
2025-03-31 10:52:36.671469: Current learning rate: 0.00753 
2025-03-31 10:57:10.647538: train_loss -0.7788 
2025-03-31 10:57:10.647867: val_loss -0.7019 
2025-03-31 10:57:10.648274: Pseudo dice [0.7411] 
2025-03-31 10:57:10.648367: Epoch time: 273.98 s 
2025-03-31 10:57:12.565678:  
2025-03-31 10:57:12.565943: Epoch 271 
2025-03-31 10:57:12.566076: Current learning rate: 0.00752 
2025-03-31 11:01:46.826592: train_loss -0.7914 
2025-03-31 11:01:46.826912: val_loss -0.5557 
2025-03-31 11:01:46.827008: Pseudo dice [0.3717] 
2025-03-31 11:01:46.827145: Epoch time: 274.26 s 
2025-03-31 11:01:48.761594:  
2025-03-31 11:01:48.761918: Epoch 272 
2025-03-31 11:01:48.762070: Current learning rate: 0.00751 
2025-03-31 11:06:22.669139: train_loss -0.7983 
2025-03-31 11:06:22.669510: val_loss -0.6707 
2025-03-31 11:06:22.669604: Pseudo dice [0.6838] 
2025-03-31 11:06:22.669708: Epoch time: 273.91 s 
2025-03-31 11:06:24.598580:  
2025-03-31 11:06:24.598818: Epoch 273 
2025-03-31 11:06:24.598954: Current learning rate: 0.00751 
2025-03-31 11:10:58.319607: train_loss -0.7802 
2025-03-31 11:10:58.320184: val_loss -0.6806 
2025-03-31 11:10:58.320269: Pseudo dice [0.6234] 
2025-03-31 11:10:58.320359: Epoch time: 273.73 s 
2025-03-31 11:11:00.239195:  
2025-03-31 11:11:00.239372: Epoch 274 
2025-03-31 11:11:00.239490: Current learning rate: 0.0075 
2025-03-31 11:15:33.610350: train_loss -0.7954 
2025-03-31 11:15:33.610735: val_loss -0.5699 
2025-03-31 11:15:33.610821: Pseudo dice [0.5472] 
2025-03-31 11:15:33.610914: Epoch time: 273.38 s 
2025-03-31 11:15:35.541079:  
2025-03-31 11:15:35.541375: Epoch 275 
2025-03-31 11:15:35.541506: Current learning rate: 0.00749 
2025-03-31 11:20:09.606148: train_loss -0.7684 
2025-03-31 11:20:09.606490: val_loss -0.6245 
2025-03-31 11:20:09.606578: Pseudo dice [0.6985] 
2025-03-31 11:20:09.606679: Epoch time: 274.07 s 
2025-03-31 11:20:11.540963:  
2025-03-31 11:20:11.541174: Epoch 276 
2025-03-31 11:20:11.541308: Current learning rate: 0.00748 
2025-03-31 11:24:45.209990: train_loss -0.7317 
2025-03-31 11:24:45.210297: val_loss -0.5953 
2025-03-31 11:24:45.210768: Pseudo dice [0.6792] 
2025-03-31 11:24:45.210887: Epoch time: 273.67 s 
2025-03-31 11:24:47.168895:  
2025-03-31 11:24:47.169120: Epoch 277 
2025-03-31 11:24:47.169240: Current learning rate: 0.00747 
2025-03-31 11:29:20.992639: train_loss -0.7555 
2025-03-31 11:29:20.993021: val_loss -0.6388 
2025-03-31 11:29:20.993128: Pseudo dice [0.5902] 
2025-03-31 11:29:20.993226: Epoch time: 273.83 s 
2025-03-31 11:29:22.983424:  
2025-03-31 11:29:22.983643: Epoch 278 
2025-03-31 11:29:22.983771: Current learning rate: 0.00746 
2025-03-31 11:33:56.723194: train_loss -0.7911 
2025-03-31 11:33:56.723502: val_loss -0.5954 
2025-03-31 11:33:56.723607: Pseudo dice [0.4894] 
2025-03-31 11:33:56.723699: Epoch time: 273.74 s 
2025-03-31 11:33:58.648463:  
2025-03-31 11:33:58.648714: Epoch 279 
2025-03-31 11:33:58.648858: Current learning rate: 0.00745 
2025-03-31 11:38:32.296880: train_loss -0.7917 
2025-03-31 11:38:32.297396: val_loss -0.5783 
2025-03-31 11:38:32.297539: Pseudo dice [0.4385] 
2025-03-31 11:38:32.297644: Epoch time: 273.65 s 
2025-03-31 11:38:34.229001:  
2025-03-31 11:38:34.229204: Epoch 280 
2025-03-31 11:38:34.229353: Current learning rate: 0.00744 
2025-03-31 11:43:07.851687: train_loss -0.7757 
2025-03-31 11:43:07.852075: val_loss -0.6412 
2025-03-31 11:43:07.852202: Pseudo dice [0.6405] 
2025-03-31 11:43:07.852293: Epoch time: 273.63 s 
2025-03-31 11:43:09.779206:  
2025-03-31 11:43:09.779417: Epoch 281 
2025-03-31 11:43:09.779532: Current learning rate: 0.00743 
2025-03-31 11:47:42.366105: train_loss -0.8096 
2025-03-31 11:47:42.366434: val_loss -0.6555 
2025-03-31 11:47:42.366924: Pseudo dice [0.6692] 
2025-03-31 11:47:42.367044: Epoch time: 272.59 s 
2025-03-31 11:47:44.298107:  
2025-03-31 11:47:44.298376: Epoch 282 
2025-03-31 11:47:44.298533: Current learning rate: 0.00742 
2025-03-31 11:52:17.612296: train_loss -0.7706 
2025-03-31 11:52:17.612637: val_loss -0.6712 
2025-03-31 11:52:17.612723: Pseudo dice [0.7107] 
2025-03-31 11:52:17.612875: Epoch time: 273.32 s 
2025-03-31 11:52:19.536289:  
2025-03-31 11:52:19.536439: Epoch 283 
2025-03-31 11:52:19.536561: Current learning rate: 0.00741 
2025-03-31 11:56:53.099107: train_loss -0.7681 
2025-03-31 11:56:53.099479: val_loss -0.5431 
2025-03-31 11:56:53.099562: Pseudo dice [0.5767] 
2025-03-31 11:56:53.099653: Epoch time: 273.57 s 
2025-03-31 11:56:55.018857:  
2025-03-31 11:56:55.019058: Epoch 284 
2025-03-31 11:56:55.019173: Current learning rate: 0.0074 
2025-03-31 12:01:28.015683: train_loss -0.7797 
2025-03-31 12:01:28.016024: val_loss -0.5512 
2025-03-31 12:01:28.016113: Pseudo dice [0.5623] 
2025-03-31 12:01:28.016208: Epoch time: 273.0 s 
2025-03-31 12:01:29.938986:  
2025-03-31 12:01:29.939274: Epoch 285 
2025-03-31 12:01:29.939403: Current learning rate: 0.00739 
2025-03-31 12:06:02.670726: train_loss -0.7976 
2025-03-31 12:06:02.671103: val_loss -0.6892 
2025-03-31 12:06:02.671191: Pseudo dice [0.7345] 
2025-03-31 12:06:02.671284: Epoch time: 272.74 s 
2025-03-31 12:06:04.590913:  
2025-03-31 12:06:04.591170: Epoch 286 
2025-03-31 12:06:04.591345: Current learning rate: 0.00738 
2025-03-31 12:10:37.643175: train_loss -0.7745 
2025-03-31 12:10:37.643488: val_loss -0.5871 
2025-03-31 12:10:37.643598: Pseudo dice [0.6847] 
2025-03-31 12:10:37.643715: Epoch time: 273.06 s 
2025-03-31 12:10:37.643782: Yayy! New best EMA pseudo Dice: 0.615 
2025-03-31 12:10:40.960517:  
2025-03-31 12:10:40.960728: Epoch 287 
2025-03-31 12:10:40.960845: Current learning rate: 0.00738 
2025-03-31 12:15:14.244934: train_loss -0.7927 
2025-03-31 12:15:14.245337: val_loss -0.6714 
2025-03-31 12:15:14.245434: Pseudo dice [0.6785] 
2025-03-31 12:15:14.245519: Epoch time: 273.29 s 
2025-03-31 12:15:14.245621: Yayy! New best EMA pseudo Dice: 0.6214 
2025-03-31 12:15:17.562875:  
2025-03-31 12:15:17.563195: Epoch 288 
2025-03-31 12:15:17.563362: Current learning rate: 0.00737 
2025-03-31 12:19:50.774733: train_loss -0.7901 
2025-03-31 12:19:50.775088: val_loss -0.6167 
2025-03-31 12:19:50.775177: Pseudo dice [0.6007] 
2025-03-31 12:19:50.775286: Epoch time: 273.22 s 
2025-03-31 12:19:52.722001:  
2025-03-31 12:19:52.722290: Epoch 289 
2025-03-31 12:19:52.722421: Current learning rate: 0.00736 
2025-03-31 12:24:26.657860: train_loss -0.7807 
2025-03-31 12:24:26.658226: val_loss -0.6135 
2025-03-31 12:24:26.658388: Pseudo dice [0.6501] 
2025-03-31 12:24:26.658489: Epoch time: 273.94 s 
2025-03-31 12:24:26.658567: Yayy! New best EMA pseudo Dice: 0.6224 
2025-03-31 12:24:30.279128:  
2025-03-31 12:24:30.279383: Epoch 290 
2025-03-31 12:24:30.279543: Current learning rate: 0.00735 
2025-03-31 12:29:03.560616: train_loss -0.81 
2025-03-31 12:29:03.560983: val_loss -0.6275 
2025-03-31 12:29:03.561069: Pseudo dice [0.6311] 
2025-03-31 12:29:03.561168: Epoch time: 273.29 s 
2025-03-31 12:29:03.561293: Yayy! New best EMA pseudo Dice: 0.6233 
2025-03-31 12:29:06.905836:  
2025-03-31 12:29:06.906047: Epoch 291 
2025-03-31 12:29:06.906171: Current learning rate: 0.00734 
2025-03-31 12:33:40.483140: train_loss -0.7994 
2025-03-31 12:33:40.483474: val_loss -0.6131 
2025-03-31 12:33:40.483564: Pseudo dice [0.5959] 
2025-03-31 12:33:40.483667: Epoch time: 273.58 s 
2025-03-31 12:33:42.451215:  
2025-03-31 12:33:42.451460: Epoch 292 
2025-03-31 12:33:42.451591: Current learning rate: 0.00733 
2025-03-31 12:38:15.877234: train_loss -0.8018 
2025-03-31 12:38:15.877556: val_loss -0.5756 
2025-03-31 12:38:15.877639: Pseudo dice [0.5334] 
2025-03-31 12:38:15.877728: Epoch time: 273.43 s 
2025-03-31 12:38:17.825109:  
2025-03-31 12:38:17.825302: Epoch 293 
2025-03-31 12:38:17.825426: Current learning rate: 0.00732 
2025-03-31 12:42:51.194219: train_loss -0.8148 
2025-03-31 12:42:51.194523: val_loss -0.6226 
2025-03-31 12:42:51.194610: Pseudo dice [0.6641] 
2025-03-31 12:42:51.194699: Epoch time: 273.37 s 
2025-03-31 12:42:53.145752:  
2025-03-31 12:42:53.145917: Epoch 294 
2025-03-31 12:42:53.146082: Current learning rate: 0.00731 
2025-03-31 12:47:26.463087: train_loss -0.806 
2025-03-31 12:47:26.463403: val_loss -0.5227 
2025-03-31 12:47:26.463517: Pseudo dice [0.4167] 
2025-03-31 12:47:26.463624: Epoch time: 273.32 s 
2025-03-31 12:47:28.408662:  
2025-03-31 12:47:28.408864: Epoch 295 
2025-03-31 12:47:28.408999: Current learning rate: 0.0073 
2025-03-31 12:52:02.354435: train_loss -0.7923 
2025-03-31 12:52:02.354838: val_loss -0.661 
2025-03-31 12:52:02.354929: Pseudo dice [0.7058] 
2025-03-31 12:52:02.355025: Epoch time: 273.95 s 
2025-03-31 12:52:04.306137:  
2025-03-31 12:52:04.306361: Epoch 296 
2025-03-31 12:52:04.306479: Current learning rate: 0.00729 
2025-03-31 12:56:38.134002: train_loss -0.7856 
2025-03-31 12:56:38.134367: val_loss -0.6784 
2025-03-31 12:56:38.134462: Pseudo dice [0.69] 
2025-03-31 12:56:38.134565: Epoch time: 273.83 s 
2025-03-31 12:56:40.088696:  
2025-03-31 12:56:40.088897: Epoch 297 
2025-03-31 12:56:40.089014: Current learning rate: 0.00728 
2025-03-31 13:01:13.960371: train_loss -0.7915 
2025-03-31 13:01:13.960706: val_loss -0.5315 
2025-03-31 13:01:13.960801: Pseudo dice [0.5248] 
2025-03-31 13:01:13.960904: Epoch time: 273.88 s 
2025-03-31 13:01:16.213093:  
2025-03-31 13:01:16.213306: Epoch 298 
2025-03-31 13:01:16.213424: Current learning rate: 0.00727 
2025-03-31 13:05:49.686915: train_loss -0.7735 
2025-03-31 13:05:49.687271: val_loss -0.5925 
2025-03-31 13:05:49.687431: Pseudo dice [0.5976] 
2025-03-31 13:05:49.687532: Epoch time: 273.48 s 
2025-03-31 13:05:51.645386:  
2025-03-31 13:05:51.645629: Epoch 299 
2025-03-31 13:05:51.645757: Current learning rate: 0.00726 
2025-03-31 13:10:25.460269: train_loss -0.8072 
2025-03-31 13:10:25.460583: val_loss -0.6415 
2025-03-31 13:10:25.460670: Pseudo dice [0.6707] 
2025-03-31 13:10:25.460795: Epoch time: 273.82 s 
2025-03-31 13:10:28.625547:  
2025-03-31 13:10:28.625727: Epoch 300 
2025-03-31 13:10:28.625894: Current learning rate: 0.00725 
2025-03-31 13:15:02.234760: train_loss -0.7866 
2025-03-31 13:15:02.235073: val_loss -0.6528 
2025-03-31 13:15:02.235202: Pseudo dice [0.6803] 
2025-03-31 13:15:02.235300: Epoch time: 273.61 s 
2025-03-31 13:15:04.190822:  
2025-03-31 13:15:04.191048: Epoch 301 
2025-03-31 13:15:04.191159: Current learning rate: 0.00724 
2025-03-31 13:19:37.924409: train_loss -0.7815 
2025-03-31 13:19:37.924756: val_loss -0.5099 
2025-03-31 13:19:37.924840: Pseudo dice [0.4632] 
2025-03-31 13:19:37.924938: Epoch time: 273.74 s 
2025-03-31 13:19:39.872793:  
2025-03-31 13:19:39.873007: Epoch 302 
2025-03-31 13:19:39.873121: Current learning rate: 0.00724 
2025-03-31 13:24:13.567802: train_loss -0.7336 
2025-03-31 13:24:13.568233: val_loss -0.5822 
2025-03-31 13:24:13.568330: Pseudo dice [0.5404] 
2025-03-31 13:24:13.568411: Epoch time: 273.7 s 
2025-03-31 13:24:15.519485:  
2025-03-31 13:24:15.519841: Epoch 303 
2025-03-31 13:24:15.519972: Current learning rate: 0.00723 
2025-03-31 13:28:49.967944: train_loss -0.7691 
2025-03-31 13:28:49.968267: val_loss -0.6465 
2025-03-31 13:28:49.968364: Pseudo dice [0.6643] 
2025-03-31 13:28:49.968462: Epoch time: 274.45 s 
2025-03-31 13:28:51.927021:  
2025-03-31 13:28:51.927256: Epoch 304 
2025-03-31 13:28:51.927423: Current learning rate: 0.00722 
2025-03-31 13:33:25.395638: train_loss -0.7812 
2025-03-31 13:33:25.395991: val_loss -0.516 
2025-03-31 13:33:25.396083: Pseudo dice [0.4769] 
2025-03-31 13:33:25.396186: Epoch time: 273.47 s 
2025-03-31 13:33:27.640990:  
2025-03-31 13:33:27.641216: Epoch 305 
2025-03-31 13:33:27.641331: Current learning rate: 0.00721 
2025-03-31 13:38:00.755790: train_loss -0.7705 
2025-03-31 13:38:00.756097: val_loss -0.5694 
2025-03-31 13:38:00.756183: Pseudo dice [0.4819] 
2025-03-31 13:38:00.756273: Epoch time: 273.12 s 
2025-03-31 13:38:02.723959:  
2025-03-31 13:38:02.724157: Epoch 306 
2025-03-31 13:38:02.724273: Current learning rate: 0.0072 
2025-03-31 13:42:36.215289: train_loss -0.7588 
2025-03-31 13:42:36.215611: val_loss -0.6129 
2025-03-31 13:42:36.215824: Pseudo dice [0.5777] 
2025-03-31 13:42:36.215936: Epoch time: 273.5 s 
2025-03-31 13:42:38.181157:  
2025-03-31 13:42:38.181367: Epoch 307 
2025-03-31 13:42:38.181491: Current learning rate: 0.00719 
2025-03-31 13:47:11.635720: train_loss -0.7759 
2025-03-31 13:47:11.636057: val_loss -0.5499 
2025-03-31 13:47:11.636139: Pseudo dice [0.4847] 
2025-03-31 13:47:11.636346: Epoch time: 273.46 s 
2025-03-31 13:47:13.622331:  
2025-03-31 13:47:13.622524: Epoch 308 
2025-03-31 13:47:13.622643: Current learning rate: 0.00718 
2025-03-31 13:51:47.023404: train_loss -0.7671 
2025-03-31 13:51:47.023648: val_loss -0.6382 
2025-03-31 13:51:47.023767: Pseudo dice [0.6336] 
2025-03-31 13:51:47.023867: Epoch time: 273.41 s 
2025-03-31 13:51:48.981352:  
2025-03-31 13:51:48.981546: Epoch 309 
2025-03-31 13:51:48.981685: Current learning rate: 0.00717 
2025-03-31 13:56:22.252899: train_loss -0.7526 
2025-03-31 13:56:22.253224: val_loss -0.5979 
2025-03-31 13:56:22.253313: Pseudo dice [0.4755] 
2025-03-31 13:56:22.253421: Epoch time: 273.28 s 
2025-03-31 13:56:24.207379:  
2025-03-31 13:56:24.207566: Epoch 310 
2025-03-31 13:56:24.207697: Current learning rate: 0.00716 
2025-03-31 14:00:58.134041: train_loss -0.7865 
2025-03-31 14:00:58.134375: val_loss -0.6186 
2025-03-31 14:00:58.134459: Pseudo dice [0.5208] 
2025-03-31 14:00:58.134556: Epoch time: 273.93 s 
2025-03-31 14:01:00.081305:  
2025-03-31 14:01:00.081587: Epoch 311 
2025-03-31 14:01:00.081708: Current learning rate: 0.00715 
2025-03-31 14:05:33.790910: train_loss -0.8081 
2025-03-31 14:05:33.791234: val_loss -0.6364 
2025-03-31 14:05:33.791317: Pseudo dice [0.5759] 
2025-03-31 14:05:33.791400: Epoch time: 273.71 s 
2025-03-31 14:05:35.729910:  
2025-03-31 14:05:35.730123: Epoch 312 
2025-03-31 14:05:35.730240: Current learning rate: 0.00714 
2025-03-31 14:10:09.327262: train_loss -0.8089 
2025-03-31 14:10:09.327680: val_loss -0.645 
2025-03-31 14:10:09.327796: Pseudo dice [0.5718] 
2025-03-31 14:10:09.327887: Epoch time: 273.6 s 
2025-03-31 14:10:11.596787:  
2025-03-31 14:10:11.597006: Epoch 313 
2025-03-31 14:10:11.597126: Current learning rate: 0.00713 
2025-03-31 14:14:45.734301: train_loss -0.7853 
2025-03-31 14:14:45.734641: val_loss -0.5054 
2025-03-31 14:14:45.734731: Pseudo dice [0.3855] 
2025-03-31 14:14:45.734832: Epoch time: 274.14 s 
2025-03-31 14:14:47.675186:  
2025-03-31 14:14:47.675397: Epoch 314 
2025-03-31 14:14:47.675533: Current learning rate: 0.00712 
2025-03-31 14:19:21.709578: train_loss -0.7852 
2025-03-31 14:19:21.709907: val_loss -0.7099 
2025-03-31 14:19:21.710010: Pseudo dice [0.6838] 
2025-03-31 14:19:21.710114: Epoch time: 274.04 s 
2025-03-31 14:19:23.655774:  
2025-03-31 14:19:23.656039: Epoch 315 
2025-03-31 14:19:23.656209: Current learning rate: 0.00711 
2025-03-31 14:23:57.322973: train_loss -0.8051 
2025-03-31 14:23:57.323304: val_loss -0.6249 
2025-03-31 14:23:57.323628: Pseudo dice [0.6748] 
2025-03-31 14:23:57.323778: Epoch time: 273.67 s 
2025-03-31 14:23:59.364752:  
2025-03-31 14:23:59.364981: Epoch 316 
2025-03-31 14:23:59.365098: Current learning rate: 0.0071 
2025-03-31 14:28:32.326842: train_loss -0.7955 
2025-03-31 14:28:32.327141: val_loss -0.6713 
2025-03-31 14:28:32.327229: Pseudo dice [0.4661] 
2025-03-31 14:28:32.327323: Epoch time: 272.97 s 
2025-03-31 14:28:34.341534:  
2025-03-31 14:28:34.341788: Epoch 317 
2025-03-31 14:28:34.341962: Current learning rate: 0.0071 
2025-03-31 14:33:07.236103: train_loss -0.7935 
2025-03-31 14:33:07.236415: val_loss -0.5204 
2025-03-31 14:33:07.236497: Pseudo dice [0.271] 
2025-03-31 14:33:07.236615: Epoch time: 272.9 s 
2025-03-31 14:33:09.186670:  
2025-03-31 14:33:09.186878: Epoch 318 
2025-03-31 14:33:09.187015: Current learning rate: 0.00709 
2025-03-31 14:37:42.366429: train_loss -0.7774 
2025-03-31 14:37:42.366813: val_loss -0.689 
2025-03-31 14:37:42.366904: Pseudo dice [0.6714] 
2025-03-31 14:37:42.366992: Epoch time: 273.18 s 
2025-03-31 14:37:44.328529:  
2025-03-31 14:37:44.328771: Epoch 319 
2025-03-31 14:37:44.328894: Current learning rate: 0.00708 
2025-03-31 14:42:17.497746: train_loss -0.7966 
2025-03-31 14:42:17.498079: val_loss -0.6989 
2025-03-31 14:42:17.498166: Pseudo dice [0.6881] 
2025-03-31 14:42:17.498276: Epoch time: 273.17 s 
2025-03-31 14:42:19.449178:  
2025-03-31 14:42:19.449428: Epoch 320 
2025-03-31 14:42:19.449559: Current learning rate: 0.00707 
2025-03-31 14:46:52.788841: train_loss -0.8013 
2025-03-31 14:46:52.789161: val_loss -0.5531 
2025-03-31 14:46:52.789248: Pseudo dice [0.5121] 
2025-03-31 14:46:52.789349: Epoch time: 273.34 s 
2025-03-31 14:46:55.053255:  
2025-03-31 14:46:55.053481: Epoch 321 
2025-03-31 14:46:55.053679: Current learning rate: 0.00706 
2025-03-31 14:51:28.387080: train_loss -0.7973 
2025-03-31 14:51:28.387390: val_loss -0.5916 
2025-03-31 14:51:28.387485: Pseudo dice [0.6698] 
2025-03-31 14:51:28.387622: Epoch time: 273.34 s 
2025-03-31 14:51:30.357386:  
2025-03-31 14:51:30.357581: Epoch 322 
2025-03-31 14:51:30.357703: Current learning rate: 0.00705 
2025-03-31 14:56:03.330142: train_loss -0.8151 
2025-03-31 14:56:03.330503: val_loss -0.7013 
2025-03-31 14:56:03.330585: Pseudo dice [0.7067] 
2025-03-31 14:56:03.330692: Epoch time: 272.98 s 
2025-03-31 14:56:05.311934:  
2025-03-31 14:56:05.312164: Epoch 323 
2025-03-31 14:56:05.312284: Current learning rate: 0.00704 
2025-03-31 15:00:38.014019: train_loss -0.8117 
2025-03-31 15:00:38.014375: val_loss -0.5832 
2025-03-31 15:00:38.017776: Pseudo dice [0.5471] 
2025-03-31 15:00:38.017862: Epoch time: 272.71 s 
2025-03-31 15:00:40.003389:  
2025-03-31 15:00:40.003613: Epoch 324 
2025-03-31 15:00:40.003734: Current learning rate: 0.00703 
2025-03-31 15:05:14.090314: train_loss -0.7725 
2025-03-31 15:05:14.090632: val_loss -0.5943 
2025-03-31 15:05:14.090760: Pseudo dice [0.6541] 
2025-03-31 15:05:14.090860: Epoch time: 274.09 s 
2025-03-31 15:05:16.050656:  
2025-03-31 15:05:16.050897: Epoch 325 
2025-03-31 15:05:16.051018: Current learning rate: 0.00702 
2025-03-31 15:09:50.575346: train_loss -0.7202 
2025-03-31 15:09:50.575657: val_loss -0.5604 
2025-03-31 15:09:50.575738: Pseudo dice [0.4085] 
2025-03-31 15:09:50.575850: Epoch time: 274.53 s 
2025-03-31 15:09:52.541158:  
2025-03-31 15:09:52.541444: Epoch 326 
2025-03-31 15:09:52.541595: Current learning rate: 0.00701 
2025-03-31 15:14:26.870697: train_loss -0.7779 
2025-03-31 15:14:26.871057: val_loss -0.614 
2025-03-31 15:14:26.871195: Pseudo dice [0.6719] 
2025-03-31 15:14:26.871290: Epoch time: 274.33 s 
2025-03-31 15:14:28.829360:  
2025-03-31 15:14:28.829613: Epoch 327 
2025-03-31 15:14:28.829793: Current learning rate: 0.007 
2025-03-31 15:19:02.743110: train_loss -0.7938 
2025-03-31 15:19:02.743419: val_loss -0.6767 
2025-03-31 15:19:02.743504: Pseudo dice [0.6423] 
2025-03-31 15:19:02.743594: Epoch time: 273.92 s 
2025-03-31 15:19:04.703114:  
2025-03-31 15:19:04.703333: Epoch 328 
2025-03-31 15:19:04.703520: Current learning rate: 0.00699 
2025-03-31 15:23:37.862369: train_loss -0.7849 
2025-03-31 15:23:37.862661: val_loss -0.5243 
2025-03-31 15:23:37.862739: Pseudo dice [0.3948] 
2025-03-31 15:23:37.862825: Epoch time: 273.16 s 
2025-03-31 15:23:40.126526:  
2025-03-31 15:23:40.126821: Epoch 329 
2025-03-31 15:23:40.126948: Current learning rate: 0.00698 
2025-03-31 15:28:13.677332: train_loss -0.7913 
2025-03-31 15:28:13.677668: val_loss -0.5552 
2025-03-31 15:28:13.677752: Pseudo dice [0.4345] 
2025-03-31 15:28:13.677852: Epoch time: 273.55 s 
2025-03-31 15:28:15.630729:  
2025-03-31 15:28:15.630936: Epoch 330 
2025-03-31 15:28:15.631054: Current learning rate: 0.00697 
2025-03-31 15:32:48.790674: train_loss -0.7933 
2025-03-31 15:32:48.791022: val_loss -0.6006 
2025-03-31 15:32:48.791112: Pseudo dice [0.5584] 
2025-03-31 15:32:48.791234: Epoch time: 273.16 s 
2025-03-31 15:32:50.757559:  
2025-03-31 15:32:50.757786: Epoch 331 
2025-03-31 15:32:50.757949: Current learning rate: 0.00696 
2025-03-31 15:37:24.105226: train_loss -0.8031 
2025-03-31 15:37:24.105590: val_loss -0.7266 
2025-03-31 15:37:24.105676: Pseudo dice [0.7227] 
2025-03-31 15:37:24.105775: Epoch time: 273.35 s 
2025-03-31 15:37:26.084947:  
2025-03-31 15:37:26.085149: Epoch 332 
2025-03-31 15:37:26.085269: Current learning rate: 0.00696 
2025-03-31 15:41:59.643521: train_loss -0.7878 
2025-03-31 15:41:59.643874: val_loss -0.6429 
2025-03-31 15:41:59.643966: Pseudo dice [0.6411] 
2025-03-31 15:41:59.644068: Epoch time: 273.56 s 
2025-03-31 15:42:01.643725:  
2025-03-31 15:42:01.643926: Epoch 333 
2025-03-31 15:42:01.644041: Current learning rate: 0.00695 
2025-03-31 15:46:34.944249: train_loss -0.771 
2025-03-31 15:46:34.944611: val_loss -0.5403 
2025-03-31 15:46:34.944706: Pseudo dice [0.4346] 
2025-03-31 15:46:34.944809: Epoch time: 273.3 s 
2025-03-31 15:46:36.901085:  
2025-03-31 15:46:36.901262: Epoch 334 
2025-03-31 15:46:36.901388: Current learning rate: 0.00694 
2025-03-31 15:51:10.106315: train_loss -0.7986 
2025-03-31 15:51:10.106677: val_loss -0.6312 
2025-03-31 15:51:10.106851: Pseudo dice [0.688] 
2025-03-31 15:51:10.106946: Epoch time: 273.21 s 
2025-03-31 15:51:12.085419:  
2025-03-31 15:51:12.085599: Epoch 335 
2025-03-31 15:51:12.085753: Current learning rate: 0.00693 
2025-03-31 15:55:45.283677: train_loss -0.8067 
2025-03-31 15:55:45.284026: val_loss -0.7152 
2025-03-31 15:55:45.284117: Pseudo dice [0.6234] 
2025-03-31 15:55:45.284221: Epoch time: 273.2 s 
2025-03-31 15:55:47.267598:  
2025-03-31 15:55:47.267827: Epoch 336 
2025-03-31 15:55:47.267945: Current learning rate: 0.00692 
2025-03-31 16:00:21.025269: train_loss -0.8145 
2025-03-31 16:00:21.025648: val_loss -0.603 
2025-03-31 16:00:21.025749: Pseudo dice [0.6053] 
2025-03-31 16:00:21.025842: Epoch time: 273.76 s 
2025-03-31 16:00:23.299708:  
2025-03-31 16:00:23.299970: Epoch 337 
2025-03-31 16:00:23.300133: Current learning rate: 0.00691 
2025-03-31 16:04:56.856445: train_loss -0.8005 
2025-03-31 16:04:56.856766: val_loss -0.6565 
2025-03-31 16:04:56.856914: Pseudo dice [0.6642] 
2025-03-31 16:04:56.857028: Epoch time: 273.56 s 
2025-03-31 16:04:58.830722:  
2025-03-31 16:04:58.830996: Epoch 338 
2025-03-31 16:04:58.831127: Current learning rate: 0.0069 
2025-03-31 16:09:32.701226: train_loss -0.8141 
2025-03-31 16:09:32.701546: val_loss -0.624 
2025-03-31 16:09:32.701706: Pseudo dice [0.5658] 
2025-03-31 16:09:32.701796: Epoch time: 273.87 s 
2025-03-31 16:09:34.685826:  
2025-03-31 16:09:34.686089: Epoch 339 
2025-03-31 16:09:34.686211: Current learning rate: 0.00689 
2025-03-31 16:14:08.786381: train_loss -0.7898 
2025-03-31 16:14:08.786690: val_loss -0.6209 
2025-03-31 16:14:08.786766: Pseudo dice [0.5259] 
2025-03-31 16:14:08.786852: Epoch time: 274.1 s 
2025-03-31 16:14:10.770123:  
2025-03-31 16:14:10.770306: Epoch 340 
2025-03-31 16:14:10.770460: Current learning rate: 0.00688 
2025-03-31 16:18:44.906207: train_loss -0.7822 
2025-03-31 16:18:44.906605: val_loss -0.4891 
2025-03-31 16:18:44.906737: Pseudo dice [0.4882] 
2025-03-31 16:18:44.906821: Epoch time: 274.14 s 
2025-03-31 16:18:46.872308:  
2025-03-31 16:18:46.872571: Epoch 341 
2025-03-31 16:18:46.872690: Current learning rate: 0.00687 
2025-03-31 16:23:21.010342: train_loss -0.8001 
2025-03-31 16:23:21.010682: val_loss -0.6066 
2025-03-31 16:23:21.010836: Pseudo dice [0.5653] 
2025-03-31 16:23:21.010935: Epoch time: 274.14 s 
2025-03-31 16:23:22.983763:  
2025-03-31 16:23:22.984063: Epoch 342 
2025-03-31 16:23:22.984191: Current learning rate: 0.00686 
2025-03-31 16:27:56.826103: train_loss -0.822 
2025-03-31 16:27:56.826436: val_loss -0.5197 
2025-03-31 16:27:56.826521: Pseudo dice [0.5679] 
2025-03-31 16:27:56.826616: Epoch time: 273.85 s 
2025-03-31 16:27:58.808616:  
2025-03-31 16:27:58.808932: Epoch 343 
2025-03-31 16:27:58.809078: Current learning rate: 0.00685 
2025-03-31 16:32:33.008609: train_loss -0.7936 
2025-03-31 16:32:33.008918: val_loss -0.623 
2025-03-31 16:32:33.009061: Pseudo dice [0.732] 
2025-03-31 16:32:33.009181: Epoch time: 274.2 s 
2025-03-31 16:32:34.982824:  
2025-03-31 16:32:34.983115: Epoch 344 
2025-03-31 16:32:34.983265: Current learning rate: 0.00684 
2025-03-31 16:37:09.156747: train_loss -0.8108 
2025-03-31 16:37:09.157059: val_loss -0.5969 
2025-03-31 16:37:09.157611: Pseudo dice [0.6229] 
2025-03-31 16:37:09.157696: Epoch time: 274.18 s 
2025-03-31 16:37:11.453444:  
2025-03-31 16:37:11.453668: Epoch 345 
2025-03-31 16:37:11.453836: Current learning rate: 0.00683 
2025-03-31 16:41:45.358735: train_loss -0.8141 
2025-03-31 16:41:45.359038: val_loss -0.672 
2025-03-31 16:41:45.359119: Pseudo dice [0.6171] 
2025-03-31 16:41:45.359226: Epoch time: 273.91 s 
2025-03-31 16:41:47.341643:  
2025-03-31 16:41:47.341965: Epoch 346 
2025-03-31 16:41:47.342119: Current learning rate: 0.00682 
2025-03-31 16:46:21.399418: train_loss -0.7943 
2025-03-31 16:46:21.399757: val_loss -0.6745 
2025-03-31 16:46:21.399869: Pseudo dice [0.6445] 
2025-03-31 16:46:21.399968: Epoch time: 274.06 s 
2025-03-31 16:46:23.395898:  
2025-03-31 16:46:23.396102: Epoch 347 
2025-03-31 16:46:23.396232: Current learning rate: 0.00681 
2025-03-31 16:50:57.704141: train_loss -0.8112 
2025-03-31 16:50:57.704450: val_loss -0.5133 
2025-03-31 16:50:57.704537: Pseudo dice [0.5468] 
2025-03-31 16:50:57.704622: Epoch time: 274.31 s 
2025-03-31 16:50:59.678898:  
2025-03-31 16:50:59.679080: Epoch 348 
2025-03-31 16:50:59.679216: Current learning rate: 0.0068 
2025-03-31 16:55:33.568960: train_loss -0.7961 
2025-03-31 16:55:33.569303: val_loss -0.6097 
2025-03-31 16:55:33.569387: Pseudo dice [0.578] 
2025-03-31 16:55:33.569483: Epoch time: 273.89 s 
2025-03-31 16:55:35.535149:  
2025-03-31 16:55:35.535382: Epoch 349 
2025-03-31 16:55:35.535496: Current learning rate: 0.0068 
2025-03-31 17:00:09.630488: train_loss -0.8089 
2025-03-31 17:00:09.630829: val_loss -0.6361 
2025-03-31 17:00:09.630920: Pseudo dice [0.5889] 
2025-03-31 17:00:09.631020: Epoch time: 274.1 s 
2025-03-31 17:00:12.937973:  
2025-03-31 17:00:12.938139: Epoch 350 
2025-03-31 17:00:12.938294: Current learning rate: 0.00679 
2025-03-31 17:04:47.149815: train_loss -0.7982 
2025-03-31 17:04:47.150193: val_loss -0.5491 
2025-03-31 17:04:47.150279: Pseudo dice [0.5427] 
2025-03-31 17:04:47.150378: Epoch time: 274.22 s 
2025-03-31 17:04:49.131850:  
2025-03-31 17:04:49.132058: Epoch 351 
2025-03-31 17:04:49.132177: Current learning rate: 0.00678 
2025-03-31 17:09:23.780301: train_loss -0.7666 
2025-03-31 17:09:23.780653: val_loss -0.5361 
2025-03-31 17:09:23.780759: Pseudo dice [0.3545] 
2025-03-31 17:09:23.780868: Epoch time: 274.65 s 
2025-03-31 17:09:26.064747:  
2025-03-31 17:09:26.065004: Epoch 352 
2025-03-31 17:09:26.065136: Current learning rate: 0.00677 
2025-03-31 17:14:00.433354: train_loss -0.7508 
2025-03-31 17:14:00.433575: val_loss -0.6204 
2025-03-31 17:14:00.433669: Pseudo dice [0.5643] 
2025-03-31 17:14:00.433748: Epoch time: 274.37 s 
2025-03-31 17:14:02.405455:  
2025-03-31 17:14:02.405657: Epoch 353 
2025-03-31 17:14:02.405770: Current learning rate: 0.00676 
2025-03-31 17:18:37.253356: train_loss -0.7767 
2025-03-31 17:18:37.253695: val_loss -0.574 
2025-03-31 17:18:37.253775: Pseudo dice [0.604] 
2025-03-31 17:18:37.253861: Epoch time: 274.85 s 
2025-03-31 17:18:39.237767:  
2025-03-31 17:18:39.238076: Epoch 354 
2025-03-31 17:18:39.238245: Current learning rate: 0.00675 
2025-03-31 17:23:14.105962: train_loss -0.7471 
2025-03-31 17:23:14.106275: val_loss -0.6033 
2025-03-31 17:23:14.106360: Pseudo dice [0.5469] 
2025-03-31 17:23:14.106447: Epoch time: 274.87 s 
2025-03-31 17:23:16.083124:  
2025-03-31 17:23:16.083399: Epoch 355 
2025-03-31 17:23:16.083516: Current learning rate: 0.00674 
2025-03-31 17:27:50.777981: train_loss -0.7815 
2025-03-31 17:27:50.778334: val_loss -0.6338 
2025-03-31 17:27:50.778421: Pseudo dice [0.6736] 
2025-03-31 17:27:50.778522: Epoch time: 274.7 s 
2025-03-31 17:27:52.760437:  
2025-03-31 17:27:52.760683: Epoch 356 
2025-03-31 17:27:52.760874: Current learning rate: 0.00673 
2025-03-31 17:32:27.514280: train_loss -0.8017 
2025-03-31 17:32:27.514584: val_loss -0.5493 
2025-03-31 17:32:27.514663: Pseudo dice [0.5523] 
2025-03-31 17:32:27.514746: Epoch time: 274.76 s 
2025-03-31 17:32:29.492887:  
2025-03-31 17:32:29.493214: Epoch 357 
2025-03-31 17:32:29.493373: Current learning rate: 0.00672 
2025-03-31 17:37:03.701291: train_loss -0.7883 
2025-03-31 17:37:03.701598: val_loss -0.5885 
2025-03-31 17:37:03.701681: Pseudo dice [0.5992] 
2025-03-31 17:37:03.701772: Epoch time: 274.21 s 
2025-03-31 17:37:05.665827:  
2025-03-31 17:37:05.666025: Epoch 358 
2025-03-31 17:37:05.666162: Current learning rate: 0.00671 
2025-03-31 17:41:39.820821: train_loss -0.7924 
2025-03-31 17:41:39.821227: val_loss -0.6336 
2025-03-31 17:41:39.821317: Pseudo dice [0.5621] 
2025-03-31 17:41:39.821414: Epoch time: 274.16 s 
2025-03-31 17:41:41.842706:  
2025-03-31 17:41:41.842929: Epoch 359 
2025-03-31 17:41:41.843057: Current learning rate: 0.0067 
2025-03-31 17:46:16.018192: train_loss -0.8161 
2025-03-31 17:46:16.018501: val_loss -0.6548 
2025-03-31 17:46:16.018587: Pseudo dice [0.6308] 
2025-03-31 17:46:16.018715: Epoch time: 274.18 s 
2025-03-31 17:46:18.313499:  
2025-03-31 17:46:18.313770: Epoch 360 
2025-03-31 17:46:18.313900: Current learning rate: 0.00669 
2025-03-31 17:50:52.239486: train_loss -0.8182 
2025-03-31 17:50:52.239865: val_loss -0.4827 
2025-03-31 17:50:52.239955: Pseudo dice [0.5092] 
2025-03-31 17:50:52.240048: Epoch time: 273.93 s 
2025-03-31 17:50:54.212777:  
2025-03-31 17:50:54.212948: Epoch 361 
2025-03-31 17:50:54.213100: Current learning rate: 0.00668 
2025-03-31 17:55:28.198593: train_loss -0.8016 
2025-03-31 17:55:28.198905: val_loss -0.6554 
2025-03-31 17:55:28.198993: Pseudo dice [0.6137] 
2025-03-31 17:55:28.199137: Epoch time: 273.99 s 
2025-03-31 17:55:30.188180:  
2025-03-31 17:55:30.188401: Epoch 362 
2025-03-31 17:55:30.188516: Current learning rate: 0.00667 
2025-03-31 18:00:03.990015: train_loss -0.7998 
2025-03-31 18:00:03.990422: val_loss -0.6277 
2025-03-31 18:00:03.990511: Pseudo dice [0.6114] 
2025-03-31 18:00:03.990591: Epoch time: 273.81 s 
2025-03-31 18:00:05.987616:  
2025-03-31 18:00:05.987926: Epoch 363 
2025-03-31 18:00:05.988069: Current learning rate: 0.00666 
2025-03-31 18:04:40.363794: train_loss -0.8028 
2025-03-31 18:04:40.364149: val_loss -0.6851 
2025-03-31 18:04:40.364278: Pseudo dice [0.6461] 
2025-03-31 18:04:40.364370: Epoch time: 274.38 s 
2025-03-31 18:04:42.345482:  
2025-03-31 18:04:42.345750: Epoch 364 
2025-03-31 18:04:42.345917: Current learning rate: 0.00665 
2025-03-31 18:09:16.580921: train_loss -0.7953 
2025-03-31 18:09:16.581245: val_loss -0.6594 
2025-03-31 18:09:16.581326: Pseudo dice [0.6924] 
2025-03-31 18:09:16.581408: Epoch time: 274.24 s 
2025-03-31 18:09:18.550793:  
2025-03-31 18:09:18.551084: Epoch 365 
2025-03-31 18:09:18.551241: Current learning rate: 0.00665 
2025-03-31 18:13:52.954303: train_loss -0.7947 
2025-03-31 18:13:52.954636: val_loss -0.6472 
2025-03-31 18:13:52.954720: Pseudo dice [0.6265] 
2025-03-31 18:13:52.954823: Epoch time: 274.41 s 
2025-03-31 18:13:54.940528:  
2025-03-31 18:13:54.940807: Epoch 366 
2025-03-31 18:13:54.940979: Current learning rate: 0.00664 
2025-03-31 18:18:29.547926: train_loss -0.8146 
2025-03-31 18:18:29.548260: val_loss -0.5031 
2025-03-31 18:18:29.548352: Pseudo dice [0.3732] 
2025-03-31 18:18:29.548451: Epoch time: 274.61 s 
2025-03-31 18:18:31.844173:  
2025-03-31 18:18:31.844383: Epoch 367 
2025-03-31 18:18:31.844533: Current learning rate: 0.00663 
2025-03-31 18:23:06.378578: train_loss -0.7969 
2025-03-31 18:23:06.378877: val_loss -0.637 
2025-03-31 18:23:06.378973: Pseudo dice [0.6823] 
2025-03-31 18:23:06.379057: Epoch time: 274.54 s 
2025-03-31 18:23:08.356423:  
2025-03-31 18:23:08.356641: Epoch 368 
2025-03-31 18:23:08.356755: Current learning rate: 0.00662 
2025-03-31 18:27:42.221148: train_loss -0.812 
2025-03-31 18:27:42.221450: val_loss -0.4502 
2025-03-31 18:27:42.221568: Pseudo dice [0.4805] 
2025-03-31 18:27:42.221671: Epoch time: 273.87 s 
2025-03-31 18:27:44.200569:  
2025-03-31 18:27:44.200773: Epoch 369 
2025-03-31 18:27:44.200895: Current learning rate: 0.00661 
2025-03-31 18:32:17.656560: train_loss -0.8088 
2025-03-31 18:32:17.656911: val_loss -0.6961 
2025-03-31 18:32:17.657005: Pseudo dice [0.7322] 
2025-03-31 18:32:17.657157: Epoch time: 273.46 s 
2025-03-31 18:32:19.632102:  
2025-03-31 18:32:19.632316: Epoch 370 
2025-03-31 18:32:19.632430: Current learning rate: 0.0066 
2025-03-31 18:36:52.243000: train_loss -0.796 
2025-03-31 18:36:52.243349: val_loss -0.6834 
2025-03-31 18:36:52.243445: Pseudo dice [0.6864] 
2025-03-31 18:36:52.243546: Epoch time: 272.61 s 
2025-03-31 18:36:54.245703:  
2025-03-31 18:36:54.245953: Epoch 371 
2025-03-31 18:36:54.246099: Current learning rate: 0.00659 
2025-03-31 18:41:26.793951: train_loss -0.8083 
2025-03-31 18:41:26.794268: val_loss -0.6028 
2025-03-31 18:41:26.794354: Pseudo dice [0.5439] 
2025-03-31 18:41:26.794464: Epoch time: 272.55 s 
2025-03-31 18:41:28.771356:  
2025-03-31 18:41:28.771598: Epoch 372 
2025-03-31 18:41:28.771718: Current learning rate: 0.00658 
2025-03-31 18:46:01.330976: train_loss -0.8161 
2025-03-31 18:46:01.331287: val_loss -0.6646 
2025-03-31 18:46:01.331378: Pseudo dice [0.6757] 
2025-03-31 18:46:01.331480: Epoch time: 272.56 s 
2025-03-31 18:46:03.357992:  
2025-03-31 18:46:03.358229: Epoch 373 
2025-03-31 18:46:03.358411: Current learning rate: 0.00657 
2025-03-31 18:50:35.379496: train_loss -0.8213 
2025-03-31 18:50:35.379907: val_loss -0.5595 
2025-03-31 18:50:35.379996: Pseudo dice [0.462] 
2025-03-31 18:50:35.380093: Epoch time: 272.03 s 
2025-03-31 18:50:37.358242:  
2025-03-31 18:50:37.358436: Epoch 374 
2025-03-31 18:50:37.358551: Current learning rate: 0.00656 
2025-03-31 18:55:09.609092: train_loss -0.8122 
2025-03-31 18:55:09.609419: val_loss -0.6797 
2025-03-31 18:55:09.609527: Pseudo dice [0.6724] 
2025-03-31 18:55:09.609628: Epoch time: 272.25 s 
2025-03-31 18:55:11.905468:  
2025-03-31 18:55:11.905672: Epoch 375 
2025-03-31 18:55:11.905788: Current learning rate: 0.00655 
2025-03-31 18:59:44.601437: train_loss -0.7942 
2025-03-31 18:59:44.601835: val_loss -0.5498 
2025-03-31 18:59:44.601937: Pseudo dice [0.5377] 
2025-03-31 18:59:44.602031: Epoch time: 272.7 s 
2025-03-31 18:59:46.592749:  
2025-03-31 18:59:46.592949: Epoch 376 
2025-03-31 18:59:46.593081: Current learning rate: 0.00654 
2025-03-31 19:04:19.349437: train_loss -0.812 
2025-03-31 19:04:19.349764: val_loss -0.6076 
2025-03-31 19:04:19.349847: Pseudo dice [0.5816] 
2025-03-31 19:04:19.349941: Epoch time: 272.76 s 
2025-03-31 19:04:21.341374:  
2025-03-31 19:04:21.341626: Epoch 377 
2025-03-31 19:04:21.341793: Current learning rate: 0.00653 
2025-03-31 19:08:53.543340: train_loss -0.8202 
2025-03-31 19:08:53.543636: val_loss -0.5786 
2025-03-31 19:08:53.543718: Pseudo dice [0.633] 
2025-03-31 19:08:53.543813: Epoch time: 272.21 s 
2025-03-31 19:08:55.535639:  
2025-03-31 19:08:55.535875: Epoch 378 
2025-03-31 19:08:55.536046: Current learning rate: 0.00652 
2025-03-31 19:13:28.612262: train_loss -0.8143 
2025-03-31 19:13:28.612574: val_loss -0.5856 
2025-03-31 19:13:28.612664: Pseudo dice [0.4456] 
2025-03-31 19:13:28.612757: Epoch time: 273.08 s 
2025-03-31 19:13:30.596889:  
2025-03-31 19:13:30.597134: Epoch 379 
2025-03-31 19:13:30.597277: Current learning rate: 0.00651 
2025-03-31 19:18:03.631960: train_loss -0.8197 
2025-03-31 19:18:03.632284: val_loss -0.5646 
2025-03-31 19:18:03.632392: Pseudo dice [0.521] 
2025-03-31 19:18:03.632520: Epoch time: 273.04 s 
2025-03-31 19:18:05.631526:  
2025-03-31 19:18:05.631739: Epoch 380 
2025-03-31 19:18:05.631951: Current learning rate: 0.0065 
2025-03-31 19:22:39.523755: train_loss -0.7937 
2025-03-31 19:22:39.524070: val_loss -0.5199 
2025-03-31 19:22:39.524178: Pseudo dice [0.5312] 
2025-03-31 19:22:39.524282: Epoch time: 273.9 s 
2025-03-31 19:22:41.530462:  
2025-03-31 19:22:41.530724: Epoch 381 
2025-03-31 19:22:41.530875: Current learning rate: 0.00649 
2025-03-31 19:27:15.945123: train_loss -0.7454 
2025-03-31 19:27:15.945430: val_loss -0.4372 
2025-03-31 19:27:15.945516: Pseudo dice [0.2265] 
2025-03-31 19:27:15.945621: Epoch time: 274.42 s 
2025-03-31 19:27:17.965907:  
2025-03-31 19:27:17.966100: Epoch 382 
2025-03-31 19:27:17.966239: Current learning rate: 0.00648 
2025-03-31 19:31:51.959907: train_loss -0.7669 
2025-03-31 19:31:51.960247: val_loss -0.6644 
2025-03-31 19:31:51.960335: Pseudo dice [0.6254] 
2025-03-31 19:31:51.960428: Epoch time: 274.0 s 
2025-03-31 19:31:54.300608:  
2025-03-31 19:31:54.300817: Epoch 383 
2025-03-31 19:31:54.300938: Current learning rate: 0.00648 
2025-03-31 19:36:28.103511: train_loss -0.775 
2025-03-31 19:36:28.103853: val_loss -0.5076 
2025-03-31 19:36:28.103943: Pseudo dice [0.3836] 
2025-03-31 19:36:28.104043: Epoch time: 273.81 s 
2025-03-31 19:36:30.127301:  
2025-03-31 19:36:30.127510: Epoch 384 
2025-03-31 19:36:30.127626: Current learning rate: 0.00647 
2025-03-31 19:41:03.996087: train_loss -0.752 
2025-03-31 19:41:03.996389: val_loss -0.604 
2025-03-31 19:41:03.996467: Pseudo dice [0.4147] 
2025-03-31 19:41:03.996568: Epoch time: 273.87 s 
2025-03-31 19:41:06.031700:  
2025-03-31 19:41:06.031973: Epoch 385 
2025-03-31 19:41:06.032094: Current learning rate: 0.00646 
2025-03-31 19:45:39.980423: train_loss -0.7748 
2025-03-31 19:45:39.980768: val_loss -0.5615 
2025-03-31 19:45:39.980855: Pseudo dice [0.5743] 
2025-03-31 19:45:39.980954: Epoch time: 273.95 s 
2025-03-31 19:45:41.991205:  
2025-03-31 19:45:41.991384: Epoch 386 
2025-03-31 19:45:41.991517: Current learning rate: 0.00645 
2025-03-31 19:50:16.073508: train_loss -0.7778 
2025-03-31 19:50:16.073876: val_loss -0.5922 
2025-03-31 19:50:16.073965: Pseudo dice [0.5285] 
2025-03-31 19:50:16.074060: Epoch time: 274.09 s 
2025-03-31 19:50:18.087948:  
2025-03-31 19:50:18.088224: Epoch 387 
2025-03-31 19:50:18.088359: Current learning rate: 0.00644 
2025-03-31 19:54:51.728369: train_loss -0.8103 
2025-03-31 19:54:51.728744: val_loss -0.6042 
2025-03-31 19:54:51.728840: Pseudo dice [0.7293] 
2025-03-31 19:54:51.728937: Epoch time: 273.64 s 
2025-03-31 19:54:53.737678:  
2025-03-31 19:54:53.737883: Epoch 388 
2025-03-31 19:54:53.737998: Current learning rate: 0.00643 
2025-03-31 19:59:27.296181: train_loss -0.7866 
2025-03-31 19:59:27.296508: val_loss -0.5376 
2025-03-31 19:59:27.296592: Pseudo dice [0.4088] 
2025-03-31 19:59:27.296706: Epoch time: 273.56 s 
2025-03-31 19:59:29.317726:  
2025-03-31 19:59:29.317944: Epoch 389 
2025-03-31 19:59:29.318062: Current learning rate: 0.00642 
2025-03-31 20:04:02.860163: train_loss -0.7741 
2025-03-31 20:04:02.860491: val_loss -0.5841 
2025-03-31 20:04:02.860625: Pseudo dice [0.3275] 
2025-03-31 20:04:02.860723: Epoch time: 273.55 s 
2025-03-31 20:04:05.195665:  
2025-03-31 20:04:05.195943: Epoch 390 
2025-03-31 20:04:05.196124: Current learning rate: 0.00641 
2025-03-31 20:08:38.871504: train_loss -0.7662 
2025-03-31 20:08:38.871839: val_loss -0.6195 
2025-03-31 20:08:38.871924: Pseudo dice [0.547] 
2025-03-31 20:08:38.872018: Epoch time: 273.68 s 
2025-03-31 20:08:40.896882:  
2025-03-31 20:08:40.897083: Epoch 391 
2025-03-31 20:08:40.897205: Current learning rate: 0.0064 
2025-03-31 20:13:14.590212: train_loss -0.7574 
2025-03-31 20:13:14.590575: val_loss -0.541 
2025-03-31 20:13:14.590660: Pseudo dice [0.4495] 
2025-03-31 20:13:14.590764: Epoch time: 273.7 s 
2025-03-31 20:13:16.593615:  
2025-03-31 20:13:16.593882: Epoch 392 
2025-03-31 20:13:16.594055: Current learning rate: 0.00639 
2025-03-31 20:17:50.218543: train_loss -0.7839 
2025-03-31 20:17:50.218857: val_loss -0.6363 
2025-03-31 20:17:50.218941: Pseudo dice [0.6342] 
2025-03-31 20:17:50.219043: Epoch time: 273.63 s 
2025-03-31 20:17:52.225518:  
2025-03-31 20:17:52.225749: Epoch 393 
2025-03-31 20:17:52.225898: Current learning rate: 0.00638 
2025-03-31 20:22:25.106480: train_loss -0.7811 
2025-03-31 20:22:25.106791: val_loss -0.6193 
2025-03-31 20:22:25.106876: Pseudo dice [0.6953] 
2025-03-31 20:22:25.107003: Epoch time: 272.88 s 
2025-03-31 20:22:27.120394:  
2025-03-31 20:22:27.120602: Epoch 394 
2025-03-31 20:22:27.120735: Current learning rate: 0.00637 
2025-03-31 20:27:00.981214: train_loss -0.7645 
2025-03-31 20:27:00.981542: val_loss -0.6026 
2025-03-31 20:27:00.981637: Pseudo dice [0.6095] 
2025-03-31 20:27:00.981743: Epoch time: 273.86 s 
2025-03-31 20:27:02.998610:  
2025-03-31 20:27:02.998829: Epoch 395 
2025-03-31 20:27:02.998984: Current learning rate: 0.00636 
2025-03-31 20:31:36.520101: train_loss -0.7836 
2025-03-31 20:31:36.520496: val_loss -0.5767 
2025-03-31 20:31:36.520603: Pseudo dice [0.5128] 
2025-03-31 20:31:36.520688: Epoch time: 273.53 s 
2025-03-31 20:31:38.549273:  
2025-03-31 20:31:38.549474: Epoch 396 
2025-03-31 20:31:38.549600: Current learning rate: 0.00635 
2025-03-31 20:36:12.327389: train_loss -0.7636 
2025-03-31 20:36:12.327724: val_loss -0.526 
2025-03-31 20:36:12.327824: Pseudo dice [0.531] 
2025-03-31 20:36:12.327930: Epoch time: 273.78 s 
2025-03-31 20:36:14.663886:  
2025-03-31 20:36:14.664096: Epoch 397 
2025-03-31 20:36:14.664222: Current learning rate: 0.00634 
2025-03-31 20:40:48.635542: train_loss -0.7562 
2025-03-31 20:40:48.635946: val_loss -0.5351 
2025-03-31 20:40:48.636047: Pseudo dice [0.5439] 
2025-03-31 20:40:48.636137: Epoch time: 273.98 s 
2025-03-31 20:40:50.657496:  
2025-03-31 20:40:50.657770: Epoch 398 
2025-03-31 20:40:50.657890: Current learning rate: 0.00633 
2025-03-31 20:45:24.912831: train_loss -0.786 
2025-03-31 20:45:24.913146: val_loss -0.64 
2025-03-31 20:45:24.913298: Pseudo dice [0.6184] 
2025-03-31 20:45:24.913393: Epoch time: 274.26 s 
2025-03-31 20:45:26.959386:  
2025-03-31 20:45:26.959642: Epoch 399 
2025-03-31 20:45:26.959812: Current learning rate: 0.00632 
2025-03-31 20:50:00.814015: train_loss -0.8004 
2025-03-31 20:50:00.814363: val_loss -0.6149 
2025-03-31 20:50:00.814450: Pseudo dice [0.6202] 
2025-03-31 20:50:00.814544: Epoch time: 273.86 s 
2025-03-31 20:50:04.203199:  
2025-03-31 20:50:04.203426: Epoch 400 
2025-03-31 20:50:04.203546: Current learning rate: 0.00631 
2025-03-31 20:54:37.766520: train_loss -0.8021 
2025-03-31 20:54:37.766779: val_loss -0.6029 
2025-03-31 20:54:37.766868: Pseudo dice [0.4711] 
2025-03-31 20:54:37.766968: Epoch time: 273.57 s 
2025-03-31 20:54:39.781722:  
2025-03-31 20:54:39.781916: Epoch 401 
2025-03-31 20:54:39.782030: Current learning rate: 0.0063 
2025-03-31 20:59:13.318690: train_loss -0.8144 
2025-03-31 20:59:13.319046: val_loss -0.5752 
2025-03-31 20:59:13.319127: Pseudo dice [0.5002] 
2025-03-31 20:59:13.319223: Epoch time: 273.54 s 
2025-03-31 20:59:15.342463:  
2025-03-31 20:59:15.342676: Epoch 402 
2025-03-31 20:59:15.342820: Current learning rate: 0.0063 
2025-03-31 21:03:49.128596: train_loss -0.7978 
2025-03-31 21:03:49.128956: val_loss -0.6815 
2025-03-31 21:03:49.129046: Pseudo dice [0.6145] 
2025-03-31 21:03:49.129159: Epoch time: 273.79 s 
2025-03-31 21:03:51.158967:  
2025-03-31 21:03:51.159173: Epoch 403 
2025-03-31 21:03:51.159325: Current learning rate: 0.00629 
2025-03-31 21:08:24.921556: train_loss -0.8156 
2025-03-31 21:08:24.921873: val_loss -0.6149 
2025-03-31 21:08:24.921957: Pseudo dice [0.5021] 
2025-03-31 21:08:24.922060: Epoch time: 273.77 s 
2025-03-31 21:08:26.941099:  
2025-03-31 21:08:26.941285: Epoch 404 
2025-03-31 21:08:26.941395: Current learning rate: 0.00628 
2025-03-31 21:13:01.270969: train_loss -0.7858 
2025-03-31 21:13:01.271327: val_loss -0.5661 
2025-03-31 21:13:01.271413: Pseudo dice [0.5304] 
2025-03-31 21:13:01.271507: Epoch time: 274.33 s 
2025-03-31 21:13:03.629364:  
2025-03-31 21:13:03.629591: Epoch 405 
2025-03-31 21:13:03.629720: Current learning rate: 0.00627 
2025-03-31 21:17:38.026858: train_loss -0.816 
2025-03-31 21:17:38.027231: val_loss -0.632 
2025-03-31 21:17:38.027335: Pseudo dice [0.6707] 
2025-03-31 21:17:38.027437: Epoch time: 274.4 s 
2025-03-31 21:17:40.073534:  
2025-03-31 21:17:40.073756: Epoch 406 
2025-03-31 21:17:40.073942: Current learning rate: 0.00626 
2025-03-31 21:22:13.939332: train_loss -0.8003 
2025-03-31 21:22:13.939646: val_loss -0.5566 
2025-03-31 21:22:13.939733: Pseudo dice [0.4846] 
2025-03-31 21:22:13.939847: Epoch time: 273.87 s 
2025-03-31 21:22:15.966498:  
2025-03-31 21:22:15.966743: Epoch 407 
2025-03-31 21:22:15.966860: Current learning rate: 0.00625 
2025-03-31 21:26:49.178595: train_loss -0.7932 
2025-03-31 21:26:49.178965: val_loss -0.6358 
2025-03-31 21:26:49.179077: Pseudo dice [0.6746] 
2025-03-31 21:26:49.179167: Epoch time: 273.22 s 
2025-03-31 21:26:51.228975:  
2025-03-31 21:26:51.229244: Epoch 408 
2025-03-31 21:26:51.229402: Current learning rate: 0.00624 
2025-03-31 21:31:24.497150: train_loss -0.7914 
2025-03-31 21:31:24.497461: val_loss -0.623 
2025-03-31 21:31:24.497545: Pseudo dice [0.5758] 
2025-03-31 21:31:24.497775: Epoch time: 273.27 s 
2025-03-31 21:31:26.519556:  
2025-03-31 21:31:26.519938: Epoch 409 
2025-03-31 21:31:26.520104: Current learning rate: 0.00623 
2025-03-31 21:35:59.539793: train_loss -0.7624 
2025-03-31 21:35:59.540412: val_loss -0.6867 
2025-03-31 21:35:59.540506: Pseudo dice [0.6973] 
2025-03-31 21:35:59.540625: Epoch time: 273.02 s 
2025-03-31 21:36:01.563812:  
2025-03-31 21:36:01.563999: Epoch 410 
2025-03-31 21:36:01.564112: Current learning rate: 0.00622 
2025-03-31 21:40:35.190662: train_loss -0.7912 
2025-03-31 21:40:35.191072: val_loss -0.4542 
2025-03-31 21:40:35.191190: Pseudo dice [0.2703] 
2025-03-31 21:40:35.191273: Epoch time: 273.63 s 
2025-03-31 21:40:37.100457:  
2025-03-31 21:40:37.100704: Epoch 411 
2025-03-31 21:40:37.100843: Current learning rate: 0.00621 
2025-03-31 21:45:10.255606: train_loss -0.7312 
2025-03-31 21:45:10.255921: val_loss -0.4945 
2025-03-31 21:45:10.256011: Pseudo dice [0.5034] 
2025-03-31 21:45:10.256119: Epoch time: 273.16 s 
2025-03-31 21:45:12.174171:  
2025-03-31 21:45:12.174378: Epoch 412 
2025-03-31 21:45:12.174506: Current learning rate: 0.0062 
2025-03-31 21:49:45.326528: train_loss -0.7483 
2025-03-31 21:49:45.326960: val_loss -0.4891 
2025-03-31 21:49:45.327067: Pseudo dice [0.3681] 
2025-03-31 21:49:45.327144: Epoch time: 273.16 s 
2025-03-31 21:49:47.244608:  
2025-03-31 21:49:47.244892: Epoch 413 
2025-03-31 21:49:47.245021: Current learning rate: 0.00619 
2025-03-31 21:54:19.232451: train_loss -0.7814 
2025-03-31 21:54:19.232760: val_loss -0.5767 
2025-03-31 21:54:19.232845: Pseudo dice [0.396] 
2025-03-31 21:54:19.232980: Epoch time: 271.99 s 
2025-03-31 21:54:21.142967:  
2025-03-31 21:54:21.143193: Epoch 414 
2025-03-31 21:54:21.143347: Current learning rate: 0.00618 
2025-03-31 21:58:53.518739: train_loss -0.7873 
2025-03-31 21:58:53.519075: val_loss -0.6543 
2025-03-31 21:58:53.519161: Pseudo dice [0.6669] 
2025-03-31 21:58:53.519268: Epoch time: 272.38 s 
2025-03-31 21:58:55.438222:  
2025-03-31 21:58:55.438436: Epoch 415 
2025-03-31 21:58:55.438637: Current learning rate: 0.00617 
2025-03-31 22:03:27.843825: train_loss -0.7936 
2025-03-31 22:03:27.844145: val_loss -0.6314 
2025-03-31 22:03:27.844228: Pseudo dice [0.5467] 
2025-03-31 22:03:27.844319: Epoch time: 272.41 s 
2025-03-31 22:03:29.772201:  
2025-03-31 22:03:29.772411: Epoch 416 
2025-03-31 22:03:29.772537: Current learning rate: 0.00616 
2025-03-31 22:08:01.866551: train_loss -0.8064 
2025-03-31 22:08:01.866888: val_loss -0.6527 
2025-03-31 22:08:01.867024: Pseudo dice [0.6192] 
2025-03-31 22:08:01.867120: Epoch time: 272.1 s 
2025-03-31 22:08:03.788492:  
2025-03-31 22:08:03.788699: Epoch 417 
2025-03-31 22:08:03.788848: Current learning rate: 0.00615 
2025-03-31 22:12:35.640568: train_loss -0.8114 
2025-03-31 22:12:35.640885: val_loss -0.5473 
2025-03-31 22:12:35.640964: Pseudo dice [0.5126] 
2025-03-31 22:12:35.641050: Epoch time: 271.86 s 
2025-03-31 22:12:37.554074:  
2025-03-31 22:12:37.554336: Epoch 418 
2025-03-31 22:12:37.554482: Current learning rate: 0.00614 
2025-03-31 22:17:10.331051: train_loss -0.7545 
2025-03-31 22:17:10.331409: val_loss -0.6569 
2025-03-31 22:17:10.331498: Pseudo dice [0.6564] 
2025-03-31 22:17:10.331597: Epoch time: 272.78 s 
2025-03-31 22:17:12.279469:  
2025-03-31 22:17:12.279719: Epoch 419 
2025-03-31 22:17:12.279857: Current learning rate: 0.00613 
2025-03-31 22:21:46.026466: train_loss -0.7468 
2025-03-31 22:21:46.026855: val_loss -0.5898 
2025-03-31 22:21:46.026952: Pseudo dice [0.5367] 
2025-03-31 22:21:46.027113: Epoch time: 273.75 s 
2025-03-31 22:21:47.959179:  
2025-03-31 22:21:47.959533: Epoch 420 
2025-03-31 22:21:47.959700: Current learning rate: 0.00612 
2025-03-31 22:26:21.779859: train_loss -0.7334 
2025-03-31 22:26:21.780174: val_loss -0.5904 
2025-03-31 22:26:21.780262: Pseudo dice [0.6301] 
2025-03-31 22:26:21.780360: Epoch time: 273.82 s 
2025-03-31 22:26:24.007232:  
2025-03-31 22:26:24.007473: Epoch 421 
2025-03-31 22:26:24.007648: Current learning rate: 0.00612 
2025-03-31 22:30:56.936948: train_loss -0.7854 
2025-03-31 22:30:56.937324: val_loss -0.6016 
2025-03-31 22:30:56.937447: Pseudo dice [0.5137] 
2025-03-31 22:30:56.937538: Epoch time: 272.93 s 
2025-03-31 22:30:58.860461:  
2025-03-31 22:30:58.860675: Epoch 422 
2025-03-31 22:30:58.860790: Current learning rate: 0.00611 
2025-03-31 22:35:31.295282: train_loss -0.8092 
2025-03-31 22:35:31.295629: val_loss -0.6697 
2025-03-31 22:35:31.295725: Pseudo dice [0.6157] 
2025-03-31 22:35:31.295911: Epoch time: 272.44 s 
2025-03-31 22:35:33.218742:  
2025-03-31 22:35:33.219024: Epoch 423 
2025-03-31 22:35:33.219142: Current learning rate: 0.0061 
2025-03-31 22:40:05.910701: train_loss -0.7995 
2025-03-31 22:40:05.910996: val_loss -0.5657 
2025-03-31 22:40:05.911119: Pseudo dice [0.5515] 
2025-03-31 22:40:05.911230: Epoch time: 272.7 s 
2025-03-31 22:40:07.834813:  
2025-03-31 22:40:07.834992: Epoch 424 
2025-03-31 22:40:07.835142: Current learning rate: 0.00609 
2025-03-31 22:44:40.555131: train_loss -0.7921 
2025-03-31 22:44:40.555483: val_loss -0.6643 
2025-03-31 22:44:40.555580: Pseudo dice [0.5985] 
2025-03-31 22:44:40.555676: Epoch time: 272.72 s 
2025-03-31 22:44:42.472353:  
2025-03-31 22:44:42.472574: Epoch 425 
2025-03-31 22:44:42.472697: Current learning rate: 0.00608 
2025-03-31 22:49:15.141603: train_loss -0.8073 
2025-03-31 22:49:15.141978: val_loss -0.6937 
2025-03-31 22:49:15.142071: Pseudo dice [0.6774] 
2025-03-31 22:49:15.142178: Epoch time: 272.67 s 
2025-03-31 22:49:17.071140:  
2025-03-31 22:49:17.071351: Epoch 426 
2025-03-31 22:49:17.071468: Current learning rate: 0.00607 
2025-03-31 22:53:50.199516: train_loss -0.7996 
2025-03-31 22:53:50.199884: val_loss -0.652 
2025-03-31 22:53:50.199993: Pseudo dice [0.7107] 
2025-03-31 22:53:50.200121: Epoch time: 273.13 s 
2025-03-31 22:53:52.121083:  
2025-03-31 22:53:52.121283: Epoch 427 
2025-03-31 22:53:52.121399: Current learning rate: 0.00606 
2025-03-31 22:58:25.945495: train_loss -0.7995 
2025-03-31 22:58:25.945813: val_loss -0.649 
2025-03-31 22:58:25.946877: Pseudo dice [0.6199] 
2025-03-31 22:58:25.946966: Epoch time: 273.83 s 
2025-03-31 22:58:27.874290:  
2025-03-31 22:58:27.874522: Epoch 428 
2025-03-31 22:58:27.874647: Current learning rate: 0.00605 
2025-03-31 23:03:01.689727: train_loss -0.7902 
2025-03-31 23:03:01.690113: val_loss -0.332 
2025-03-31 23:03:01.690200: Pseudo dice [0.1634] 
2025-03-31 23:03:01.690299: Epoch time: 273.82 s 
2025-03-31 23:03:03.925065:  
2025-03-31 23:03:03.925286: Epoch 429 
2025-03-31 23:03:03.925407: Current learning rate: 0.00604 
2025-03-31 23:07:37.529142: train_loss -0.7955 
2025-03-31 23:07:37.529462: val_loss -0.5405 
2025-03-31 23:07:37.529546: Pseudo dice [0.4054] 
2025-03-31 23:07:37.529638: Epoch time: 273.61 s 
2025-03-31 23:07:39.463860:  
2025-03-31 23:07:39.464155: Epoch 430 
2025-03-31 23:07:39.464276: Current learning rate: 0.00603 
2025-03-31 23:12:13.085977: train_loss -0.7914 
2025-03-31 23:12:13.086282: val_loss -0.5844 
2025-03-31 23:12:13.086370: Pseudo dice [0.4207] 
2025-03-31 23:12:13.086462: Epoch time: 273.63 s 
2025-03-31 23:12:15.026599:  
2025-03-31 23:12:15.026866: Epoch 431 
2025-03-31 23:12:15.027001: Current learning rate: 0.00602 
2025-03-31 23:16:48.405827: train_loss -0.813 
2025-03-31 23:16:48.406211: val_loss -0.5699 
2025-03-31 23:16:48.406305: Pseudo dice [0.5669] 
2025-03-31 23:16:48.406403: Epoch time: 273.38 s 
2025-03-31 23:16:50.344406:  
2025-03-31 23:16:50.344751: Epoch 432 
2025-03-31 23:16:50.344873: Current learning rate: 0.00601 
2025-03-31 23:21:23.651891: train_loss -0.8033 
2025-03-31 23:21:23.652251: val_loss -0.6045 
2025-03-31 23:21:23.652337: Pseudo dice [0.5748] 
2025-03-31 23:21:23.652432: Epoch time: 273.31 s 
2025-03-31 23:21:25.584774:  
2025-03-31 23:21:25.584962: Epoch 433 
2025-03-31 23:21:25.585079: Current learning rate: 0.006 
2025-03-31 23:25:59.008277: train_loss -0.8202 
2025-03-31 23:25:59.008649: val_loss -0.66 
2025-03-31 23:25:59.008754: Pseudo dice [0.6657] 
2025-03-31 23:25:59.008868: Epoch time: 273.43 s 
2025-03-31 23:26:00.940917:  
2025-03-31 23:26:00.941113: Epoch 434 
2025-03-31 23:26:00.941242: Current learning rate: 0.00599 
2025-03-31 23:30:34.476604: train_loss -0.8263 
2025-03-31 23:30:34.476933: val_loss -0.6466 
2025-03-31 23:30:34.477019: Pseudo dice [0.5406] 
2025-03-31 23:30:34.477123: Epoch time: 273.54 s 
2025-03-31 23:30:36.396626:  
2025-03-31 23:30:36.396883: Epoch 435 
2025-03-31 23:30:36.397012: Current learning rate: 0.00598 
2025-03-31 23:35:10.812572: train_loss -0.806 
2025-03-31 23:35:10.812931: val_loss -0.5263 
2025-03-31 23:35:10.813134: Pseudo dice [0.4321] 
2025-03-31 23:35:10.813218: Epoch time: 274.42 s 
2025-03-31 23:35:12.743861:  
2025-03-31 23:35:12.744098: Epoch 436 
2025-03-31 23:35:12.744235: Current learning rate: 0.00597 
2025-03-31 23:39:46.922507: train_loss -0.7852 
2025-03-31 23:39:46.922825: val_loss -0.6304 
2025-03-31 23:39:46.922916: Pseudo dice [0.7544] 
2025-03-31 23:39:46.923067: Epoch time: 274.18 s 
2025-03-31 23:39:49.223928:  
2025-03-31 23:39:49.224104: Epoch 437 
2025-03-31 23:39:49.224222: Current learning rate: 0.00596 
2025-03-31 23:44:22.572133: train_loss -0.8067 
2025-03-31 23:44:22.572450: val_loss -0.6323 
2025-03-31 23:44:22.572540: Pseudo dice [0.7058] 
2025-03-31 23:44:22.572639: Epoch time: 273.35 s 
2025-03-31 23:44:24.495894:  
2025-03-31 23:44:24.496088: Epoch 438 
2025-03-31 23:44:24.496247: Current learning rate: 0.00595 
2025-03-31 23:48:57.650009: train_loss -0.8124 
2025-03-31 23:48:57.650318: val_loss -0.5881 
2025-03-31 23:48:57.650403: Pseudo dice [0.5118] 
2025-03-31 23:48:57.650524: Epoch time: 273.16 s 
2025-03-31 23:48:59.572627:  
2025-03-31 23:48:59.572872: Epoch 439 
2025-03-31 23:48:59.573074: Current learning rate: 0.00594 
2025-03-31 23:53:32.873417: train_loss -0.827 
2025-03-31 23:53:32.873761: val_loss -0.6322 
2025-03-31 23:53:32.873844: Pseudo dice [0.5513] 
2025-03-31 23:53:32.873948: Epoch time: 273.3 s 
2025-03-31 23:53:34.813577:  
2025-03-31 23:53:34.813797: Epoch 440 
2025-03-31 23:53:34.813991: Current learning rate: 0.00593 
2025-03-31 23:58:08.494199: train_loss -0.8242 
2025-03-31 23:58:08.494523: val_loss -0.6539 
2025-03-31 23:58:08.494607: Pseudo dice [0.6993] 
2025-03-31 23:58:08.494709: Epoch time: 273.68 s 
2025-03-31 23:58:10.412175:  
2025-03-31 23:58:10.412378: Epoch 441 
2025-03-31 23:58:10.412495: Current learning rate: 0.00592 
2025-04-01 00:02:43.778090: train_loss -0.8215 
2025-04-01 00:02:43.778455: val_loss -0.6217 
2025-04-01 00:02:43.778539: Pseudo dice [0.4241] 
2025-04-01 00:02:43.778634: Epoch time: 273.37 s 
2025-04-01 00:02:45.697651:  
2025-04-01 00:02:45.697886: Epoch 442 
2025-04-01 00:02:45.698031: Current learning rate: 0.00592 
2025-04-01 00:07:19.119262: train_loss -0.823 
2025-04-01 00:07:19.119580: val_loss -0.5935 
2025-04-01 00:07:19.119661: Pseudo dice [0.6349] 
2025-04-01 00:07:19.119747: Epoch time: 273.43 s 
2025-04-01 00:07:21.059436:  
2025-04-01 00:07:21.059742: Epoch 443 
2025-04-01 00:07:21.059915: Current learning rate: 0.00591 
2025-04-01 00:11:54.484806: train_loss -0.8199 
2025-04-01 00:11:54.485140: val_loss -0.6972 
2025-04-01 00:11:54.485225: Pseudo dice [0.759] 
2025-04-01 00:11:54.485325: Epoch time: 273.43 s 
2025-04-01 00:11:56.394204:  
2025-04-01 00:11:56.394409: Epoch 444 
2025-04-01 00:11:56.394526: Current learning rate: 0.0059 
2025-04-01 00:16:29.921713: train_loss -0.8264 
2025-04-01 00:16:29.922040: val_loss -0.5474 
2025-04-01 00:16:29.922143: Pseudo dice [0.5303] 
2025-04-01 00:16:29.922241: Epoch time: 273.53 s 
2025-04-01 00:16:32.127709:  
2025-04-01 00:16:32.128007: Epoch 445 
2025-04-01 00:16:32.128150: Current learning rate: 0.00589 
2025-04-01 00:21:06.388807: train_loss -0.814 
2025-04-01 00:21:06.389140: val_loss -0.6546 
2025-04-01 00:21:06.389296: Pseudo dice [0.6908] 
2025-04-01 00:21:06.389457: Epoch time: 274.26 s 
2025-04-01 00:21:08.310177:  
2025-04-01 00:21:08.310414: Epoch 446 
2025-04-01 00:21:08.310536: Current learning rate: 0.00588 
2025-04-01 00:25:42.475444: train_loss -0.8265 
2025-04-01 00:25:42.475806: val_loss -0.5999 
2025-04-01 00:25:42.475906: Pseudo dice [0.6171] 
2025-04-01 00:25:42.476027: Epoch time: 274.17 s 
2025-04-01 00:25:44.398209:  
2025-04-01 00:25:44.398383: Epoch 447 
2025-04-01 00:25:44.398502: Current learning rate: 0.00587 
2025-04-01 00:30:17.925977: train_loss -0.817 
2025-04-01 00:30:17.926275: val_loss -0.6443 
2025-04-01 00:30:17.926357: Pseudo dice [0.6777] 
2025-04-01 00:30:17.926441: Epoch time: 273.53 s 
2025-04-01 00:30:19.843291:  
2025-04-01 00:30:19.843546: Epoch 448 
2025-04-01 00:30:19.843693: Current learning rate: 0.00586 
2025-04-01 00:34:52.976838: train_loss -0.816 
2025-04-01 00:34:52.977228: val_loss -0.7309 
2025-04-01 00:34:52.977331: Pseudo dice [0.7682] 
2025-04-01 00:34:52.977417: Epoch time: 273.14 s 
2025-04-01 00:34:54.912394:  
2025-04-01 00:34:54.912666: Epoch 449 
2025-04-01 00:34:54.912779: Current learning rate: 0.00585 
2025-04-01 00:39:27.661098: train_loss -0.8169 
2025-04-01 00:39:27.661411: val_loss -0.6636 
2025-04-01 00:39:27.661490: Pseudo dice [0.6565] 
2025-04-01 00:39:27.661574: Epoch time: 272.75 s 
2025-04-01 00:39:29.057860: Yayy! New best EMA pseudo Dice: 0.6237 
2025-04-01 00:39:32.398054:  
2025-04-01 00:39:32.398338: Epoch 450 
2025-04-01 00:39:32.398533: Current learning rate: 0.00584 
2025-04-01 00:44:05.611537: train_loss -0.8013 
2025-04-01 00:44:05.611885: val_loss -0.5594 
2025-04-01 00:44:05.611970: Pseudo dice [0.5932] 
2025-04-01 00:44:05.612069: Epoch time: 273.22 s 
2025-04-01 00:44:07.522351:  
2025-04-01 00:44:07.522660: Epoch 451 
2025-04-01 00:44:07.522860: Current learning rate: 0.00583 
2025-04-01 00:48:41.290272: train_loss -0.801 
2025-04-01 00:48:41.290597: val_loss -0.6687 
2025-04-01 00:48:41.290682: Pseudo dice [0.533] 
2025-04-01 00:48:41.290799: Epoch time: 273.77 s 
2025-04-01 00:48:43.223552:  
2025-04-01 00:48:43.223728: Epoch 452 
2025-04-01 00:48:43.223858: Current learning rate: 0.00582 
2025-04-01 00:53:16.594883: train_loss -0.8209 
2025-04-01 00:53:16.595190: val_loss -0.569 
2025-04-01 00:53:16.595320: Pseudo dice [0.6175] 
2025-04-01 00:53:16.595426: Epoch time: 273.38 s 
2025-04-01 00:53:18.828581:  
2025-04-01 00:53:18.828790: Epoch 453 
2025-04-01 00:53:18.828933: Current learning rate: 0.00581 
2025-04-01 00:57:52.041444: train_loss -0.7931 
2025-04-01 00:57:52.041785: val_loss -0.6271 
2025-04-01 00:57:52.041881: Pseudo dice [0.6412] 
2025-04-01 00:57:52.041982: Epoch time: 273.22 s 
2025-04-01 00:57:53.960477:  
2025-04-01 00:57:53.960728: Epoch 454 
2025-04-01 00:57:53.960846: Current learning rate: 0.0058 
2025-04-01 01:02:26.768350: train_loss -0.8098 
2025-04-01 01:02:26.768663: val_loss -0.5578 
2025-04-01 01:02:26.768748: Pseudo dice [0.3857] 
2025-04-01 01:02:26.768841: Epoch time: 272.81 s 
2025-04-01 01:02:28.677744:  
2025-04-01 01:02:28.677953: Epoch 455 
2025-04-01 01:02:28.678126: Current learning rate: 0.00579 
2025-04-01 01:07:01.062529: train_loss -0.8323 
2025-04-01 01:07:01.062842: val_loss -0.6695 
2025-04-01 01:07:01.062926: Pseudo dice [0.5961] 
2025-04-01 01:07:01.063014: Epoch time: 272.39 s 
2025-04-01 01:07:02.997628:  
2025-04-01 01:07:02.997949: Epoch 456 
2025-04-01 01:07:02.998083: Current learning rate: 0.00578 
2025-04-01 01:11:35.562429: train_loss -0.8123 
2025-04-01 01:11:35.562756: val_loss -0.63 
2025-04-01 01:11:35.562837: Pseudo dice [0.6063] 
2025-04-01 01:11:35.562932: Epoch time: 272.57 s 
2025-04-01 01:11:37.488287:  
2025-04-01 01:11:37.488501: Epoch 457 
2025-04-01 01:11:37.488614: Current learning rate: 0.00577 
2025-04-01 01:16:10.390796: train_loss -0.8106 
2025-04-01 01:16:10.391118: val_loss -0.5831 
2025-04-01 01:16:10.391252: Pseudo dice [0.5971] 
2025-04-01 01:16:10.391351: Epoch time: 272.91 s 
2025-04-01 01:16:12.316096:  
2025-04-01 01:16:12.316334: Epoch 458 
2025-04-01 01:16:12.316465: Current learning rate: 0.00576 
2025-04-01 01:20:45.848481: train_loss -0.7876 
2025-04-01 01:20:45.848865: val_loss -0.5109 
2025-04-01 01:20:45.849004: Pseudo dice [0.3437] 
2025-04-01 01:20:45.849090: Epoch time: 273.54 s 
2025-04-01 01:20:47.786389:  
2025-04-01 01:20:47.786678: Epoch 459 
2025-04-01 01:20:47.786813: Current learning rate: 0.00575 
2025-04-01 01:25:20.824665: train_loss -0.7968 
2025-04-01 01:25:20.824977: val_loss -0.6463 
2025-04-01 01:25:20.825123: Pseudo dice [0.5366] 
2025-04-01 01:25:20.825263: Epoch time: 273.04 s 
2025-04-01 01:25:22.737111:  
2025-04-01 01:25:22.737385: Epoch 460 
2025-04-01 01:25:22.737514: Current learning rate: 0.00574 
2025-04-01 01:29:54.799699: train_loss -0.8266 
2025-04-01 01:29:54.800066: val_loss -0.645 
2025-04-01 01:29:54.800153: Pseudo dice [0.6188] 
2025-04-01 01:29:54.800250: Epoch time: 272.07 s 
2025-04-01 01:29:57.016636:  
2025-04-01 01:29:57.016863: Epoch 461 
2025-04-01 01:29:57.016996: Current learning rate: 0.00573 
2025-04-01 01:34:30.054351: train_loss -0.8217 
2025-04-01 01:34:30.054864: val_loss -0.6138 
2025-04-01 01:34:30.054943: Pseudo dice [0.648] 
2025-04-01 01:34:30.055048: Epoch time: 273.04 s 
2025-04-01 01:34:31.995447:  
2025-04-01 01:34:31.995665: Epoch 462 
2025-04-01 01:34:31.995828: Current learning rate: 0.00572 
2025-04-01 01:39:05.399347: train_loss -0.8241 
2025-04-01 01:39:05.399710: val_loss -0.6596 
2025-04-01 01:39:05.399830: Pseudo dice [0.5959] 
2025-04-01 01:39:05.399928: Epoch time: 273.41 s 
2025-04-01 01:39:07.310792:  
2025-04-01 01:39:07.311060: Epoch 463 
2025-04-01 01:39:07.311239: Current learning rate: 0.00571 
2025-04-01 01:43:40.601306: train_loss -0.8185 
2025-04-01 01:43:40.601629: val_loss -0.5229 
2025-04-01 01:43:40.601712: Pseudo dice [0.3784] 
2025-04-01 01:43:40.601810: Epoch time: 273.29 s 
2025-04-01 01:43:42.529458:  
2025-04-01 01:43:42.529760: Epoch 464 
2025-04-01 01:43:42.529882: Current learning rate: 0.0057 
2025-04-01 01:48:16.191673: train_loss -0.8148 
2025-04-01 01:48:16.192004: val_loss -0.6542 
2025-04-01 01:48:16.192089: Pseudo dice [0.6816] 
2025-04-01 01:48:16.192192: Epoch time: 273.67 s 
2025-04-01 01:48:18.123915:  
2025-04-01 01:48:18.124112: Epoch 465 
2025-04-01 01:48:18.124227: Current learning rate: 0.0057 
2025-04-01 01:52:51.915995: train_loss -0.7926 
2025-04-01 01:52:51.916317: val_loss -0.5878 
2025-04-01 01:52:51.916398: Pseudo dice [0.4616] 
2025-04-01 01:52:51.916497: Epoch time: 273.8 s 
2025-04-01 01:52:53.850732:  
2025-04-01 01:52:53.851037: Epoch 466 
2025-04-01 01:52:53.851162: Current learning rate: 0.00569 
2025-04-01 01:57:27.913114: train_loss -0.785 
2025-04-01 01:57:27.913473: val_loss -0.6073 
2025-04-01 01:57:27.913565: Pseudo dice [0.6555] 
2025-04-01 01:57:27.913662: Epoch time: 274.07 s 
2025-04-01 01:57:29.831840:  
2025-04-01 01:57:29.832036: Epoch 467 
2025-04-01 01:57:29.832156: Current learning rate: 0.00568 
2025-04-01 02:02:03.439860: train_loss -0.7877 
2025-04-01 02:02:03.440262: val_loss -0.6054 
2025-04-01 02:02:03.440371: Pseudo dice [0.5517] 
2025-04-01 02:02:03.440451: Epoch time: 273.61 s 
2025-04-01 02:02:05.371008:  
2025-04-01 02:02:05.371236: Epoch 468 
2025-04-01 02:02:05.371394: Current learning rate: 0.00567 
2025-04-01 02:06:38.785535: train_loss -0.7905 
2025-04-01 02:06:38.785853: val_loss -0.6162 
2025-04-01 02:06:38.785934: Pseudo dice [0.6147] 
2025-04-01 02:06:38.786039: Epoch time: 273.42 s 
2025-04-01 02:06:40.695034:  
2025-04-01 02:06:40.695238: Epoch 469 
2025-04-01 02:06:40.695348: Current learning rate: 0.00566 
2025-04-01 02:11:14.489121: train_loss -0.8057 
2025-04-01 02:11:14.489506: val_loss -0.5776 
2025-04-01 02:11:14.489596: Pseudo dice [0.453] 
2025-04-01 02:11:14.489736: Epoch time: 273.8 s 
2025-04-01 02:11:16.736992:  
2025-04-01 02:11:16.737204: Epoch 470 
2025-04-01 02:11:16.737336: Current learning rate: 0.00565 
2025-04-01 02:15:50.564698: train_loss -0.8169 
2025-04-01 02:15:50.565030: val_loss -0.58 
2025-04-01 02:15:50.565115: Pseudo dice [0.5772] 
2025-04-01 02:15:50.565214: Epoch time: 273.83 s 
2025-04-01 02:15:52.477052:  
2025-04-01 02:15:52.477326: Epoch 471 
2025-04-01 02:15:52.477493: Current learning rate: 0.00564 
2025-04-01 02:20:26.430080: train_loss -0.7691 
2025-04-01 02:20:26.430379: val_loss -0.5267 
2025-04-01 02:20:26.430465: Pseudo dice [0.3076] 
2025-04-01 02:20:26.430551: Epoch time: 273.96 s 
2025-04-01 02:20:28.338421:  
2025-04-01 02:20:28.338629: Epoch 472 
2025-04-01 02:20:28.338745: Current learning rate: 0.00563 
2025-04-01 02:25:02.026371: train_loss -0.7932 
2025-04-01 02:25:02.026691: val_loss -0.6148 
2025-04-01 02:25:02.026832: Pseudo dice [0.6244] 
2025-04-01 02:25:02.026929: Epoch time: 273.69 s 
2025-04-01 02:25:03.952772:  
2025-04-01 02:25:03.952960: Epoch 473 
2025-04-01 02:25:03.953121: Current learning rate: 0.00562 
2025-04-01 02:29:37.524143: train_loss -0.8163 
2025-04-01 02:29:37.524483: val_loss -0.5854 
2025-04-01 02:29:37.524652: Pseudo dice [0.4737] 
2025-04-01 02:29:37.524759: Epoch time: 273.58 s 
2025-04-01 02:29:39.458524:  
2025-04-01 02:29:39.458776: Epoch 474 
2025-04-01 02:29:39.458899: Current learning rate: 0.00561 
2025-04-01 02:34:12.967007: train_loss -0.8198 
2025-04-01 02:34:12.967335: val_loss -0.5447 
2025-04-01 02:34:12.967481: Pseudo dice [0.5488] 
2025-04-01 02:34:12.967575: Epoch time: 273.51 s 
2025-04-01 02:34:14.900741:  
2025-04-01 02:34:14.900907: Epoch 475 
2025-04-01 02:34:14.901060: Current learning rate: 0.0056 
2025-04-01 02:38:48.439265: train_loss -0.7964 
2025-04-01 02:38:48.439587: val_loss -0.6097 
2025-04-01 02:38:48.439671: Pseudo dice [0.7208] 
2025-04-01 02:38:48.439775: Epoch time: 273.54 s 
2025-04-01 02:38:50.375250:  
2025-04-01 02:38:50.375480: Epoch 476 
2025-04-01 02:38:50.375629: Current learning rate: 0.00559 
2025-04-01 02:43:24.281487: train_loss -0.8074 
2025-04-01 02:43:24.281825: val_loss -0.5698 
2025-04-01 02:43:24.281931: Pseudo dice [0.6166] 
2025-04-01 02:43:24.282037: Epoch time: 273.91 s 
2025-04-01 02:43:26.210731:  
2025-04-01 02:43:26.210927: Epoch 477 
2025-04-01 02:43:26.211042: Current learning rate: 0.00558 
2025-04-01 02:47:59.381678: train_loss -0.8289 
2025-04-01 02:47:59.382009: val_loss -0.5818 
2025-04-01 02:47:59.382093: Pseudo dice [0.6975] 
2025-04-01 02:47:59.382195: Epoch time: 273.17 s 
2025-04-01 02:48:01.770221:  
2025-04-01 02:48:01.770485: Epoch 478 
2025-04-01 02:48:01.770626: Current learning rate: 0.00557 
2025-04-01 02:52:34.907121: train_loss -0.8052 
2025-04-01 02:52:34.907475: val_loss -0.4403 
2025-04-01 02:52:34.908228: Pseudo dice [0.3328] 
2025-04-01 02:52:34.908311: Epoch time: 273.14 s 
2025-04-01 02:52:36.887566:  
2025-04-01 02:52:36.887850: Epoch 479 
2025-04-01 02:52:36.887966: Current learning rate: 0.00556 
2025-04-01 02:57:10.905845: train_loss -0.7862 
2025-04-01 02:57:10.906182: val_loss -0.5704 
2025-04-01 02:57:10.906271: Pseudo dice [0.6107] 
2025-04-01 02:57:10.906366: Epoch time: 274.02 s 
2025-04-01 02:57:12.858548:  
2025-04-01 02:57:12.858741: Epoch 480 
2025-04-01 02:57:12.858857: Current learning rate: 0.00555 
2025-04-01 03:01:47.510707: train_loss -0.7855 
2025-04-01 03:01:47.511072: val_loss -0.4727 
2025-04-01 03:01:47.511161: Pseudo dice [0.3732] 
2025-04-01 03:01:47.511259: Epoch time: 274.66 s 
2025-04-01 03:01:49.474225:  
2025-04-01 03:01:49.474481: Epoch 481 
2025-04-01 03:01:49.474617: Current learning rate: 0.00554 
2025-04-01 03:06:23.487403: train_loss -0.815 
2025-04-01 03:06:23.487735: val_loss -0.6055 
2025-04-01 03:06:23.488286: Pseudo dice [0.5479] 
2025-04-01 03:06:23.488370: Epoch time: 274.02 s 
2025-04-01 03:06:25.456148:  
2025-04-01 03:06:25.456359: Epoch 482 
2025-04-01 03:06:25.456483: Current learning rate: 0.00553 
2025-04-01 03:10:59.534781: train_loss -0.7466 
2025-04-01 03:10:59.535163: val_loss -0.5258 
2025-04-01 03:10:59.535259: Pseudo dice [0.5625] 
2025-04-01 03:10:59.535361: Epoch time: 274.08 s 
2025-04-01 03:11:01.485505:  
2025-04-01 03:11:01.485696: Epoch 483 
2025-04-01 03:11:01.485813: Current learning rate: 0.00552 
2025-04-01 03:15:35.605237: train_loss -0.7334 
2025-04-01 03:15:35.605583: val_loss -0.5191 
2025-04-01 03:15:35.605683: Pseudo dice [0.406] 
2025-04-01 03:15:35.605804: Epoch time: 274.12 s 
2025-04-01 03:15:37.569792:  
2025-04-01 03:15:37.570038: Epoch 484 
2025-04-01 03:15:37.570166: Current learning rate: 0.00551 
2025-04-01 03:20:12.061554: train_loss -0.7594 
2025-04-01 03:20:12.061878: val_loss -0.6717 
2025-04-01 03:20:12.061968: Pseudo dice [0.6233] 
2025-04-01 03:20:12.062086: Epoch time: 274.5 s 
2025-04-01 03:20:14.081788:  
2025-04-01 03:20:14.082042: Epoch 485 
2025-04-01 03:20:14.082201: Current learning rate: 0.0055 
2025-04-01 03:24:48.289335: train_loss -0.7738 
2025-04-01 03:24:48.289862: val_loss -0.5906 
2025-04-01 03:24:48.290300: Pseudo dice [0.4635] 
2025-04-01 03:24:48.290395: Epoch time: 274.21 s 
2025-04-01 03:24:50.549198:  
2025-04-01 03:24:50.549438: Epoch 486 
2025-04-01 03:24:50.549621: Current learning rate: 0.00549 
2025-04-01 03:29:24.601971: train_loss -0.7809 
2025-04-01 03:29:24.602343: val_loss -0.5277 
2025-04-01 03:29:24.602463: Pseudo dice [0.5285] 
2025-04-01 03:29:24.602547: Epoch time: 274.06 s 
2025-04-01 03:29:26.546741:  
2025-04-01 03:29:26.546954: Epoch 487 
2025-04-01 03:29:26.547078: Current learning rate: 0.00548 
2025-04-01 03:34:00.449533: train_loss -0.7973 
2025-04-01 03:34:00.449833: val_loss -0.6536 
2025-04-01 03:34:00.449918: Pseudo dice [0.6352] 
2025-04-01 03:34:00.450001: Epoch time: 273.91 s 
2025-04-01 03:34:02.400802:  
2025-04-01 03:34:02.401023: Epoch 488 
2025-04-01 03:34:02.401139: Current learning rate: 0.00547 
2025-04-01 03:38:35.979152: train_loss -0.8103 
2025-04-01 03:38:35.979522: val_loss -0.5112 
2025-04-01 03:38:35.979726: Pseudo dice [0.4035] 
2025-04-01 03:38:35.979838: Epoch time: 273.58 s 
2025-04-01 03:38:37.948468:  
2025-04-01 03:38:37.948784: Epoch 489 
2025-04-01 03:38:37.948907: Current learning rate: 0.00546 
2025-04-01 03:43:11.909050: train_loss -0.8156 
2025-04-01 03:43:11.909621: val_loss -0.6342 
2025-04-01 03:43:11.910091: Pseudo dice [0.6868] 
2025-04-01 03:43:11.910184: Epoch time: 273.96 s 
2025-04-01 03:43:13.875909:  
2025-04-01 03:43:13.876196: Epoch 490 
2025-04-01 03:43:13.876351: Current learning rate: 0.00546 
2025-04-01 03:47:48.173301: train_loss -0.789 
2025-04-01 03:47:48.173610: val_loss -0.6003 
2025-04-01 03:47:48.173720: Pseudo dice [0.5204] 
2025-04-01 03:47:48.173859: Epoch time: 274.3 s 
2025-04-01 03:47:50.161802:  
2025-04-01 03:47:50.161992: Epoch 491 
2025-04-01 03:47:50.162147: Current learning rate: 0.00545 
2025-04-01 03:52:25.165575: train_loss -0.7701 
2025-04-01 03:52:25.165893: val_loss -0.6608 
2025-04-01 03:52:25.165982: Pseudo dice [0.4853] 
2025-04-01 03:52:25.166084: Epoch time: 275.01 s 
2025-04-01 03:52:27.120252:  
2025-04-01 03:52:27.120461: Epoch 492 
2025-04-01 03:52:27.120590: Current learning rate: 0.00544 
2025-04-01 03:57:01.950182: train_loss -0.7912 
2025-04-01 03:57:01.950482: val_loss -0.6183 
2025-04-01 03:57:01.950564: Pseudo dice [0.6174] 
2025-04-01 03:57:01.950650: Epoch time: 274.83 s 
2025-04-01 03:57:03.898570:  
2025-04-01 03:57:03.898777: Epoch 493 
2025-04-01 03:57:03.898893: Current learning rate: 0.00543 
2025-04-01 04:01:38.602522: train_loss -0.8046 
2025-04-01 04:01:38.602861: val_loss -0.6614 
2025-04-01 04:01:38.602949: Pseudo dice [0.6028] 
2025-04-01 04:01:38.603046: Epoch time: 274.71 s 
2025-04-01 04:01:40.866917:  
2025-04-01 04:01:40.867149: Epoch 494 
2025-04-01 04:01:40.867290: Current learning rate: 0.00542 
2025-04-01 04:06:15.268543: train_loss -0.802 
2025-04-01 04:06:15.268856: val_loss -0.5478 
2025-04-01 04:06:15.268956: Pseudo dice [0.4379] 
2025-04-01 04:06:15.269071: Epoch time: 274.41 s 
2025-04-01 04:06:17.230612:  
2025-04-01 04:06:17.230817: Epoch 495 
2025-04-01 04:06:17.230934: Current learning rate: 0.00541 
2025-04-01 04:10:51.730923: train_loss -0.8248 
2025-04-01 04:10:51.731291: val_loss -0.6883 
2025-04-01 04:10:51.731382: Pseudo dice [0.6254] 
2025-04-01 04:10:51.731478: Epoch time: 274.5 s 
2025-04-01 04:10:53.699852:  
2025-04-01 04:10:53.700073: Epoch 496 
2025-04-01 04:10:53.700188: Current learning rate: 0.0054 
2025-04-01 04:15:28.358389: train_loss -0.8087 
2025-04-01 04:15:28.358769: val_loss -0.6816 
2025-04-01 04:15:28.358880: Pseudo dice [0.6234] 
2025-04-01 04:15:28.358968: Epoch time: 274.66 s 
2025-04-01 04:15:30.313681:  
2025-04-01 04:15:30.313881: Epoch 497 
2025-04-01 04:15:30.313996: Current learning rate: 0.00539 
2025-04-01 04:20:04.972311: train_loss -0.8189 
2025-04-01 04:20:04.972670: val_loss -0.5836 
2025-04-01 04:20:04.972759: Pseudo dice [0.5458] 
2025-04-01 04:20:04.972854: Epoch time: 274.66 s 
2025-04-01 04:20:06.952578:  
2025-04-01 04:20:06.952765: Epoch 498 
2025-04-01 04:20:06.952917: Current learning rate: 0.00538 
2025-04-01 04:24:41.780397: train_loss -0.8214 
2025-04-01 04:24:41.780940: val_loss -0.6653 
2025-04-01 04:24:41.781040: Pseudo dice [0.6729] 
2025-04-01 04:24:41.781176: Epoch time: 274.83 s 
2025-04-01 04:24:43.759937:  
2025-04-01 04:24:43.760133: Epoch 499 
2025-04-01 04:24:43.760249: Current learning rate: 0.00537 
2025-04-01 04:29:18.824119: train_loss -0.8288 
2025-04-01 04:29:18.824426: val_loss -0.6635 
2025-04-01 04:29:18.824511: Pseudo dice [0.6814] 
2025-04-01 04:29:18.824602: Epoch time: 275.07 s 
2025-04-01 04:29:22.024810:  
2025-04-01 04:29:22.025005: Epoch 500 
2025-04-01 04:29:22.025119: Current learning rate: 0.00536 
2025-04-01 04:33:56.786610: train_loss -0.8368 
2025-04-01 04:33:56.786951: val_loss -0.6511 
2025-04-01 04:33:56.787082: Pseudo dice [0.6802] 
2025-04-01 04:33:56.787189: Epoch time: 274.77 s 
2025-04-01 04:33:58.737325:  
2025-04-01 04:33:58.737492: Epoch 501 
2025-04-01 04:33:58.737636: Current learning rate: 0.00535 
2025-04-01 04:38:34.220291: train_loss -0.8306 
2025-04-01 04:38:34.220614: val_loss -0.6298 
2025-04-01 04:38:34.220702: Pseudo dice [0.6542] 
2025-04-01 04:38:34.220806: Epoch time: 275.49 s 
2025-04-01 04:38:36.488775:  
2025-04-01 04:38:36.488999: Epoch 502 
2025-04-01 04:38:36.489126: Current learning rate: 0.00534 
2025-04-01 04:43:39.801200: train_loss -0.8232 
2025-04-01 04:43:39.801883: val_loss -0.6594 
2025-04-01 04:43:39.801962: Pseudo dice [0.7201] 
2025-04-01 04:43:39.802040: Epoch time: 303.32 s 
2025-04-01 04:43:41.931764:  
2025-04-01 04:43:41.931999: Epoch 503 
2025-04-01 04:43:41.932126: Current learning rate: 0.00533 
2025-04-01 04:48:33.335263: train_loss -0.8137 
2025-04-01 04:48:33.335885: val_loss -0.6438 
2025-04-01 04:48:33.336007: Pseudo dice [0.6477] 
2025-04-01 04:48:33.336099: Epoch time: 291.41 s 
2025-04-01 04:48:35.461841:  
2025-04-01 04:48:35.462096: Epoch 504 
2025-04-01 04:48:35.462268: Current learning rate: 0.00532 
2025-04-01 04:53:26.503584: train_loss -0.7981 
2025-04-01 04:53:26.504155: val_loss -0.5469 
2025-04-01 04:53:26.504245: Pseudo dice [0.401] 
2025-04-01 04:53:26.504363: Epoch time: 291.05 s 
2025-04-01 04:53:28.599142:  
2025-04-01 04:53:28.599388: Epoch 505 
2025-04-01 04:53:28.599507: Current learning rate: 0.00531 
2025-04-01 04:58:18.153728: train_loss -0.822 
2025-04-01 04:58:18.154376: val_loss -0.579 
2025-04-01 04:58:18.154486: Pseudo dice [0.5315] 
2025-04-01 04:58:18.154575: Epoch time: 289.56 s 
2025-04-01 04:58:20.279548:  
2025-04-01 04:58:20.279772: Epoch 506 
2025-04-01 04:58:20.279963: Current learning rate: 0.0053 
2025-04-01 05:03:08.464664: train_loss -0.7998 
2025-04-01 05:03:08.465015: val_loss -0.6186 
2025-04-01 05:03:08.465105: Pseudo dice [0.4696] 
2025-04-01 05:03:08.465205: Epoch time: 288.19 s 
2025-04-01 05:03:10.569872:  
2025-04-01 05:03:10.570118: Epoch 507 
2025-04-01 05:03:10.570253: Current learning rate: 0.00529 
2025-04-01 05:07:58.482101: train_loss -0.8042 
2025-04-01 05:07:58.505528: val_loss -0.6482 
2025-04-01 05:07:58.505677: Pseudo dice [0.6994] 
2025-04-01 05:07:58.505775: Epoch time: 287.92 s 
2025-04-01 05:08:00.609935:  
2025-04-01 05:08:00.610179: Epoch 508 
2025-04-01 05:08:00.610303: Current learning rate: 0.00528 
2025-04-01 05:12:51.917529: train_loss -0.8206 
2025-04-01 05:12:51.918520: val_loss -0.6864 
2025-04-01 05:12:51.918696: Pseudo dice [0.7685] 
2025-04-01 05:12:51.918830: Epoch time: 291.31 s 
2025-04-01 05:12:54.032363:  
2025-04-01 05:12:54.032725: Epoch 509 
2025-04-01 05:12:54.032914: Current learning rate: 0.00527 
2025-04-01 05:17:41.849590: train_loss -0.8253 
2025-04-01 05:17:41.850151: val_loss -0.5747 
2025-04-01 05:17:41.850260: Pseudo dice [0.407] 
2025-04-01 05:17:41.850394: Epoch time: 287.82 s 
2025-04-01 05:17:44.324815:  
2025-04-01 05:17:44.325053: Epoch 510 
2025-04-01 05:17:44.325187: Current learning rate: 0.00526 
2025-04-01 05:22:32.027104: train_loss -0.8228 
2025-04-01 05:22:32.027745: val_loss -0.6511 
2025-04-01 05:22:32.027905: Pseudo dice [0.6712] 
2025-04-01 05:22:32.027992: Epoch time: 287.71 s 
2025-04-01 05:22:34.056682:  
2025-04-01 05:22:34.056923: Epoch 511 
2025-04-01 05:22:34.057041: Current learning rate: 0.00525 
2025-04-01 05:27:24.988319: train_loss -0.8253 
2025-04-01 05:27:24.988822: val_loss -0.5651 
2025-04-01 05:27:24.988938: Pseudo dice [0.5648] 
2025-04-01 05:27:24.989038: Epoch time: 290.94 s 
2025-04-01 05:27:27.056584:  
2025-04-01 05:27:27.056832: Epoch 512 
2025-04-01 05:27:27.056959: Current learning rate: 0.00524 
2025-04-01 05:32:14.495890: train_loss -0.8343 
2025-04-01 05:32:14.496467: val_loss -0.6797 
2025-04-01 05:32:14.496562: Pseudo dice [0.7256] 
2025-04-01 05:32:14.496653: Epoch time: 287.44 s 
2025-04-01 05:32:16.589293:  
2025-04-01 05:32:16.589536: Epoch 513 
2025-04-01 05:32:16.589663: Current learning rate: 0.00523 
2025-04-01 05:37:04.653089: train_loss -0.8205 
2025-04-01 05:37:04.653669: val_loss -0.6189 
2025-04-01 05:37:04.653773: Pseudo dice [0.6073] 
2025-04-01 05:37:04.653861: Epoch time: 288.07 s 
2025-04-01 05:37:06.721044:  
2025-04-01 05:37:06.721279: Epoch 514 
2025-04-01 05:37:06.721398: Current learning rate: 0.00522 
2025-04-01 05:41:59.899102: train_loss -0.8227 
2025-04-01 05:41:59.899482: val_loss -0.6664 
2025-04-01 05:41:59.899578: Pseudo dice [0.698] 
2025-04-01 05:41:59.899688: Epoch time: 293.18 s 
2025-04-01 05:42:01.920254:  
2025-04-01 05:42:01.920490: Epoch 515 
2025-04-01 05:42:01.920608: Current learning rate: 0.00521 
2025-04-01 05:46:55.337085: train_loss -0.8419 
2025-04-01 05:46:55.340430: val_loss -0.6762 
2025-04-01 05:46:55.340559: Pseudo dice [0.7465] 
2025-04-01 05:46:55.340654: Epoch time: 293.42 s 
2025-04-01 05:46:55.340722: Yayy! New best EMA pseudo Dice: 0.6266 
2025-04-01 05:46:58.748577:  
2025-04-01 05:46:58.748811: Epoch 516 
2025-04-01 05:46:58.748930: Current learning rate: 0.0052 
2025-04-01 05:51:46.991089: train_loss -0.8214 
2025-04-01 05:51:46.991656: val_loss -0.5891 
2025-04-01 05:51:46.991784: Pseudo dice [0.5954] 
2025-04-01 05:51:46.991874: Epoch time: 288.25 s 
2025-04-01 05:51:49.053326:  
2025-04-01 05:51:49.053569: Epoch 517 
2025-04-01 05:51:49.053702: Current learning rate: 0.00519 
2025-04-01 05:56:37.574424: train_loss -0.8327 
2025-04-01 05:56:37.574927: val_loss -0.5495 
2025-04-01 05:56:37.575015: Pseudo dice [0.4921] 
2025-04-01 05:56:37.575104: Epoch time: 288.53 s 
2025-04-01 05:56:39.931573:  
2025-04-01 05:56:39.931827: Epoch 518 
2025-04-01 05:56:39.931948: Current learning rate: 0.00518 
2025-04-01 06:01:29.062429: train_loss -0.8032 
2025-04-01 06:01:29.062790: val_loss -0.5192 
2025-04-01 06:01:29.062881: Pseudo dice [0.3435] 
2025-04-01 06:01:29.062980: Epoch time: 289.14 s 
2025-04-01 06:01:31.090517:  
2025-04-01 06:01:31.090732: Epoch 519 
2025-04-01 06:01:31.090850: Current learning rate: 0.00518 
2025-04-01 06:06:22.534063: train_loss -0.8272 
2025-04-01 06:06:22.534612: val_loss -0.6329 
2025-04-01 06:06:22.534713: Pseudo dice [0.5752] 
2025-04-01 06:06:22.534802: Epoch time: 291.45 s 
2025-04-01 06:06:24.551727:  
2025-04-01 06:06:24.551989: Epoch 520 
2025-04-01 06:06:24.552115: Current learning rate: 0.00517 
2025-04-01 06:11:17.155070: train_loss -0.8282 
2025-04-01 06:11:17.155641: val_loss -0.6084 
2025-04-01 06:11:17.155769: Pseudo dice [0.3453] 
2025-04-01 06:11:17.155868: Epoch time: 292.61 s 
2025-04-01 06:11:19.312895:  
2025-04-01 06:11:19.313152: Epoch 521 
2025-04-01 06:11:19.313272: Current learning rate: 0.00516 
2025-04-01 06:16:09.296018: train_loss -0.8086 
2025-04-01 06:16:09.296571: val_loss -0.585 
2025-04-01 06:16:09.296674: Pseudo dice [0.5271] 
2025-04-01 06:16:09.296762: Epoch time: 289.99 s 
2025-04-01 06:16:11.318774:  
2025-04-01 06:16:11.319056: Epoch 522 
2025-04-01 06:16:11.319173: Current learning rate: 0.00515 
2025-04-01 06:21:00.203795: train_loss -0.8212 
2025-04-01 06:21:00.204177: val_loss -0.617 
2025-04-01 06:21:00.205075: Pseudo dice [0.5533] 
2025-04-01 06:21:00.205212: Epoch time: 288.89 s 
2025-04-01 06:21:02.237484:  
2025-04-01 06:21:02.237695: Epoch 523 
2025-04-01 06:21:02.237850: Current learning rate: 0.00514 
2025-04-01 06:25:52.434779: train_loss -0.829 
2025-04-01 06:25:52.435377: val_loss -0.6388 
2025-04-01 06:25:52.435499: Pseudo dice [0.5348] 
2025-04-01 06:25:52.435591: Epoch time: 290.2 s 
2025-04-01 06:25:54.493630:  
2025-04-01 06:25:54.493840: Epoch 524 
2025-04-01 06:25:54.493973: Current learning rate: 0.00513 
2025-04-01 06:30:45.214697: train_loss -0.7828 
2025-04-01 06:30:45.215260: val_loss -0.5067 
2025-04-01 06:30:45.215365: Pseudo dice [0.4787] 
2025-04-01 06:30:45.215457: Epoch time: 290.73 s 
2025-04-01 06:30:47.272220:  
2025-04-01 06:30:47.272522: Epoch 525 
2025-04-01 06:30:47.272653: Current learning rate: 0.00512 
2025-04-01 06:35:42.116151: train_loss -0.8052 
2025-04-01 06:35:42.116676: val_loss -0.5882 
2025-04-01 06:35:42.116761: Pseudo dice [0.5296] 
2025-04-01 06:35:42.116844: Epoch time: 294.85 s 
2025-04-01 06:35:44.501061:  
2025-04-01 06:35:44.501374: Epoch 526 
2025-04-01 06:35:44.501516: Current learning rate: 0.00511 
2025-04-01 06:40:25.928598: train_loss -0.7901 
2025-04-01 06:40:25.929166: val_loss -0.4945 
2025-04-01 06:40:25.929282: Pseudo dice [0.3296] 
2025-04-01 06:40:25.929371: Epoch time: 281.43 s 
2025-04-01 06:40:27.905258:  
2025-04-01 06:40:27.905478: Epoch 527 
2025-04-01 06:40:27.905614: Current learning rate: 0.0051 
2025-04-01 06:45:01.694897: train_loss -0.8016 
2025-04-01 06:45:01.695235: val_loss -0.6229 
2025-04-01 06:45:01.695357: Pseudo dice [0.5428] 
2025-04-01 06:45:01.695455: Epoch time: 273.79 s 
2025-04-01 06:45:03.650134:  
2025-04-01 06:45:03.650396: Epoch 528 
2025-04-01 06:45:03.650553: Current learning rate: 0.00509 
2025-04-01 06:49:38.097646: train_loss -0.8084 
2025-04-01 06:49:38.098068: val_loss -0.6492 
2025-04-01 06:49:38.098153: Pseudo dice [0.4975] 
2025-04-01 06:49:38.098243: Epoch time: 274.45 s 
2025-04-01 06:49:40.197293:  
2025-04-01 06:49:40.197546: Epoch 529 
2025-04-01 06:49:40.197709: Current learning rate: 0.00508 
2025-04-01 06:54:28.187347: train_loss -0.8147 
2025-04-01 06:54:28.206013: val_loss -0.5912 
2025-04-01 06:54:28.206129: Pseudo dice [0.5399] 
2025-04-01 06:54:28.206277: Epoch time: 287.99 s 
2025-04-01 06:54:30.290826:  
2025-04-01 06:54:30.291086: Epoch 530 
2025-04-01 06:54:30.291224: Current learning rate: 0.00507 
2025-04-01 06:59:17.665066: train_loss -0.8068 
2025-04-01 06:59:17.665438: val_loss -0.64 
2025-04-01 06:59:17.665932: Pseudo dice [0.5776] 
2025-04-01 06:59:17.666018: Epoch time: 287.38 s 
2025-04-01 06:59:19.716824:  
2025-04-01 06:59:19.717073: Epoch 531 
2025-04-01 06:59:19.717198: Current learning rate: 0.00506 
2025-04-01 07:04:32.315044: train_loss -0.825 
2025-04-01 07:04:32.315622: val_loss -0.4829 
2025-04-01 07:04:32.315730: Pseudo dice [0.3467] 
2025-04-01 07:04:32.315911: Epoch time: 312.6 s 
2025-04-01 07:04:34.446357:  
2025-04-01 07:04:34.446610: Epoch 532 
2025-04-01 07:04:34.446740: Current learning rate: 0.00505 
2025-04-01 07:09:30.405660: train_loss -0.8075 
2025-04-01 07:09:30.406271: val_loss -0.5566 
2025-04-01 07:09:30.406443: Pseudo dice [0.5496] 
2025-04-01 07:09:30.406542: Epoch time: 295.96 s 
2025-04-01 07:09:32.528438:  
2025-04-01 07:09:32.528722: Epoch 533 
2025-04-01 07:09:32.528852: Current learning rate: 0.00504 
2025-04-01 07:14:26.975252: train_loss -0.8192 
2025-04-01 07:14:26.975829: val_loss -0.5553 
2025-04-01 07:14:26.975970: Pseudo dice [0.4107] 
2025-04-01 07:14:26.976068: Epoch time: 294.45 s 
2025-04-01 07:14:29.363043:  
2025-04-01 07:14:29.363248: Epoch 534 
2025-04-01 07:14:29.363397: Current learning rate: 0.00503 
2025-04-01 07:19:17.826462: train_loss -0.8243 
2025-04-01 07:19:17.826987: val_loss -0.7216 
2025-04-01 07:19:17.827084: Pseudo dice [0.7452] 
2025-04-01 07:19:17.827170: Epoch time: 288.47 s 
2025-04-01 07:19:19.897002:  
2025-04-01 07:19:19.897368: Epoch 535 
2025-04-01 07:19:19.897499: Current learning rate: 0.00502 
2025-04-01 07:24:09.292754: train_loss -0.837 
2025-04-01 07:24:09.293098: val_loss -0.5821 
2025-04-01 07:24:09.293194: Pseudo dice [0.5422] 
2025-04-01 07:24:09.293297: Epoch time: 289.4 s 
2025-04-01 07:24:11.422164:  
2025-04-01 07:24:11.422421: Epoch 536 
2025-04-01 07:24:11.422549: Current learning rate: 0.00501 
2025-04-01 07:29:00.074661: train_loss -0.8259 
2025-04-01 07:29:00.082753: val_loss -0.6375 
2025-04-01 07:29:00.082881: Pseudo dice [0.6448] 
2025-04-01 07:29:00.082982: Epoch time: 288.66 s 
2025-04-01 07:29:02.379700:  
2025-04-01 07:29:02.380086: Epoch 537 
2025-04-01 07:29:02.380324: Current learning rate: 0.005 
2025-04-01 07:34:02.288335: train_loss -0.8019 
2025-04-01 07:34:02.289312: val_loss -0.6235 
2025-04-01 07:34:02.289477: Pseudo dice [0.6928] 
2025-04-01 07:34:02.289590: Epoch time: 299.91 s 
2025-04-01 07:34:04.922033:  
2025-04-01 07:34:04.922376: Epoch 538 
2025-04-01 07:34:04.922518: Current learning rate: 0.00499 
2025-04-01 07:38:54.103365: train_loss -0.8084 
2025-04-01 07:38:54.103957: val_loss -0.6651 
2025-04-01 07:38:54.104132: Pseudo dice [0.744] 
2025-04-01 07:38:54.104227: Epoch time: 289.19 s 
2025-04-01 07:38:56.378971:  
2025-04-01 07:38:56.379225: Epoch 539 
2025-04-01 07:38:56.379353: Current learning rate: 0.00498 
2025-04-01 07:43:53.833184: train_loss -0.7703 
2025-04-01 07:43:53.833752: val_loss -0.5239 
2025-04-01 07:43:53.833898: Pseudo dice [0.483] 
2025-04-01 07:43:53.834037: Epoch time: 297.46 s 
2025-04-01 07:43:56.124517:  
2025-04-01 07:43:56.124825: Epoch 540 
2025-04-01 07:43:56.125004: Current learning rate: 0.00497 
2025-04-01 07:48:37.285088: train_loss -0.7935 
2025-04-01 07:48:37.330680: val_loss -0.6697 
2025-04-01 07:48:37.330840: Pseudo dice [0.623] 
2025-04-01 07:48:37.330949: Epoch time: 281.16 s 
2025-04-01 07:48:40.060395:  
2025-04-01 07:48:40.060617: Epoch 541 
2025-04-01 07:48:40.060739: Current learning rate: 0.00496 
2025-04-01 07:54:19.012572: train_loss -0.7805 
2025-04-01 07:54:19.013524: val_loss -0.6554 
2025-04-01 07:54:19.013727: Pseudo dice [0.6278] 
2025-04-01 07:54:19.013850: Epoch time: 338.96 s 
2025-04-01 07:54:22.182799:  
2025-04-01 07:54:22.183139: Epoch 542 
2025-04-01 07:54:22.183373: Current learning rate: 0.00495 
2025-04-01 07:59:09.623573: train_loss -0.7753 
2025-04-01 07:59:09.627100: val_loss -0.5769 
2025-04-01 07:59:09.627288: Pseudo dice [0.5859] 
2025-04-01 07:59:09.627420: Epoch time: 287.45 s 
2025-04-01 07:59:12.655855:  
2025-04-01 07:59:12.656362: Epoch 543 
2025-04-01 07:59:12.656760: Current learning rate: 0.00494 
2025-04-01 08:03:56.968908: train_loss -0.7957 
2025-04-01 08:03:56.969540: val_loss -0.4997 
2025-04-01 08:03:56.969627: Pseudo dice [0.6097] 
2025-04-01 08:03:56.969716: Epoch time: 284.32 s 
2025-04-01 08:03:59.794986:  
2025-04-01 08:03:59.795313: Epoch 544 
2025-04-01 08:03:59.795565: Current learning rate: 0.00493 
2025-04-01 08:08:33.045130: train_loss -0.7995 
2025-04-01 08:08:33.045690: val_loss -0.6297 
2025-04-01 08:08:33.045774: Pseudo dice [0.6576] 
2025-04-01 08:08:33.045856: Epoch time: 273.26 s 
2025-04-01 08:08:35.027605:  
2025-04-01 08:08:35.027831: Epoch 545 
2025-04-01 08:08:35.027950: Current learning rate: 0.00492 
2025-04-01 08:13:08.283796: train_loss -0.7896 
2025-04-01 08:13:08.284104: val_loss -0.6243 
2025-04-01 08:13:08.284188: Pseudo dice [0.5441] 
2025-04-01 08:13:08.284287: Epoch time: 273.26 s 
2025-04-01 08:13:10.250958:  
2025-04-01 08:13:10.251231: Epoch 546 
2025-04-01 08:13:10.251374: Current learning rate: 0.00491 
2025-04-01 08:17:43.468480: train_loss -0.812 
2025-04-01 08:17:43.468796: val_loss -0.6337 
2025-04-01 08:17:43.468924: Pseudo dice [0.637] 
2025-04-01 08:17:43.469051: Epoch time: 273.22 s 
2025-04-01 08:17:45.438222:  
2025-04-01 08:17:45.438555: Epoch 547 
2025-04-01 08:17:45.438674: Current learning rate: 0.0049 
2025-04-01 08:22:19.513237: train_loss -0.8113 
2025-04-01 08:22:19.513558: val_loss -0.6079 
2025-04-01 08:22:19.513639: Pseudo dice [0.5889] 
2025-04-01 08:22:19.513741: Epoch time: 274.08 s 
2025-04-01 08:22:21.509887:  
2025-04-01 08:22:21.510235: Epoch 548 
2025-04-01 08:22:21.510406: Current learning rate: 0.00489 
2025-04-01 08:26:55.016188: train_loss -0.8264 
2025-04-01 08:26:55.016598: val_loss -0.5812 
2025-04-01 08:26:55.016746: Pseudo dice [0.5203] 
2025-04-01 08:26:55.016828: Epoch time: 273.51 s 
2025-04-01 08:26:56.988251:  
2025-04-01 08:26:56.988527: Epoch 549 
2025-04-01 08:26:56.988662: Current learning rate: 0.00488 
2025-04-01 08:31:29.868903: train_loss -0.8125 
2025-04-01 08:31:29.869321: val_loss -0.6031 
2025-04-01 08:31:29.869474: Pseudo dice [0.5357] 
2025-04-01 08:31:29.869557: Epoch time: 272.88 s 
2025-04-01 08:31:33.141762:  
2025-04-01 08:31:33.141984: Epoch 550 
2025-04-01 08:31:33.142104: Current learning rate: 0.00487 
2025-04-01 08:36:06.253259: train_loss -0.8099 
2025-04-01 08:36:06.253594: val_loss -0.6252 
2025-04-01 08:36:06.253774: Pseudo dice [0.6127] 
2025-04-01 08:36:06.253861: Epoch time: 273.12 s 
2025-04-01 08:36:08.531017:  
2025-04-01 08:36:08.531239: Epoch 551 
2025-04-01 08:36:08.531367: Current learning rate: 0.00486 
2025-04-01 08:40:40.925048: train_loss -0.8314 
2025-04-01 08:40:40.925413: val_loss -0.6892 
2025-04-01 08:40:40.925502: Pseudo dice [0.6527] 
2025-04-01 08:40:40.925599: Epoch time: 272.4 s 
2025-04-01 08:40:42.903483:  
2025-04-01 08:40:42.903712: Epoch 552 
2025-04-01 08:40:42.903842: Current learning rate: 0.00485 
2025-04-01 08:45:15.436697: train_loss -0.8338 
2025-04-01 08:45:15.437009: val_loss -0.6651 
2025-04-01 08:45:15.437092: Pseudo dice [0.6705] 
2025-04-01 08:45:15.437192: Epoch time: 272.54 s 
2025-04-01 08:45:17.404707:  
2025-04-01 08:45:17.404939: Epoch 553 
2025-04-01 08:45:17.405071: Current learning rate: 0.00484 
2025-04-01 08:49:51.405285: train_loss -0.8385 
2025-04-01 08:49:51.405635: val_loss -0.5621 
2025-04-01 08:49:51.405743: Pseudo dice [0.3613] 
2025-04-01 08:49:51.405836: Epoch time: 274.0 s 
2025-04-01 08:49:53.373024:  
2025-04-01 08:49:53.373234: Epoch 554 
2025-04-01 08:49:53.373360: Current learning rate: 0.00484 
2025-04-01 08:54:26.626656: train_loss -0.8041 
2025-04-01 08:54:26.626997: val_loss -0.6335 
2025-04-01 08:54:26.627081: Pseudo dice [0.546] 
2025-04-01 08:54:26.627177: Epoch time: 273.26 s 
2025-04-01 08:54:28.608750:  
2025-04-01 08:54:28.608974: Epoch 555 
2025-04-01 08:54:28.609096: Current learning rate: 0.00483 
2025-04-01 08:59:01.809099: train_loss -0.8265 
2025-04-01 08:59:01.809486: val_loss -0.6982 
2025-04-01 08:59:01.809570: Pseudo dice [0.6501] 
2025-04-01 08:59:01.809661: Epoch time: 273.2 s 
2025-04-01 08:59:03.816659:  
2025-04-01 08:59:03.816881: Epoch 556 
2025-04-01 08:59:03.817015: Current learning rate: 0.00482 
2025-04-01 09:03:37.341482: train_loss -0.8141 
2025-04-01 09:03:37.341800: val_loss -0.5871 
2025-04-01 09:03:37.341897: Pseudo dice [0.5647] 
2025-04-01 09:03:37.341998: Epoch time: 273.53 s 
2025-04-01 09:03:39.345770:  
2025-04-01 09:03:39.346015: Epoch 557 
2025-04-01 09:03:39.346151: Current learning rate: 0.00481 
2025-04-01 09:08:13.285093: train_loss -0.8214 
2025-04-01 09:08:13.285392: val_loss -0.555 
2025-04-01 09:08:13.285475: Pseudo dice [0.5788] 
2025-04-01 09:08:13.285624: Epoch time: 273.94 s 
2025-04-01 09:08:15.279781:  
2025-04-01 09:08:15.279992: Epoch 558 
2025-04-01 09:08:15.280104: Current learning rate: 0.0048 
2025-04-01 09:12:49.357348: train_loss -0.8111 
2025-04-01 09:12:49.357687: val_loss -0.5657 
2025-04-01 09:12:49.357770: Pseudo dice [0.5841] 
2025-04-01 09:12:49.357867: Epoch time: 274.08 s 
2025-04-01 09:12:51.647606:  
2025-04-01 09:12:51.647853: Epoch 559 
2025-04-01 09:12:51.648040: Current learning rate: 0.00479 
2025-04-01 09:17:26.178817: train_loss -0.8129 
2025-04-01 09:17:26.179160: val_loss -0.6658 
2025-04-01 09:17:26.179243: Pseudo dice [0.7051] 
2025-04-01 09:17:26.179342: Epoch time: 274.54 s 
2025-04-01 09:17:28.153915:  
2025-04-01 09:17:28.154257: Epoch 560 
2025-04-01 09:17:28.154414: Current learning rate: 0.00478 
2025-04-01 09:22:02.678798: train_loss -0.7959 
2025-04-01 09:22:02.679115: val_loss -0.5387 
2025-04-01 09:22:02.679208: Pseudo dice [0.4185] 
2025-04-01 09:22:02.679360: Epoch time: 274.53 s 
2025-04-01 09:22:04.683241:  
2025-04-01 09:22:04.683533: Epoch 561 
2025-04-01 09:22:04.683657: Current learning rate: 0.00477 
2025-04-01 09:26:38.796919: train_loss -0.8122 
2025-04-01 09:26:38.797313: val_loss -0.616 
2025-04-01 09:26:38.797408: Pseudo dice [0.5782] 
2025-04-01 09:26:38.797502: Epoch time: 274.12 s 
2025-04-01 09:26:40.779960:  
2025-04-01 09:26:40.780164: Epoch 562 
2025-04-01 09:26:40.780280: Current learning rate: 0.00476 
2025-04-01 09:31:14.995724: train_loss -0.8203 
2025-04-01 09:31:14.996118: val_loss -0.6992 
2025-04-01 09:31:14.996246: Pseudo dice [0.6906] 
2025-04-01 09:31:14.996334: Epoch time: 274.22 s 
2025-04-01 09:31:16.977174:  
2025-04-01 09:31:16.977376: Epoch 563 
2025-04-01 09:31:16.977492: Current learning rate: 0.00475 
2025-04-01 09:35:50.878168: train_loss -0.8245 
2025-04-01 09:35:50.878612: val_loss -0.6622 
2025-04-01 09:35:50.878705: Pseudo dice [0.5427] 
2025-04-01 09:35:50.878784: Epoch time: 273.9 s 
2025-04-01 09:35:52.867234:  
2025-04-01 09:35:52.867503: Epoch 564 
2025-04-01 09:35:52.867658: Current learning rate: 0.00474 
2025-04-01 09:40:27.140343: train_loss -0.8274 
2025-04-01 09:40:27.140687: val_loss -0.5837 
2025-04-01 09:40:27.140774: Pseudo dice [0.5277] 
2025-04-01 09:40:27.140872: Epoch time: 274.28 s 
2025-04-01 09:40:29.125646:  
2025-04-01 09:40:29.125922: Epoch 565 
2025-04-01 09:40:29.126112: Current learning rate: 0.00473 
2025-04-01 09:45:03.608014: train_loss -0.8224 
2025-04-01 09:45:03.608367: val_loss -0.6445 
2025-04-01 09:45:03.608455: Pseudo dice [0.4644] 
2025-04-01 09:45:03.608555: Epoch time: 274.49 s 
2025-04-01 09:45:05.600328:  
2025-04-01 09:45:05.600627: Epoch 566 
2025-04-01 09:45:05.600745: Current learning rate: 0.00472 
2025-04-01 09:49:39.694154: train_loss -0.835 
2025-04-01 09:49:39.694458: val_loss -0.5651 
2025-04-01 09:49:39.694541: Pseudo dice [0.6083] 
2025-04-01 09:49:39.694625: Epoch time: 274.1 s 
2025-04-01 09:49:41.985177:  
2025-04-01 09:49:41.985397: Epoch 567 
2025-04-01 09:49:41.985528: Current learning rate: 0.00471 
2025-04-01 09:54:16.097840: train_loss -0.8221 
2025-04-01 09:54:16.098247: val_loss -0.5678 
2025-04-01 09:54:16.098358: Pseudo dice [0.4069] 
2025-04-01 09:54:16.098447: Epoch time: 274.12 s 
2025-04-01 09:54:18.081083:  
2025-04-01 09:54:18.081311: Epoch 568 
2025-04-01 09:54:18.081425: Current learning rate: 0.0047 
2025-04-01 09:58:52.427785: train_loss -0.8382 
2025-04-01 09:58:52.428106: val_loss -0.5889 
2025-04-01 09:58:52.428198: Pseudo dice [0.5219] 
2025-04-01 09:58:52.428302: Epoch time: 274.35 s 
2025-04-01 09:58:54.411947:  
2025-04-01 09:58:54.412148: Epoch 569 
2025-04-01 09:58:54.412271: Current learning rate: 0.00469 
2025-04-01 10:03:28.658391: train_loss -0.8333 
2025-04-01 10:03:28.658759: val_loss -0.5978 
2025-04-01 10:03:28.658838: Pseudo dice [0.5574] 
2025-04-01 10:03:28.658929: Epoch time: 274.25 s 
2025-04-01 10:03:30.651792:  
2025-04-01 10:03:30.652015: Epoch 570 
2025-04-01 10:03:30.652149: Current learning rate: 0.00468 
2025-04-01 10:08:04.954761: train_loss -0.8407 
2025-04-01 10:08:04.955100: val_loss -0.6023 
2025-04-01 10:08:04.955185: Pseudo dice [0.6779] 
2025-04-01 10:08:04.955288: Epoch time: 274.31 s 
2025-04-01 10:08:06.935663:  
2025-04-01 10:08:06.935891: Epoch 571 
2025-04-01 10:08:06.936022: Current learning rate: 0.00467 
2025-04-01 10:12:41.635376: train_loss -0.8227 
2025-04-01 10:12:41.635721: val_loss -0.6595 
2025-04-01 10:12:41.635818: Pseudo dice [0.6459] 
2025-04-01 10:12:41.635915: Epoch time: 274.7 s 
2025-04-01 10:12:43.613091:  
2025-04-01 10:12:43.613308: Epoch 572 
2025-04-01 10:12:43.613468: Current learning rate: 0.00466 
2025-04-01 10:17:18.229810: train_loss -0.8202 
2025-04-01 10:17:18.230149: val_loss -0.6468 
2025-04-01 10:17:18.230234: Pseudo dice [0.5143] 
2025-04-01 10:17:18.230352: Epoch time: 274.62 s 
2025-04-01 10:17:20.237602:  
2025-04-01 10:17:20.237885: Epoch 573 
2025-04-01 10:17:20.238018: Current learning rate: 0.00465 
2025-04-01 10:21:55.256823: train_loss -0.8284 
2025-04-01 10:21:55.257201: val_loss -0.6164 
2025-04-01 10:21:55.257288: Pseudo dice [0.6024] 
2025-04-01 10:21:55.257392: Epoch time: 275.02 s 
2025-04-01 10:21:57.254640:  
2025-04-01 10:21:57.254900: Epoch 574 
2025-04-01 10:21:57.255033: Current learning rate: 0.00464 
2025-04-01 10:26:31.850934: train_loss -0.8333 
2025-04-01 10:26:31.851293: val_loss -0.5564 
2025-04-01 10:26:31.851434: Pseudo dice [0.6347] 
2025-04-01 10:26:31.851526: Epoch time: 274.6 s 
2025-04-01 10:26:34.166342:  
2025-04-01 10:26:34.166597: Epoch 575 
2025-04-01 10:26:34.166772: Current learning rate: 0.00463 
2025-04-01 10:31:41.495370: train_loss -0.8342 
2025-04-01 10:31:41.495687: val_loss -0.6463 
2025-04-01 10:31:41.495788: Pseudo dice [0.6635] 
2025-04-01 10:31:41.495896: Epoch time: 307.33 s 
2025-04-01 10:31:43.500206:  
2025-04-01 10:31:43.500414: Epoch 576 
2025-04-01 10:31:43.500562: Current learning rate: 0.00462 
2025-04-01 10:36:35.372699: train_loss -0.8195 
2025-04-01 10:36:35.373008: val_loss -0.5701 
2025-04-01 10:36:35.373126: Pseudo dice [0.4839] 
2025-04-01 10:36:35.373229: Epoch time: 291.88 s 
2025-04-01 10:36:37.381769:  
2025-04-01 10:36:37.381982: Epoch 577 
2025-04-01 10:36:37.382109: Current learning rate: 0.00461 
2025-04-01 10:41:12.713053: train_loss -0.8309 
2025-04-01 10:41:12.713421: val_loss -0.6319 
2025-04-01 10:41:12.713536: Pseudo dice [0.5531] 
2025-04-01 10:41:12.713630: Epoch time: 275.34 s 
2025-04-01 10:41:14.773278:  
2025-04-01 10:41:14.773459: Epoch 578 
2025-04-01 10:41:14.773595: Current learning rate: 0.0046 
2025-04-01 10:45:50.015480: train_loss -0.8144 
2025-04-01 10:45:50.015824: val_loss -0.5585 
2025-04-01 10:45:50.015911: Pseudo dice [0.5982] 
2025-04-01 10:45:50.016009: Epoch time: 275.25 s 
2025-04-01 10:45:52.068835:  
2025-04-01 10:45:52.069093: Epoch 579 
2025-04-01 10:45:52.069239: Current learning rate: 0.00459 
2025-04-01 10:50:27.916327: train_loss -0.8222 
2025-04-01 10:50:27.916664: val_loss -0.6405 
2025-04-01 10:50:27.916756: Pseudo dice [0.5911] 
2025-04-01 10:50:27.916859: Epoch time: 275.85 s 
2025-04-01 10:50:29.928431:  
2025-04-01 10:50:29.928644: Epoch 580 
2025-04-01 10:50:29.928761: Current learning rate: 0.00458 
2025-04-01 10:55:06.684432: train_loss -0.8183 
2025-04-01 10:55:06.684765: val_loss -0.6526 
2025-04-01 10:55:06.684899: Pseudo dice [0.5258] 
2025-04-01 10:55:06.685007: Epoch time: 276.76 s 
2025-04-01 10:55:08.744702:  
2025-04-01 10:55:08.744872: Epoch 581 
2025-04-01 10:55:08.744984: Current learning rate: 0.00457 
2025-04-01 10:59:45.122464: train_loss -0.8162 
2025-04-01 10:59:45.122822: val_loss -0.6366 
2025-04-01 10:59:45.122974: Pseudo dice [0.6081] 
2025-04-01 10:59:45.123067: Epoch time: 276.38 s 
2025-04-01 10:59:47.216913:  
2025-04-01 10:59:47.217118: Epoch 582 
2025-04-01 10:59:47.217265: Current learning rate: 0.00456 
2025-04-01 11:04:21.694381: train_loss -0.8177 
2025-04-01 11:04:21.694722: val_loss -0.6551 
2025-04-01 11:04:21.694888: Pseudo dice [0.5859] 
2025-04-01 11:04:21.694982: Epoch time: 274.48 s 
2025-04-01 11:04:23.714182:  
2025-04-01 11:04:23.714444: Epoch 583 
2025-04-01 11:04:23.714623: Current learning rate: 0.00455 
2025-04-01 11:09:07.264974: train_loss -0.8265 
2025-04-01 11:09:07.265309: val_loss -0.6537 
2025-04-01 11:09:07.265393: Pseudo dice [0.616] 
2025-04-01 11:09:07.265488: Epoch time: 283.55 s 
2025-04-01 11:09:09.588208:  
2025-04-01 11:09:09.588501: Epoch 584 
2025-04-01 11:09:09.588634: Current learning rate: 0.00454 
2025-04-01 11:13:50.540798: train_loss -0.8246 
2025-04-01 11:13:50.541159: val_loss -0.5693 
2025-04-01 11:13:50.541256: Pseudo dice [0.4494] 
2025-04-01 11:13:50.541354: Epoch time: 280.96 s 
2025-04-01 11:13:52.548040:  
2025-04-01 11:13:52.548217: Epoch 585 
2025-04-01 11:13:52.548362: Current learning rate: 0.00453 
2025-04-01 11:18:42.030414: train_loss -0.8113 
2025-04-01 11:18:42.030727: val_loss -0.5182 
2025-04-01 11:18:42.030809: Pseudo dice [0.4567] 
2025-04-01 11:18:42.030901: Epoch time: 289.49 s 
2025-04-01 11:18:44.031914:  
2025-04-01 11:18:44.032130: Epoch 586 
2025-04-01 11:18:44.032248: Current learning rate: 0.00452 
2025-04-01 11:23:17.890085: train_loss -0.8087 
2025-04-01 11:23:17.890399: val_loss -0.556 
2025-04-01 11:23:17.890477: Pseudo dice [0.5821] 
2025-04-01 11:23:17.890562: Epoch time: 273.86 s 
2025-04-01 11:23:19.887640:  
2025-04-01 11:23:19.887861: Epoch 587 
2025-04-01 11:23:19.887976: Current learning rate: 0.00451 
2025-04-01 11:27:53.884254: train_loss -0.7825 
2025-04-01 11:27:53.884567: val_loss -0.5966 
2025-04-01 11:27:53.884653: Pseudo dice [0.4955] 
2025-04-01 11:27:53.884743: Epoch time: 274.0 s 
2025-04-01 11:27:55.884814:  
2025-04-01 11:27:55.885116: Epoch 588 
2025-04-01 11:27:55.885279: Current learning rate: 0.0045 
2025-04-01 11:32:29.893215: train_loss -0.7968 
2025-04-01 11:32:29.893633: val_loss -0.6252 
2025-04-01 11:32:29.893754: Pseudo dice [0.5907] 
2025-04-01 11:32:29.893844: Epoch time: 274.01 s 
2025-04-01 11:32:31.900073:  
2025-04-01 11:32:31.900428: Epoch 589 
2025-04-01 11:32:31.900572: Current learning rate: 0.00449 
2025-04-01 11:37:05.631039: train_loss -0.8288 
2025-04-01 11:37:05.631413: val_loss -0.624 
2025-04-01 11:37:05.631502: Pseudo dice [0.5105] 
2025-04-01 11:37:05.631601: Epoch time: 273.73 s 
2025-04-01 11:37:07.635067:  
2025-04-01 11:37:07.635262: Epoch 590 
2025-04-01 11:37:07.635458: Current learning rate: 0.00448 
2025-04-01 11:41:40.841904: train_loss -0.8294 
2025-04-01 11:41:40.842321: val_loss -0.7062 
2025-04-01 11:41:40.842433: Pseudo dice [0.6823] 
2025-04-01 11:41:40.842512: Epoch time: 273.21 s 
2025-04-01 11:41:42.839578:  
2025-04-01 11:41:42.839864: Epoch 591 
2025-04-01 11:41:42.839999: Current learning rate: 0.00447 
2025-04-01 11:46:16.441472: train_loss -0.8151 
2025-04-01 11:46:16.441774: val_loss -0.6715 
2025-04-01 11:46:16.441862: Pseudo dice [0.6254] 
2025-04-01 11:46:16.441950: Epoch time: 273.61 s 
2025-04-01 11:46:18.738015:  
2025-04-01 11:46:18.738209: Epoch 592 
2025-04-01 11:46:18.738334: Current learning rate: 0.00446 
2025-04-01 11:50:52.473829: train_loss -0.8161 
2025-04-01 11:50:52.474130: val_loss -0.6184 
2025-04-01 11:50:52.474215: Pseudo dice [0.5754] 
2025-04-01 11:50:52.474310: Epoch time: 273.74 s 
2025-04-01 11:50:54.478997:  
2025-04-01 11:50:54.479217: Epoch 593 
2025-04-01 11:50:54.479395: Current learning rate: 0.00445 
2025-04-01 11:55:27.661749: train_loss -0.8148 
2025-04-01 11:55:27.662112: val_loss -0.6065 
2025-04-01 11:55:27.662229: Pseudo dice [0.5408] 
2025-04-01 11:55:27.662328: Epoch time: 273.19 s 
2025-04-01 11:55:29.662668:  
2025-04-01 11:55:29.662927: Epoch 594 
2025-04-01 11:55:29.663059: Current learning rate: 0.00444 
2025-04-01 12:00:02.231464: train_loss -0.8261 
2025-04-01 12:00:02.231842: val_loss -0.6964 
2025-04-01 12:00:02.231929: Pseudo dice [0.7683] 
2025-04-01 12:00:02.232030: Epoch time: 272.57 s 
2025-04-01 12:00:04.239524:  
2025-04-01 12:00:04.239797: Epoch 595 
2025-04-01 12:00:04.239924: Current learning rate: 0.00443 
2025-04-01 12:04:36.926071: train_loss -0.8379 
2025-04-01 12:04:36.926366: val_loss -0.7396 
2025-04-01 12:04:36.926446: Pseudo dice [0.7343] 
2025-04-01 12:04:36.926531: Epoch time: 272.69 s 
2025-04-01 12:04:38.909842:  
2025-04-01 12:04:38.910046: Epoch 596 
2025-04-01 12:04:38.910163: Current learning rate: 0.00442 
2025-04-01 12:09:11.248748: train_loss -0.8306 
2025-04-01 12:09:11.249052: val_loss -0.6227 
2025-04-01 12:09:11.249133: Pseudo dice [0.5216] 
2025-04-01 12:09:11.249224: Epoch time: 272.34 s 
2025-04-01 12:09:13.256603:  
2025-04-01 12:09:13.256831: Epoch 597 
2025-04-01 12:09:13.256946: Current learning rate: 0.00441 
2025-04-01 12:13:46.010628: train_loss -0.8227 
2025-04-01 12:13:46.010919: val_loss -0.6873 
2025-04-01 12:13:46.010996: Pseudo dice [0.7086] 
2025-04-01 12:13:46.011079: Epoch time: 272.76 s 
2025-04-01 12:13:48.006099:  
2025-04-01 12:13:48.006317: Epoch 598 
2025-04-01 12:13:48.006436: Current learning rate: 0.0044 
2025-04-01 12:18:21.035402: train_loss -0.813 
2025-04-01 12:18:21.035698: val_loss -0.5983 
2025-04-01 12:18:21.035791: Pseudo dice [0.5624] 
2025-04-01 12:18:21.035913: Epoch time: 273.03 s 
2025-04-01 12:18:23.059106:  
2025-04-01 12:18:23.059358: Epoch 599 
2025-04-01 12:18:23.059530: Current learning rate: 0.00439 
2025-04-01 12:22:57.217349: train_loss -0.7908 
2025-04-01 12:22:57.217670: val_loss -0.5759 
2025-04-01 12:22:57.217759: Pseudo dice [0.5742] 
2025-04-01 12:22:57.217916: Epoch time: 274.16 s 
2025-04-01 12:23:00.923639:  
2025-04-01 12:23:00.923916: Epoch 600 
2025-04-01 12:23:00.924052: Current learning rate: 0.00438 
2025-04-01 12:27:34.282334: train_loss -0.8265 
2025-04-01 12:27:34.282654: val_loss -0.6602 
2025-04-01 12:27:34.282778: Pseudo dice [0.7006] 
2025-04-01 12:27:34.282896: Epoch time: 273.36 s 
2025-04-01 12:27:36.302932:  
2025-04-01 12:27:36.303121: Epoch 601 
2025-04-01 12:27:36.303292: Current learning rate: 0.00437 
2025-04-01 12:32:09.380356: train_loss -0.8129 
2025-04-01 12:32:09.380682: val_loss -0.6592 
2025-04-01 12:32:09.380839: Pseudo dice [0.6529] 
2025-04-01 12:32:09.380935: Epoch time: 273.08 s 
2025-04-01 12:32:11.382477:  
2025-04-01 12:32:11.382687: Epoch 602 
2025-04-01 12:32:11.382805: Current learning rate: 0.00436 
2025-04-01 12:36:44.648551: train_loss -0.8355 
2025-04-01 12:36:44.648884: val_loss -0.5237 
2025-04-01 12:36:44.648976: Pseudo dice [0.501] 
2025-04-01 12:36:44.649126: Epoch time: 273.27 s 
2025-04-01 12:36:46.727634:  
2025-04-01 12:36:46.727862: Epoch 603 
2025-04-01 12:36:46.727979: Current learning rate: 0.00435 
2025-04-01 12:41:20.696690: train_loss -0.8363 
2025-04-01 12:41:20.697105: val_loss -0.6703 
2025-04-01 12:41:20.697197: Pseudo dice [0.6865] 
2025-04-01 12:41:20.697278: Epoch time: 273.97 s 
2025-04-01 12:41:22.713059:  
2025-04-01 12:41:22.713289: Epoch 604 
2025-04-01 12:41:22.713474: Current learning rate: 0.00434 
2025-04-01 12:45:56.583860: train_loss -0.8431 
2025-04-01 12:45:56.584232: val_loss -0.6751 
2025-04-01 12:45:56.584373: Pseudo dice [0.749] 
2025-04-01 12:45:56.584458: Epoch time: 273.87 s 
2025-04-01 12:45:58.611290:  
2025-04-01 12:45:58.611559: Epoch 605 
2025-04-01 12:45:58.611676: Current learning rate: 0.00433 
2025-04-01 12:50:32.905035: train_loss -0.8308 
2025-04-01 12:50:32.905389: val_loss -0.5565 
2025-04-01 12:50:32.905468: Pseudo dice [0.5548] 
2025-04-01 12:50:32.905562: Epoch time: 274.3 s 
2025-04-01 12:50:34.922841:  
2025-04-01 12:50:34.923051: Epoch 606 
2025-04-01 12:50:34.923234: Current learning rate: 0.00432 
2025-04-01 12:55:09.250879: train_loss -0.8323 
2025-04-01 12:55:09.251256: val_loss -0.6648 
2025-04-01 12:55:09.251342: Pseudo dice [0.7027] 
2025-04-01 12:55:09.251434: Epoch time: 274.33 s 
2025-04-01 12:55:11.546611:  
2025-04-01 12:55:11.546827: Epoch 607 
2025-04-01 12:55:11.546954: Current learning rate: 0.00431 
2025-04-01 12:59:45.507850: train_loss -0.8347 
2025-04-01 12:59:45.508247: val_loss -0.5967 
2025-04-01 12:59:45.508358: Pseudo dice [0.6381] 
2025-04-01 12:59:45.508459: Epoch time: 273.97 s 
2025-04-01 12:59:45.508525: Yayy! New best EMA pseudo Dice: 0.6273 
2025-04-01 12:59:48.765716:  
2025-04-01 12:59:48.765918: Epoch 608 
2025-04-01 12:59:48.766034: Current learning rate: 0.0043 
2025-04-01 13:04:23.203036: train_loss -0.8164 
2025-04-01 13:04:23.203360: val_loss -0.6579 
2025-04-01 13:04:23.203441: Pseudo dice [0.7225] 
2025-04-01 13:04:23.203524: Epoch time: 274.44 s 
2025-04-01 13:04:23.203593: Yayy! New best EMA pseudo Dice: 0.6368 
2025-04-01 13:04:26.571774:  
2025-04-01 13:04:26.571968: Epoch 609 
2025-04-01 13:04:26.572087: Current learning rate: 0.00429 
2025-04-01 13:09:01.096842: train_loss -0.8364 
2025-04-01 13:09:01.097185: val_loss -0.6444 
2025-04-01 13:09:01.097264: Pseudo dice [0.6576] 
2025-04-01 13:09:01.097362: Epoch time: 274.53 s 
2025-04-01 13:09:01.097418: Yayy! New best EMA pseudo Dice: 0.6389 
2025-04-01 13:09:04.446898:  
2025-04-01 13:09:04.447139: Epoch 610 
2025-04-01 13:09:04.447292: Current learning rate: 0.00429 
2025-04-01 13:13:39.383496: train_loss -0.8376 
2025-04-01 13:13:39.383854: val_loss -0.7028 
2025-04-01 13:13:39.383946: Pseudo dice [0.7447] 
2025-04-01 13:13:39.384047: Epoch time: 274.94 s 
2025-04-01 13:13:39.384125: Yayy! New best EMA pseudo Dice: 0.6494 
2025-04-01 13:13:42.737649:  
2025-04-01 13:13:42.737890: Epoch 611 
2025-04-01 13:13:42.738039: Current learning rate: 0.00428 
2025-04-01 13:18:17.532738: train_loss -0.8308 
2025-04-01 13:18:17.533096: val_loss -0.6612 
2025-04-01 13:18:17.533184: Pseudo dice [0.6832] 
2025-04-01 13:18:17.533286: Epoch time: 274.8 s 
2025-04-01 13:18:17.533341: Yayy! New best EMA pseudo Dice: 0.6528 
2025-04-01 13:18:20.954102:  
2025-04-01 13:18:20.954317: Epoch 612 
2025-04-01 13:18:20.954437: Current learning rate: 0.00427 
2025-04-01 13:22:54.747200: train_loss -0.8246 
2025-04-01 13:22:54.747576: val_loss -0.7292 
2025-04-01 13:22:54.747664: Pseudo dice [0.7596] 
2025-04-01 13:22:54.747783: Epoch time: 273.8 s 
2025-04-01 13:22:54.747847: Yayy! New best EMA pseudo Dice: 0.6635 
2025-04-01 13:22:58.092674:  
2025-04-01 13:22:58.092911: Epoch 613 
2025-04-01 13:22:58.093041: Current learning rate: 0.00426 
2025-04-01 13:27:31.714848: train_loss -0.8279 
2025-04-01 13:27:31.715220: val_loss -0.7097 
2025-04-01 13:27:31.715329: Pseudo dice [0.7751] 
2025-04-01 13:27:31.715430: Epoch time: 273.63 s 
2025-04-01 13:27:31.715487: Yayy! New best EMA pseudo Dice: 0.6747 
2025-04-01 13:27:35.381947:  
2025-04-01 13:27:35.382303: Epoch 614 
2025-04-01 13:27:35.382440: Current learning rate: 0.00425 
2025-04-01 13:32:08.851390: train_loss -0.8345 
2025-04-01 13:32:08.851723: val_loss -0.6325 
2025-04-01 13:32:08.851818: Pseudo dice [0.6674] 
2025-04-01 13:32:08.851920: Epoch time: 273.47 s 
2025-04-01 13:32:10.869009:  
2025-04-01 13:32:10.869319: Epoch 615 
2025-04-01 13:32:10.869561: Current learning rate: 0.00424 
2025-04-01 13:36:44.707821: train_loss -0.8298 
2025-04-01 13:36:44.708159: val_loss -0.6264 
2025-04-01 13:36:44.708252: Pseudo dice [0.6278] 
2025-04-01 13:36:44.708356: Epoch time: 273.84 s 
2025-04-01 13:36:46.819201:  
2025-04-01 13:36:46.819418: Epoch 616 
2025-04-01 13:36:46.819561: Current learning rate: 0.00423 
2025-04-01 13:41:20.795437: train_loss -0.8402 
2025-04-01 13:41:20.795843: val_loss -0.5643 
2025-04-01 13:41:20.795945: Pseudo dice [0.6261] 
2025-04-01 13:41:20.796031: Epoch time: 273.98 s 
2025-04-01 13:41:22.871362:  
2025-04-01 13:41:22.871618: Epoch 617 
2025-04-01 13:41:22.871760: Current learning rate: 0.00422 
2025-04-01 13:45:56.598553: train_loss -0.8388 
2025-04-01 13:45:56.598881: val_loss -0.6825 
2025-04-01 13:45:56.598968: Pseudo dice [0.6986] 
2025-04-01 13:45:56.599111: Epoch time: 273.73 s 
2025-04-01 13:45:58.608778:  
2025-04-01 13:45:58.608993: Epoch 618 
2025-04-01 13:45:58.609145: Current learning rate: 0.00421 
2025-04-01 13:50:32.349363: train_loss -0.8432 
2025-04-01 13:50:32.349681: val_loss -0.6237 
2025-04-01 13:50:32.349768: Pseudo dice [0.483] 
2025-04-01 13:50:32.349859: Epoch time: 273.74 s 
2025-04-01 13:50:34.359955:  
2025-04-01 13:50:34.360164: Epoch 619 
2025-04-01 13:50:34.360305: Current learning rate: 0.0042 
2025-04-01 13:55:08.386530: train_loss -0.8243 
2025-04-01 13:55:08.386848: val_loss -0.5571 
2025-04-01 13:55:08.387952: Pseudo dice [0.3794] 
2025-04-01 13:55:08.388105: Epoch time: 274.03 s 
2025-04-01 13:55:10.405524:  
2025-04-01 13:55:10.405733: Epoch 620 
2025-04-01 13:55:10.405851: Current learning rate: 0.00419 
2025-04-01 13:59:45.188577: train_loss -0.8297 
2025-04-01 13:59:45.188933: val_loss -0.5934 
2025-04-01 13:59:45.189064: Pseudo dice [0.5824] 
2025-04-01 13:59:45.189159: Epoch time: 274.79 s 
2025-04-01 13:59:47.500351:  
2025-04-01 13:59:47.500570: Epoch 621 
2025-04-01 13:59:47.500686: Current learning rate: 0.00418 
2025-04-01 14:04:23.442087: train_loss -0.8121 
2025-04-01 14:04:23.442396: val_loss -0.5924 
2025-04-01 14:04:23.442473: Pseudo dice [0.5563] 
2025-04-01 14:04:23.442559: Epoch time: 275.95 s 
2025-04-01 14:04:25.445575:  
2025-04-01 14:04:25.445768: Epoch 622 
2025-04-01 14:04:25.445889: Current learning rate: 0.00417 
2025-04-01 14:09:00.782500: train_loss -0.8089 
2025-04-01 14:09:00.782799: val_loss -0.5528 
2025-04-01 14:09:00.782881: Pseudo dice [0.4938] 
2025-04-01 14:09:00.782983: Epoch time: 275.34 s 
2025-04-01 14:09:02.810944:  
2025-04-01 14:09:02.811167: Epoch 623 
2025-04-01 14:09:02.811289: Current learning rate: 0.00416 
2025-04-01 14:13:38.301312: train_loss -0.8114 
2025-04-01 14:13:38.301673: val_loss -0.6492 
2025-04-01 14:13:38.301770: Pseudo dice [0.6227] 
2025-04-01 14:13:38.301874: Epoch time: 275.49 s 
2025-04-01 14:13:40.323902:  
2025-04-01 14:13:40.324146: Epoch 624 
2025-04-01 14:13:40.324260: Current learning rate: 0.00415 
2025-04-01 14:18:13.116100: train_loss -0.8296 
2025-04-01 14:18:13.116411: val_loss -0.6241 
2025-04-01 14:18:13.116497: Pseudo dice [0.5959] 
2025-04-01 14:18:13.116605: Epoch time: 272.8 s 
2025-04-01 14:18:15.138101:  
2025-04-01 14:18:15.138396: Epoch 625 
2025-04-01 14:18:15.138554: Current learning rate: 0.00414 
2025-04-01 14:22:46.673368: train_loss -0.8451 
2025-04-01 14:22:46.673703: val_loss -0.6396 
2025-04-01 14:22:46.673792: Pseudo dice [0.5887] 
2025-04-01 14:22:46.673891: Epoch time: 271.54 s 
2025-04-01 14:22:48.687132:  
2025-04-01 14:22:48.687412: Epoch 626 
2025-04-01 14:22:48.687712: Current learning rate: 0.00413 
2025-04-01 14:27:20.223958: train_loss -0.827 
2025-04-01 14:27:20.224276: val_loss -0.6112 
2025-04-01 14:27:20.224363: Pseudo dice [0.6192] 
2025-04-01 14:27:20.224461: Epoch time: 271.54 s 
2025-04-01 14:27:22.240082:  
2025-04-01 14:27:22.240319: Epoch 627 
2025-04-01 14:27:22.240436: Current learning rate: 0.00412 
2025-04-01 14:31:53.934263: train_loss -0.8356 
2025-04-01 14:31:53.934571: val_loss -0.6683 
2025-04-01 14:31:53.934658: Pseudo dice [0.7621] 
2025-04-01 14:31:53.934748: Epoch time: 271.7 s 
2025-04-01 14:31:55.941175:  
2025-04-01 14:31:55.941357: Epoch 628 
2025-04-01 14:31:55.941472: Current learning rate: 0.00411 
2025-04-01 14:36:27.614024: train_loss -0.8239 
2025-04-01 14:36:27.614375: val_loss -0.49 
2025-04-01 14:36:27.614466: Pseudo dice [0.301] 
2025-04-01 14:36:27.614566: Epoch time: 271.68 s 
2025-04-01 14:36:29.938955:  
2025-04-01 14:36:29.939171: Epoch 629 
2025-04-01 14:36:29.939290: Current learning rate: 0.0041 
2025-04-01 14:41:02.606271: train_loss -0.8162 
2025-04-01 14:41:02.606581: val_loss -0.6494 
2025-04-01 14:41:02.606668: Pseudo dice [0.6276] 
2025-04-01 14:41:02.606838: Epoch time: 272.67 s 
2025-04-01 14:41:04.622658:  
2025-04-01 14:41:04.622817: Epoch 630 
2025-04-01 14:41:04.622939: Current learning rate: 0.00409 
2025-04-01 14:45:37.046197: train_loss -0.8249 
2025-04-01 14:45:37.046525: val_loss -0.5841 
2025-04-01 14:45:37.046608: Pseudo dice [0.5283] 
2025-04-01 14:45:37.046705: Epoch time: 272.43 s 
2025-04-01 14:45:39.057228:  
2025-04-01 14:45:39.057409: Epoch 631 
2025-04-01 14:45:39.057522: Current learning rate: 0.00408 
2025-04-01 14:50:11.939735: train_loss -0.8051 
2025-04-01 14:50:11.940096: val_loss -0.6002 
2025-04-01 14:50:11.940197: Pseudo dice [0.5515] 
2025-04-01 14:50:11.940294: Epoch time: 272.89 s 
2025-04-01 14:50:13.984627:  
2025-04-01 14:50:13.984813: Epoch 632 
2025-04-01 14:50:13.984932: Current learning rate: 0.00407 
2025-04-01 14:54:46.691569: train_loss -0.8263 
2025-04-01 14:54:46.691906: val_loss -0.6342 
2025-04-01 14:54:46.692029: Pseudo dice [0.6577] 
2025-04-01 14:54:46.692154: Epoch time: 272.71 s 
2025-04-01 14:54:48.717247:  
2025-04-01 14:54:48.717527: Epoch 633 
2025-04-01 14:54:48.717644: Current learning rate: 0.00406 
2025-04-01 14:59:21.404260: train_loss -0.8441 
2025-04-01 14:59:21.404619: val_loss -0.692 
2025-04-01 14:59:21.404710: Pseudo dice [0.7569] 
2025-04-01 14:59:21.404809: Epoch time: 272.69 s 
2025-04-01 14:59:23.448083:  
2025-04-01 14:59:23.448273: Epoch 634 
2025-04-01 14:59:23.448433: Current learning rate: 0.00405 
2025-04-01 15:03:56.270388: train_loss -0.8294 
2025-04-01 15:03:56.270787: val_loss -0.595 
2025-04-01 15:03:56.270874: Pseudo dice [0.5756] 
2025-04-01 15:03:56.270970: Epoch time: 272.83 s 
2025-04-01 15:03:58.333400:  
2025-04-01 15:03:58.333601: Epoch 635 
2025-04-01 15:03:58.333765: Current learning rate: 0.00404 
2025-04-01 15:08:31.345634: train_loss -0.8333 
2025-04-01 15:08:31.346088: val_loss -0.7004 
2025-04-01 15:08:31.346210: Pseudo dice [0.663] 
2025-04-01 15:08:31.346301: Epoch time: 273.02 s 
2025-04-01 15:08:33.371608:  
2025-04-01 15:08:33.371909: Epoch 636 
2025-04-01 15:08:33.372035: Current learning rate: 0.00403 
2025-04-01 15:13:06.547246: train_loss -0.8178 
2025-04-01 15:13:06.547580: val_loss -0.5603 
2025-04-01 15:13:06.547668: Pseudo dice [0.4418] 
2025-04-01 15:13:06.547774: Epoch time: 273.18 s 
2025-04-01 15:13:08.565898:  
2025-04-01 15:13:08.566132: Epoch 637 
2025-04-01 15:13:08.566256: Current learning rate: 0.00402 
2025-04-01 15:17:42.525152: train_loss -0.8003 
2025-04-01 15:17:42.525571: val_loss -0.6921 
2025-04-01 15:17:42.525670: Pseudo dice [0.7342] 
2025-04-01 15:17:42.525756: Epoch time: 273.96 s 
2025-04-01 15:17:44.878914:  
2025-04-01 15:17:44.879246: Epoch 638 
2025-04-01 15:17:44.879368: Current learning rate: 0.00401 
2025-04-01 15:22:18.406147: train_loss -0.8186 
2025-04-01 15:22:18.406477: val_loss -0.6745 
2025-04-01 15:22:18.406563: Pseudo dice [0.6543] 
2025-04-01 15:22:18.406684: Epoch time: 273.53 s 
2025-04-01 15:22:20.428844:  
2025-04-01 15:22:20.429050: Epoch 639 
2025-04-01 15:22:20.429164: Current learning rate: 0.004 
2025-04-01 15:26:53.100718: train_loss -0.8328 
2025-04-01 15:26:53.101090: val_loss -0.7085 
2025-04-01 15:26:53.101190: Pseudo dice [0.7498] 
2025-04-01 15:26:53.101317: Epoch time: 272.68 s 
2025-04-01 15:26:55.132011:  
2025-04-01 15:26:55.132347: Epoch 640 
2025-04-01 15:26:55.132464: Current learning rate: 0.00399 
2025-04-01 15:31:27.414149: train_loss -0.84 
2025-04-01 15:31:27.414457: val_loss -0.7139 
2025-04-01 15:31:27.414536: Pseudo dice [0.6894] 
2025-04-01 15:31:27.414621: Epoch time: 272.29 s 
2025-04-01 15:31:29.433923:  
2025-04-01 15:31:29.434146: Epoch 641 
2025-04-01 15:31:29.434304: Current learning rate: 0.00398 
2025-04-01 15:36:01.895828: train_loss -0.8387 
2025-04-01 15:36:01.896154: val_loss -0.5962 
2025-04-01 15:36:01.896244: Pseudo dice [0.6095] 
2025-04-01 15:36:01.896350: Epoch time: 272.47 s 
2025-04-01 15:36:03.920655:  
2025-04-01 15:36:03.920851: Epoch 642 
2025-04-01 15:36:03.920978: Current learning rate: 0.00397 
2025-04-01 15:40:36.615837: train_loss -0.8307 
2025-04-01 15:40:36.616165: val_loss -0.5934 
2025-04-01 15:40:36.616301: Pseudo dice [0.5456] 
2025-04-01 15:40:36.616409: Epoch time: 272.7 s 
2025-04-01 15:40:38.652647:  
2025-04-01 15:40:38.652879: Epoch 643 
2025-04-01 15:40:38.653007: Current learning rate: 0.00396 
2025-04-01 15:45:11.334464: train_loss -0.8311 
2025-04-01 15:45:11.334842: val_loss -0.6693 
2025-04-01 15:45:11.334924: Pseudo dice [0.6159] 
2025-04-01 15:45:11.335016: Epoch time: 272.69 s 
2025-04-01 15:45:13.360930:  
2025-04-01 15:45:13.361107: Epoch 644 
2025-04-01 15:45:13.361274: Current learning rate: 0.00395 
2025-04-01 15:49:45.829458: train_loss -0.8381 
2025-04-01 15:49:45.829796: val_loss -0.6409 
2025-04-01 15:49:45.829883: Pseudo dice [0.6925] 
2025-04-01 15:49:45.829983: Epoch time: 272.47 s 
2025-04-01 15:49:47.859801:  
2025-04-01 15:49:47.860062: Epoch 645 
2025-04-01 15:49:47.860246: Current learning rate: 0.00394 
2025-04-01 15:54:20.066639: train_loss -0.8452 
2025-04-01 15:54:20.066970: val_loss -0.6619 
2025-04-01 15:54:20.067056: Pseudo dice [0.613] 
2025-04-01 15:54:20.067173: Epoch time: 272.21 s 
2025-04-01 15:54:22.392984:  
2025-04-01 15:54:22.393198: Epoch 646 
2025-04-01 15:54:22.393357: Current learning rate: 0.00393 
2025-04-01 15:58:54.630632: train_loss -0.8409 
2025-04-01 15:58:54.630982: val_loss -0.6421 
2025-04-01 15:58:54.631069: Pseudo dice [0.6279] 
2025-04-01 15:58:54.631172: Epoch time: 272.24 s 
2025-04-01 15:58:56.659158:  
2025-04-01 15:58:56.659371: Epoch 647 
2025-04-01 15:58:56.659505: Current learning rate: 0.00392 
2025-04-01 16:03:29.699421: train_loss -0.8356 
2025-04-01 16:03:29.699745: val_loss -0.5828 
2025-04-01 16:03:29.699867: Pseudo dice [0.5834] 
2025-04-01 16:03:29.699968: Epoch time: 273.04 s 
2025-04-01 16:03:31.729373:  
2025-04-01 16:03:31.729636: Epoch 648 
2025-04-01 16:03:31.729769: Current learning rate: 0.00391 
2025-04-01 16:08:05.115301: train_loss -0.8424 
2025-04-01 16:08:05.115624: val_loss -0.7324 
2025-04-01 16:08:05.115721: Pseudo dice [0.7531] 
2025-04-01 16:08:05.115836: Epoch time: 273.39 s 
2025-04-01 16:08:07.146281:  
2025-04-01 16:08:07.146456: Epoch 649 
2025-04-01 16:08:07.146597: Current learning rate: 0.0039 
2025-04-01 16:12:40.253375: train_loss -0.8467 
2025-04-01 16:12:40.253681: val_loss -0.6217 
2025-04-01 16:12:40.253762: Pseudo dice [0.5682] 
2025-04-01 16:12:40.253854: Epoch time: 273.11 s 
2025-04-01 16:12:43.744597:  
2025-04-01 16:12:43.744827: Epoch 650 
2025-04-01 16:12:43.744962: Current learning rate: 0.00389 
2025-04-01 16:17:16.884411: train_loss -0.8543 
2025-04-01 16:17:16.884789: val_loss -0.6759 
2025-04-01 16:17:16.884886: Pseudo dice [0.6205] 
2025-04-01 16:17:16.884979: Epoch time: 273.14 s 
2025-04-01 16:17:18.946876:  
2025-04-01 16:17:18.947095: Epoch 651 
2025-04-01 16:17:18.947219: Current learning rate: 0.00388 
2025-04-01 16:21:52.012546: train_loss -0.8476 
2025-04-01 16:21:52.012935: val_loss -0.5256 
2025-04-01 16:21:52.013038: Pseudo dice [0.4515] 
2025-04-01 16:21:52.013143: Epoch time: 273.07 s 
2025-04-01 16:21:54.046468:  
2025-04-01 16:21:54.046702: Epoch 652 
2025-04-01 16:21:54.046843: Current learning rate: 0.00387 
2025-04-01 16:26:26.794068: train_loss -0.8571 
2025-04-01 16:26:26.794409: val_loss -0.673 
2025-04-01 16:26:26.794498: Pseudo dice [0.648] 
2025-04-01 16:26:26.794597: Epoch time: 272.75 s 
2025-04-01 16:26:29.102719:  
2025-04-01 16:26:29.102966: Epoch 653 
2025-04-01 16:26:29.103091: Current learning rate: 0.00386 
2025-04-01 16:31:02.332921: train_loss -0.8417 
2025-04-01 16:31:02.333262: val_loss -0.6616 
2025-04-01 16:31:02.333347: Pseudo dice [0.6046] 
2025-04-01 16:31:02.333449: Epoch time: 273.23 s 
2025-04-01 16:31:04.352359:  
2025-04-01 16:31:04.352557: Epoch 654 
2025-04-01 16:31:04.352675: Current learning rate: 0.00385 
2025-04-01 16:35:37.641044: train_loss -0.8253 
2025-04-01 16:35:37.641360: val_loss -0.6769 
2025-04-01 16:35:37.641440: Pseudo dice [0.5635] 
2025-04-01 16:35:37.641540: Epoch time: 273.29 s 
2025-04-01 16:35:39.678316:  
2025-04-01 16:35:39.678575: Epoch 655 
2025-04-01 16:35:39.678702: Current learning rate: 0.00384 
2025-04-01 16:40:13.370971: train_loss -0.8516 
2025-04-01 16:40:13.371314: val_loss -0.6904 
2025-04-01 16:40:13.371889: Pseudo dice [0.6853] 
2025-04-01 16:40:13.371976: Epoch time: 273.7 s 
2025-04-01 16:40:15.383660:  
2025-04-01 16:40:15.383942: Epoch 656 
2025-04-01 16:40:15.384086: Current learning rate: 0.00383 
2025-04-01 16:44:49.442879: train_loss -0.8468 
2025-04-01 16:44:49.443221: val_loss -0.6247 
2025-04-01 16:44:49.443301: Pseudo dice [0.6327] 
2025-04-01 16:44:49.443388: Epoch time: 274.06 s 
2025-04-01 16:44:51.473385:  
2025-04-01 16:44:51.473598: Epoch 657 
2025-04-01 16:44:51.473728: Current learning rate: 0.00382 
2025-04-01 16:49:25.624457: train_loss -0.8395 
2025-04-01 16:49:25.624795: val_loss -0.6412 
2025-04-01 16:49:25.625361: Pseudo dice [0.5783] 
2025-04-01 16:49:25.625447: Epoch time: 274.16 s 
2025-04-01 16:49:27.663291:  
2025-04-01 16:49:27.663545: Epoch 658 
2025-04-01 16:49:27.663711: Current learning rate: 0.00381 
2025-04-01 16:54:01.984912: train_loss -0.8172 
2025-04-01 16:54:01.985284: val_loss -0.6158 
2025-04-01 16:54:01.985369: Pseudo dice [0.5705] 
2025-04-01 16:54:01.985464: Epoch time: 274.33 s 
2025-04-01 16:54:04.011000:  
2025-04-01 16:54:04.011223: Epoch 659 
2025-04-01 16:54:04.011337: Current learning rate: 0.0038 
2025-04-01 16:58:38.272266: train_loss -0.8155 
2025-04-01 16:58:38.272591: val_loss -0.6787 
2025-04-01 16:58:38.272668: Pseudo dice [0.7161] 
2025-04-01 16:58:38.272754: Epoch time: 274.27 s 
2025-04-01 16:58:40.291147:  
2025-04-01 16:58:40.291333: Epoch 660 
2025-04-01 16:58:40.291469: Current learning rate: 0.00379 
2025-04-01 17:03:14.178912: train_loss -0.8356 
2025-04-01 17:03:14.179276: val_loss -0.6514 
2025-04-01 17:03:14.179357: Pseudo dice [0.6121] 
2025-04-01 17:03:14.179457: Epoch time: 273.89 s 
2025-04-01 17:03:16.496122:  
2025-04-01 17:03:16.496393: Epoch 661 
2025-04-01 17:03:16.496548: Current learning rate: 0.00378 
2025-04-01 17:07:50.144689: train_loss -0.8282 
2025-04-01 17:07:50.145064: val_loss -0.7139 
2025-04-01 17:07:50.145150: Pseudo dice [0.7586] 
2025-04-01 17:07:50.145252: Epoch time: 273.65 s 
2025-04-01 17:07:52.167258:  
2025-04-01 17:07:52.167484: Epoch 662 
2025-04-01 17:07:52.167711: Current learning rate: 0.00377 
2025-04-01 17:12:25.399022: train_loss -0.8352 
2025-04-01 17:12:25.399336: val_loss -0.603 
2025-04-01 17:12:25.399422: Pseudo dice [0.3964] 
2025-04-01 17:12:25.399522: Epoch time: 273.24 s 
2025-04-01 17:12:27.428991:  
2025-04-01 17:12:27.429187: Epoch 663 
2025-04-01 17:12:27.429302: Current learning rate: 0.00376 
2025-04-01 17:17:01.174647: train_loss -0.8412 
2025-04-01 17:17:01.175050: val_loss -0.626 
2025-04-01 17:17:01.175169: Pseudo dice [0.6043] 
2025-04-01 17:17:01.175253: Epoch time: 273.75 s 
2025-04-01 17:17:03.206745:  
2025-04-01 17:17:03.206996: Epoch 664 
2025-04-01 17:17:03.207117: Current learning rate: 0.00375 
2025-04-01 17:21:37.066052: train_loss -0.8394 
2025-04-01 17:21:37.066350: val_loss -0.654 
2025-04-01 17:21:37.066432: Pseudo dice [0.5819] 
2025-04-01 17:21:37.066520: Epoch time: 273.86 s 
2025-04-01 17:21:39.093159:  
2025-04-01 17:21:39.093371: Epoch 665 
2025-04-01 17:21:39.093480: Current learning rate: 0.00374 
2025-04-01 17:26:12.767744: train_loss -0.8334 
2025-04-01 17:26:12.768144: val_loss -0.6488 
2025-04-01 17:26:12.768271: Pseudo dice [0.6335] 
2025-04-01 17:26:12.768357: Epoch time: 273.68 s 
2025-04-01 17:26:14.806441:  
2025-04-01 17:26:14.806647: Epoch 666 
2025-04-01 17:26:14.806755: Current learning rate: 0.00373 
2025-04-01 17:30:48.355342: train_loss -0.8355 
2025-04-01 17:30:48.355701: val_loss -0.6185 
2025-04-01 17:30:48.355795: Pseudo dice [0.6463] 
2025-04-01 17:30:48.355907: Epoch time: 273.55 s 
2025-04-01 17:30:50.379560:  
2025-04-01 17:30:50.379772: Epoch 667 
2025-04-01 17:30:50.379891: Current learning rate: 0.00372 
2025-04-01 17:35:24.276820: train_loss -0.8233 
2025-04-01 17:35:24.277210: val_loss -0.5761 
2025-04-01 17:35:24.277300: Pseudo dice [0.5294] 
2025-04-01 17:35:24.277393: Epoch time: 273.9 s 
2025-04-01 17:35:26.310474:  
2025-04-01 17:35:26.310669: Epoch 668 
2025-04-01 17:35:26.310796: Current learning rate: 0.00371 
2025-04-01 17:40:00.534713: train_loss -0.8393 
2025-04-01 17:40:00.535099: val_loss -0.6776 
2025-04-01 17:40:00.535195: Pseudo dice [0.6744] 
2025-04-01 17:40:00.535277: Epoch time: 274.23 s 
2025-04-01 17:40:02.897536:  
2025-04-01 17:40:02.897795: Epoch 669 
2025-04-01 17:40:02.897911: Current learning rate: 0.0037 
2025-04-01 17:44:36.826117: train_loss -0.8439 
2025-04-01 17:44:36.826465: val_loss -0.6401 
2025-04-01 17:44:36.826589: Pseudo dice [0.6257] 
2025-04-01 17:44:36.826700: Epoch time: 273.93 s 
2025-04-01 17:44:38.895229:  
2025-04-01 17:44:38.895491: Epoch 670 
2025-04-01 17:44:38.895658: Current learning rate: 0.00369 
2025-04-01 17:49:12.823607: train_loss -0.8403 
2025-04-01 17:49:12.823953: val_loss -0.5759 
2025-04-01 17:49:12.824035: Pseudo dice [0.6075] 
2025-04-01 17:49:12.824126: Epoch time: 273.93 s 
2025-04-01 17:49:14.883264:  
2025-04-01 17:49:14.883604: Epoch 671 
2025-04-01 17:49:14.883728: Current learning rate: 0.00368 
2025-04-01 17:53:49.021724: train_loss -0.8379 
2025-04-01 17:53:49.022047: val_loss -0.5888 
2025-04-01 17:53:49.022133: Pseudo dice [0.6047] 
2025-04-01 17:53:49.022218: Epoch time: 274.14 s 
2025-04-01 17:53:51.123043:  
2025-04-01 17:53:51.123208: Epoch 672 
2025-04-01 17:53:51.123324: Current learning rate: 0.00367 
2025-04-01 17:58:25.591790: train_loss -0.8115 
2025-04-01 17:58:25.592055: val_loss -0.6308 
2025-04-01 17:58:25.592140: Pseudo dice [0.6593] 
2025-04-01 17:58:25.592238: Epoch time: 274.47 s 
2025-04-01 17:58:27.649344:  
2025-04-01 17:58:27.649638: Epoch 673 
2025-04-01 17:58:27.649789: Current learning rate: 0.00366 
2025-04-01 18:03:00.957309: train_loss -0.853 
2025-04-01 18:03:00.957639: val_loss -0.6514 
2025-04-01 18:03:00.957724: Pseudo dice [0.6498] 
2025-04-01 18:03:00.957828: Epoch time: 273.31 s 
2025-04-01 18:03:03.011165:  
2025-04-01 18:03:03.011465: Epoch 674 
2025-04-01 18:03:03.011644: Current learning rate: 0.00365 
2025-04-01 18:07:36.486434: train_loss -0.8277 
2025-04-01 18:07:36.486797: val_loss -0.6788 
2025-04-01 18:07:36.486887: Pseudo dice [0.7207] 
2025-04-01 18:07:36.486980: Epoch time: 273.48 s 
2025-04-01 18:07:38.533756:  
2025-04-01 18:07:38.534014: Epoch 675 
2025-04-01 18:07:38.534127: Current learning rate: 0.00364 
2025-04-01 18:12:12.245277: train_loss -0.8368 
2025-04-01 18:12:12.245576: val_loss -0.5469 
2025-04-01 18:12:12.245665: Pseudo dice [0.5694] 
2025-04-01 18:12:12.245750: Epoch time: 273.72 s 
2025-04-01 18:12:14.643662:  
2025-04-01 18:12:14.643988: Epoch 676 
2025-04-01 18:12:14.644109: Current learning rate: 0.00363 
2025-04-01 18:16:48.433734: train_loss -0.8306 
2025-04-01 18:16:48.434095: val_loss -0.6165 
2025-04-01 18:16:48.434182: Pseudo dice [0.6508] 
2025-04-01 18:16:48.434305: Epoch time: 273.79 s 
2025-04-01 18:16:50.490308:  
2025-04-01 18:16:50.490545: Epoch 677 
2025-04-01 18:16:50.490670: Current learning rate: 0.00362 
2025-04-01 18:21:24.146019: train_loss -0.8408 
2025-04-01 18:21:24.146373: val_loss -0.6441 
2025-04-01 18:21:24.146734: Pseudo dice [0.7064] 
2025-04-01 18:21:24.146841: Epoch time: 273.66 s 
2025-04-01 18:21:26.242866:  
2025-04-01 18:21:26.243127: Epoch 678 
2025-04-01 18:21:26.243253: Current learning rate: 0.00361 
2025-04-01 18:25:59.591223: train_loss -0.8375 
2025-04-01 18:25:59.591574: val_loss -0.6654 
2025-04-01 18:25:59.591668: Pseudo dice [0.6553] 
2025-04-01 18:25:59.591790: Epoch time: 273.35 s 
2025-04-01 18:26:01.663153:  
2025-04-01 18:26:01.663396: Epoch 679 
2025-04-01 18:26:01.663547: Current learning rate: 0.0036 
2025-04-01 18:30:35.205910: train_loss -0.8453 
2025-04-01 18:30:35.206339: val_loss -0.6922 
2025-04-01 18:30:35.206430: Pseudo dice [0.7242] 
2025-04-01 18:30:35.206511: Epoch time: 273.55 s 
2025-04-01 18:30:37.265731:  
2025-04-01 18:30:37.266010: Epoch 680 
2025-04-01 18:30:37.266127: Current learning rate: 0.00359 
2025-04-01 18:35:11.156530: train_loss -0.8234 
2025-04-01 18:35:11.156895: val_loss -0.6483 
2025-04-01 18:35:11.156996: Pseudo dice [0.6968] 
2025-04-01 18:35:11.157094: Epoch time: 273.89 s 
2025-04-01 18:35:13.204978:  
2025-04-01 18:35:13.205241: Epoch 681 
2025-04-01 18:35:13.205405: Current learning rate: 0.00358 
2025-04-01 18:39:47.092578: train_loss -0.8498 
2025-04-01 18:39:47.092919: val_loss -0.6282 
2025-04-01 18:39:47.093013: Pseudo dice [0.6826] 
2025-04-01 18:39:47.093112: Epoch time: 273.89 s 
2025-04-01 18:39:49.157202:  
2025-04-01 18:39:49.157425: Epoch 682 
2025-04-01 18:39:49.157594: Current learning rate: 0.00357 
2025-04-01 18:44:23.243626: train_loss -0.8152 
2025-04-01 18:44:23.243975: val_loss -0.632 
2025-04-01 18:44:23.244065: Pseudo dice [0.6848] 
2025-04-01 18:44:23.244177: Epoch time: 274.09 s 
2025-04-01 18:44:25.339050:  
2025-04-01 18:44:25.339185: Epoch 683 
2025-04-01 18:44:25.339298: Current learning rate: 0.00356 
2025-04-01 18:48:59.152064: train_loss -0.8258 
2025-04-01 18:48:59.152486: val_loss -0.7458 
2025-04-01 18:48:59.152609: Pseudo dice [0.7723] 
2025-04-01 18:48:59.152691: Epoch time: 273.82 s 
2025-04-01 18:49:01.529807:  
2025-04-01 18:49:01.530096: Epoch 684 
2025-04-01 18:49:01.530218: Current learning rate: 0.00355 
2025-04-01 18:53:35.614985: train_loss -0.8267 
2025-04-01 18:53:35.615336: val_loss -0.5721 
2025-04-01 18:53:35.615430: Pseudo dice [0.5588] 
2025-04-01 18:53:35.615527: Epoch time: 274.09 s 
2025-04-01 18:53:37.684144:  
2025-04-01 18:53:37.684385: Epoch 685 
2025-04-01 18:53:37.684534: Current learning rate: 0.00354 
2025-04-01 18:58:11.332881: train_loss -0.8296 
2025-04-01 18:58:11.333212: val_loss -0.6737 
2025-04-01 18:58:11.333333: Pseudo dice [0.7529] 
2025-04-01 18:58:11.333436: Epoch time: 273.65 s 
2025-04-01 18:58:13.384502:  
2025-04-01 18:58:13.384803: Epoch 686 
2025-04-01 18:58:13.384943: Current learning rate: 0.00353 
2025-04-01 19:02:46.685776: train_loss -0.8409 
2025-04-01 19:02:46.686103: val_loss -0.5044 
2025-04-01 19:02:46.686191: Pseudo dice [0.5012] 
2025-04-01 19:02:46.686277: Epoch time: 273.31 s 
2025-04-01 19:02:48.733927:  
2025-04-01 19:02:48.734148: Epoch 687 
2025-04-01 19:02:48.734265: Current learning rate: 0.00352 
2025-04-01 19:07:22.185935: train_loss -0.82 
2025-04-01 19:07:22.186262: val_loss -0.6592 
2025-04-01 19:07:22.186341: Pseudo dice [0.6039] 
2025-04-01 19:07:22.186424: Epoch time: 273.46 s 
2025-04-01 19:07:24.266546:  
2025-04-01 19:07:24.266866: Epoch 688 
2025-04-01 19:07:24.267050: Current learning rate: 0.00351 
2025-04-01 19:11:58.230860: train_loss -0.8131 
2025-04-01 19:11:58.231149: val_loss -0.6043 
2025-04-01 19:11:58.231231: Pseudo dice [0.6463] 
2025-04-01 19:11:58.231315: Epoch time: 273.97 s 
2025-04-01 19:12:00.284162:  
2025-04-01 19:12:00.284390: Epoch 689 
2025-04-01 19:12:00.284505: Current learning rate: 0.0035 
2025-04-01 19:16:33.831588: train_loss -0.8237 
2025-04-01 19:16:33.831921: val_loss -0.6635 
2025-04-01 19:16:33.832011: Pseudo dice [0.6833] 
2025-04-01 19:16:33.832251: Epoch time: 273.55 s 
2025-04-01 19:16:35.884482:  
2025-04-01 19:16:35.884691: Epoch 690 
2025-04-01 19:16:35.884807: Current learning rate: 0.00349 
2025-04-01 19:21:09.459799: train_loss -0.8274 
2025-04-01 19:21:09.460178: val_loss -0.6802 
2025-04-01 19:21:09.460285: Pseudo dice [0.715] 
2025-04-01 19:21:09.460382: Epoch time: 273.58 s 
2025-04-01 19:21:11.527935:  
2025-04-01 19:21:11.528195: Epoch 691 
2025-04-01 19:21:11.528361: Current learning rate: 0.00348 
2025-04-01 19:25:45.791392: train_loss -0.8258 
2025-04-01 19:25:45.791724: val_loss -0.4981 
2025-04-01 19:25:45.791819: Pseudo dice [0.3644] 
2025-04-01 19:25:45.791917: Epoch time: 274.27 s 
2025-04-01 19:25:48.150646:  
2025-04-01 19:25:48.150889: Epoch 692 
2025-04-01 19:25:48.151047: Current learning rate: 0.00346 
2025-04-01 19:30:22.102560: train_loss -0.8479 
2025-04-01 19:30:22.102882: val_loss -0.6465 
2025-04-01 19:30:22.103034: Pseudo dice [0.6118] 
2025-04-01 19:30:22.103129: Epoch time: 273.96 s 
2025-04-01 19:30:24.159144:  
2025-04-01 19:30:24.159388: Epoch 693 
2025-04-01 19:30:24.159518: Current learning rate: 0.00345 
2025-04-01 19:34:58.411542: train_loss -0.8312 
2025-04-01 19:34:58.411929: val_loss -0.6394 
2025-04-01 19:34:58.412017: Pseudo dice [0.5798] 
2025-04-01 19:34:58.412112: Epoch time: 274.26 s 
2025-04-01 19:35:00.472550:  
2025-04-01 19:35:00.472849: Epoch 694 
2025-04-01 19:35:00.472967: Current learning rate: 0.00344 
2025-04-01 19:39:34.769462: train_loss -0.805 
2025-04-01 19:39:34.769801: val_loss -0.6912 
2025-04-01 19:39:34.769893: Pseudo dice [0.6257] 
2025-04-01 19:39:34.769999: Epoch time: 274.3 s 
2025-04-01 19:39:36.826156:  
2025-04-01 19:39:36.826366: Epoch 695 
2025-04-01 19:39:36.826487: Current learning rate: 0.00343 
2025-04-01 19:44:11.259570: train_loss -0.8322 
2025-04-01 19:44:11.259900: val_loss -0.6005 
2025-04-01 19:44:11.259988: Pseudo dice [0.5077] 
2025-04-01 19:44:11.260082: Epoch time: 274.44 s 
2025-04-01 19:44:13.327630:  
2025-04-01 19:44:13.327909: Epoch 696 
2025-04-01 19:44:13.328053: Current learning rate: 0.00342 
2025-04-01 19:48:47.620708: train_loss -0.8208 
2025-04-01 19:48:47.621073: val_loss -0.5948 
2025-04-01 19:48:47.621161: Pseudo dice [0.3583] 
2025-04-01 19:48:47.621263: Epoch time: 274.3 s 
2025-04-01 19:48:49.697439:  
2025-04-01 19:48:49.697657: Epoch 697 
2025-04-01 19:48:49.697771: Current learning rate: 0.00341 
2025-04-01 19:53:23.970026: train_loss -0.8367 
2025-04-01 19:53:23.970358: val_loss -0.6903 
2025-04-01 19:53:23.970464: Pseudo dice [0.6863] 
2025-04-01 19:53:23.970639: Epoch time: 274.28 s 
2025-04-01 19:53:26.030280:  
2025-04-01 19:53:26.030522: Epoch 698 
2025-04-01 19:53:26.030669: Current learning rate: 0.0034 
2025-04-01 19:58:00.234370: train_loss -0.8383 
2025-04-01 19:58:00.234678: val_loss -0.6506 
2025-04-01 19:58:00.234773: Pseudo dice [0.6646] 
2025-04-01 19:58:00.234882: Epoch time: 274.21 s 
2025-04-01 19:58:02.290749:  
2025-04-01 19:58:02.291023: Epoch 699 
2025-04-01 19:58:02.291142: Current learning rate: 0.00339 
2025-04-01 20:02:36.971806: train_loss -0.8241 
2025-04-01 20:02:36.972115: val_loss -0.6075 
2025-04-01 20:02:36.972197: Pseudo dice [0.5908] 
2025-04-01 20:02:36.972295: Epoch time: 274.69 s 
2025-04-01 20:02:40.794117:  
2025-04-01 20:02:40.794369: Epoch 700 
2025-04-01 20:02:40.794517: Current learning rate: 0.00338 
2025-04-01 20:07:15.356221: train_loss -0.8371 
2025-04-01 20:07:15.356553: val_loss -0.6125 
2025-04-01 20:07:15.356643: Pseudo dice [0.531] 
2025-04-01 20:07:15.356741: Epoch time: 274.57 s 
2025-04-01 20:07:17.406578:  
2025-04-01 20:07:17.406777: Epoch 701 
2025-04-01 20:07:17.406893: Current learning rate: 0.00337 
2025-04-01 20:11:51.053373: train_loss -0.8461 
2025-04-01 20:11:51.053664: val_loss -0.6181 
2025-04-01 20:11:51.053760: Pseudo dice [0.5638] 
2025-04-01 20:11:51.053850: Epoch time: 273.65 s 
2025-04-01 20:11:53.109036:  
2025-04-01 20:11:53.109222: Epoch 702 
2025-04-01 20:11:53.109339: Current learning rate: 0.00336 
2025-04-01 20:16:26.032085: train_loss -0.8394 
2025-04-01 20:16:26.032393: val_loss -0.5892 
2025-04-01 20:16:26.032476: Pseudo dice [0.6679] 
2025-04-01 20:16:26.032565: Epoch time: 272.93 s 
2025-04-01 20:16:28.084647:  
2025-04-01 20:16:28.084839: Epoch 703 
2025-04-01 20:16:28.084956: Current learning rate: 0.00335 
2025-04-01 20:21:01.104201: train_loss -0.8538 
2025-04-01 20:21:01.104511: val_loss -0.5946 
2025-04-01 20:21:01.104599: Pseudo dice [0.5028] 
2025-04-01 20:21:01.104698: Epoch time: 273.02 s 
2025-04-01 20:21:03.157394:  
2025-04-01 20:21:03.157681: Epoch 704 
2025-04-01 20:21:03.157809: Current learning rate: 0.00334 
2025-04-01 20:25:36.463913: train_loss -0.8506 
2025-04-01 20:25:36.464278: val_loss -0.544 
2025-04-01 20:25:36.464369: Pseudo dice [0.602] 
2025-04-01 20:25:36.464459: Epoch time: 273.31 s 
2025-04-01 20:25:38.533705:  
2025-04-01 20:25:38.533879: Epoch 705 
2025-04-01 20:25:38.534029: Current learning rate: 0.00333 
2025-04-01 20:30:11.937717: train_loss -0.8325 
2025-04-01 20:30:11.938066: val_loss -0.6405 
2025-04-01 20:30:11.938175: Pseudo dice [0.502] 
2025-04-01 20:30:11.938272: Epoch time: 273.41 s 
2025-04-01 20:30:14.028197:  
2025-04-01 20:30:14.028441: Epoch 706 
2025-04-01 20:30:14.028561: Current learning rate: 0.00332 
2025-04-01 20:34:47.434157: train_loss -0.8547 
2025-04-01 20:34:47.434530: val_loss -0.4955 
2025-04-01 20:34:47.434623: Pseudo dice [0.4635] 
2025-04-01 20:34:47.434718: Epoch time: 273.41 s 
2025-04-01 20:34:49.847728:  
2025-04-01 20:34:49.847990: Epoch 707 
2025-04-01 20:34:49.848155: Current learning rate: 0.00331 
2025-04-01 20:39:23.143487: train_loss -0.8492 
2025-04-01 20:39:23.143866: val_loss -0.5738 
2025-04-01 20:39:23.143960: Pseudo dice [0.5116] 
2025-04-01 20:39:23.144073: Epoch time: 273.3 s 
2025-04-01 20:39:25.245875:  
2025-04-01 20:39:25.246162: Epoch 708 
2025-04-01 20:39:25.246322: Current learning rate: 0.0033 
2025-04-01 20:43:58.410435: train_loss -0.8402 
2025-04-01 20:43:58.410729: val_loss -0.6067 
2025-04-01 20:43:58.410808: Pseudo dice [0.6172] 
2025-04-01 20:43:58.410891: Epoch time: 273.17 s 
2025-04-01 20:44:00.471368:  
2025-04-01 20:44:00.471678: Epoch 709 
2025-04-01 20:44:00.471802: Current learning rate: 0.00329 
2025-04-01 20:48:34.393675: train_loss -0.8602 
2025-04-01 20:48:34.394057: val_loss -0.6468 
2025-04-01 20:48:34.394218: Pseudo dice [0.6998] 
2025-04-01 20:48:34.394302: Epoch time: 273.93 s 
2025-04-01 20:48:36.461454:  
2025-04-01 20:48:36.461664: Epoch 710 
2025-04-01 20:48:36.461815: Current learning rate: 0.00328 
2025-04-01 20:53:10.505996: train_loss -0.8359 
2025-04-01 20:53:10.506310: val_loss -0.6679 
2025-04-01 20:53:10.506416: Pseudo dice [0.7591] 
2025-04-01 20:53:10.506547: Epoch time: 274.05 s 
2025-04-01 20:53:12.575972:  
2025-04-01 20:53:12.576157: Epoch 711 
2025-04-01 20:53:12.576275: Current learning rate: 0.00327 
2025-04-01 20:57:46.201514: train_loss -0.8436 
2025-04-01 20:57:46.201820: val_loss -0.6173 
2025-04-01 20:57:46.201915: Pseudo dice [0.6101] 
2025-04-01 20:57:46.202014: Epoch time: 273.63 s 
2025-04-01 20:57:48.288579:  
2025-04-01 20:57:48.288795: Epoch 712 
2025-04-01 20:57:48.288912: Current learning rate: 0.00326 
2025-04-01 21:02:21.583515: train_loss -0.85 
2025-04-01 21:02:21.583865: val_loss -0.651 
2025-04-01 21:02:21.583955: Pseudo dice [0.5789] 
2025-04-01 21:02:21.584051: Epoch time: 273.3 s 
2025-04-01 21:02:23.647063:  
2025-04-01 21:02:23.647243: Epoch 713 
2025-04-01 21:02:23.647412: Current learning rate: 0.00325 
2025-04-01 21:06:56.766472: train_loss -0.8467 
2025-04-01 21:06:56.766776: val_loss -0.6687 
2025-04-01 21:06:56.766914: Pseudo dice [0.7381] 
2025-04-01 21:06:56.767017: Epoch time: 273.12 s 
2025-04-01 21:06:58.837897:  
2025-04-01 21:06:58.838088: Epoch 714 
2025-04-01 21:06:58.838199: Current learning rate: 0.00324 
2025-04-01 21:11:31.866984: train_loss -0.8493 
2025-04-01 21:11:31.867338: val_loss -0.647 
2025-04-01 21:11:31.867428: Pseudo dice [0.6139] 
2025-04-01 21:11:31.867567: Epoch time: 273.03 s 
2025-04-01 21:11:34.253647:  
2025-04-01 21:11:34.253896: Epoch 715 
2025-04-01 21:11:34.254051: Current learning rate: 0.00323 
2025-04-01 21:16:07.320523: train_loss -0.8566 
2025-04-01 21:16:07.320837: val_loss -0.6881 
2025-04-01 21:16:07.320923: Pseudo dice [0.7682] 
2025-04-01 21:16:07.321024: Epoch time: 273.07 s 
2025-04-01 21:16:09.387247:  
2025-04-01 21:16:09.387437: Epoch 716 
2025-04-01 21:16:09.387566: Current learning rate: 0.00322 
2025-04-01 21:20:42.420533: train_loss -0.8458 
2025-04-01 21:20:42.420843: val_loss -0.6367 
2025-04-01 21:20:42.421002: Pseudo dice [0.5776] 
2025-04-01 21:20:42.421097: Epoch time: 273.04 s 
2025-04-01 21:20:44.471343:  
2025-04-01 21:20:44.471636: Epoch 717 
2025-04-01 21:20:44.471777: Current learning rate: 0.00321 
2025-04-01 21:25:17.969737: train_loss -0.8371 
2025-04-01 21:25:17.970044: val_loss -0.6575 
2025-04-01 21:25:17.970128: Pseudo dice [0.6197] 
2025-04-01 21:25:17.970255: Epoch time: 273.5 s 
2025-04-01 21:25:20.042147:  
2025-04-01 21:25:20.042414: Epoch 718 
2025-04-01 21:25:20.042547: Current learning rate: 0.0032 
2025-04-01 21:29:53.789630: train_loss -0.8369 
2025-04-01 21:29:53.790031: val_loss -0.6741 
2025-04-01 21:29:53.790118: Pseudo dice [0.658] 
2025-04-01 21:29:53.790216: Epoch time: 273.75 s 
2025-04-01 21:29:55.866970:  
2025-04-01 21:29:55.867212: Epoch 719 
2025-04-01 21:29:55.867340: Current learning rate: 0.00319 
2025-04-01 21:34:29.843235: train_loss -0.8481 
2025-04-01 21:34:29.843543: val_loss -0.644 
2025-04-01 21:34:29.843636: Pseudo dice [0.5561] 
2025-04-01 21:34:29.843724: Epoch time: 273.98 s 
2025-04-01 21:34:31.928607:  
2025-04-01 21:34:31.928851: Epoch 720 
2025-04-01 21:34:31.928975: Current learning rate: 0.00318 
2025-04-01 21:39:06.347552: train_loss -0.8246 
2025-04-01 21:39:06.347932: val_loss -0.6367 
2025-04-01 21:39:06.348020: Pseudo dice [0.6457] 
2025-04-01 21:39:06.348116: Epoch time: 274.43 s 
2025-04-01 21:39:08.399495:  
2025-04-01 21:39:08.399714: Epoch 721 
2025-04-01 21:39:08.399835: Current learning rate: 0.00317 
2025-04-01 21:43:42.605796: train_loss -0.8353 
2025-04-01 21:43:42.606104: val_loss -0.6528 
2025-04-01 21:43:42.606227: Pseudo dice [0.7332] 
2025-04-01 21:43:42.606334: Epoch time: 274.21 s 
2025-04-01 21:43:44.676054:  
2025-04-01 21:43:44.676290: Epoch 722 
2025-04-01 21:43:44.676406: Current learning rate: 0.00316 
2025-04-01 21:48:18.843885: train_loss -0.8019 
2025-04-01 21:48:18.844304: val_loss -0.631 
2025-04-01 21:48:18.844418: Pseudo dice [0.5845] 
2025-04-01 21:48:18.844506: Epoch time: 274.17 s 
2025-04-01 21:48:21.236569:  
2025-04-01 21:48:21.236796: Epoch 723 
2025-04-01 21:48:21.236906: Current learning rate: 0.00315 
2025-04-01 21:52:54.662758: train_loss -0.8329 
2025-04-01 21:52:54.663188: val_loss -0.7186 
2025-04-01 21:52:54.663295: Pseudo dice [0.7286] 
2025-04-01 21:52:54.663375: Epoch time: 273.43 s 
2025-04-01 21:52:56.729751:  
2025-04-01 21:52:56.729973: Epoch 724 
2025-04-01 21:52:56.730101: Current learning rate: 0.00314 
2025-04-01 21:57:29.883012: train_loss -0.8431 
2025-04-01 21:57:29.883322: val_loss -0.7133 
2025-04-01 21:57:29.883404: Pseudo dice [0.6892] 
2025-04-01 21:57:29.883494: Epoch time: 273.16 s 
2025-04-01 21:57:31.966906:  
2025-04-01 21:57:31.967211: Epoch 725 
2025-04-01 21:57:31.967337: Current learning rate: 0.00313 
2025-04-01 22:02:05.175142: train_loss -0.8357 
2025-04-01 22:02:05.175449: val_loss -0.6509 
2025-04-01 22:02:05.175532: Pseudo dice [0.6834] 
2025-04-01 22:02:05.175622: Epoch time: 273.21 s 
2025-04-01 22:02:07.227579:  
2025-04-01 22:02:07.227864: Epoch 726 
2025-04-01 22:02:07.228021: Current learning rate: 0.00312 
2025-04-01 22:06:40.784116: train_loss -0.819 
2025-04-01 22:06:40.784456: val_loss -0.5101 
2025-04-01 22:06:40.784539: Pseudo dice [0.2714] 
2025-04-01 22:06:40.784637: Epoch time: 273.56 s 
2025-04-01 22:06:42.852020:  
2025-04-01 22:06:42.852265: Epoch 727 
2025-04-01 22:06:42.852411: Current learning rate: 0.00311 
2025-04-01 22:11:16.604907: train_loss -0.839 
2025-04-01 22:11:16.605231: val_loss -0.695 
2025-04-01 22:11:16.605316: Pseudo dice [0.7044] 
2025-04-01 22:11:16.605417: Epoch time: 273.76 s 
2025-04-01 22:11:18.694867:  
2025-04-01 22:11:18.695153: Epoch 728 
2025-04-01 22:11:18.695291: Current learning rate: 0.0031 
2025-04-01 22:15:52.362830: train_loss -0.8358 
2025-04-01 22:15:52.363148: val_loss -0.6068 
2025-04-01 22:15:52.363231: Pseudo dice [0.5971] 
2025-04-01 22:15:52.363328: Epoch time: 273.67 s 
2025-04-01 22:15:54.457474:  
2025-04-01 22:15:54.457680: Epoch 729 
2025-04-01 22:15:54.457831: Current learning rate: 0.00309 
2025-04-01 22:20:27.594907: train_loss -0.8454 
2025-04-01 22:20:27.595217: val_loss -0.6978 
2025-04-01 22:20:27.595301: Pseudo dice [0.7395] 
2025-04-01 22:20:27.595414: Epoch time: 273.14 s 
2025-04-01 22:20:29.710906:  
2025-04-01 22:20:29.711136: Epoch 730 
2025-04-01 22:20:29.711264: Current learning rate: 0.00308 
2025-04-01 22:25:03.322002: train_loss -0.8401 
2025-04-01 22:25:03.322338: val_loss -0.6031 
2025-04-01 22:25:03.322445: Pseudo dice [0.5115] 
2025-04-01 22:25:03.322603: Epoch time: 273.62 s 
2025-04-01 22:25:05.394868:  
2025-04-01 22:25:05.395122: Epoch 731 
2025-04-01 22:25:05.395245: Current learning rate: 0.00307 
2025-04-01 22:29:39.719821: train_loss -0.8346 
2025-04-01 22:29:39.720210: val_loss -0.6882 
2025-04-01 22:29:39.720304: Pseudo dice [0.6483] 
2025-04-01 22:29:39.720399: Epoch time: 274.33 s 
2025-04-01 22:29:41.795648:  
2025-04-01 22:29:41.795893: Epoch 732 
2025-04-01 22:29:41.796010: Current learning rate: 0.00306 
2025-04-01 22:34:16.136909: train_loss -0.8309 
2025-04-01 22:34:16.137261: val_loss -0.6305 
2025-04-01 22:34:16.137350: Pseudo dice [0.5855] 
2025-04-01 22:34:16.137446: Epoch time: 274.35 s 
2025-04-01 22:34:18.209166:  
2025-04-01 22:34:18.209414: Epoch 733 
2025-04-01 22:34:18.209565: Current learning rate: 0.00305 
2025-04-01 22:38:52.481942: train_loss -0.8288 
2025-04-01 22:38:52.482302: val_loss -0.7016 
2025-04-01 22:38:52.482667: Pseudo dice [0.7093] 
2025-04-01 22:38:52.482750: Epoch time: 274.28 s 
2025-04-01 22:38:54.554871:  
2025-04-01 22:38:54.555248: Epoch 734 
2025-04-01 22:38:54.555400: Current learning rate: 0.00304 
2025-04-01 22:43:28.337409: train_loss -0.8367 
2025-04-01 22:43:28.337757: val_loss -0.6012 
2025-04-01 22:43:28.337849: Pseudo dice [0.5281] 
2025-04-01 22:43:28.337949: Epoch time: 273.79 s 
2025-04-01 22:43:30.398247:  
2025-04-01 22:43:30.398428: Epoch 735 
2025-04-01 22:43:30.398613: Current learning rate: 0.00303 
2025-04-01 22:48:04.245134: train_loss -0.8499 
2025-04-01 22:48:04.245461: val_loss -0.6118 
2025-04-01 22:48:04.245548: Pseudo dice [0.4707] 
2025-04-01 22:48:04.245651: Epoch time: 273.85 s 
2025-04-01 22:48:06.334657:  
2025-04-01 22:48:06.334946: Epoch 736 
2025-04-01 22:48:06.335072: Current learning rate: 0.00302 
2025-04-01 22:52:40.235844: train_loss -0.8363 
2025-04-01 22:52:40.236171: val_loss -0.6436 
2025-04-01 22:52:40.236264: Pseudo dice [0.6116] 
2025-04-01 22:52:40.236368: Epoch time: 273.91 s 
2025-04-01 22:52:42.310776:  
2025-04-01 22:52:42.310979: Epoch 737 
2025-04-01 22:52:42.311095: Current learning rate: 0.00301 
2025-04-01 22:57:16.519670: train_loss -0.8422 
2025-04-01 22:57:16.520010: val_loss -0.6662 
2025-04-01 22:57:16.520100: Pseudo dice [0.725] 
2025-04-01 22:57:16.520201: Epoch time: 274.21 s 
2025-04-01 22:57:18.864427:  
2025-04-01 22:57:18.864694: Epoch 738 
2025-04-01 22:57:18.864810: Current learning rate: 0.003 
2025-04-01 23:01:52.787728: train_loss -0.8466 
2025-04-01 23:01:52.788131: val_loss -0.6725 
2025-04-01 23:01:52.788230: Pseudo dice [0.7077] 
2025-04-01 23:01:52.788322: Epoch time: 273.93 s 
2025-04-01 23:01:54.866347:  
2025-04-01 23:01:54.866577: Epoch 739 
2025-04-01 23:01:54.866694: Current learning rate: 0.00299 
2025-04-01 23:06:28.878244: train_loss -0.8591 
2025-04-01 23:06:28.878557: val_loss -0.7013 
2025-04-01 23:06:28.878647: Pseudo dice [0.7464] 
2025-04-01 23:06:28.878746: Epoch time: 274.02 s 
2025-04-01 23:06:30.960683:  
2025-04-01 23:06:30.960944: Epoch 740 
2025-04-01 23:06:30.961101: Current learning rate: 0.00297 
2025-04-01 23:11:04.821691: train_loss -0.8584 
2025-04-01 23:11:04.822067: val_loss -0.5951 
2025-04-01 23:11:04.822186: Pseudo dice [0.5614] 
2025-04-01 23:11:04.822269: Epoch time: 273.86 s 
2025-04-01 23:11:06.897831:  
2025-04-01 23:11:06.898062: Epoch 741 
2025-04-01 23:11:06.898230: Current learning rate: 0.00296 
2025-04-01 23:15:40.554078: train_loss -0.86 
2025-04-01 23:15:40.554443: val_loss -0.6292 
2025-04-01 23:15:40.554538: Pseudo dice [0.6052] 
2025-04-01 23:15:40.554631: Epoch time: 273.66 s 
2025-04-01 23:15:42.681710:  
2025-04-01 23:15:42.681926: Epoch 742 
2025-04-01 23:15:42.682039: Current learning rate: 0.00295 
2025-04-01 23:20:16.451358: train_loss -0.8565 
2025-04-01 23:20:16.451664: val_loss -0.6819 
2025-04-01 23:20:16.451782: Pseudo dice [0.7457] 
2025-04-01 23:20:16.451894: Epoch time: 273.77 s 
2025-04-01 23:20:18.514445:  
2025-04-01 23:20:18.514694: Epoch 743 
2025-04-01 23:20:18.514840: Current learning rate: 0.00294 
2025-04-01 23:24:52.667954: train_loss -0.8426 
2025-04-01 23:24:52.668267: val_loss -0.6383 
2025-04-01 23:24:52.668362: Pseudo dice [0.6728] 
2025-04-01 23:24:52.668499: Epoch time: 274.16 s 
2025-04-01 23:24:54.727537:  
2025-04-01 23:24:54.727757: Epoch 744 
2025-04-01 23:24:54.727888: Current learning rate: 0.00293 
2025-04-01 23:29:29.090731: train_loss -0.8324 
2025-04-01 23:29:29.091057: val_loss -0.6907 
2025-04-01 23:29:29.091144: Pseudo dice [0.7598] 
2025-04-01 23:29:29.091244: Epoch time: 274.37 s 
2025-04-01 23:29:31.170658:  
2025-04-01 23:29:31.170846: Epoch 745 
2025-04-01 23:29:31.170988: Current learning rate: 0.00292 
2025-04-01 23:34:05.471597: train_loss -0.8126 
2025-04-01 23:34:05.471954: val_loss -0.6424 
2025-04-01 23:34:05.472037: Pseudo dice [0.7115] 
2025-04-01 23:34:05.472135: Epoch time: 274.31 s 
2025-04-01 23:34:07.853713:  
2025-04-01 23:34:07.853954: Epoch 746 
2025-04-01 23:34:07.854074: Current learning rate: 0.00291 
2025-04-01 23:38:41.405770: train_loss -0.8141 
2025-04-01 23:38:41.406079: val_loss -0.5851 
2025-04-01 23:38:41.406165: Pseudo dice [0.6787] 
2025-04-01 23:38:41.406253: Epoch time: 273.56 s 
2025-04-01 23:38:43.484867:  
2025-04-01 23:38:43.485076: Epoch 747 
2025-04-01 23:38:43.485194: Current learning rate: 0.0029 
2025-04-01 23:43:16.585846: train_loss -0.8346 
2025-04-01 23:43:16.586256: val_loss -0.6256 
2025-04-01 23:43:16.586339: Pseudo dice [0.6734] 
2025-04-01 23:43:16.586434: Epoch time: 273.1 s 
2025-04-01 23:43:18.716574:  
2025-04-01 23:43:18.716790: Epoch 748 
2025-04-01 23:43:18.716917: Current learning rate: 0.00289 
2025-04-01 23:47:51.262863: train_loss -0.8534 
2025-04-01 23:47:51.263210: val_loss -0.6213 
2025-04-01 23:47:51.263303: Pseudo dice [0.68] 
2025-04-01 23:47:51.263402: Epoch time: 272.55 s 
2025-04-01 23:47:53.344104:  
2025-04-01 23:47:53.344319: Epoch 749 
2025-04-01 23:47:53.344435: Current learning rate: 0.00288 
2025-04-01 23:52:25.584070: train_loss -0.8567 
2025-04-01 23:52:25.584392: val_loss -0.6696 
2025-04-01 23:52:25.584473: Pseudo dice [0.7015] 
2025-04-01 23:52:25.584604: Epoch time: 272.24 s 
2025-04-01 23:52:29.059399:  
2025-04-01 23:52:29.059641: Epoch 750 
2025-04-01 23:52:29.059786: Current learning rate: 0.00287 
2025-04-01 23:57:01.450701: train_loss -0.8547 
2025-04-01 23:57:01.451099: val_loss -0.6106 
2025-04-01 23:57:01.451262: Pseudo dice [0.5337] 
2025-04-01 23:57:01.451345: Epoch time: 272.4 s 
2025-04-01 23:57:03.509259:  
2025-04-01 23:57:03.509448: Epoch 751 
2025-04-01 23:57:03.509577: Current learning rate: 0.00286 
2025-04-02 00:01:35.887237: train_loss -0.856 
2025-04-02 00:01:35.887567: val_loss -0.5818 
2025-04-02 00:01:35.887651: Pseudo dice [0.5815] 
2025-04-02 00:01:35.887760: Epoch time: 272.38 s 
2025-04-02 00:01:37.961151:  
2025-04-02 00:01:37.961394: Epoch 752 
2025-04-02 00:01:37.961545: Current learning rate: 0.00285 
2025-04-02 00:06:10.764480: train_loss -0.8501 
2025-04-02 00:06:10.764789: val_loss -0.6256 
2025-04-02 00:06:10.764874: Pseudo dice [0.5622] 
2025-04-02 00:06:10.764962: Epoch time: 272.81 s 
2025-04-02 00:06:12.837649:  
2025-04-02 00:06:12.837912: Epoch 753 
2025-04-02 00:06:12.838047: Current learning rate: 0.00284 
2025-04-02 00:10:45.178074: train_loss -0.8487 
2025-04-02 00:10:45.178398: val_loss -0.575 
2025-04-02 00:10:45.178505: Pseudo dice [0.4932] 
2025-04-02 00:10:45.178618: Epoch time: 272.34 s 
2025-04-02 00:10:47.596276:  
2025-04-02 00:10:47.596467: Epoch 754 
2025-04-02 00:10:47.596579: Current learning rate: 0.00283 
2025-04-02 00:15:20.638956: train_loss -0.8544 
2025-04-02 00:15:20.639288: val_loss -0.6189 
2025-04-02 00:15:20.639398: Pseudo dice [0.6799] 
2025-04-02 00:15:20.639491: Epoch time: 273.05 s 
2025-04-02 00:15:22.701089:  
2025-04-02 00:15:22.701344: Epoch 755 
2025-04-02 00:15:22.701487: Current learning rate: 0.00282 
2025-04-02 00:19:56.185395: train_loss -0.8419 
2025-04-02 00:19:56.185703: val_loss -0.64 
2025-04-02 00:19:56.185777: Pseudo dice [0.6215] 
2025-04-02 00:19:56.185863: Epoch time: 273.49 s 
2025-04-02 00:19:58.253098:  
2025-04-02 00:19:58.253345: Epoch 756 
2025-04-02 00:19:58.253477: Current learning rate: 0.00281 
2025-04-02 00:24:31.491114: train_loss -0.8424 
2025-04-02 00:24:31.491457: val_loss -0.6351 
2025-04-02 00:24:31.491550: Pseudo dice [0.5921] 
2025-04-02 00:24:31.491662: Epoch time: 273.24 s 
2025-04-02 00:24:33.562489:  
2025-04-02 00:24:33.562700: Epoch 757 
2025-04-02 00:24:33.562823: Current learning rate: 0.0028 
2025-04-02 00:29:07.107548: train_loss -0.8404 
2025-04-02 00:29:07.107902: val_loss -0.6127 
2025-04-02 00:29:07.108004: Pseudo dice [0.4888] 
2025-04-02 00:29:07.108113: Epoch time: 273.55 s 
2025-04-02 00:29:09.196521:  
2025-04-02 00:29:09.196743: Epoch 758 
2025-04-02 00:29:09.196858: Current learning rate: 0.00279 
2025-04-02 00:33:42.689447: train_loss -0.8573 
2025-04-02 00:33:42.689858: val_loss -0.7227 
2025-04-02 00:33:42.689953: Pseudo dice [0.716] 
2025-04-02 00:33:42.690050: Epoch time: 273.5 s 
2025-04-02 00:33:44.788085:  
2025-04-02 00:33:44.788305: Epoch 759 
2025-04-02 00:33:44.788424: Current learning rate: 0.00278 
2025-04-02 00:38:18.095822: train_loss -0.8611 
2025-04-02 00:38:18.096192: val_loss -0.6716 
2025-04-02 00:38:18.096280: Pseudo dice [0.5555] 
2025-04-02 00:38:18.096373: Epoch time: 273.31 s 
2025-04-02 00:38:20.168217:  
2025-04-02 00:38:20.168429: Epoch 760 
2025-04-02 00:38:20.168582: Current learning rate: 0.00277 
2025-04-02 00:42:53.306924: train_loss -0.8533 
2025-04-02 00:42:53.307147: val_loss -0.7045 
2025-04-02 00:42:53.307227: Pseudo dice [0.6547] 
2025-04-02 00:42:53.307323: Epoch time: 273.14 s 
2025-04-02 00:42:55.672263:  
2025-04-02 00:42:55.672466: Epoch 761 
2025-04-02 00:42:55.672584: Current learning rate: 0.00276 
2025-04-02 00:47:29.346643: train_loss -0.8455 
2025-04-02 00:47:29.346958: val_loss -0.7267 
2025-04-02 00:47:29.347053: Pseudo dice [0.7122] 
2025-04-02 00:47:29.347164: Epoch time: 273.68 s 
2025-04-02 00:47:31.425933:  
2025-04-02 00:47:31.426260: Epoch 762 
2025-04-02 00:47:31.426431: Current learning rate: 0.00275 
2025-04-02 00:52:05.608801: train_loss -0.8554 
2025-04-02 00:52:05.609139: val_loss -0.6607 
2025-04-02 00:52:05.609220: Pseudo dice [0.6896] 
2025-04-02 00:52:05.609313: Epoch time: 274.19 s 
2025-04-02 00:52:07.698538:  
2025-04-02 00:52:07.698780: Epoch 763 
2025-04-02 00:52:07.698936: Current learning rate: 0.00274 
2025-04-02 00:56:41.858162: train_loss -0.8527 
2025-04-02 00:56:41.858475: val_loss -0.743 
2025-04-02 00:56:41.858558: Pseudo dice [0.7584] 
2025-04-02 00:56:41.858659: Epoch time: 274.16 s 
2025-04-02 00:56:43.992744:  
2025-04-02 00:56:43.992991: Epoch 764 
2025-04-02 00:56:43.993136: Current learning rate: 0.00273 
2025-04-02 01:01:17.899420: train_loss -0.8461 
2025-04-02 01:01:17.899780: val_loss -0.694 
2025-04-02 01:01:17.899883: Pseudo dice [0.7499] 
2025-04-02 01:01:17.899971: Epoch time: 273.91 s 
2025-04-02 01:01:20.018613:  
2025-04-02 01:01:20.018887: Epoch 765 
2025-04-02 01:01:20.019006: Current learning rate: 0.00272 
2025-04-02 01:05:54.155392: train_loss -0.8504 
2025-04-02 01:05:54.156089: val_loss -0.6585 
2025-04-02 01:05:54.156188: Pseudo dice [0.7545] 
2025-04-02 01:05:54.156284: Epoch time: 274.14 s 
2025-04-02 01:05:56.260395:  
2025-04-02 01:05:56.260612: Epoch 766 
2025-04-02 01:05:56.260726: Current learning rate: 0.00271 
2025-04-02 01:10:30.378586: train_loss -0.8596 
2025-04-02 01:10:30.378920: val_loss -0.6572 
2025-04-02 01:10:30.379055: Pseudo dice [0.5559] 
2025-04-02 01:10:30.379215: Epoch time: 274.12 s 
2025-04-02 01:10:32.471272:  
2025-04-02 01:10:32.471522: Epoch 767 
2025-04-02 01:10:32.471669: Current learning rate: 0.0027 
2025-04-02 01:15:06.356868: train_loss -0.8615 
2025-04-02 01:15:06.357184: val_loss -0.6326 
2025-04-02 01:15:06.357269: Pseudo dice [0.6837] 
2025-04-02 01:15:06.357350: Epoch time: 273.89 s 
2025-04-02 01:15:08.452283:  
2025-04-02 01:15:08.452459: Epoch 768 
2025-04-02 01:15:08.452574: Current learning rate: 0.00268 
2025-04-02 01:19:42.307497: train_loss -0.8484 
2025-04-02 01:19:42.307961: val_loss -0.6136 
2025-04-02 01:19:42.308053: Pseudo dice [0.6081] 
2025-04-02 01:19:42.308136: Epoch time: 273.86 s 
2025-04-02 01:19:44.715803:  
2025-04-02 01:19:44.716008: Epoch 769 
2025-04-02 01:19:44.716157: Current learning rate: 0.00267 
2025-04-02 01:24:18.282735: train_loss -0.8684 
2025-04-02 01:24:18.283094: val_loss -0.6397 
2025-04-02 01:24:18.283219: Pseudo dice [0.5995] 
2025-04-02 01:24:18.283315: Epoch time: 273.57 s 
2025-04-02 01:24:20.371117:  
2025-04-02 01:24:20.371331: Epoch 770 
2025-04-02 01:24:20.371448: Current learning rate: 0.00266 
2025-04-02 01:28:53.987929: train_loss -0.8565 
2025-04-02 01:28:53.988260: val_loss -0.6704 
2025-04-02 01:28:53.988345: Pseudo dice [0.691] 
2025-04-02 01:28:53.988440: Epoch time: 273.62 s 
2025-04-02 01:28:56.084692:  
2025-04-02 01:28:56.084942: Epoch 771 
2025-04-02 01:28:56.085060: Current learning rate: 0.00265 
2025-04-02 01:33:30.379364: train_loss -0.8427 
2025-04-02 01:33:30.379662: val_loss -0.6502 
2025-04-02 01:33:30.379739: Pseudo dice [0.6193] 
2025-04-02 01:33:30.379953: Epoch time: 274.3 s 
2025-04-02 01:33:32.488536:  
2025-04-02 01:33:32.488819: Epoch 772 
2025-04-02 01:33:32.488966: Current learning rate: 0.00264 
2025-04-02 01:38:06.435714: train_loss -0.8408 
2025-04-02 01:38:06.436120: val_loss -0.6258 
2025-04-02 01:38:06.436205: Pseudo dice [0.6013] 
2025-04-02 01:38:06.436297: Epoch time: 273.95 s 
2025-04-02 01:38:08.527687:  
2025-04-02 01:38:08.527933: Epoch 773 
2025-04-02 01:38:08.528051: Current learning rate: 0.00263 
2025-04-02 01:42:41.852288: train_loss -0.8613 
2025-04-02 01:42:41.852622: val_loss -0.6682 
2025-04-02 01:42:41.853196: Pseudo dice [0.662] 
2025-04-02 01:42:41.853286: Epoch time: 273.33 s 
2025-04-02 01:42:43.956434:  
2025-04-02 01:42:43.956643: Epoch 774 
2025-04-02 01:42:43.956760: Current learning rate: 0.00262 
2025-04-02 01:47:17.419062: train_loss -0.8515 
2025-04-02 01:47:17.419402: val_loss -0.5972 
2025-04-02 01:47:17.419496: Pseudo dice [0.5662] 
2025-04-02 01:47:17.419632: Epoch time: 273.47 s 
2025-04-02 01:47:19.530003:  
2025-04-02 01:47:19.530210: Epoch 775 
2025-04-02 01:47:19.530338: Current learning rate: 0.00261 
2025-04-02 01:51:52.614398: train_loss -0.8621 
2025-04-02 01:51:52.614830: val_loss -0.6968 
2025-04-02 01:51:52.614925: Pseudo dice [0.7038] 
2025-04-02 01:51:52.615006: Epoch time: 273.09 s 
2025-04-02 01:51:54.808484:  
2025-04-02 01:51:54.808719: Epoch 776 
2025-04-02 01:51:54.808850: Current learning rate: 0.0026 
2025-04-02 01:56:28.654489: train_loss -0.8529 
2025-04-02 01:56:28.654890: val_loss -0.5229 
2025-04-02 01:56:28.655105: Pseudo dice [0.5575] 
2025-04-02 01:56:28.655278: Epoch time: 273.85 s 
2025-04-02 01:56:31.097442:  
2025-04-02 01:56:31.097738: Epoch 777 
2025-04-02 01:56:31.097855: Current learning rate: 0.00259 
2025-04-02 02:01:05.100947: train_loss -0.8472 
2025-04-02 02:01:05.101287: val_loss -0.6403 
2025-04-02 02:01:05.101380: Pseudo dice [0.6104] 
2025-04-02 02:01:05.101475: Epoch time: 274.01 s 
2025-04-02 02:01:07.210239:  
2025-04-02 02:01:07.210428: Epoch 778 
2025-04-02 02:01:07.210559: Current learning rate: 0.00258 
2025-04-02 02:05:41.111986: train_loss -0.8394 
2025-04-02 02:05:41.112355: val_loss -0.6151 
2025-04-02 02:05:41.112447: Pseudo dice [0.6442] 
2025-04-02 02:05:41.112540: Epoch time: 273.91 s 
2025-04-02 02:05:43.222875:  
2025-04-02 02:05:43.223107: Epoch 779 
2025-04-02 02:05:43.223226: Current learning rate: 0.00257 
2025-04-02 02:10:16.943905: train_loss -0.844 
2025-04-02 02:10:16.944242: val_loss -0.6094 
2025-04-02 02:10:16.944336: Pseudo dice [0.4904] 
2025-04-02 02:10:16.944438: Epoch time: 273.73 s 
2025-04-02 02:10:19.067966:  
2025-04-02 02:10:19.068238: Epoch 780 
2025-04-02 02:10:19.068414: Current learning rate: 0.00256 
2025-04-02 02:14:52.268578: train_loss -0.8524 
2025-04-02 02:14:52.268973: val_loss -0.6251 
2025-04-02 02:14:52.269105: Pseudo dice [0.6907] 
2025-04-02 02:14:52.269193: Epoch time: 273.2 s 
2025-04-02 02:14:54.360383:  
2025-04-02 02:14:54.360578: Epoch 781 
2025-04-02 02:14:54.360696: Current learning rate: 0.00255 
2025-04-02 02:19:27.925389: train_loss -0.8571 
2025-04-02 02:19:27.925735: val_loss -0.6583 
2025-04-02 02:19:27.925870: Pseudo dice [0.6436] 
2025-04-02 02:19:27.925961: Epoch time: 273.57 s 
2025-04-02 02:19:30.026509:  
2025-04-02 02:19:30.026698: Epoch 782 
2025-04-02 02:19:30.026805: Current learning rate: 0.00254 
2025-04-02 02:24:03.427928: train_loss -0.8459 
2025-04-02 02:24:03.428273: val_loss -0.6737 
2025-04-02 02:24:03.428358: Pseudo dice [0.7533] 
2025-04-02 02:24:03.428456: Epoch time: 273.41 s 
2025-04-02 02:24:05.523888:  
2025-04-02 02:24:05.524101: Epoch 783 
2025-04-02 02:24:05.524217: Current learning rate: 0.00253 
2025-04-02 02:28:39.100590: train_loss -0.8531 
2025-04-02 02:28:39.100954: val_loss -0.61 
2025-04-02 02:28:39.101041: Pseudo dice [0.5463] 
2025-04-02 02:28:39.101132: Epoch time: 273.58 s 
2025-04-02 02:28:41.190705:  
2025-04-02 02:28:41.190909: Epoch 784 
2025-04-02 02:28:41.191091: Current learning rate: 0.00252 
2025-04-02 02:33:14.697799: train_loss -0.8496 
2025-04-02 02:33:14.698133: val_loss -0.5911 
2025-04-02 02:33:14.698215: Pseudo dice [0.6128] 
2025-04-02 02:33:14.698323: Epoch time: 273.51 s 
2025-04-02 02:33:17.099634:  
2025-04-02 02:33:17.099908: Epoch 785 
2025-04-02 02:33:17.100072: Current learning rate: 0.00251 
2025-04-02 02:37:51.673002: train_loss -0.8328 
2025-04-02 02:37:51.673391: val_loss -0.767 
2025-04-02 02:37:51.673478: Pseudo dice [0.7583] 
2025-04-02 02:37:51.673568: Epoch time: 274.58 s 
2025-04-02 02:37:53.775738:  
2025-04-02 02:37:53.775911: Epoch 786 
2025-04-02 02:37:53.776070: Current learning rate: 0.0025 
2025-04-02 02:42:28.469691: train_loss -0.8423 
2025-04-02 02:42:28.470028: val_loss -0.6701 
2025-04-02 02:42:28.470139: Pseudo dice [0.7474] 
2025-04-02 02:42:28.470232: Epoch time: 274.7 s 
2025-04-02 02:42:30.583674:  
2025-04-02 02:42:30.583879: Epoch 787 
2025-04-02 02:42:30.584001: Current learning rate: 0.00249 
2025-04-02 02:47:04.938771: train_loss -0.8576 
2025-04-02 02:47:04.939099: val_loss -0.6862 
2025-04-02 02:47:04.939185: Pseudo dice [0.5735] 
2025-04-02 02:47:04.939293: Epoch time: 274.36 s 
2025-04-02 02:47:07.026652:  
2025-04-02 02:47:07.026867: Epoch 788 
2025-04-02 02:47:07.026983: Current learning rate: 0.00248 
2025-04-02 02:51:41.272363: train_loss -0.8474 
2025-04-02 02:51:41.272722: val_loss -0.6329 
2025-04-02 02:51:41.274121: Pseudo dice [0.6596] 
2025-04-02 02:51:41.274206: Epoch time: 274.25 s 
2025-04-02 02:51:43.377099:  
2025-04-02 02:51:43.377303: Epoch 789 
2025-04-02 02:51:43.377422: Current learning rate: 0.00247 
2025-04-02 02:56:18.286501: train_loss -0.8473 
2025-04-02 02:56:18.286834: val_loss -0.6559 
2025-04-02 02:56:18.286923: Pseudo dice [0.6844] 
2025-04-02 02:56:18.287021: Epoch time: 274.91 s 
2025-04-02 02:56:20.397380:  
2025-04-02 02:56:20.397586: Epoch 790 
2025-04-02 02:56:20.397701: Current learning rate: 0.00245 
2025-04-02 03:00:55.152799: train_loss -0.8259 
2025-04-02 03:00:55.153141: val_loss -0.5602 
2025-04-02 03:00:55.153256: Pseudo dice [0.5346] 
2025-04-02 03:00:55.153351: Epoch time: 274.76 s 
2025-04-02 03:00:57.260691:  
2025-04-02 03:00:57.260933: Epoch 791 
2025-04-02 03:00:57.261045: Current learning rate: 0.00244 
2025-04-02 03:05:31.807844: train_loss -0.8441 
2025-04-02 03:05:31.808241: val_loss -0.7187 
2025-04-02 03:05:31.808361: Pseudo dice [0.7397] 
2025-04-02 03:05:31.808442: Epoch time: 274.55 s 
2025-04-02 03:05:34.223625:  
2025-04-02 03:05:34.223890: Epoch 792 
2025-04-02 03:05:34.224022: Current learning rate: 0.00243 
2025-04-02 03:10:08.913342: train_loss -0.8421 
2025-04-02 03:10:08.913670: val_loss -0.7613 
2025-04-02 03:10:08.913753: Pseudo dice [0.7669] 
2025-04-02 03:10:08.913859: Epoch time: 274.69 s 
2025-04-02 03:10:11.021676:  
2025-04-02 03:10:11.021897: Epoch 793 
2025-04-02 03:10:11.022015: Current learning rate: 0.00242 
2025-04-02 03:14:45.426728: train_loss -0.8458 
2025-04-02 03:14:45.427041: val_loss -0.6965 
2025-04-02 03:14:45.427121: Pseudo dice [0.6944] 
2025-04-02 03:14:45.427215: Epoch time: 274.41 s 
2025-04-02 03:14:47.580326:  
2025-04-02 03:14:47.580646: Epoch 794 
2025-04-02 03:14:47.580811: Current learning rate: 0.00241 
2025-04-02 03:19:21.469749: train_loss -0.86 
2025-04-02 03:19:21.470069: val_loss -0.6961 
2025-04-02 03:19:21.470172: Pseudo dice [0.7154] 
2025-04-02 03:19:21.470274: Epoch time: 273.89 s 
2025-04-02 03:19:23.562209:  
2025-04-02 03:19:23.562422: Epoch 795 
2025-04-02 03:19:23.562551: Current learning rate: 0.0024 
2025-04-02 03:23:57.448093: train_loss -0.8575 
2025-04-02 03:23:57.448467: val_loss -0.7005 
2025-04-02 03:23:57.448565: Pseudo dice [0.7371] 
2025-04-02 03:23:57.448667: Epoch time: 273.89 s 
2025-04-02 03:23:57.448729: Yayy! New best EMA pseudo Dice: 0.676 
2025-04-02 03:24:00.933872:  
2025-04-02 03:24:00.934085: Epoch 796 
2025-04-02 03:24:00.934199: Current learning rate: 0.00239 
2025-04-02 03:28:34.967968: train_loss -0.8578 
2025-04-02 03:28:34.968293: val_loss -0.6731 
2025-04-02 03:28:34.968378: Pseudo dice [0.6749] 
2025-04-02 03:28:34.968479: Epoch time: 274.04 s 
2025-04-02 03:28:37.061650:  
2025-04-02 03:28:37.061865: Epoch 797 
2025-04-02 03:28:37.061978: Current learning rate: 0.00238 
2025-04-02 03:33:11.118791: train_loss -0.8515 
2025-04-02 03:33:11.119091: val_loss -0.6498 
2025-04-02 03:33:11.119174: Pseudo dice [0.6253] 
2025-04-02 03:33:11.119260: Epoch time: 274.06 s 
2025-04-02 03:33:13.257647:  
2025-04-02 03:33:13.257865: Epoch 798 
2025-04-02 03:33:13.257982: Current learning rate: 0.00237 
2025-04-02 03:37:47.355799: train_loss -0.8455 
2025-04-02 03:37:47.356138: val_loss -0.7365 
2025-04-02 03:37:47.356230: Pseudo dice [0.7148] 
2025-04-02 03:37:47.356331: Epoch time: 274.1 s 
2025-04-02 03:37:49.491022:  
2025-04-02 03:37:49.491200: Epoch 799 
2025-04-02 03:37:49.491318: Current learning rate: 0.00236 
2025-04-02 03:42:23.713927: train_loss -0.8547 
2025-04-02 03:42:23.714287: val_loss -0.6393 
2025-04-02 03:42:23.714374: Pseudo dice [0.6965] 
2025-04-02 03:42:23.714470: Epoch time: 274.23 s 
2025-04-02 03:42:25.137364: Yayy! New best EMA pseudo Dice: 0.6774 
2025-04-02 03:42:28.614200:  
2025-04-02 03:42:28.614439: Epoch 800 
2025-04-02 03:42:28.614590: Current learning rate: 0.00235 
2025-04-02 03:47:02.965570: train_loss -0.8639 
2025-04-02 03:47:02.965899: val_loss -0.6761 
2025-04-02 03:47:02.965975: Pseudo dice [0.6788] 
2025-04-02 03:47:02.966071: Epoch time: 274.36 s 
2025-04-02 03:47:02.966126: Yayy! New best EMA pseudo Dice: 0.6775 
2025-04-02 03:47:06.503237:  
2025-04-02 03:47:06.503457: Epoch 801 
2025-04-02 03:47:06.503608: Current learning rate: 0.00234 
2025-04-02 03:51:41.220745: train_loss -0.8563 
2025-04-02 03:51:41.221071: val_loss -0.6718 
2025-04-02 03:51:41.221157: Pseudo dice [0.6675] 
2025-04-02 03:51:41.221256: Epoch time: 274.72 s 
2025-04-02 03:51:43.336097:  
2025-04-02 03:51:43.336289: Epoch 802 
2025-04-02 03:51:43.336411: Current learning rate: 0.00233 
2025-04-02 03:56:17.826498: train_loss -0.8617 
2025-04-02 03:56:17.826834: val_loss -0.6893 
2025-04-02 03:56:17.826925: Pseudo dice [0.7861] 
2025-04-02 03:56:17.827029: Epoch time: 274.49 s 
2025-04-02 03:56:17.827155: Yayy! New best EMA pseudo Dice: 0.6875 
2025-04-02 03:56:21.359280:  
2025-04-02 03:56:21.359464: Epoch 803 
2025-04-02 03:56:21.359641: Current learning rate: 0.00232 
2025-04-02 04:00:55.947152: train_loss -0.865 
2025-04-02 04:00:55.947495: val_loss -0.6442 
2025-04-02 04:00:55.947573: Pseudo dice [0.7056] 
2025-04-02 04:00:55.947683: Epoch time: 274.59 s 
2025-04-02 04:00:55.947741: Yayy! New best EMA pseudo Dice: 0.6893 
2025-04-02 04:00:59.456798:  
2025-04-02 04:00:59.457034: Epoch 804 
2025-04-02 04:00:59.457150: Current learning rate: 0.00231 
2025-04-02 04:05:34.918881: train_loss -0.8676 
2025-04-02 04:05:34.919184: val_loss -0.6867 
2025-04-02 04:05:34.919264: Pseudo dice [0.7541] 
2025-04-02 04:05:34.919412: Epoch time: 275.47 s 
2025-04-02 04:05:34.919498: Yayy! New best EMA pseudo Dice: 0.6958 
2025-04-02 04:05:38.624107:  
2025-04-02 04:05:38.624363: Epoch 805 
2025-04-02 04:05:38.624483: Current learning rate: 0.0023 
2025-04-02 04:10:14.487282: train_loss -0.8583 
2025-04-02 04:10:14.487665: val_loss -0.6677 
2025-04-02 04:10:14.487819: Pseudo dice [0.6949] 
2025-04-02 04:10:14.487899: Epoch time: 275.87 s 
2025-04-02 04:10:16.591523:  
2025-04-02 04:10:16.591742: Epoch 806 
2025-04-02 04:10:16.591884: Current learning rate: 0.00229 
2025-04-02 04:14:52.757660: train_loss -0.8549 
2025-04-02 04:14:52.757967: val_loss -0.613 
2025-04-02 04:14:52.758055: Pseudo dice [0.6138] 
2025-04-02 04:14:52.758213: Epoch time: 276.17 s 
2025-04-02 04:14:54.865765:  
2025-04-02 04:14:54.865994: Epoch 807 
2025-04-02 04:14:54.866128: Current learning rate: 0.00228 
2025-04-02 04:19:31.104436: train_loss -0.8451 
2025-04-02 04:19:31.104743: val_loss -0.7155 
2025-04-02 04:19:31.104824: Pseudo dice [0.7605] 
2025-04-02 04:19:31.104912: Epoch time: 276.24 s 
2025-04-02 04:19:33.215127:  
2025-04-02 04:19:33.215351: Epoch 808 
2025-04-02 04:19:33.215468: Current learning rate: 0.00226 
2025-04-02 04:24:09.572486: train_loss -0.8399 
2025-04-02 04:24:09.572815: val_loss -0.7268 
2025-04-02 04:24:09.572900: Pseudo dice [0.7068] 
2025-04-02 04:24:09.573003: Epoch time: 276.36 s 
2025-04-02 04:24:09.573061: Yayy! New best EMA pseudo Dice: 0.696 
2025-04-02 04:24:13.067924:  
2025-04-02 04:24:13.068153: Epoch 809 
2025-04-02 04:24:13.068267: Current learning rate: 0.00225 
2025-04-02 04:28:50.681393: train_loss -0.8537 
2025-04-02 04:28:50.681700: val_loss -0.6591 
2025-04-02 04:28:50.681788: Pseudo dice [0.5595] 
2025-04-02 04:28:50.681879: Epoch time: 277.62 s 
2025-04-02 04:28:52.784095:  
2025-04-02 04:28:52.784318: Epoch 810 
2025-04-02 04:28:52.784446: Current learning rate: 0.00224 
2025-04-02 04:33:29.155200: train_loss -0.8537 
2025-04-02 04:33:29.155536: val_loss -0.6911 
2025-04-02 04:33:29.155737: Pseudo dice [0.7511] 
2025-04-02 04:33:29.155848: Epoch time: 276.38 s 
2025-04-02 04:33:31.278127:  
2025-04-02 04:33:31.278355: Epoch 811 
2025-04-02 04:33:31.278486: Current learning rate: 0.00223 
2025-04-02 04:38:13.322781: train_loss -0.8607 
2025-04-02 04:38:13.323411: val_loss -0.608 
2025-04-02 04:38:13.323512: Pseudo dice [0.6625] 
2025-04-02 04:38:13.323607: Epoch time: 282.05 s 
2025-04-02 04:38:15.794425:  
2025-04-02 04:38:15.794677: Epoch 812 
2025-04-02 04:38:15.794863: Current learning rate: 0.00222 
2025-04-02 04:42:52.587711: train_loss -0.8622 
2025-04-02 04:42:52.588106: val_loss -0.5648 
2025-04-02 04:42:52.588205: Pseudo dice [0.459] 
2025-04-02 04:42:52.588285: Epoch time: 276.8 s 
2025-04-02 04:42:54.761328:  
2025-04-02 04:42:54.761624: Epoch 813 
2025-04-02 04:42:54.761755: Current learning rate: 0.00221 
2025-04-02 04:47:29.505087: train_loss -0.8618 
2025-04-02 04:47:29.523413: val_loss -0.6097 
2025-04-02 04:47:29.523531: Pseudo dice [0.4857] 
2025-04-02 04:47:29.523626: Epoch time: 274.75 s 
2025-04-02 04:47:31.735979:  
2025-04-02 04:47:31.736167: Epoch 814 
2025-04-02 04:47:31.736282: Current learning rate: 0.0022 
2025-04-02 04:52:06.030606: train_loss -0.8564 
2025-04-02 04:52:06.030944: val_loss -0.6562 
2025-04-02 04:52:06.031025: Pseudo dice [0.6617] 
2025-04-02 04:52:06.031118: Epoch time: 274.3 s 
2025-04-02 04:52:08.189871:  
2025-04-02 04:52:08.190050: Epoch 815 
2025-04-02 04:52:08.190163: Current learning rate: 0.00219 
2025-04-02 04:56:41.644026: train_loss -0.8557 
2025-04-02 04:56:41.644640: val_loss -0.6918 
2025-04-02 04:56:41.644750: Pseudo dice [0.7439] 
2025-04-02 04:56:41.644850: Epoch time: 273.46 s 
2025-04-02 04:56:43.753684:  
2025-04-02 04:56:43.753880: Epoch 816 
2025-04-02 04:56:43.754024: Current learning rate: 0.00218 
2025-04-02 05:01:16.467621: train_loss -0.8559 
2025-04-02 05:01:16.467975: val_loss -0.676 
2025-04-02 05:01:16.468066: Pseudo dice [0.6564] 
2025-04-02 05:01:16.468233: Epoch time: 272.72 s 
2025-04-02 05:01:18.626779:  
2025-04-02 05:01:18.627084: Epoch 817 
2025-04-02 05:01:18.627253: Current learning rate: 0.00217 
2025-04-02 05:05:52.039945: train_loss -0.8666 
2025-04-02 05:05:52.048200: val_loss -0.6876 
2025-04-02 05:05:52.048308: Pseudo dice [0.7298] 
2025-04-02 05:05:52.048396: Epoch time: 273.42 s 
2025-04-02 05:05:54.161779:  
2025-04-02 05:05:54.162141: Epoch 818 
2025-04-02 05:05:54.162272: Current learning rate: 0.00216 
2025-04-02 05:10:27.250482: train_loss -0.8688 
2025-04-02 05:10:27.250808: val_loss -0.7109 
2025-04-02 05:10:27.250910: Pseudo dice [0.7405] 
2025-04-02 05:10:27.251001: Epoch time: 273.09 s 
2025-04-02 05:10:29.371737:  
2025-04-02 05:10:29.372049: Epoch 819 
2025-04-02 05:10:29.372230: Current learning rate: 0.00215 
2025-04-02 05:15:03.111738: train_loss -0.8699 
2025-04-02 05:15:03.112154: val_loss -0.5757 
2025-04-02 05:15:03.112480: Pseudo dice [0.5803] 
2025-04-02 05:15:03.112561: Epoch time: 273.74 s 
2025-04-02 05:15:05.463598:  
2025-04-02 05:15:05.463904: Epoch 820 
2025-04-02 05:15:05.464231: Current learning rate: 0.00214 
2025-04-02 05:19:39.025034: train_loss -0.8592 
2025-04-02 05:19:39.025343: val_loss -0.6192 
2025-04-02 05:19:39.025423: Pseudo dice [0.7077] 
2025-04-02 05:19:39.025533: Epoch time: 273.57 s 
2025-04-02 05:19:41.020297:  
2025-04-02 05:19:41.020490: Epoch 821 
2025-04-02 05:19:41.020618: Current learning rate: 0.00213 
2025-04-02 05:24:14.795132: train_loss -0.8519 
2025-04-02 05:24:14.795462: val_loss -0.6329 
2025-04-02 05:24:14.795576: Pseudo dice [0.5872] 
2025-04-02 05:24:14.795675: Epoch time: 273.78 s 
2025-04-02 05:24:16.869597:  
2025-04-02 05:24:16.869808: Epoch 822 
2025-04-02 05:24:16.869925: Current learning rate: 0.00212 
2025-04-02 05:28:50.288864: train_loss -0.8662 
2025-04-02 05:28:50.289353: val_loss -0.6553 
2025-04-02 05:28:50.289457: Pseudo dice [0.6571] 
2025-04-02 05:28:50.289543: Epoch time: 273.42 s 
2025-04-02 05:28:52.338046:  
2025-04-02 05:28:52.338280: Epoch 823 
2025-04-02 05:28:52.338458: Current learning rate: 0.0021 
2025-04-02 05:33:25.887233: train_loss -0.8649 
2025-04-02 05:33:25.887586: val_loss -0.5902 
2025-04-02 05:33:25.887676: Pseudo dice [0.6118] 
2025-04-02 05:33:25.887788: Epoch time: 273.55 s 
2025-04-02 05:33:27.990219:  
2025-04-02 05:33:27.990437: Epoch 824 
2025-04-02 05:33:27.990556: Current learning rate: 0.00209 
2025-04-02 05:38:02.036686: train_loss -0.8698 
2025-04-02 05:38:02.069169: val_loss -0.6316 
2025-04-02 05:38:02.069392: Pseudo dice [0.6347] 
2025-04-02 05:38:02.069474: Epoch time: 274.05 s 
2025-04-02 05:38:04.168958:  
2025-04-02 05:38:04.169204: Epoch 825 
2025-04-02 05:38:04.169362: Current learning rate: 0.00208 
2025-04-02 05:42:38.607735: train_loss -0.8634 
2025-04-02 05:42:38.608100: val_loss -0.6356 
2025-04-02 05:42:38.608186: Pseudo dice [0.7251] 
2025-04-02 05:42:38.608281: Epoch time: 274.44 s 
2025-04-02 05:42:40.608436:  
2025-04-02 05:42:40.608670: Epoch 826 
2025-04-02 05:42:40.608791: Current learning rate: 0.00207 
2025-04-02 05:47:15.024444: train_loss -0.8658 
2025-04-02 05:47:15.024768: val_loss -0.654 
2025-04-02 05:47:15.024858: Pseudo dice [0.6375] 
2025-04-02 05:47:15.024999: Epoch time: 274.42 s 
2025-04-02 05:47:17.024832:  
2025-04-02 05:47:17.025030: Epoch 827 
2025-04-02 05:47:17.025145: Current learning rate: 0.00206 
2025-04-02 05:51:51.498788: train_loss -0.8636 
2025-04-02 05:51:51.499083: val_loss -0.7073 
2025-04-02 05:51:51.499177: Pseudo dice [0.7634] 
2025-04-02 05:51:51.499258: Epoch time: 274.48 s 
2025-04-02 05:51:53.807039:  
2025-04-02 05:51:53.807330: Epoch 828 
2025-04-02 05:51:53.807464: Current learning rate: 0.00205 
2025-04-02 05:56:28.487357: train_loss -0.8579 
2025-04-02 05:56:28.487669: val_loss -0.6481 
2025-04-02 05:56:28.487766: Pseudo dice [0.6864] 
2025-04-02 05:56:28.487910: Epoch time: 274.68 s 
2025-04-02 05:56:30.482663:  
2025-04-02 05:56:30.482872: Epoch 829 
2025-04-02 05:56:30.482987: Current learning rate: 0.00204 
2025-04-02 06:01:05.210064: train_loss -0.862 
2025-04-02 06:01:05.210371: val_loss -0.5262 
2025-04-02 06:01:05.210458: Pseudo dice [0.5353] 
2025-04-02 06:01:05.210562: Epoch time: 274.73 s 
2025-04-02 06:01:07.210366:  
2025-04-02 06:01:07.210534: Epoch 830 
2025-04-02 06:01:07.210713: Current learning rate: 0.00203 
2025-04-02 06:05:42.215031: train_loss -0.8622 
2025-04-02 06:05:42.215405: val_loss -0.7295 
2025-04-02 06:05:42.215510: Pseudo dice [0.7304] 
2025-04-02 06:05:42.215602: Epoch time: 275.01 s 
2025-04-02 06:05:44.231320:  
2025-04-02 06:05:44.231544: Epoch 831 
2025-04-02 06:05:44.231658: Current learning rate: 0.00202 
2025-04-02 06:10:18.889271: train_loss -0.8617 
2025-04-02 06:10:18.889577: val_loss -0.6378 
2025-04-02 06:10:18.889657: Pseudo dice [0.6285] 
2025-04-02 06:10:18.889741: Epoch time: 274.66 s 
2025-04-02 06:10:20.893581:  
2025-04-02 06:10:20.893811: Epoch 832 
2025-04-02 06:10:20.893928: Current learning rate: 0.00201 
2025-04-02 06:14:54.574482: train_loss -0.8669 
2025-04-02 06:14:54.574799: val_loss -0.4884 
2025-04-02 06:14:54.574898: Pseudo dice [0.4314] 
2025-04-02 06:14:54.575006: Epoch time: 273.68 s 
2025-04-02 06:14:56.582149:  
2025-04-02 06:14:56.582450: Epoch 833 
2025-04-02 06:14:56.582581: Current learning rate: 0.002 
2025-04-02 06:19:30.122941: train_loss -0.8712 
2025-04-02 06:19:30.123292: val_loss -0.738 
2025-04-02 06:19:30.123376: Pseudo dice [0.7305] 
2025-04-02 06:19:30.123536: Epoch time: 273.54 s 
2025-04-02 06:19:32.124938:  
2025-04-02 06:19:32.125123: Epoch 834 
2025-04-02 06:19:32.125237: Current learning rate: 0.00199 
2025-04-02 06:24:06.017093: train_loss -0.8759 
2025-04-02 06:24:06.017436: val_loss -0.5605 
2025-04-02 06:24:06.017510: Pseudo dice [0.6243] 
2025-04-02 06:24:06.017627: Epoch time: 273.9 s 
2025-04-02 06:24:08.017087:  
2025-04-02 06:24:08.017354: Epoch 835 
2025-04-02 06:24:08.017529: Current learning rate: 0.00198 
2025-04-02 06:28:42.090768: train_loss -0.866 
2025-04-02 06:28:42.091087: val_loss -0.6667 
2025-04-02 06:28:42.091177: Pseudo dice [0.7546] 
2025-04-02 06:28:42.091278: Epoch time: 274.08 s 
2025-04-02 06:28:44.413109:  
2025-04-02 06:28:44.413374: Epoch 836 
2025-04-02 06:28:44.413530: Current learning rate: 0.00196 
2025-04-02 06:33:18.780183: train_loss -0.8663 
2025-04-02 06:33:18.780509: val_loss -0.724 
2025-04-02 06:33:18.780597: Pseudo dice [0.7064] 
2025-04-02 06:33:18.780693: Epoch time: 274.37 s 
2025-04-02 06:33:20.779110:  
2025-04-02 06:33:20.779392: Epoch 837 
2025-04-02 06:33:20.779537: Current learning rate: 0.00195 
2025-04-02 06:37:55.271924: train_loss -0.8576 
2025-04-02 06:37:55.272246: val_loss -0.669 
2025-04-02 06:37:55.272331: Pseudo dice [0.7018] 
2025-04-02 06:37:55.272424: Epoch time: 274.5 s 
2025-04-02 06:37:57.274510:  
2025-04-02 06:37:57.274786: Epoch 838 
2025-04-02 06:37:57.274945: Current learning rate: 0.00194 
2025-04-02 06:42:31.607265: train_loss -0.8652 
2025-04-02 06:42:31.607584: val_loss -0.6178 
2025-04-02 06:42:31.607669: Pseudo dice [0.6012] 
2025-04-02 06:42:31.607779: Epoch time: 274.34 s 
2025-04-02 06:42:33.647131:  
2025-04-02 06:42:33.647421: Epoch 839 
2025-04-02 06:42:33.647559: Current learning rate: 0.00193 
2025-04-02 06:47:07.997478: train_loss -0.8618 
2025-04-02 06:47:07.997788: val_loss -0.6855 
2025-04-02 06:47:07.997883: Pseudo dice [0.7091] 
2025-04-02 06:47:07.997972: Epoch time: 274.35 s 
2025-04-02 06:47:09.993585:  
2025-04-02 06:47:09.993813: Epoch 840 
2025-04-02 06:47:09.993984: Current learning rate: 0.00192 
2025-04-02 06:51:44.435825: train_loss -0.859 
2025-04-02 06:51:44.436230: val_loss -0.5969 
2025-04-02 06:51:44.436360: Pseudo dice [0.5833] 
2025-04-02 06:51:44.436448: Epoch time: 274.45 s 
2025-04-02 06:51:46.452576:  
2025-04-02 06:51:46.452817: Epoch 841 
2025-04-02 06:51:46.452956: Current learning rate: 0.00191 
2025-04-02 06:56:21.073953: train_loss -0.8641 
2025-04-02 06:56:21.074368: val_loss -0.6057 
2025-04-02 06:56:21.074455: Pseudo dice [0.5897] 
2025-04-02 06:56:21.074551: Epoch time: 274.63 s 
2025-04-02 06:56:23.069581:  
2025-04-02 06:56:23.069867: Epoch 842 
2025-04-02 06:56:23.070012: Current learning rate: 0.0019 
2025-04-02 07:00:58.131116: train_loss -0.8706 
2025-04-02 07:00:58.131420: val_loss -0.7099 
2025-04-02 07:00:58.131503: Pseudo dice [0.7611] 
2025-04-02 07:00:58.131594: Epoch time: 275.07 s 
2025-04-02 07:01:00.182446:  
2025-04-02 07:01:00.182640: Epoch 843 
2025-04-02 07:01:00.182778: Current learning rate: 0.00189 
2025-04-02 07:05:34.792794: train_loss -0.85 
2025-04-02 07:05:34.793128: val_loss -0.599 
2025-04-02 07:05:34.793233: Pseudo dice [0.4417] 
2025-04-02 07:05:34.793358: Epoch time: 274.61 s 
2025-04-02 07:05:36.794425:  
2025-04-02 07:05:36.794648: Epoch 844 
2025-04-02 07:05:36.794769: Current learning rate: 0.00188 
2025-04-02 07:10:25.203368: train_loss -0.8565 
2025-04-02 07:10:25.204067: val_loss -0.635 
2025-04-02 07:10:25.204175: Pseudo dice [0.6779] 
2025-04-02 07:10:25.204274: Epoch time: 288.41 s 
2025-04-02 07:10:27.218817:  
2025-04-02 07:10:27.219083: Epoch 845 
2025-04-02 07:10:27.219208: Current learning rate: 0.00187 
2025-04-02 07:15:01.376863: train_loss -0.8552 
2025-04-02 07:15:01.377203: val_loss -0.6719 
2025-04-02 07:15:01.377288: Pseudo dice [0.7261] 
2025-04-02 07:15:01.377397: Epoch time: 274.16 s 
2025-04-02 07:15:03.373389:  
2025-04-02 07:15:03.373594: Epoch 846 
2025-04-02 07:15:03.373720: Current learning rate: 0.00186 
2025-04-02 07:20:13.952222: train_loss -0.8555 
2025-04-02 07:20:13.964951: val_loss -0.6678 
2025-04-02 07:20:13.965061: Pseudo dice [0.6157] 
2025-04-02 07:20:13.965149: Epoch time: 310.58 s 
2025-04-02 07:20:16.929278:  
2025-04-02 07:20:16.929421: Epoch 847 
2025-04-02 07:20:16.929539: Current learning rate: 0.00185 
2025-04-02 07:31:36.769639: train_loss -0.8601 
2025-04-02 07:31:36.770269: val_loss -0.5978 
2025-04-02 07:31:36.770358: Pseudo dice [0.4636] 
2025-04-02 07:31:36.770449: Epoch time: 679.84 s 
2025-04-02 07:31:39.375366:  
2025-04-02 07:31:39.375518: Epoch 848 
2025-04-02 07:31:39.375696: Current learning rate: 0.00184 
2025-04-02 07:40:18.691548: train_loss -0.8666 
2025-04-02 07:40:18.691913: val_loss -0.6757 
2025-04-02 07:40:18.692013: Pseudo dice [0.6902] 
2025-04-02 07:40:18.692106: Epoch time: 519.32 s 
2025-04-02 07:40:20.801246:  
2025-04-02 07:40:20.801471: Epoch 849 
2025-04-02 07:40:20.801588: Current learning rate: 0.00182 
2025-04-02 07:44:54.548847: train_loss -0.8625 
2025-04-02 07:44:54.549373: val_loss -0.7035 
2025-04-02 07:44:54.549450: Pseudo dice [0.6995] 
2025-04-02 07:44:54.549535: Epoch time: 273.75 s 
2025-04-02 07:44:57.996413:  
2025-04-02 07:44:57.996629: Epoch 850 
2025-04-02 07:44:57.996794: Current learning rate: 0.00181 
2025-04-02 07:49:31.881418: train_loss -0.8625 
2025-04-02 07:49:31.881819: val_loss -0.6054 
2025-04-02 07:49:31.881956: Pseudo dice [0.5845] 
2025-04-02 07:49:31.882079: Epoch time: 273.89 s 
2025-04-02 07:49:33.935371:  
2025-04-02 07:49:33.935615: Epoch 851 
2025-04-02 07:49:33.935801: Current learning rate: 0.0018 
2025-04-02 07:54:08.037840: train_loss -0.8653 
2025-04-02 07:54:08.038180: val_loss -0.6696 
2025-04-02 07:54:08.038258: Pseudo dice [0.6401] 
2025-04-02 07:54:08.038355: Epoch time: 274.11 s 
2025-04-02 07:54:10.366922:  
2025-04-02 07:54:10.367166: Epoch 852 
2025-04-02 07:54:10.367289: Current learning rate: 0.00179 
2025-04-02 07:58:45.105253: train_loss -0.8512 
2025-04-02 07:58:45.105582: val_loss -0.6365 
2025-04-02 07:58:45.105671: Pseudo dice [0.5662] 
2025-04-02 07:58:45.105819: Epoch time: 274.74 s 
2025-04-02 07:58:47.144202:  
2025-04-02 07:58:47.144392: Epoch 853 
2025-04-02 07:58:47.144547: Current learning rate: 0.00178 
2025-04-02 08:03:22.270678: train_loss -0.8514 
2025-04-02 08:03:22.311166: val_loss -0.6448 
2025-04-02 08:03:22.311266: Pseudo dice [0.6956] 
2025-04-02 08:03:22.311347: Epoch time: 275.13 s 
2025-04-02 08:03:24.380383:  
2025-04-02 08:03:24.380605: Epoch 854 
2025-04-02 08:03:24.380723: Current learning rate: 0.00177 
2025-04-02 08:08:15.994306: train_loss -0.8621 
2025-04-02 08:08:15.994655: val_loss -0.6782 
2025-04-02 08:08:15.994741: Pseudo dice [0.7153] 
2025-04-02 08:08:15.994842: Epoch time: 291.62 s 
2025-04-02 08:08:18.059168:  
2025-04-02 08:08:18.059356: Epoch 855 
2025-04-02 08:08:18.059489: Current learning rate: 0.00176 
2025-04-02 08:12:51.968766: train_loss -0.8688 
2025-04-02 08:12:51.969130: val_loss -0.6335 
2025-04-02 08:12:51.969217: Pseudo dice [0.6552] 
2025-04-02 08:12:51.969318: Epoch time: 273.91 s 
2025-04-02 08:12:54.008437:  
2025-04-02 08:12:54.008643: Epoch 856 
2025-04-02 08:12:54.008752: Current learning rate: 0.00175 
2025-04-02 08:18:11.071970: train_loss -0.8607 
2025-04-02 08:18:11.072555: val_loss -0.5973 
2025-04-02 08:18:11.072660: Pseudo dice [0.54] 
2025-04-02 08:18:11.072746: Epoch time: 317.07 s 
2025-04-02 08:18:13.123455:  
2025-04-02 08:18:13.123662: Epoch 857 
2025-04-02 08:18:13.123805: Current learning rate: 0.00174 
2025-04-02 08:22:46.408136: train_loss -0.8676 
2025-04-02 08:22:46.408475: val_loss -0.6916 
2025-04-02 08:22:46.408558: Pseudo dice [0.6739] 
2025-04-02 08:22:46.408656: Epoch time: 273.29 s 
2025-04-02 08:22:48.440395:  
2025-04-02 08:22:48.440628: Epoch 858 
2025-04-02 08:22:48.440758: Current learning rate: 0.00173 
2025-04-02 08:28:49.881772: train_loss -0.8683 
2025-04-02 08:28:49.882319: val_loss -0.6215 
2025-04-02 08:28:49.882426: Pseudo dice [0.5826] 
2025-04-02 08:28:49.882515: Epoch time: 361.45 s 
2025-04-02 08:28:51.923421:  
2025-04-02 08:28:51.923659: Epoch 859 
2025-04-02 08:28:51.923835: Current learning rate: 0.00172 
2025-04-02 08:33:25.336420: train_loss -0.862 
2025-04-02 08:33:25.336742: val_loss -0.675 
2025-04-02 08:33:25.336844: Pseudo dice [0.5923] 
2025-04-02 08:33:25.336948: Epoch time: 273.42 s 
2025-04-02 08:33:27.360917:  
2025-04-02 08:33:27.361133: Epoch 860 
2025-04-02 08:33:27.361249: Current learning rate: 0.0017 
2025-04-02 08:38:01.202362: train_loss -0.8552 
2025-04-02 08:38:01.202623: val_loss -0.6686 
2025-04-02 08:38:01.202761: Pseudo dice [0.6619] 
2025-04-02 08:38:01.202856: Epoch time: 273.85 s 
2025-04-02 08:38:03.594232:  
2025-04-02 08:38:03.594544: Epoch 861 
2025-04-02 08:38:03.594686: Current learning rate: 0.00169 
2025-04-02 08:42:37.252839: train_loss -0.8641 
2025-04-02 08:42:37.253232: val_loss -0.6022 
2025-04-02 08:42:37.253319: Pseudo dice [0.6154] 
2025-04-02 08:42:37.253412: Epoch time: 273.66 s 
2025-04-02 08:42:39.292444:  
2025-04-02 08:42:39.292644: Epoch 862 
2025-04-02 08:42:39.292757: Current learning rate: 0.00168 
2025-04-02 08:47:12.702563: train_loss -0.8673 
2025-04-02 08:47:12.702928: val_loss -0.6342 
2025-04-02 08:47:12.703077: Pseudo dice [0.5435] 
2025-04-02 08:47:12.703169: Epoch time: 273.41 s 
2025-04-02 08:47:14.722504:  
2025-04-02 08:47:14.722660: Epoch 863 
2025-04-02 08:47:14.722771: Current learning rate: 0.00167 
2025-04-02 08:51:48.185127: train_loss -0.8594 
2025-04-02 08:51:48.185445: val_loss -0.7046 
2025-04-02 08:51:48.185522: Pseudo dice [0.6455] 
2025-04-02 08:51:48.185616: Epoch time: 273.47 s 
2025-04-02 08:51:50.240447:  
2025-04-02 08:51:50.240704: Epoch 864 
2025-04-02 08:51:50.240852: Current learning rate: 0.00166 
2025-04-02 08:56:42.437597: train_loss -0.859 
2025-04-02 08:56:42.437932: val_loss -0.6595 
2025-04-02 08:56:42.438021: Pseudo dice [0.7423] 
2025-04-02 08:56:42.438120: Epoch time: 292.2 s 
2025-04-02 08:56:44.497124:  
2025-04-02 08:56:44.497424: Epoch 865 
2025-04-02 08:56:44.497584: Current learning rate: 0.00165 
2025-04-02 09:01:24.444828: train_loss -0.8697 
2025-04-02 09:01:24.445168: val_loss -0.654 
2025-04-02 09:01:24.445254: Pseudo dice [0.5987] 
2025-04-02 09:01:24.445356: Epoch time: 279.95 s 
2025-04-02 09:01:26.549874:  
2025-04-02 09:01:26.550140: Epoch 866 
2025-04-02 09:01:26.550313: Current learning rate: 0.00164 
2025-04-02 09:07:24.382874: train_loss -0.8588 
2025-04-02 09:07:24.383493: val_loss -0.7388 
2025-04-02 09:07:24.383598: Pseudo dice [0.7561] 
2025-04-02 09:07:24.383730: Epoch time: 357.84 s 
2025-04-02 09:07:26.515946:  
2025-04-02 09:07:26.516197: Epoch 867 
2025-04-02 09:07:26.516345: Current learning rate: 0.00163 
2025-04-02 09:12:00.403479: train_loss -0.8654 
2025-04-02 09:12:00.403855: val_loss -0.5825 
2025-04-02 09:12:00.403943: Pseudo dice [0.6221] 
2025-04-02 09:12:00.404040: Epoch time: 273.89 s 
2025-04-02 09:12:02.437136:  
2025-04-02 09:12:02.437403: Epoch 868 
2025-04-02 09:12:02.437550: Current learning rate: 0.00162 
2025-04-02 09:16:37.036787: train_loss -0.8566 
2025-04-02 09:16:37.037332: val_loss -0.5956 
2025-04-02 09:16:37.037421: Pseudo dice [0.553] 
2025-04-02 09:16:37.037500: Epoch time: 274.6 s 
2025-04-02 09:16:39.408958:  
2025-04-02 09:16:39.409276: Epoch 869 
2025-04-02 09:16:39.409437: Current learning rate: 0.00161 
2025-04-02 09:21:13.946201: train_loss -0.85 
2025-04-02 09:21:13.946542: val_loss -0.5719 
2025-04-02 09:21:13.946626: Pseudo dice [0.6673] 
2025-04-02 09:21:13.946728: Epoch time: 274.54 s 
2025-04-02 09:21:16.004832:  
2025-04-02 09:21:16.005007: Epoch 870 
2025-04-02 09:21:16.005125: Current learning rate: 0.00159 
2025-04-02 09:25:50.357237: train_loss -0.8629 
2025-04-02 09:25:50.357602: val_loss -0.6184 
2025-04-02 09:25:50.357722: Pseudo dice [0.592] 
2025-04-02 09:25:50.357819: Epoch time: 274.36 s 
2025-04-02 09:25:52.420712:  
2025-04-02 09:25:52.421067: Epoch 871 
2025-04-02 09:25:52.421227: Current learning rate: 0.00158 
2025-04-02 09:30:27.000820: train_loss -0.8611 
2025-04-02 09:30:27.001202: val_loss -0.6096 
2025-04-02 09:30:27.001292: Pseudo dice [0.6215] 
2025-04-02 09:30:27.001393: Epoch time: 274.58 s 
2025-04-02 09:30:29.077347:  
2025-04-02 09:30:29.077563: Epoch 872 
2025-04-02 09:30:29.077677: Current learning rate: 0.00157 
2025-04-02 09:35:03.870094: train_loss -0.8561 
2025-04-02 09:35:03.870449: val_loss -0.6357 
2025-04-02 09:35:03.870563: Pseudo dice [0.6301] 
2025-04-02 09:35:03.870657: Epoch time: 274.8 s 
2025-04-02 09:35:06.014501:  
2025-04-02 09:35:06.014781: Epoch 873 
2025-04-02 09:35:06.014914: Current learning rate: 0.00156 
2025-04-02 09:39:40.668042: train_loss -0.8604 
2025-04-02 09:39:40.668406: val_loss -0.6861 
2025-04-02 09:39:40.668549: Pseudo dice [0.7251] 
2025-04-02 09:39:40.668644: Epoch time: 274.66 s 
2025-04-02 09:39:42.723885:  
2025-04-02 09:39:42.724097: Epoch 874 
2025-04-02 09:39:42.724215: Current learning rate: 0.00155 
2025-04-02 09:44:17.495481: train_loss -0.8665 
2025-04-02 09:44:17.495866: val_loss -0.6807 
2025-04-02 09:44:17.495965: Pseudo dice [0.7101] 
2025-04-02 09:44:17.496065: Epoch time: 274.78 s 
2025-04-02 09:44:19.541732:  
2025-04-02 09:44:19.541903: Epoch 875 
2025-04-02 09:44:19.542063: Current learning rate: 0.00154 
2025-04-02 09:48:54.946801: train_loss -0.8556 
2025-04-02 09:48:54.947117: val_loss -0.5345 
2025-04-02 09:48:54.947200: Pseudo dice [0.4727] 
2025-04-02 09:48:54.947307: Epoch time: 275.41 s 
2025-04-02 09:48:57.104877:  
2025-04-02 09:48:57.105133: Epoch 876 
2025-04-02 09:48:57.105258: Current learning rate: 0.00153 
2025-04-02 09:53:31.458932: train_loss -0.8551 
2025-04-02 09:53:31.459260: val_loss -0.6339 
2025-04-02 09:53:31.459408: Pseudo dice [0.6752] 
2025-04-02 09:53:31.459500: Epoch time: 274.36 s 
2025-04-02 09:53:33.557436:  
2025-04-02 09:53:33.557621: Epoch 877 
2025-04-02 09:53:33.557766: Current learning rate: 0.00152 
2025-04-02 09:58:07.900646: train_loss -0.8555 
2025-04-02 09:58:07.900993: val_loss -0.5484 
2025-04-02 09:58:07.901119: Pseudo dice [0.4449] 
2025-04-02 09:58:07.901219: Epoch time: 274.35 s 
2025-04-02 09:58:10.331932:  
2025-04-02 09:58:10.332258: Epoch 878 
2025-04-02 09:58:10.332464: Current learning rate: 0.00151 
2025-04-02 10:02:44.772551: train_loss -0.8499 
2025-04-02 10:02:44.772877: val_loss -0.6288 
2025-04-02 10:02:44.772969: Pseudo dice [0.6611] 
2025-04-02 10:02:44.773070: Epoch time: 274.44 s 
2025-04-02 10:02:46.895956:  
2025-04-02 10:02:46.896225: Epoch 879 
2025-04-02 10:02:46.896343: Current learning rate: 0.00149 
2025-04-02 10:07:21.068279: train_loss -0.867 
2025-04-02 10:07:21.068636: val_loss -0.6812 
2025-04-02 10:07:21.068717: Pseudo dice [0.7035] 
2025-04-02 10:07:21.068854: Epoch time: 274.18 s 
2025-04-02 10:07:23.140373:  
2025-04-02 10:07:23.140594: Epoch 880 
2025-04-02 10:07:23.140717: Current learning rate: 0.00148 
2025-04-02 10:11:57.348728: train_loss -0.8695 
2025-04-02 10:11:57.349091: val_loss -0.6218 
2025-04-02 10:11:57.349183: Pseudo dice [0.5922] 
2025-04-02 10:11:57.349299: Epoch time: 274.21 s 
2025-04-02 10:11:59.416278:  
2025-04-02 10:11:59.416536: Epoch 881 
2025-04-02 10:11:59.416704: Current learning rate: 0.00147 
2025-04-02 10:16:33.546518: train_loss -0.8572 
2025-04-02 10:16:33.546819: val_loss -0.6616 
2025-04-02 10:16:33.546905: Pseudo dice [0.677] 
2025-04-02 10:16:33.546988: Epoch time: 274.13 s 
2025-04-02 10:16:35.590064:  
2025-04-02 10:16:35.590257: Epoch 882 
2025-04-02 10:16:35.590372: Current learning rate: 0.00146 
2025-04-02 10:21:09.923803: train_loss -0.8634 
2025-04-02 10:21:09.924121: val_loss -0.583 
2025-04-02 10:21:09.924204: Pseudo dice [0.4673] 
2025-04-02 10:21:09.924306: Epoch time: 274.34 s 
2025-04-02 10:21:11.980896:  
2025-04-02 10:21:11.981117: Epoch 883 
2025-04-02 10:21:11.981231: Current learning rate: 0.00145 
2025-04-02 10:25:46.827861: train_loss -0.8667 
2025-04-02 10:25:46.828234: val_loss -0.5941 
2025-04-02 10:25:46.828318: Pseudo dice [0.5203] 
2025-04-02 10:25:46.828413: Epoch time: 274.85 s 
2025-04-02 10:25:48.890397:  
2025-04-02 10:25:48.890707: Epoch 884 
2025-04-02 10:25:48.890843: Current learning rate: 0.00144 
2025-04-02 10:30:31.520547: train_loss -0.8578 
2025-04-02 10:30:31.521240: val_loss -0.6815 
2025-04-02 10:30:31.521351: Pseudo dice [0.7055] 
2025-04-02 10:30:31.521441: Epoch time: 282.63 s 
2025-04-02 10:30:33.586210:  
2025-04-02 10:30:33.586444: Epoch 885 
2025-04-02 10:30:33.586560: Current learning rate: 0.00143 
2025-04-02 10:35:07.563674: train_loss -0.868 
2025-04-02 10:35:07.564054: val_loss -0.5679 
2025-04-02 10:35:07.564151: Pseudo dice [0.5942] 
2025-04-02 10:35:07.564286: Epoch time: 273.98 s 
2025-04-02 10:35:10.005077:  
2025-04-02 10:35:10.005291: Epoch 886 
2025-04-02 10:35:10.005436: Current learning rate: 0.00142 
2025-04-02 10:39:44.104205: train_loss -0.8542 
2025-04-02 10:39:44.104546: val_loss -0.6133 
2025-04-02 10:39:44.104650: Pseudo dice [0.5304] 
2025-04-02 10:39:44.104753: Epoch time: 274.1 s 
2025-04-02 10:39:46.318476:  
2025-04-02 10:39:46.318674: Epoch 887 
2025-04-02 10:39:46.318794: Current learning rate: 0.00141 
2025-04-02 10:44:20.356586: train_loss -0.855 
2025-04-02 10:44:20.356957: val_loss -0.5346 
2025-04-02 10:44:20.357040: Pseudo dice [0.5663] 
2025-04-02 10:44:20.357136: Epoch time: 274.04 s 
2025-04-02 10:44:22.419482:  
2025-04-02 10:44:22.419684: Epoch 888 
2025-04-02 10:44:22.419803: Current learning rate: 0.00139 
2025-04-02 10:48:56.193223: train_loss -0.8701 
2025-04-02 10:48:56.193547: val_loss -0.5254 
2025-04-02 10:48:56.193637: Pseudo dice [0.4772] 
2025-04-02 10:48:56.193720: Epoch time: 273.78 s 
2025-04-02 10:48:58.267457:  
2025-04-02 10:48:58.267681: Epoch 889 
2025-04-02 10:48:58.267879: Current learning rate: 0.00138 
2025-04-02 10:53:32.406938: train_loss -0.8673 
2025-04-02 10:53:32.407267: val_loss -0.7181 
2025-04-02 10:53:32.407356: Pseudo dice [0.7658] 
2025-04-02 10:53:32.407458: Epoch time: 274.14 s 
2025-04-02 10:53:34.469109:  
2025-04-02 10:53:34.469368: Epoch 890 
2025-04-02 10:53:34.469499: Current learning rate: 0.00137 
2025-04-02 10:58:08.705706: train_loss -0.8551 
2025-04-02 10:58:08.706046: val_loss -0.6943 
2025-04-02 10:58:08.706176: Pseudo dice [0.7191] 
2025-04-02 10:58:08.706270: Epoch time: 274.24 s 
2025-04-02 10:58:10.767866:  
2025-04-02 10:58:10.768086: Epoch 891 
2025-04-02 10:58:10.768232: Current learning rate: 0.00136 
2025-04-02 11:02:45.074400: train_loss -0.8606 
2025-04-02 11:02:45.074705: val_loss -0.7335 
2025-04-02 11:02:45.074789: Pseudo dice [0.6898] 
2025-04-02 11:02:45.074880: Epoch time: 274.31 s 
2025-04-02 11:02:47.128235:  
2025-04-02 11:02:47.128455: Epoch 892 
2025-04-02 11:02:47.128586: Current learning rate: 0.00135 
2025-04-02 11:07:21.451968: train_loss -0.875 
2025-04-02 11:07:21.452381: val_loss -0.6077 
2025-04-02 11:07:21.452513: Pseudo dice [0.5739] 
2025-04-02 11:07:21.452595: Epoch time: 274.33 s 
2025-04-02 11:07:23.513430:  
2025-04-02 11:07:23.513632: Epoch 893 
2025-04-02 11:07:23.513748: Current learning rate: 0.00134 
2025-04-02 11:11:58.031669: train_loss -0.8654 
2025-04-02 11:11:58.032028: val_loss -0.592 
2025-04-02 11:11:58.032123: Pseudo dice [0.5664] 
2025-04-02 11:11:58.032223: Epoch time: 274.52 s 
2025-04-02 11:12:00.089163:  
2025-04-02 11:12:00.089364: Epoch 894 
2025-04-02 11:12:00.089488: Current learning rate: 0.00133 
2025-04-02 11:16:34.480705: train_loss -0.8693 
2025-04-02 11:16:34.481023: val_loss -0.7349 
2025-04-02 11:16:34.481103: Pseudo dice [0.6949] 
2025-04-02 11:16:34.481189: Epoch time: 274.4 s 
2025-04-02 11:16:36.526679:  
2025-04-02 11:16:36.526920: Epoch 895 
2025-04-02 11:16:36.527043: Current learning rate: 0.00132 
2025-04-02 11:21:10.276376: train_loss -0.8709 
2025-04-02 11:21:10.276721: val_loss -0.6192 
2025-04-02 11:21:10.277245: Pseudo dice [0.5838] 
2025-04-02 11:21:10.277326: Epoch time: 273.75 s 
2025-04-02 11:21:12.348216:  
2025-04-02 11:21:12.348406: Epoch 896 
2025-04-02 11:21:12.348518: Current learning rate: 0.0013 
2025-04-02 11:25:45.950777: train_loss -0.8671 
2025-04-02 11:25:45.951115: val_loss -0.6811 
2025-04-02 11:25:45.951227: Pseudo dice [0.684] 
2025-04-02 11:25:45.951322: Epoch time: 273.61 s 
2025-04-02 11:25:48.029595:  
2025-04-02 11:25:48.029835: Epoch 897 
2025-04-02 11:25:48.029986: Current learning rate: 0.00129 
2025-04-02 11:30:21.086694: train_loss -0.8751 
2025-04-02 11:30:21.087003: val_loss -0.6859 
2025-04-02 11:30:21.089752: Pseudo dice [0.592] 
2025-04-02 11:30:21.089840: Epoch time: 273.06 s 
2025-04-02 11:30:23.153998:  
2025-04-02 11:30:23.154212: Epoch 898 
2025-04-02 11:30:23.154350: Current learning rate: 0.00128 
2025-04-02 11:34:55.805162: train_loss -0.8767 
2025-04-02 11:34:55.805478: val_loss -0.4972 
2025-04-02 11:34:55.805599: Pseudo dice [0.4125] 
2025-04-02 11:34:55.805696: Epoch time: 272.66 s 
2025-04-02 11:34:57.874036:  
2025-04-02 11:34:57.874286: Epoch 899 
2025-04-02 11:34:57.874419: Current learning rate: 0.00127 
2025-04-02 11:39:30.630791: train_loss -0.874 
2025-04-02 11:39:30.631167: val_loss -0.5228 
2025-04-02 11:39:30.631270: Pseudo dice [0.431] 
2025-04-02 11:39:30.631360: Epoch time: 272.76 s 
2025-04-02 11:39:33.989236:  
2025-04-02 11:39:33.989439: Epoch 900 
2025-04-02 11:39:33.989551: Current learning rate: 0.00126 
2025-04-02 11:44:06.747692: train_loss -0.8736 
2025-04-02 11:44:06.748015: val_loss -0.6866 
2025-04-02 11:44:06.748214: Pseudo dice [0.4854] 
2025-04-02 11:44:06.748300: Epoch time: 272.76 s 
2025-04-02 11:44:08.785152:  
2025-04-02 11:44:08.785370: Epoch 901 
2025-04-02 11:44:08.785487: Current learning rate: 0.00125 
2025-04-02 11:48:41.633395: train_loss -0.8788 
2025-04-02 11:48:41.633697: val_loss -0.533 
2025-04-02 11:48:41.633791: Pseudo dice [0.4942] 
2025-04-02 11:48:41.633886: Epoch time: 272.85 s 
2025-04-02 11:48:43.960074:  
2025-04-02 11:48:43.960287: Epoch 902 
2025-04-02 11:48:43.960409: Current learning rate: 0.00124 
2025-04-02 11:53:16.695922: train_loss -0.8764 
2025-04-02 11:53:16.696282: val_loss -0.6037 
2025-04-02 11:53:16.696374: Pseudo dice [0.6159] 
2025-04-02 11:53:16.696468: Epoch time: 272.74 s 
2025-04-02 11:53:18.748560:  
2025-04-02 11:53:18.748787: Epoch 903 
2025-04-02 11:53:18.748920: Current learning rate: 0.00122 
2025-04-02 11:57:51.279791: train_loss -0.8743 
2025-04-02 11:57:51.280140: val_loss -0.6281 
2025-04-02 11:57:51.280226: Pseudo dice [0.6387] 
2025-04-02 11:57:51.280324: Epoch time: 272.54 s 
2025-04-02 11:57:53.355758:  
2025-04-02 11:57:53.356068: Epoch 904 
2025-04-02 11:57:53.356190: Current learning rate: 0.00121 
2025-04-02 12:02:26.567372: train_loss -0.8709 
2025-04-02 12:02:26.567702: val_loss -0.5841 
2025-04-02 12:02:26.567794: Pseudo dice [0.6422] 
2025-04-02 12:02:26.567893: Epoch time: 273.22 s 
2025-04-02 12:02:28.677299:  
2025-04-02 12:02:28.677567: Epoch 905 
2025-04-02 12:02:28.677711: Current learning rate: 0.0012 
2025-04-02 12:07:02.560951: train_loss -0.8647 
2025-04-02 12:07:02.561279: val_loss -0.5723 
2025-04-02 12:07:02.561377: Pseudo dice [0.4413] 
2025-04-02 12:07:02.561500: Epoch time: 273.89 s 
2025-04-02 12:07:04.613012:  
2025-04-02 12:07:04.613244: Epoch 906 
2025-04-02 12:07:04.613379: Current learning rate: 0.00119 
2025-04-02 12:11:38.500806: train_loss -0.8678 
2025-04-02 12:11:38.501123: val_loss -0.6853 
2025-04-02 12:11:38.501206: Pseudo dice [0.6954] 
2025-04-02 12:11:38.501307: Epoch time: 273.89 s 
2025-04-02 12:11:40.536421:  
2025-04-02 12:11:40.536647: Epoch 907 
2025-04-02 12:11:40.536763: Current learning rate: 0.00118 
2025-04-02 12:16:13.466931: train_loss -0.8675 
2025-04-02 12:16:13.467292: val_loss -0.6638 
2025-04-02 12:16:13.467377: Pseudo dice [0.6829] 
2025-04-02 12:16:13.467473: Epoch time: 272.93 s 
2025-04-02 12:16:15.516714:  
2025-04-02 12:16:15.516990: Epoch 908 
2025-04-02 12:16:15.517129: Current learning rate: 0.00117 
2025-04-02 12:20:48.624558: train_loss -0.8571 
2025-04-02 12:20:48.624937: val_loss -0.6289 
2025-04-02 12:20:48.625039: Pseudo dice [0.4386] 
2025-04-02 12:20:48.625132: Epoch time: 273.11 s 
2025-04-02 12:20:50.679144:  
2025-04-02 12:20:50.679362: Epoch 909 
2025-04-02 12:20:50.679486: Current learning rate: 0.00116 
2025-04-02 12:25:23.980211: train_loss -0.8592 
2025-04-02 12:25:23.980519: val_loss -0.6757 
2025-04-02 12:25:23.980621: Pseudo dice [0.7] 
2025-04-02 12:25:23.980760: Epoch time: 273.31 s 
2025-04-02 12:25:26.343898:  
2025-04-02 12:25:26.344116: Epoch 910 
2025-04-02 12:25:26.344276: Current learning rate: 0.00115 
2025-04-02 12:29:59.337794: train_loss -0.86 
2025-04-02 12:29:59.338119: val_loss -0.6134 
2025-04-02 12:29:59.338221: Pseudo dice [0.6159] 
2025-04-02 12:29:59.338316: Epoch time: 273.0 s 
2025-04-02 12:30:01.407030:  
2025-04-02 12:30:01.407226: Epoch 911 
2025-04-02 12:30:01.407343: Current learning rate: 0.00113 
2025-04-02 12:34:34.850977: train_loss -0.8639 
2025-04-02 12:34:34.851318: val_loss -0.621 
2025-04-02 12:34:34.851401: Pseudo dice [0.663] 
2025-04-02 12:34:34.851522: Epoch time: 273.45 s 
2025-04-02 12:34:36.907038:  
2025-04-02 12:34:36.907282: Epoch 912 
2025-04-02 12:34:36.907417: Current learning rate: 0.00112 
2025-04-02 12:39:10.061138: train_loss -0.8643 
2025-04-02 12:39:10.061455: val_loss -0.5267 
2025-04-02 12:39:10.061541: Pseudo dice [0.5282] 
2025-04-02 12:39:10.061646: Epoch time: 273.16 s 
2025-04-02 12:39:12.103402:  
2025-04-02 12:39:12.103618: Epoch 913 
2025-04-02 12:39:12.103734: Current learning rate: 0.00111 
2025-04-02 12:43:45.174547: train_loss -0.8633 
2025-04-02 12:43:45.174862: val_loss -0.6365 
2025-04-02 12:43:45.174978: Pseudo dice [0.6566] 
2025-04-02 12:43:45.175078: Epoch time: 273.08 s 
2025-04-02 12:43:47.226486:  
2025-04-02 12:43:47.226758: Epoch 914 
2025-04-02 12:43:47.226933: Current learning rate: 0.0011 
2025-04-02 12:48:20.348913: train_loss -0.8754 
2025-04-02 12:48:20.349244: val_loss -0.6398 
2025-04-02 12:48:20.349332: Pseudo dice [0.6346] 
2025-04-02 12:48:20.349431: Epoch time: 273.13 s 
2025-04-02 12:48:22.407705:  
2025-04-02 12:48:22.408040: Epoch 915 
2025-04-02 12:48:22.408201: Current learning rate: 0.00109 
2025-04-02 12:52:56.421418: train_loss -0.871 
2025-04-02 12:52:56.421763: val_loss -0.5855 
2025-04-02 12:52:56.421855: Pseudo dice [0.435] 
2025-04-02 12:52:56.421975: Epoch time: 274.02 s 
2025-04-02 12:52:58.494041:  
2025-04-02 12:52:58.494344: Epoch 916 
2025-04-02 12:52:58.494491: Current learning rate: 0.00108 
2025-04-02 12:57:32.510656: train_loss -0.8624 
2025-04-02 12:57:32.510996: val_loss -0.6551 
2025-04-02 12:57:32.511088: Pseudo dice [0.6629] 
2025-04-02 12:57:32.511187: Epoch time: 274.02 s 
2025-04-02 12:57:34.572934:  
2025-04-02 12:57:34.573150: Epoch 917 
2025-04-02 12:57:34.573265: Current learning rate: 0.00106 
2025-04-02 13:02:08.871528: train_loss -0.8703 
2025-04-02 13:02:08.871871: val_loss -0.7208 
2025-04-02 13:02:08.871972: Pseudo dice [0.7487] 
2025-04-02 13:02:08.872099: Epoch time: 274.3 s 
2025-04-02 13:02:10.912913:  
2025-04-02 13:02:10.913169: Epoch 918 
2025-04-02 13:02:10.913320: Current learning rate: 0.00105 
2025-04-02 13:06:44.638867: train_loss -0.8748 
2025-04-02 13:06:44.639328: val_loss -0.651 
2025-04-02 13:06:44.639426: Pseudo dice [0.642] 
2025-04-02 13:06:44.639508: Epoch time: 273.73 s 
2025-04-02 13:06:47.075246:  
2025-04-02 13:06:47.075460: Epoch 919 
2025-04-02 13:06:47.075579: Current learning rate: 0.00104 
2025-04-02 13:11:24.664792: train_loss -0.8758 
2025-04-02 13:11:24.665355: val_loss -0.6881 
2025-04-02 13:11:24.665436: Pseudo dice [0.7476] 
2025-04-02 13:11:24.665514: Epoch time: 277.59 s 
2025-04-02 13:11:26.736059:  
2025-04-02 13:11:26.736362: Epoch 920 
2025-04-02 13:11:26.736486: Current learning rate: 0.00103 
2025-04-02 13:16:00.344565: train_loss -0.8695 
2025-04-02 13:16:00.344901: val_loss -0.6391 
2025-04-02 13:16:00.345004: Pseudo dice [0.7005] 
2025-04-02 13:16:00.345099: Epoch time: 273.61 s 
2025-04-02 13:16:02.429787:  
2025-04-02 13:16:02.430041: Epoch 921 
2025-04-02 13:16:02.430180: Current learning rate: 0.00102 
2025-04-02 13:20:36.006342: train_loss -0.8723 
2025-04-02 13:20:36.006705: val_loss -0.7212 
2025-04-02 13:20:36.006789: Pseudo dice [0.7657] 
2025-04-02 13:20:36.006884: Epoch time: 273.58 s 
2025-04-02 13:20:38.123712:  
2025-04-02 13:20:38.124018: Epoch 922 
2025-04-02 13:20:38.124179: Current learning rate: 0.00101 
2025-04-02 13:25:11.642892: train_loss -0.8773 
2025-04-02 13:25:11.643197: val_loss -0.6595 
2025-04-02 13:25:11.643275: Pseudo dice [0.689] 
2025-04-02 13:25:11.643357: Epoch time: 273.52 s 
2025-04-02 13:25:13.686552:  
2025-04-02 13:25:13.686766: Epoch 923 
2025-04-02 13:25:13.686886: Current learning rate: 0.001 
2025-04-02 13:29:47.963514: train_loss -0.869 
2025-04-02 13:29:47.963876: val_loss -0.6847 
2025-04-02 13:29:47.963964: Pseudo dice [0.7525] 
2025-04-02 13:29:47.964107: Epoch time: 274.28 s 
2025-04-02 13:29:50.025830:  
2025-04-02 13:29:50.026037: Epoch 924 
2025-04-02 13:29:50.026156: Current learning rate: 0.00098 
2025-04-02 13:34:24.369760: train_loss -0.8738 
2025-04-02 13:34:24.370083: val_loss -0.5854 
2025-04-02 13:34:24.370169: Pseudo dice [0.69] 
2025-04-02 13:34:24.370282: Epoch time: 274.35 s 
2025-04-02 13:34:26.425978:  
2025-04-02 13:34:26.426185: Epoch 925 
2025-04-02 13:34:26.426303: Current learning rate: 0.00097 
2025-04-02 13:39:00.640203: train_loss -0.8695 
2025-04-02 13:39:00.640540: val_loss -0.6497 
2025-04-02 13:39:00.640625: Pseudo dice [0.7148] 
2025-04-02 13:39:00.640722: Epoch time: 274.22 s 
2025-04-02 13:39:02.689564:  
2025-04-02 13:39:02.689767: Epoch 926 
2025-04-02 13:39:02.689911: Current learning rate: 0.00096 
2025-04-02 13:43:37.238248: train_loss -0.8724 
2025-04-02 13:43:37.238557: val_loss -0.6994 
2025-04-02 13:43:37.238639: Pseudo dice [0.735] 
2025-04-02 13:43:37.238723: Epoch time: 274.55 s 
2025-04-02 13:43:39.289549:  
2025-04-02 13:43:39.289829: Epoch 927 
2025-04-02 13:43:39.289994: Current learning rate: 0.00095 
2025-04-02 13:48:13.670175: train_loss -0.8715 
2025-04-02 13:48:13.670509: val_loss -0.6858 
2025-04-02 13:48:13.670597: Pseudo dice [0.6505] 
2025-04-02 13:48:13.670717: Epoch time: 274.38 s 
2025-04-02 13:48:16.037697:  
2025-04-02 13:48:16.037918: Epoch 928 
2025-04-02 13:48:16.038055: Current learning rate: 0.00094 
2025-04-02 13:52:49.849621: train_loss -0.8773 
2025-04-02 13:52:49.849998: val_loss -0.6569 
2025-04-02 13:52:49.850097: Pseudo dice [0.7015] 
2025-04-02 13:52:49.850191: Epoch time: 273.82 s 
2025-04-02 13:52:51.903058:  
2025-04-02 13:52:51.903281: Epoch 929 
2025-04-02 13:52:51.903398: Current learning rate: 0.00092 
2025-04-02 13:57:25.402447: train_loss -0.8752 
2025-04-02 13:57:25.402783: val_loss -0.6609 
2025-04-02 13:57:25.402863: Pseudo dice [0.7561] 
2025-04-02 13:57:25.402958: Epoch time: 273.5 s 
2025-04-02 13:57:27.448500:  
2025-04-02 13:57:27.448710: Epoch 930 
2025-04-02 13:57:27.448824: Current learning rate: 0.00091 
2025-04-02 14:02:00.754282: train_loss -0.8712 
2025-04-02 14:02:00.754626: val_loss -0.6611 
2025-04-02 14:02:00.755004: Pseudo dice [0.747] 
2025-04-02 14:02:00.755091: Epoch time: 273.31 s 
2025-04-02 14:02:02.821012:  
2025-04-02 14:02:02.821277: Epoch 931 
2025-04-02 14:02:02.821432: Current learning rate: 0.0009 
2025-04-02 14:06:36.112428: train_loss -0.8824 
2025-04-02 14:06:36.112777: val_loss -0.7055 
2025-04-02 14:06:36.112864: Pseudo dice [0.7704] 
2025-04-02 14:06:36.112961: Epoch time: 273.3 s 
2025-04-02 14:06:36.113016: Yayy! New best EMA pseudo Dice: 0.6982 
2025-04-02 14:06:39.425112:  
2025-04-02 14:06:39.425308: Epoch 932 
2025-04-02 14:06:39.425421: Current learning rate: 0.00089 
2025-04-02 14:11:12.913478: train_loss -0.8806 
2025-04-02 14:11:12.913825: val_loss -0.7082 
2025-04-02 14:11:12.913919: Pseudo dice [0.7286] 
2025-04-02 14:11:12.914023: Epoch time: 273.49 s 
2025-04-02 14:11:12.914119: Yayy! New best EMA pseudo Dice: 0.7012 
2025-04-02 14:11:16.380068:  
2025-04-02 14:11:16.380310: Epoch 933 
2025-04-02 14:11:16.380487: Current learning rate: 0.00088 
2025-04-02 14:15:49.934522: train_loss -0.881 
2025-04-02 14:15:49.934842: val_loss -0.6796 
2025-04-02 14:15:49.934923: Pseudo dice [0.7389] 
2025-04-02 14:15:49.935023: Epoch time: 273.56 s 
2025-04-02 14:15:49.935080: Yayy! New best EMA pseudo Dice: 0.705 
2025-04-02 14:15:53.666073:  
2025-04-02 14:15:53.666305: Epoch 934 
2025-04-02 14:15:53.666492: Current learning rate: 0.00087 
2025-04-02 14:20:27.254424: train_loss -0.8772 
2025-04-02 14:20:27.254761: val_loss -0.7129 
2025-04-02 14:20:27.254849: Pseudo dice [0.7053] 
2025-04-02 14:20:27.254948: Epoch time: 273.59 s 
2025-04-02 14:20:27.255007: Yayy! New best EMA pseudo Dice: 0.705 
2025-04-02 14:20:30.719344:  
2025-04-02 14:20:30.719591: Epoch 935 
2025-04-02 14:20:30.719708: Current learning rate: 0.00085 
2025-04-02 14:25:03.948766: train_loss -0.8723 
2025-04-02 14:25:03.949095: val_loss -0.6593 
2025-04-02 14:25:03.949177: Pseudo dice [0.7015] 
2025-04-02 14:25:03.949278: Epoch time: 273.23 s 
2025-04-02 14:25:05.999978:  
2025-04-02 14:25:06.000243: Epoch 936 
2025-04-02 14:25:06.000407: Current learning rate: 0.00084 
2025-04-02 14:29:39.869678: train_loss -0.8716 
2025-04-02 14:29:39.870030: val_loss -0.6598 
2025-04-02 14:29:39.870124: Pseudo dice [0.756] 
2025-04-02 14:29:39.870221: Epoch time: 273.87 s 
2025-04-02 14:29:39.870279: Yayy! New best EMA pseudo Dice: 0.7098 
2025-04-02 14:29:43.344521:  
2025-04-02 14:29:43.344685: Epoch 937 
2025-04-02 14:29:43.344825: Current learning rate: 0.00083 
2025-04-02 14:34:17.425718: train_loss -0.8748 
2025-04-02 14:34:17.426061: val_loss -0.7197 
2025-04-02 14:34:17.426153: Pseudo dice [0.777] 
2025-04-02 14:34:17.426256: Epoch time: 274.09 s 
2025-04-02 14:34:17.426316: Yayy! New best EMA pseudo Dice: 0.7165 
2025-04-02 14:34:20.906248:  
2025-04-02 14:34:20.906481: Epoch 938 
2025-04-02 14:34:20.906624: Current learning rate: 0.00082 
2025-04-02 14:38:54.906549: train_loss -0.8721 
2025-04-02 14:38:54.906865: val_loss -0.5979 
2025-04-02 14:38:54.906951: Pseudo dice [0.5453] 
2025-04-02 14:38:54.907050: Epoch time: 274.0 s 
2025-04-02 14:38:57.100861:  
2025-04-02 14:38:57.101073: Epoch 939 
2025-04-02 14:38:57.101213: Current learning rate: 0.00081 
2025-04-02 14:43:31.256371: train_loss -0.8692 
2025-04-02 14:43:31.256786: val_loss -0.6447 
2025-04-02 14:43:31.256903: Pseudo dice [0.6513] 
2025-04-02 14:43:31.256989: Epoch time: 274.16 s 
2025-04-02 14:43:33.300500:  
2025-04-02 14:43:33.300699: Epoch 940 
2025-04-02 14:43:33.300828: Current learning rate: 0.00079 
2025-04-02 14:48:07.402640: train_loss -0.8742 
2025-04-02 14:48:07.402971: val_loss -0.6799 
2025-04-02 14:48:07.403061: Pseudo dice [0.6752] 
2025-04-02 14:48:07.403168: Epoch time: 274.11 s 
2025-04-02 14:48:09.782801:  
2025-04-02 14:48:09.783074: Epoch 941 
2025-04-02 14:48:09.783222: Current learning rate: 0.00078 
2025-04-02 14:52:43.844728: train_loss -0.8794 
2025-04-02 14:52:43.845120: val_loss -0.6612 
2025-04-02 14:52:43.845205: Pseudo dice [0.6843] 
2025-04-02 14:52:43.845294: Epoch time: 274.07 s 
2025-04-02 14:52:45.918652:  
2025-04-02 14:52:45.918872: Epoch 942 
2025-04-02 14:52:45.919008: Current learning rate: 0.00077 
2025-04-02 14:57:19.908521: train_loss -0.874 
2025-04-02 14:57:19.908854: val_loss -0.562 
2025-04-02 14:57:19.908940: Pseudo dice [0.5997] 
2025-04-02 14:57:19.909042: Epoch time: 273.99 s 
2025-04-02 14:57:21.997004:  
2025-04-02 14:57:21.997335: Epoch 943 
2025-04-02 14:57:21.997525: Current learning rate: 0.00076 
2025-04-02 15:01:55.986976: train_loss -0.8809 
2025-04-02 15:01:55.987290: val_loss -0.7171 
2025-04-02 15:01:55.987381: Pseudo dice [0.7481] 
2025-04-02 15:01:55.987478: Epoch time: 273.99 s 
2025-04-02 15:01:58.085556:  
2025-04-02 15:01:58.085738: Epoch 944 
2025-04-02 15:01:58.085917: Current learning rate: 0.00075 
2025-04-02 15:06:32.459579: train_loss -0.8783 
2025-04-02 15:06:32.460044: val_loss -0.5798 
2025-04-02 15:06:32.460219: Pseudo dice [0.4246] 
2025-04-02 15:06:32.460317: Epoch time: 274.38 s 
2025-04-02 15:06:34.516437:  
2025-04-02 15:06:34.516662: Epoch 945 
2025-04-02 15:06:34.516783: Current learning rate: 0.00074 
2025-04-02 15:11:08.878578: train_loss -0.8852 
2025-04-02 15:11:08.878933: val_loss -0.552 
2025-04-02 15:11:08.879016: Pseudo dice [0.6205] 
2025-04-02 15:11:08.879109: Epoch time: 274.37 s 
2025-04-02 15:11:10.932479:  
2025-04-02 15:11:10.932698: Epoch 946 
2025-04-02 15:11:10.932826: Current learning rate: 0.00072 
2025-04-02 15:15:45.466435: train_loss -0.8781 
2025-04-02 15:15:45.466725: val_loss -0.6207 
2025-04-02 15:15:45.466813: Pseudo dice [0.6573] 
2025-04-02 15:15:45.466923: Epoch time: 274.54 s 
2025-04-02 15:15:47.512597:  
2025-04-02 15:15:47.512800: Epoch 947 
2025-04-02 15:15:47.512914: Current learning rate: 0.00071 
2025-04-02 15:20:22.277475: train_loss -0.877 
2025-04-02 15:20:22.277862: val_loss -0.7069 
2025-04-02 15:20:22.277951: Pseudo dice [0.7663] 
2025-04-02 15:20:22.278048: Epoch time: 274.77 s 
2025-04-02 15:20:24.345899:  
2025-04-02 15:20:24.346063: Epoch 948 
2025-04-02 15:20:24.346196: Current learning rate: 0.0007 
2025-04-02 15:25:10.146101: train_loss -0.8798 
2025-04-02 15:25:10.146745: val_loss -0.5034 
2025-04-02 15:25:10.146848: Pseudo dice [0.461] 
2025-04-02 15:25:10.146934: Epoch time: 285.8 s 
2025-04-02 15:25:12.247082:  
2025-04-02 15:25:12.247273: Epoch 949 
2025-04-02 15:25:12.247387: Current learning rate: 0.00069 
2025-04-02 15:29:46.808203: train_loss -0.8803 
2025-04-02 15:29:46.808549: val_loss -0.6413 
2025-04-02 15:29:46.808636: Pseudo dice [0.5255] 
2025-04-02 15:29:46.808735: Epoch time: 274.57 s 
2025-04-02 15:29:50.516561:  
2025-04-02 15:29:50.516775: Epoch 950 
2025-04-02 15:29:50.516893: Current learning rate: 0.00067 
2025-04-02 15:34:24.199309: train_loss -0.8845 
2025-04-02 15:34:24.199675: val_loss -0.5995 
2025-04-02 15:34:24.199775: Pseudo dice [0.673] 
2025-04-02 15:34:24.199872: Epoch time: 273.69 s 
2025-04-02 15:34:26.258136:  
2025-04-02 15:34:26.258310: Epoch 951 
2025-04-02 15:34:26.258462: Current learning rate: 0.00066 
2025-04-02 15:38:59.995515: train_loss -0.8803 
2025-04-02 15:38:59.995893: val_loss -0.6284 
2025-04-02 15:38:59.996257: Pseudo dice [0.6369] 
2025-04-02 15:38:59.996344: Epoch time: 273.74 s 
2025-04-02 15:39:02.047442:  
2025-04-02 15:39:02.047656: Epoch 952 
2025-04-02 15:39:02.047781: Current learning rate: 0.00065 
2025-04-02 15:43:36.031054: train_loss -0.8766 
2025-04-02 15:43:36.031398: val_loss -0.6294 
2025-04-02 15:43:36.031481: Pseudo dice [0.597] 
2025-04-02 15:43:36.031579: Epoch time: 273.99 s 
2025-04-02 15:43:38.087051:  
2025-04-02 15:43:38.087282: Epoch 953 
2025-04-02 15:43:38.087450: Current learning rate: 0.00064 
2025-04-02 15:48:12.059687: train_loss -0.8776 
2025-04-02 15:48:12.060043: val_loss -0.6768 
2025-04-02 15:48:12.060133: Pseudo dice [0.6448] 
2025-04-02 15:48:12.060224: Epoch time: 273.98 s 
2025-04-02 15:48:14.169560:  
2025-04-02 15:48:14.169798: Epoch 954 
2025-04-02 15:48:14.169975: Current learning rate: 0.00063 
2025-04-02 15:52:48.205568: train_loss -0.8815 
2025-04-02 15:52:48.205883: val_loss -0.6549 
2025-04-02 15:52:48.205964: Pseudo dice [0.7083] 
2025-04-02 15:52:48.206050: Epoch time: 274.04 s 
2025-04-02 15:52:50.295201:  
2025-04-02 15:52:50.295458: Epoch 955 
2025-04-02 15:52:50.295621: Current learning rate: 0.00061 
2025-04-02 15:57:24.353029: train_loss -0.8781 
2025-04-02 15:57:24.353392: val_loss -0.7063 
2025-04-02 15:57:24.353476: Pseudo dice [0.6687] 
2025-04-02 15:57:24.353566: Epoch time: 274.06 s 
2025-04-02 15:57:26.437517:  
2025-04-02 15:57:26.437695: Epoch 956 
2025-04-02 15:57:26.437808: Current learning rate: 0.0006 
2025-04-02 16:02:00.094260: train_loss -0.8735 
2025-04-02 16:02:00.094664: val_loss -0.6728 
2025-04-02 16:02:00.094763: Pseudo dice [0.686] 
2025-04-02 16:02:00.094846: Epoch time: 273.66 s 
2025-04-02 16:02:02.160307:  
2025-04-02 16:02:02.160498: Epoch 957 
2025-04-02 16:02:02.160608: Current learning rate: 0.00059 
2025-04-02 16:06:35.313261: train_loss -0.88 
2025-04-02 16:06:35.313628: val_loss -0.655 
2025-04-02 16:06:35.313741: Pseudo dice [0.6797] 
2025-04-02 16:06:35.313842: Epoch time: 273.16 s 
2025-04-02 16:06:37.698033:  
2025-04-02 16:06:37.698264: Epoch 958 
2025-04-02 16:06:37.698394: Current learning rate: 0.00058 
2025-04-02 16:11:10.901640: train_loss -0.874 
2025-04-02 16:11:10.901981: val_loss -0.6227 
2025-04-02 16:11:10.902080: Pseudo dice [0.6441] 
2025-04-02 16:11:10.902227: Epoch time: 273.21 s 
2025-04-02 16:11:12.990907:  
2025-04-02 16:11:12.991174: Epoch 959 
2025-04-02 16:11:12.991292: Current learning rate: 0.00056 
2025-04-02 16:15:46.058886: train_loss -0.8827 
2025-04-02 16:15:46.059196: val_loss -0.6566 
2025-04-02 16:15:46.059280: Pseudo dice [0.5175] 
2025-04-02 16:15:46.059456: Epoch time: 273.07 s 
2025-04-02 16:15:48.140452:  
2025-04-02 16:15:48.140636: Epoch 960 
2025-04-02 16:15:48.140750: Current learning rate: 0.00055 
2025-04-02 16:20:21.344481: train_loss -0.875 
2025-04-02 16:20:21.344833: val_loss -0.5919 
2025-04-02 16:20:21.344945: Pseudo dice [0.613] 
2025-04-02 16:20:21.345043: Epoch time: 273.21 s 
2025-04-02 16:20:23.412556:  
2025-04-02 16:20:23.412786: Epoch 961 
2025-04-02 16:20:23.412900: Current learning rate: 0.00054 
2025-04-02 16:24:56.718170: train_loss -0.8801 
2025-04-02 16:24:56.718534: val_loss -0.5967 
2025-04-02 16:24:56.718629: Pseudo dice [0.432] 
2025-04-02 16:24:56.718741: Epoch time: 273.31 s 
2025-04-02 16:24:58.798763:  
2025-04-02 16:24:58.799027: Epoch 962 
2025-04-02 16:24:58.799152: Current learning rate: 0.00053 
2025-04-02 16:29:31.024898: train_loss -0.8812 
2025-04-02 16:29:31.025229: val_loss -0.5872 
2025-04-02 16:29:31.025316: Pseudo dice [0.5944] 
2025-04-02 16:29:31.025415: Epoch time: 272.23 s 
2025-04-02 16:29:33.098282:  
2025-04-02 16:29:33.098464: Epoch 963 
2025-04-02 16:29:33.098610: Current learning rate: 0.00051 
2025-04-02 16:34:05.416682: train_loss -0.88 
2025-04-02 16:34:05.417024: val_loss -0.5912 
2025-04-02 16:34:05.417124: Pseudo dice [0.5226] 
2025-04-02 16:34:05.417220: Epoch time: 272.32 s 
2025-04-02 16:34:07.501805:  
2025-04-02 16:34:07.502004: Epoch 964 
2025-04-02 16:34:07.502121: Current learning rate: 0.0005 
2025-04-02 16:38:39.911607: train_loss -0.8849 
2025-04-02 16:38:39.911915: val_loss -0.5942 
2025-04-02 16:38:39.911996: Pseudo dice [0.5594] 
2025-04-02 16:38:39.912083: Epoch time: 272.41 s 
2025-04-02 16:38:42.040988:  
2025-04-02 16:38:42.041282: Epoch 965 
2025-04-02 16:38:42.041424: Current learning rate: 0.00049 
2025-04-02 16:43:14.319895: train_loss -0.8863 
2025-04-02 16:43:14.320203: val_loss -0.6548 
2025-04-02 16:43:14.320307: Pseudo dice [0.6313] 
2025-04-02 16:43:14.320403: Epoch time: 272.28 s 
2025-04-02 16:43:16.712463:  
2025-04-02 16:43:16.712723: Epoch 966 
2025-04-02 16:43:16.712877: Current learning rate: 0.00048 
2025-04-02 16:47:49.245103: train_loss -0.8774 
2025-04-02 16:47:49.245474: val_loss -0.5145 
2025-04-02 16:47:49.245557: Pseudo dice [0.4636] 
2025-04-02 16:47:49.245648: Epoch time: 272.54 s 
2025-04-02 16:47:51.308321:  
2025-04-02 16:47:51.308613: Epoch 967 
2025-04-02 16:47:51.308762: Current learning rate: 0.00046 
2025-04-02 16:52:23.486064: train_loss -0.8852 
2025-04-02 16:52:23.486412: val_loss -0.5473 
2025-04-02 16:52:23.486738: Pseudo dice [0.5854] 
2025-04-02 16:52:23.486823: Epoch time: 272.18 s 
2025-04-02 16:52:25.564995:  
2025-04-02 16:52:25.565238: Epoch 968 
2025-04-02 16:52:25.565377: Current learning rate: 0.00045 
2025-04-02 16:56:57.825257: train_loss -0.8779 
2025-04-02 16:56:57.825602: val_loss -0.5894 
2025-04-02 16:56:57.825683: Pseudo dice [0.4386] 
2025-04-02 16:56:57.825779: Epoch time: 272.26 s 
2025-04-02 16:56:59.934617:  
2025-04-02 16:56:59.934756: Epoch 969 
2025-04-02 16:56:59.934870: Current learning rate: 0.00044 
2025-04-02 17:01:32.392895: train_loss -0.8833 
2025-04-02 17:01:32.393260: val_loss -0.7406 
2025-04-02 17:01:32.393653: Pseudo dice [0.749] 
2025-04-02 17:01:32.393737: Epoch time: 272.46 s 
2025-04-02 17:01:34.492315:  
2025-04-02 17:01:34.492563: Epoch 970 
2025-04-02 17:01:34.492736: Current learning rate: 0.00043 
2025-04-02 17:06:07.603522: train_loss -0.8841 
2025-04-02 17:06:07.603858: val_loss -0.6773 
2025-04-02 17:06:07.603944: Pseudo dice [0.7165] 
2025-04-02 17:06:07.604057: Epoch time: 273.12 s 
2025-04-02 17:06:09.700994:  
2025-04-02 17:06:09.701204: Epoch 971 
2025-04-02 17:06:09.701316: Current learning rate: 0.00041 
2025-04-02 17:10:42.782830: train_loss -0.8825 
2025-04-02 17:10:42.783148: val_loss -0.5873 
2025-04-02 17:10:42.783228: Pseudo dice [0.5994] 
2025-04-02 17:10:42.783322: Epoch time: 273.09 s 
2025-04-02 17:10:44.866999:  
2025-04-02 17:10:44.867246: Epoch 972 
2025-04-02 17:10:44.867372: Current learning rate: 0.0004 
2025-04-02 17:15:18.176281: train_loss -0.8697 
2025-04-02 17:15:18.176531: val_loss -0.6871 
2025-04-02 17:15:18.176643: Pseudo dice [0.6464] 
2025-04-02 17:15:18.176759: Epoch time: 273.31 s 
2025-04-02 17:15:20.288178:  
2025-04-02 17:15:20.288426: Epoch 973 
2025-04-02 17:15:20.288561: Current learning rate: 0.00039 
2025-04-02 17:19:54.445025: train_loss -0.8809 
2025-04-02 17:19:54.445317: val_loss -0.6277 
2025-04-02 17:19:54.445476: Pseudo dice [0.5732] 
2025-04-02 17:19:54.445570: Epoch time: 274.16 s 
2025-04-02 17:19:56.855791:  
2025-04-02 17:19:56.856021: Epoch 974 
2025-04-02 17:19:56.856155: Current learning rate: 0.00037 
2025-04-02 17:24:31.182813: train_loss -0.8769 
2025-04-02 17:24:31.183144: val_loss -0.6709 
2025-04-02 17:24:31.183231: Pseudo dice [0.7584] 
2025-04-02 17:24:31.183344: Epoch time: 274.33 s 
2025-04-02 17:24:33.286311:  
2025-04-02 17:24:33.286534: Epoch 975 
2025-04-02 17:24:33.286707: Current learning rate: 0.00036 
2025-04-02 17:29:06.905462: train_loss -0.8764 
2025-04-02 17:29:06.905795: val_loss -0.6499 
2025-04-02 17:29:06.905919: Pseudo dice [0.6444] 
2025-04-02 17:29:06.906016: Epoch time: 273.62 s 
2025-04-02 17:29:09.009040:  
2025-04-02 17:29:09.009250: Epoch 976 
2025-04-02 17:29:09.009365: Current learning rate: 0.00035 
2025-04-02 17:33:42.835509: train_loss -0.8813 
2025-04-02 17:33:42.835842: val_loss -0.6707 
2025-04-02 17:33:42.835923: Pseudo dice [0.6768] 
2025-04-02 17:33:42.836067: Epoch time: 273.83 s 
2025-04-02 17:33:44.961911:  
2025-04-02 17:33:44.962109: Epoch 977 
2025-04-02 17:33:44.962225: Current learning rate: 0.00034 
2025-04-02 17:38:18.649260: train_loss -0.8795 
2025-04-02 17:38:18.649579: val_loss -0.6704 
2025-04-02 17:38:18.649670: Pseudo dice [0.5544] 
2025-04-02 17:38:18.649770: Epoch time: 273.69 s 
2025-04-02 17:38:20.728451:  
2025-04-02 17:38:20.728667: Epoch 978 
2025-04-02 17:38:20.728798: Current learning rate: 0.00032 
2025-04-02 17:42:55.029897: train_loss -0.8867 
2025-04-02 17:42:55.030249: val_loss -0.6802 
2025-04-02 17:42:55.030340: Pseudo dice [0.6358] 
2025-04-02 17:42:55.030433: Epoch time: 274.31 s 
2025-04-02 17:42:57.144766:  
2025-04-02 17:42:57.144987: Epoch 979 
2025-04-02 17:42:57.145098: Current learning rate: 0.00031 
2025-04-02 17:47:31.670401: train_loss -0.8793 
2025-04-02 17:47:31.670714: val_loss -0.6434 
2025-04-02 17:47:31.670798: Pseudo dice [0.6648] 
2025-04-02 17:47:31.670930: Epoch time: 274.53 s 
2025-04-02 17:47:33.778674:  
2025-04-02 17:47:33.778925: Epoch 980 
2025-04-02 17:47:33.779107: Current learning rate: 0.0003 
2025-04-02 17:52:08.359708: train_loss -0.8775 
2025-04-02 17:52:08.360049: val_loss -0.6668 
2025-04-02 17:52:08.360162: Pseudo dice [0.5614] 
2025-04-02 17:52:08.360325: Epoch time: 274.59 s 
2025-04-02 17:52:10.467982:  
2025-04-02 17:52:10.468233: Epoch 981 
2025-04-02 17:52:10.468461: Current learning rate: 0.00028 
2025-04-02 17:56:44.375126: train_loss -0.8766 
2025-04-02 17:56:44.375538: val_loss -0.6924 
2025-04-02 17:56:44.375703: Pseudo dice [0.7183] 
2025-04-02 17:56:44.375825: Epoch time: 273.91 s 
2025-04-02 17:56:46.813196:  
2025-04-02 17:56:46.813425: Epoch 982 
2025-04-02 17:56:46.813539: Current learning rate: 0.00027 
2025-04-02 18:01:20.883310: train_loss -0.89 
2025-04-02 18:01:20.883623: val_loss -0.7015 
2025-04-02 18:01:20.883746: Pseudo dice [0.7678] 
2025-04-02 18:01:20.883886: Epoch time: 274.07 s 
2025-04-02 18:01:23.022313:  
2025-04-02 18:01:23.022600: Epoch 983 
2025-04-02 18:01:23.022719: Current learning rate: 0.00026 
2025-04-02 18:05:57.089338: train_loss -0.8878 
2025-04-02 18:05:57.089660: val_loss -0.6478 
2025-04-02 18:05:57.089743: Pseudo dice [0.7579] 
2025-04-02 18:05:57.089840: Epoch time: 274.07 s 
2025-04-02 18:05:59.310755:  
2025-04-02 18:05:59.310961: Epoch 984 
2025-04-02 18:05:59.311078: Current learning rate: 0.00024 
2025-04-02 18:10:37.307108: train_loss -0.887 
2025-04-02 18:10:37.307476: val_loss -0.654 
2025-04-02 18:10:37.307561: Pseudo dice [0.6899] 
2025-04-02 18:10:37.307661: Epoch time: 278.0 s 
2025-04-02 18:10:39.443462:  
2025-04-02 18:10:39.443696: Epoch 985 
2025-04-02 18:10:39.443884: Current learning rate: 0.00023 
2025-04-02 18:15:13.532736: train_loss -0.8868 
2025-04-02 18:15:13.533114: val_loss -0.6156 
2025-04-02 18:15:13.533199: Pseudo dice [0.5931] 
2025-04-02 18:15:13.533293: Epoch time: 274.09 s 
2025-04-02 18:15:15.682685:  
2025-04-02 18:15:15.682978: Epoch 986 
2025-04-02 18:15:15.683097: Current learning rate: 0.00021 
2025-04-02 18:19:49.772935: train_loss -0.8805 
2025-04-02 18:19:49.773242: val_loss -0.6449 
2025-04-02 18:19:49.773335: Pseudo dice [0.6431] 
2025-04-02 18:19:49.773433: Epoch time: 274.09 s 
2025-04-02 18:19:51.863887:  
2025-04-02 18:19:51.864107: Epoch 987 
2025-04-02 18:19:51.864223: Current learning rate: 0.0002 
2025-04-02 18:24:26.183830: train_loss -0.8859 
2025-04-02 18:24:26.184162: val_loss -0.5801 
2025-04-02 18:24:26.184251: Pseudo dice [0.5683] 
2025-04-02 18:24:26.184354: Epoch time: 274.32 s 
2025-04-02 18:24:28.290215:  
2025-04-02 18:24:28.290426: Epoch 988 
2025-04-02 18:24:28.290557: Current learning rate: 0.00019 
2025-04-02 18:29:02.618447: train_loss -0.8835 
2025-04-02 18:29:02.618756: val_loss -0.6716 
2025-04-02 18:29:02.618859: Pseudo dice [0.6517] 
2025-04-02 18:29:02.618948: Epoch time: 274.33 s 
2025-04-02 18:29:04.712550:  
2025-04-02 18:29:04.712846: Epoch 989 
2025-04-02 18:29:04.712972: Current learning rate: 0.00017 
2025-04-02 18:33:39.370698: train_loss -0.8863 
2025-04-02 18:33:39.371013: val_loss -0.5499 
2025-04-02 18:33:39.371097: Pseudo dice [0.7031] 
2025-04-02 18:33:39.371185: Epoch time: 274.66 s 
2025-04-02 18:33:41.753106:  
2025-04-02 18:33:41.753301: Epoch 990 
2025-04-02 18:33:41.753420: Current learning rate: 0.00016 
2025-04-02 18:38:16.532380: train_loss -0.8831 
2025-04-02 18:38:16.532783: val_loss -0.594 
2025-04-02 18:38:16.532878: Pseudo dice [0.5876] 
2025-04-02 18:38:16.532975: Epoch time: 274.78 s 
2025-04-02 18:38:18.628497:  
2025-04-02 18:38:18.628710: Epoch 991 
2025-04-02 18:38:18.628831: Current learning rate: 0.00014 
2025-04-02 18:42:53.463226: train_loss -0.8847 
2025-04-02 18:42:53.463556: val_loss -0.6216 
2025-04-02 18:42:53.463672: Pseudo dice [0.5789] 
2025-04-02 18:42:53.463778: Epoch time: 274.84 s 
2025-04-02 18:42:55.562701:  
2025-04-02 18:42:55.562981: Epoch 992 
2025-04-02 18:42:55.563164: Current learning rate: 0.00013 
2025-04-02 18:47:30.473594: train_loss -0.878 
2025-04-02 18:47:30.473929: val_loss -0.5647 
2025-04-02 18:47:30.474058: Pseudo dice [0.5124] 
2025-04-02 18:47:30.474174: Epoch time: 274.91 s 
2025-04-02 18:47:32.558350:  
2025-04-02 18:47:32.558572: Epoch 993 
2025-04-02 18:47:32.558691: Current learning rate: 0.00011 
2025-04-02 18:52:07.205812: train_loss -0.8752 
2025-04-02 18:52:07.206151: val_loss -0.6328 
2025-04-02 18:52:07.206262: Pseudo dice [0.5923] 
2025-04-02 18:52:07.206356: Epoch time: 274.65 s 
2025-04-02 18:52:09.295740:  
2025-04-02 18:52:09.295959: Epoch 994 
2025-04-02 18:52:09.296088: Current learning rate: 0.0001 
2025-04-02 18:56:43.644189: train_loss -0.8826 
2025-04-02 18:56:43.644527: val_loss -0.6469 
2025-04-02 18:56:43.644612: Pseudo dice [0.5218] 
2025-04-02 18:56:43.644709: Epoch time: 274.35 s 
2025-04-02 18:56:45.755161:  
2025-04-02 18:56:45.755452: Epoch 995 
2025-04-02 18:56:45.755576: Current learning rate: 8e-05 
2025-04-02 19:01:19.995223: train_loss -0.8846 
2025-04-02 19:01:19.995571: val_loss -0.5667 
2025-04-02 19:01:19.995713: Pseudo dice [0.4682] 
2025-04-02 19:01:19.995813: Epoch time: 274.24 s 
2025-04-02 19:01:22.095999:  
2025-04-02 19:01:22.096216: Epoch 996 
2025-04-02 19:01:22.096337: Current learning rate: 7e-05 
2025-04-02 19:05:56.290746: train_loss -0.8838 
2025-04-02 19:05:56.291070: val_loss -0.6864 
2025-04-02 19:05:56.291174: Pseudo dice [0.6594] 
2025-04-02 19:05:56.291285: Epoch time: 274.2 s 
2025-04-02 19:05:58.385428:  
2025-04-02 19:05:58.385680: Epoch 997 
2025-04-02 19:05:58.385808: Current learning rate: 5e-05 
2025-04-02 19:10:32.500344: train_loss -0.8858 
2025-04-02 19:10:32.500717: val_loss -0.6604 
2025-04-02 19:10:32.500808: Pseudo dice [0.7536] 
2025-04-02 19:10:32.500901: Epoch time: 274.12 s 
2025-04-02 19:10:34.595430:  
2025-04-02 19:10:34.595693: Epoch 998 
2025-04-02 19:10:34.595852: Current learning rate: 4e-05 
2025-04-02 19:15:08.830799: train_loss -0.8771 
2025-04-02 19:15:08.831123: val_loss -0.635 
2025-04-02 19:15:08.831242: Pseudo dice [0.4295] 
2025-04-02 19:15:08.831347: Epoch time: 274.24 s 
2025-04-02 19:15:11.258396:  
2025-04-02 19:15:11.258652: Epoch 999 
2025-04-02 19:15:11.258803: Current learning rate: 2e-05 
2025-04-02 19:19:44.730695: train_loss -0.8835 
2025-04-02 19:19:44.731000: val_loss -0.4773 
2025-04-02 19:19:44.731087: Pseudo dice [0.4017] 
2025-04-02 19:19:44.731173: Epoch time: 273.48 s 
2025-04-02 19:19:47.960159: Training done. 
2025-04-02 19:19:47.988840: Using splits from existing split file: /mrhung_nguyen_minh_quang_108/workspace/train/nnUNet_preprocessed/Dataset015_lungTumor/splits_final.json 
2025-04-02 19:19:47.989385: The split file contains 5 splits. 
2025-04-02 19:19:47.989444: Desired fold for training: 2 
2025-04-02 19:19:47.989481: This split has 92 training and 23 validation cases. 
2025-04-02 19:19:47.989673: predicting lung_002 
2025-04-02 19:19:48.877385: lung_002, shape torch.Size([1, 269, 589, 589]), rank 0 
2025-04-02 19:25:13.325302: predicting lung_023 
2025-04-02 19:25:13.880614: lung_023, shape torch.Size([1, 242, 552, 552]), rank 0 
2025-04-02 19:29:03.026958: predicting lung_026 
2025-04-02 19:29:03.677465: lung_026, shape torch.Size([1, 301, 525, 525]), rank 0 
2025-04-02 19:33:31.129632: predicting lung_031 
2025-04-02 19:33:31.864685: lung_031, shape torch.Size([1, 271, 512, 512]), rank 0 
2025-04-02 19:37:21.178274: predicting lung_032 
2025-04-02 19:37:21.696939: lung_032, shape torch.Size([1, 304, 461, 461]), rank 0 
2025-04-02 19:40:20.296472: predicting lung_036 
2025-04-02 19:40:21.181153: lung_036, shape torch.Size([1, 322, 640, 640]), rank 0 
2025-04-02 19:47:29.898775: predicting lung_041 
2025-04-02 19:47:30.530160: lung_041, shape torch.Size([1, 285, 563, 563]), rank 0 
2025-04-02 19:52:43.409041: predicting lung_046 
2025-04-02 19:52:44.046355: lung_046, shape torch.Size([1, 252, 563, 563]), rank 0 
2025-04-02 19:57:10.572100: predicting lung_058 
2025-04-02 19:57:11.035521: lung_058, shape torch.Size([1, 224, 512, 512]), rank 0 
2025-04-02 20:00:21.170141: predicting lung_062 
2025-04-02 20:00:21.686827: lung_062, shape torch.Size([1, 211, 563, 563]), rank 0 
2025-04-02 20:04:03.352156: predicting lung_067 
2025-04-02 20:04:37.002289: lung_067, shape torch.Size([1, 241, 581, 581]), rank 0 
2025-04-02 20:09:55.934005: predicting lung_069 
2025-04-02 20:09:56.814657: lung_069, shape torch.Size([1, 261, 590, 590]), rank 0 
2025-04-02 20:15:16.125869: predicting lung_076 
2025-04-02 20:15:16.963214: lung_076, shape torch.Size([1, 271, 524, 524]), rank 0 
2025-04-02 20:19:05.482866: predicting lung_082 
2025-04-02 20:19:06.279164: lung_082, shape torch.Size([1, 249, 577, 577]), rank 0 
2025-04-02 20:24:27.248325: predicting lung_092 
2025-04-02 20:24:27.801203: lung_092, shape torch.Size([1, 245, 461, 461]), rank 0 
2025-04-02 20:27:00.237931: predicting lung_094 
2025-04-02 20:27:01.127597: lung_094, shape torch.Size([1, 245, 622, 622]), rank 0 
2025-04-02 20:32:21.178852: predicting lung_108 
2025-04-02 20:32:21.860049: lung_108, shape torch.Size([1, 251, 513, 513]), rank 0 
2025-04-02 20:36:10.312829: predicting lung_118 
2025-04-02 20:36:10.987463: lung_118, shape torch.Size([1, 211, 563, 563]), rank 0 
2025-04-02 20:39:53.030683: predicting lung_119 
2025-04-02 20:39:53.650213: lung_119, shape torch.Size([1, 228, 525, 525]), rank 0 
2025-04-02 20:43:04.301963: predicting lung_120 
2025-04-02 20:43:04.990075: lung_120, shape torch.Size([1, 242, 538, 538]), rank 0 
2025-04-02 20:46:53.590606: predicting lung_126 
2025-04-02 20:46:54.247109: lung_126, shape torch.Size([1, 327, 461, 461]), rank 0 
2025-04-02 20:50:17.374393: predicting lung_128 
2025-04-02 20:50:17.719050: lung_128, shape torch.Size([1, 207, 408, 408]), rank 0 
2025-04-02 20:52:24.823967: predicting lung_136 
2025-04-02 20:52:25.155256: lung_136, shape torch.Size([1, 262, 407, 407]), rank 0 
2025-04-02 21:02:58.898133: Validation complete 
2025-04-02 21:02:58.898466: Mean Validation Dice:  0.6523847876364387 
